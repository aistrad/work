"""
Chat Routes V5 - Unified chat endpoint with CoreAgent
Based on: Claude Agent SDK style architecture

Features:
- Single /chat/stream endpoint
- CoreAgent with LLM-based skill selection
- Quota check at entry + usage recording
- OpenAI compatible SSE format (works with AI SDK 4.x useChat)
- åˆ†é˜¶æ®µæ¸è¿›å¼åŠ è½½ï¼ˆPhase 1: Skill é€‰æ‹©, Phase 2: Skill æ‰§è¡Œï¼‰
- å†å²æ¶ˆæ¯ä»æ•°æ®åº“è·å–ï¼ˆä¸ä¾èµ–å‰ç«¯ä¼ å…¥ï¼‰
- åè®®æµæ”¯æŒ (REFACTOR_PLAN.md Phase 3)

v2.1 æ›´æ–° (2026-01-20):
- æ·»åŠ åè®®æµæ”¯æŒ
- åè®®çŠ¶æ€è‡ªåŠ¨æ¢å¤
- åè®®è¿›åº¦ SSE äº‹ä»¶
- åè®®æ­¥éª¤è‡ªåŠ¨æ¨è¿›

v2.0 æ›´æ–° (2026-01-20):
- åˆ é™¤å‰ç«¯ä¼ å…¥ history æœºåˆ¶ï¼Œæ”¹ä¸ºæ•°æ®åº“æŸ¥è¯¢
- åˆ†é˜¶æ®µåŠ è½½ï¼šPhase 1 ä¸åŠ è½½ profileï¼ŒPhase 2 æŒ‰éœ€åŠ è½½
- use_skill åŒè½®é‡è½½ä¸Šä¸‹æ–‡
"""
import json
import logging
import asyncio
import time
import yaml
from pathlib import Path
from typing import Optional, Dict
from uuid import UUID, uuid4

from fastapi import APIRouter, Depends, HTTPException, Request
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from sse_starlette.sse import EventSourceResponse

from services.identity import get_optional_user, CurrentUser
from services.agent import CoreAgent, AgentContext, QuotaTracker, create_agent, get_adapter, AgentEvent
from stores.profile_cache import get_cached_profile_with_skill
from stores import message_repo, conversation_repo
from stores.unified_profile_repo import UnifiedProfileRepository

router = APIRouter(prefix="/chat/v5", tags=["Chat V5"])
logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Request/Response Models
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MessageItem(BaseModel):
    """Single message in AI SDK format"""
    role: str
    content: str


class ChatRequestV5(BaseModel):
    """V5 Chat request - supports both simple and AI SDK format"""
    message: Optional[str] = Field(None, description="User message (simple format)")
    messages: Optional[list[MessageItem]] = Field(None, description="Messages array (AI SDK format, used for user message extraction only)")
    conversation_id: Optional[UUID] = Field(None, description="Conversation ID")
    skill: Optional[str] = Field(None, description="Skill ID (bazi/zodiac/career/tarot)")
    scenario: Optional[str] = Field(None, description="Scenario/Rule ID (dankoe/covey/weekly-review)")
    voice_mode: Optional[str] = Field(None, description="Voice mode (warm/sarcastic)")

    def get_user_message(self) -> str:
        """Extract user message from either format"""
        if self.message:
            return self.message
        if self.messages:
            # Get the last user message from the array
            for msg in reversed(self.messages):
                if msg.role == "user":
                    return msg.content
        return ""

    # æ³¨æ„ï¼šget_history() å·²åˆ é™¤ï¼Œå†å²æ¶ˆæ¯ä»æ•°æ®åº“è·å–


class GuestChatRequestV5(BaseModel):
    """Guest chat request - supports both simple and AI SDK format"""
    message: Optional[str] = Field(None, description="User message (simple format)")
    messages: Optional[list[MessageItem]] = Field(None, description="Messages array (AI SDK format)")

    def get_user_message(self) -> str:
        """Extract user message from either format"""
        if self.message:
            return self.message
        if self.messages:
            for msg in reversed(self.messages):
                if msg.role == "user":
                    return msg.content
        return ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Helper Functions
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def get_user_context(user_id: Optional[UUID], skill: Optional[str] = None) -> tuple:
    """
    Get user profile and skill data (åˆ†é˜¶æ®µåŠ è½½)

    Phase 1 (skill=None): ä¸åŠ è½½ profileï¼Œè¿”å›ç©º
    Phase 2 (skill æœ‰å€¼): æŒ‰éœ€åŠ è½½å½“å‰ skill éœ€è¦çš„æ•°æ®
    """
    if not user_id:
        return {}, {}

    if not skill:
        # Phase 1: Skill é€‰æ‹©é˜¶æ®µï¼Œä¸éœ€è¦ profile
        return {}, {}

    try:
        # Phase 2: åªåŠ è½½å½“å‰ skill éœ€è¦çš„æ•°æ®
        result = await get_cached_profile_with_skill(user_id, skill)
        return result.get("profile", {}), result.get("skill_data", {})
    except Exception as e:
        logger.error(f"Failed to get user context: {e}")
        return {}, {}


async def get_conversation_history(conversation_id: Optional[UUID], skill: Optional[str] = None) -> list:
    """
    Get recent conversation history from database (åˆ†é˜¶æ®µåŠ è½½)

    Phase 1 (skill=None): 5 æ¡å†å²ï¼Œè¶³å¤Ÿç†è§£æ„å›¾
    Phase 2 (skill æœ‰å€¼): 10 æ¡å†å²ï¼Œæ·±åº¦åˆ†æéœ€è¦æ›´å¤šä¸Šä¸‹æ–‡
    """
    if not conversation_id:
        return []

    # æ ¹æ®é˜¶æ®µå†³å®šå†å²æ¡æ•°
    limit = 5 if not skill else 10

    try:
        messages = await message_repo.get_messages_for_context(conversation_id, limit)
        return messages
    except Exception as e:
        logger.error(f"Failed to get history: {e}")
        return []


async def ensure_conversation_exists(
    conversation_id: UUID,
    user_id: Optional[UUID],
    skill: Optional[str] = None,
    voice_mode: Optional[str] = None
) -> None:
    """Ensure conversation exists in database, create if not"""
    try:
        existing = await conversation_repo.get_conversation(conversation_id)
        if not existing:
            await conversation_repo.create_conversation(
                skill=skill or "core",
                user_id=user_id,
                voice_mode=voice_mode or "warm",
                conversation_id=conversation_id
            )
    except Exception as e:
        logger.warning(f"Failed to ensure conversation: {e}")


async def save_message(conversation_id: UUID, role: str, content: str) -> None:
    """Save message to database"""
    try:
        await message_repo.create_message(
            conversation_id=conversation_id,
            role=role,
            content=content
        )
    except Exception as e:
        logger.warning(f"Failed to save message: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Protocol Support - REFACTOR_PLAN.md Phase 3
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_protocol_config(protocol_id: str) -> dict:
    """åŠ è½½åè®®é…ç½®"""
    config_path = Path(__file__).parent.parent / f"skills/lifecoach/protocols/{protocol_id}.yaml"
    try:
        with open(config_path) as f:
            return yaml.safe_load(f)
    except Exception as e:
        logger.error(f"Failed to load protocol config {protocol_id}: {e}")
        return {}


def build_protocol_prompt(
    protocol_config: dict,
    step: int,
    lifecoach_state: dict
) -> str:
    """æ„å»ºåè®®é©±åŠ¨çš„ system prompt"""
    total_steps = protocol_config.get("total_steps", 6)
    steps = protocol_config.get("steps", {})

    if step < 1 or step > total_steps:
        return ""

    step_config = steps.get(step)  # steps æ˜¯ dictï¼Œkey æ˜¯ 1-6
    if not step_config:
        return ""

    # æ„å»ºå·²æ”¶é›†æ•°æ®çš„æ‘˜è¦
    protocol_data = lifecoach_state.get("protocol", {}).get("data", {})
    collected_data = "\n".join([
        f"- æ­¥éª¤ {k.replace('step_', '')}: {v.get('summary', 'å·²å®Œæˆ')}"
        for k, v in protocol_data.items()
        if k.startswith("step_")
    ])

    prompt = f"""
## ğŸ¯ åè®®æ¨¡å¼æ¿€æ´»

ä½ æ­£åœ¨æ‰§è¡Œ **{protocol_config.get('name', '')}** åè®®ã€‚

**è¿›åº¦**: æ­¥éª¤ {step}/{total_steps}
**é˜¶æ®µ**: {step_config.get('phase', '')}
**å½“å‰ä»»åŠ¡**: {step_config.get('name', '')}

### å·²æ”¶é›†çš„æ•°æ®
{collected_data or "å°šæœªæ”¶é›†æ•°æ®"}

### æœ¬æ­¥éª¤çš„é—®é¢˜
{step_config.get('question', '')}

### å›åº”æŒ‡å¯¼
{step_config.get('response_prompt', '')}

### é‡è¦åŸåˆ™
1. **ä¸€æ¬¡åªé—®ä¸€ä¸ªé—®é¢˜**ï¼Œç­‰ç”¨æˆ·å›ç­”
2. ç”¨æˆ·å›ç­”åï¼Œè°ƒç”¨ `advance_protocol_step` ä¿å­˜æ•°æ®
3. ä¿å­˜å®Œæˆåï¼Œ**è‡ªåŠ¨è¿‡æ¸¡åˆ°ä¸‹ä¸€ä¸ªé—®é¢˜**
4. ä¿æŒå¯¹è¯è‡ªç„¶ï¼Œä¸è¦è®©ç”¨æˆ·æ„Ÿè§‰åœ¨å¡«è¡¨å•
5. ä¸è¦è·³å‡ºåè®®æµç¨‹ï¼Œé™¤éç”¨æˆ·æ˜ç¡®è¦æ±‚

---
"""
    return prompt


async def get_protocol_state(user_id: UUID, skill: str) -> Optional[Dict]:
    """è·å–å½“å‰åè®®çŠ¶æ€"""
    if skill != "lifecoach":
        return None

    try:
        data = await UnifiedProfileRepository.get_skill_state(user_id, "lifecoach")
        protocol = data.get("protocol", {})

        # åªè¿”å›è¿›è¡Œä¸­çš„åè®®
        if protocol.get("id") and not protocol.get("completed"):
            return protocol
    except Exception as e:
        logger.error(f"Failed to get protocol state: {e}")

    return None


async def emit_protocol_progress_event(
    protocol_state: dict,
    protocol_config: dict
) -> AgentEvent:
    """ç”Ÿæˆåè®®è¿›åº¦ SSE äº‹ä»¶"""
    step = protocol_state.get("step", 1)
    total_steps = protocol_config.get("total_steps", 6)
    steps = protocol_config.get("steps", {})

    step_config = steps.get(step, {})  # steps æ˜¯ dictï¼Œkey æ˜¯ 1-6

    return AgentEvent(
        type="protocol_progress",
        data={
            "protocol_id": protocol_state["id"],
            "step": step,
            "total_steps": total_steps,
            "phase": step_config.get("phase", ""),
            "progress": step / total_steps,
            "step_name": step_config.get("name", ""),
        }
    )


async def async_generator(items):
    """è¾…åŠ©å‡½æ•°ï¼šå°†åˆ—è¡¨è½¬æ¢ä¸ºå¼‚æ­¥ç”Ÿæˆå™¨"""
    for item in items:
        yield item


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•ï¿½ï¿½ï¿½â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Endpoints
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@router.post("/stream")
async def chat_stream_v5(
    request: ChatRequestV5,
    req: Request,
    current_user: Optional[CurrentUser] = Depends(get_optional_user)
):
    """
    V5 Chat endpoint with CoreAgent.

    Features:
    - CoreAgent decides skill via LLM (no keyword matching)
    - Supports multi-skill fusion
    - Quota check at entry
    - Vercel AI SDK compatible SSE

    Test mode:
    - Add header `X-Test-Tier: paid` to simulate paid user
    - Add header `X-Test-Tier: free` to simulate free user
    """
    user_id = current_user.user_id if current_user else None
    user_tier = "free"

    # Test mode: allow tier override via header
    test_tier = req.headers.get("x-test-tier")
    if test_tier and test_tier in ("free", "paid", "guest"):
        user_tier = test_tier
        logger.info(f"Test mode: using tier={test_tier}")
    elif user_id:
        from services.entitlement import EntitlementService
        entitlements = await EntitlementService.get_entitlements(user_id)
        user_tier = entitlements.get("tier", "free")

    # [A] Entry quota check
    quota_ok, quota_message = await QuotaTracker.check(
        user_id=str(user_id) if user_id else "guest",
        tier=user_tier
    )

    if not quota_ok:
        return EventSourceResponse(_quota_exceeded_response(quota_message, user_tier))

    conversation_id = request.conversation_id or uuid4()

    async def generate():
        try:
            perf_start = time.time()
            perf_log = {}

            # [PERF T3] Get user context (åˆ†é˜¶æ®µåŠ è½½)
            # Phase 1: skill=None æ—¶ä¸åŠ è½½ profile
            # Phase 2: skill æœ‰å€¼æ—¶æŒ‰éœ€åŠ è½½
            t3_start = time.time()
            profile, skill_data = await get_user_context(user_id, request.skill)
            perf_log["T3_user_context_ms"] = int((time.time() - t3_start) * 1000)
            perf_log["phase"] = "phase2" if request.skill else "phase1"

            # Save user message first (needed for history query)
            user_message = request.get_user_message()
            if not user_message:
                # AI SDK 4.x error format: 3:"error message"
                yield f'3:{json.dumps("No user message provided")}\n'
                yield f'd:{json.dumps({"finishReason": "error", "usage": {"promptTokens": 0, "completionTokens": 0}})}\n'
                return

            # [PERF T4] Ensure conversation exists before saving messages
            t4_start = time.time()
            await ensure_conversation_exists(
                conversation_id=conversation_id,
                user_id=user_id,
                skill=request.skill,
                voice_mode=request.voice_mode
            )
            perf_log["T4_ensure_conv_ms"] = int((time.time() - t4_start) * 1000)

            # [v8] ä» conversation æ¢å¤ skillï¼ˆå¦‚æœå‰ç«¯æ²¡ä¼ ï¼‰
            active_skill = request.skill
            if not active_skill:
                try:
                    conv = await conversation_repo.get_conversation(conversation_id)
                    if conv and conv.skill and conv.skill != "core":
                        active_skill = conv.skill
                        # æ¢å¤äº† skillï¼Œéœ€è¦é‡æ–°åŠ è½½ profile å’Œ skill_data
                        profile, skill_data = await get_user_context(user_id, active_skill)
                        perf_log["phase"] = "phase2"
                        perf_log["skill_restored"] = active_skill
                        logger.info(f"[v8] Restored skill from conversation: {active_skill}")
                except Exception as e:
                    logger.warning(f"[v8] Failed to restore skill: {e}")

            # [Protocol] æ¢å¤åè®®çŠ¶æ€ï¼ˆREFACTOR_PLAN.md Phase 3ï¼‰
            protocol_state = None
            protocol_config = None

            if active_skill == "lifecoach" and user_id:
                protocol_state = await get_protocol_state(user_id, active_skill)
                if protocol_state:
                    # åŠ è½½åè®®é…ç½®
                    protocol_config = load_protocol_config(protocol_state["id"])
                    logger.info(f"[Protocol] Restored: {protocol_state['id']} step {protocol_state.get('step', 1)}")
                    perf_log["protocol_active"] = protocol_state["id"]

            # [PERF T5] Save user message
            t5_start = time.time()
            await save_message(conversation_id, "user", user_message)
            perf_log["T5_save_msg_ms"] = int((time.time() - t5_start) * 1000)

            # [NEW] Get history from database (not from request)
            t_history_start = time.time()
            history = await get_conversation_history(conversation_id, active_skill)
            perf_log["T_history_ms"] = int((time.time() - t_history_start) * 1000)
            perf_log["history_count"] = len(history)

            # Build agent context
            context = AgentContext(
                user_id=str(user_id) if user_id else "guest",
                user_tier=user_tier,
                profile=profile,
                skill_data=skill_data,
                history=history,  # ä»æ•°æ®åº“è·å–ï¼Œä¸å†ä¾èµ–å‰ç«¯ä¼ å…¥
                skill=active_skill,  # v8: å¯èƒ½ä» conversation æ¢å¤
                voice_mode=request.voice_mode,
                conversation_id=str(conversation_id)
            )

            # [Protocol] æ³¨å…¥åè®® promptï¼ˆå¦‚æœæœ‰ï¼‰
            if protocol_state and protocol_config:
                lifecoach_data = await UnifiedProfileRepository.get_skill_state(user_id, "lifecoach")
                context.protocol_prompt = build_protocol_prompt(
                    protocol_config=protocol_config,
                    step=protocol_state.get("step", 1),
                    lifecoach_state=lifecoach_data
                )

            # Create agent and adapter
            agent = create_agent()
            adapter = get_adapter("simple")

            logger.info(f"[PERF] Pre-agent: {perf_log}")

            # [Protocol] å‘é€åˆå§‹åè®®è¿›åº¦äº‹ä»¶ï¼ˆå¦‚æœæœ‰åè®®çŠ¶æ€ï¼‰
            if protocol_state and protocol_config:
                progress_event = await emit_protocol_progress_event(protocol_state, protocol_config)
                # é€šè¿‡ adapter è½¬æ¢ä¸º SSE æ ¼å¼
                async for chunk in adapter.adapt(async_generator([progress_event])):
                    yield chunk

            # [PERF T6-T9] Stream through adapter (converts AgentEvent â†’ AI SDK 4.x format)
            t_agent_start = time.time()
            first_token_time = None
            full_content = ""
            async for event in adapter.adapt(agent.run(user_message, context)):
                # [Protocol] æ£€æµ‹æ­¥éª¤å®Œæˆï¼ˆé€šè¿‡å·¥å…·è°ƒç”¨ï¼‰
                if protocol_state and protocol_config and isinstance(event, str):
                    # æ£€æŸ¥æ˜¯å¦æ˜¯ advance_protocol_step å·¥å…·è°ƒç”¨ç»“æœ
                    if '"advance_protocol_step"' in event and event.startswith('0:'):
                        try:
                            # æå–å·¥å…·ç»“æœ
                            content = json.loads(event[2:].rstrip('\n'))
                            if isinstance(content, str) and '[[TOOL:advance_protocol_step:' in content:
                                # æ­¥éª¤å®Œæˆï¼Œæ›´æ–°åè®®çŠ¶æ€
                                current_step = protocol_state.get("step", 1)
                                total_steps = protocol_config.get("total_steps", 6)

                                if current_step < total_steps:
                                    # æ¨è¿›åˆ°ä¸‹ä¸€æ­¥
                                    await UnifiedProfileRepository.update_skill_state(
                                        user_id,
                                        "lifecoach",
                                        "protocol",
                                        {"step": current_step + 1}
                                    )

                                    # æ›´æ–°å†…å­˜ä¸­çš„çŠ¶æ€
                                    protocol_state["step"] = current_step + 1

                                    # å‘é€è¿›åº¦æ›´æ–°äº‹ä»¶
                                    progress_event = await emit_protocol_progress_event(
                                        protocol_state, protocol_config
                                    )
                                    async for chunk in adapter.adapt(async_generator([progress_event])):
                                        yield chunk

                                    logger.info(f"[Protocol] Advanced to step {current_step + 1}")
                                else:
                                    # åè®®å®Œæˆ
                                    await UnifiedProfileRepository.update_skill_state(
                                        user_id,
                                        "lifecoach",
                                        "protocol",
                                        {"completed": True}
                                    )

                                    # å‘é€å®Œæˆäº‹ä»¶
                                    complete_event = AgentEvent(
                                        type="protocol_completed",
                                        data={"protocol_id": protocol_state["id"]}
                                    )
                                    async for chunk in adapter.adapt(async_generator([complete_event])):
                                        yield chunk

                                    logger.info(f"[Protocol] Completed: {protocol_state['id']}")
                        except:
                            pass

                # SimpleToolAdapter returns "0:\"text\"\n" format strings
                if isinstance(event, str):
                    # Record first token time
                    if first_token_time is None and event.startswith('0:'):
                        first_token_time = time.time()
                        perf_log["TTFT_ms"] = int((first_token_time - t_agent_start) * 1000)
                        logger.info(f"[PERF] First token: TTFT={perf_log['TTFT_ms']}ms")
                    yield event
                    # Extract actual content from AI SDK 4.x format: 0:"content"\n
                    if event.startswith('0:'):
                        try:
                            content = json.loads(event[2:].rstrip('\n'))
                            # Skip tool markers for saved content
                            if not (isinstance(content, str) and content.startswith('[[TOOL:')):
                                full_content += content
                        except:
                            pass
                else:
                    # Other adapters return dicts - convert to SSE string for StreamingResponse
                    data_str = event.get("data", "") if isinstance(event, dict) else str(event)
                    yield f"data: {data_str}\n\n"
                    if '"delta"' in data_str and '"content"' in data_str:
                        try:
                            data = json.loads(data_str)
                            delta = data.get("choices", [{}])[0].get("delta", {})
                            full_content += delta.get("content", "")
                        except:
                            pass

            # [PERF] Agent done
            perf_log["agent_total_ms"] = int((time.time() - t_agent_start) * 1000)

            # Save assistant message
            if full_content:
                await save_message(conversation_id, "assistant", full_content)

            # [C] Record usage
            await QuotaTracker.record(
                user_id=str(user_id) if user_id else "guest",
                usage=agent.usage
            )

            # [PERF] Total time
            perf_log["total_ms"] = int((time.time() - perf_start) * 1000)
            logger.info(f"[PERF] Complete: {perf_log}")

        except Exception as e:
            logger.error(f"Chat error: {e}", exc_info=True)
            yield f"\n\nâŒ Error: {str(e)}"

    # ä½¿ç”¨ StreamingResponse è¾“å‡º AI SDK 4.x data stream æ ¼å¼
    return StreamingResponse(
        generate(),
        media_type="text/plain; charset=utf-8",
        headers={
            "X-Content-Type-Options": "nosniff",
            "X-Vercel-AI-Data-Stream": "v1"  # AI SDK 4.x å¿…éœ€çš„ header
        }
    )


@router.post("/guest/stream")
async def guest_chat_stream_v5(request: GuestChatRequestV5):
    """
    Guest chat endpoint (no auth, limited functionality).
    """
    async def generate():
        try:
            context = AgentContext(
                user_id="guest",
                user_tier="guest",
                profile={},
                skill_data={}
            )

            agent = create_agent(max_iterations=5)
            adapter = get_adapter("text")

            user_message = request.get_user_message()
            if not user_message:
                yield {"data": json.dumps({"type": "error", "errorText": "No user message provided"})}
                return

            # Stream through adapter
            async for event in adapter.adapt(agent.run(user_message, context)):
                yield event

        except Exception as e:
            logger.error(f"Guest chat error: {e}")
            yield {"data": json.dumps({"type": "error", "errorText": str(e)})}

    headers = {"x-vercel-ai-ui-message-stream": "v1"}
    return EventSourceResponse(generate(), headers=headers)


async def _quota_exceeded_response(message: str, tier: str):
    """Generate quota exceeded SSE response"""
    yield {
        "event": "error",
        "data": json.dumps({
            "type": "quota_exceeded",
            "message": message,
            "tier": tier,
            "upgrade_url": "/membership"
        })
    }
