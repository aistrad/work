/**
 * useVibeChat - AI SDK 4.x useChat wrapper for VibeLife
 *
 * v6.0 简化版:
 * - 移除 Protocol 状态管理（改为 LLM 自己管理）
 * - 添加 scenario 参数支持
 *
 * v7.0 新增:
 * - 支持从后端加载历史消息
 * - conversation_id 切换时自动加载历史
 *
 * Provides streaming chat with OpenAI-compatible backend
 * Uses standard OpenAI SSE format from Python CoreAgent
 */

'use client';

import { useChat, Message } from 'ai/react';
import { useCallback, useMemo, useEffect, useRef, useState } from 'react';
import { getAccessToken } from '@/utils/storage';
import { useConversationDetail } from './useConversations';

// v11: Thinking step type for UI display
export interface ThinkingStep {
  id: string;
  content: string;
  phase: 'analyzing' | 'skill_activate' | 'tool_call' | 'complete';
  iteration?: number;
}

export type SkillId = 'bazi' | 'zodiac' | 'mbti' | 'tarot' | 'attach' | 'career' | 'lifecoach';
export type VoiceMode = 'warm' | 'sarcastic' | 'wise';

export interface UseVibeChatOptions {
  /**
   * Skill ID - 可选
   * - 传入时：后端直接使用该 skill，不走 LLM 路由
   * - 不传时：后端 CoreAgent 通过 LLM 自动识别用户意图并路由到合适的 skill
   */
  skillId?: SkillId;
  /**
   * Scenario/Rule ID - 可选
   * - 传入时：后端直接加载对应的 Rule 文件
   * - 不传时：后端根据 tags 匹配或使用默认 scenario
   */
  scenario?: string;
  voiceMode?: VoiceMode;
  conversationId?: string;
  onConversationStart?: (id: string) => void;
  onError?: (error: Error) => void;
  onFinish?: (message: Message) => void;
}

export function useVibeChat({
  skillId,
  scenario,
  voiceMode = 'warm',
  conversationId,
  onConversationStart,
  onError,
  onFinish,
}: UseVibeChatOptions) {
  // Track previous conversation_id to detect changes
  const prevConversationIdRef = useRef<string | undefined>(conversationId);

  // Get auth token - getAccessToken() uses cached Map lookup (O(1)), safe to call on each render
  // This ensures token changes (login/logout) are reflected immediately
  const accessToken = getAccessToken();

  // Load conversation history when conversation_id is provided
  const { conversation: conversationDetail } = useConversationDetail(conversationId || null);

  // Memoize headers to prevent unnecessary re-renders (Vercel rule: rerender-usememo-expensive)
  const headers = useMemo(
    () => (accessToken ? { Authorization: `Bearer ${accessToken}` } : undefined),
    [accessToken]
  );

  // Memoize body to prevent unnecessary re-renders
  // 当 skillId 为 undefined 时，不传 skill 字段，让后端 LLM 自动路由
  const body = useMemo(
    () => ({
      ...(skillId && { skill: skillId }),
      ...(scenario && { scenario }),
      voice_mode: voiceMode,
      conversation_id: conversationId,
    }),
    [skillId, scenario, voiceMode, conversationId]
  );


  // v11: Track thinking data manually since chat.data may not auto-populate
  const [thinkingData, setThinkingData] = useState<ThinkingStep[]>([]);

  // AI SDK 4.x useChat hook
  const chat = useChat({
    api: '/api/v1/chat/v5/stream',
    // 使用默认 data 协议，支持 toolInvocations (0:, 9:, a: 格式) 和自定义数据 (2:[key, value])
    headers,
    body,
    onFinish: (message) => {
      onFinish?.(message);
      // v11: Keep thinking data after completion for display
      // Will be cleared when next message starts
    },
    onError: (error) => {
      console.error('Chat error:', error);
      onError?.(error);
    },
    // v11: Custom fetch to intercept and parse thinking events
    fetch: async (input, init) => {
      // Clear previous thinking data at the start of a new request
      setThinkingData([]);

      const response = await fetch(input, init);

      // Clone the response so we can read it twice
      const [streamForParsing, streamForSDK] = response.body!.tee();

      // Parse thinking events in background
      (async () => {
        const reader = streamForParsing.getReader();
        const decoder = new TextDecoder();

        try {
          while (true) {
            const { value, done } = await reader.read();
            if (done) break;

            const text = decoder.decode(value, { stream: true });
            const lines = text.split('\n');

            for (const line of lines) {
              // Parse thinking events (2:["thinking", {...}])
              if (line.startsWith('2:') && line.includes('thinking')) {
                try {
                  const data = JSON.parse(line.slice(2));
                  if (Array.isArray(data) && data[0] === 'thinking') {
                    const thinkingEvent = data[1] as Record<string, unknown>;
                    setThinkingData(prev => {
                      const step: ThinkingStep = {
                        id: String(thinkingEvent.id || 'think_0'),
                        content: String(thinkingEvent.content || ''),
                        phase: (thinkingEvent.phase as ThinkingStep['phase']) || 'analyzing',
                        iteration: typeof thinkingEvent.iteration === 'number' ? thinkingEvent.iteration : undefined,
                      };
                      // Avoid duplicates
                      const exists = prev.some(s => s.id === step.id && s.phase === step.phase);
                      if (exists) return prev;
                      return [...prev, step];
                    });
                  }
                } catch (e) {
                  // Ignore parse errors
                }
              }
            }
          }
        } catch (e) {
          // Stream reading error, ignore
        }
      })();

      // Return response with cloned stream for AI SDK
      return new Response(streamForSDK, {
        headers: response.headers,
        status: response.status,
        statusText: response.statusText,
      });
    },
  });


  // Load history messages when conversation_id changes
  useEffect(() => {
    // Only load when conversation_id changes
    if (conversationId !== prevConversationIdRef.current) {
      prevConversationIdRef.current = conversationId;

      if (conversationId && conversationDetail?.messages) {
        // Convert backend messages to AI SDK format
        const historyMessages: Message[] = conversationDetail.messages.map((msg) => ({
          id: msg.id,
          role: msg.role as 'user' | 'assistant',
          content: msg.content,
          createdAt: new Date(msg.created_at),
        }));
        chat.setMessages(historyMessages);
      } else if (!conversationId) {
        // New chat - clear messages
        chat.setMessages([]);
      }
    }
  }, [conversationId, conversationDetail, chat]);

  // Wrapper for sending messages
  const sendVibeMessage = useCallback(
    async (content: string) => {
      return chat.append({
        role: 'user',
        content,
      });
    },
    [chat]
  );

  // Clear messages and send (for quick prompts)
  const sendQuickPrompt = useCallback(
    async (content: string) => {
      chat.setMessages([]);
      return sendVibeMessage(content);
    },
    [chat, sendVibeMessage]
  );

  // Tool approval (placeholder for AI SDK 4.x compatibility)
  // In AI SDK 4.x, tool results are handled server-side
  const approveToolCall = useCallback(
    (toolCallId: string, approved: boolean) => {
      console.log(`Tool ${toolCallId} ${approved ? 'approved' : 'rejected'}`);
      // AI SDK 4.x handles tool execution server-side
    },
    []
  );

  // v11: Helper to get thinking steps - now uses thinkingData directly
  const getThinkingSteps = useCallback(
    (_messageId: string): ThinkingStep[] => {
      // Return current thinking data (tracked globally during stream)
      return thinkingData;
    },
    [thinkingData]
  );

  return {
    // Core state
    messages: chat.messages,
    isLoading: chat.isLoading,
    error: chat.error,

    // Actions
    sendMessage: sendVibeMessage,
    sendQuickPrompt,
    stop: chat.stop,
    reload: chat.reload,
    approveToolCall,

    // For advanced use
    setMessages: chat.setMessages,
    append: chat.append,
    input: chat.input,
    setInput: chat.setInput,
    handleInputChange: chat.handleInputChange,
    handleSubmit: chat.handleSubmit,

    // v11: Thinking steps
    thinkingData,
    getThinkingSteps,

    // Metadata
    conversationId,
    skillId,
    scenario,
    voiceMode,
  };
}

export default useVibeChat;
