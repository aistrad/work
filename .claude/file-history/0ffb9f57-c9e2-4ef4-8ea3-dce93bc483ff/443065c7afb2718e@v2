/**
 * useVibeChat - AI SDK 4.x useChat wrapper for VibeLife
 *
 * v6.0 简化版:
 * - 移除 Protocol 状态管理（改为 LLM 自己管理）
 * - 添加 scenario 参数支持
 *
 * v7.0 新增:
 * - 支持从后端加载历史消息
 * - conversation_id 切换时自动加载历史
 *
 * Provides streaming chat with OpenAI-compatible backend
 * Uses standard OpenAI SSE format from Python CoreAgent
 */

'use client';

import { useChat, Message } from 'ai/react';
import { useCallback, useMemo, useEffect, useRef, useState } from 'react';
import { getAccessToken } from '@/utils/storage';
import { useConversationDetail } from './useConversations';

// v11: Thinking step type for UI display
export interface ThinkingStep {
  id: string;
  content: string;
  phase: 'analyzing' | 'skill_activate' | 'tool_call' | 'complete';
  iteration?: number;
}

export type SkillId = 'bazi' | 'zodiac' | 'mbti' | 'tarot' | 'attach' | 'career' | 'lifecoach';
export type VoiceMode = 'warm' | 'sarcastic' | 'wise';

export interface UseVibeChatOptions {
  /**
   * Skill ID - 可选
   * - 传入时：后端直接使用该 skill，不走 LLM 路由
   * - 不传时：后端 CoreAgent 通过 LLM 自动识别用户意图并路由到合适的 skill
   */
  skillId?: SkillId;
  /**
   * Scenario/Rule ID - 可选
   * - 传入时：后端直接加载对应的 Rule 文件
   * - 不传时：后端根据 tags 匹配或使用默认 scenario
   */
  scenario?: string;
  voiceMode?: VoiceMode;
  conversationId?: string;
  onConversationStart?: (id: string) => void;
  onError?: (error: Error) => void;
  onFinish?: (message: Message) => void;
}

export function useVibeChat({
  skillId,
  scenario,
  voiceMode = 'warm',
  conversationId,
  onConversationStart,
  onError,
  onFinish,
}: UseVibeChatOptions) {
  // Track previous conversation_id to detect changes
  const prevConversationIdRef = useRef<string | undefined>(conversationId);

  // Get auth token - getAccessToken() uses cached Map lookup (O(1)), safe to call on each render
  // This ensures token changes (login/logout) are reflected immediately
  const accessToken = getAccessToken();

  // Load conversation history when conversation_id is provided
  const { conversation: conversationDetail } = useConversationDetail(conversationId || null);

  // Memoize headers to prevent unnecessary re-renders (Vercel rule: rerender-usememo-expensive)
  const headers = useMemo(
    () => (accessToken ? { Authorization: `Bearer ${accessToken}` } : undefined),
    [accessToken]
  );

  // Memoize body to prevent unnecessary re-renders
  // 当 skillId 为 undefined 时，不传 skill 字段，让后端 LLM 自动路由
  const body = useMemo(
    () => ({
      ...(skillId && { skill: skillId }),
      ...(scenario && { scenario }),
      voice_mode: voiceMode,
      conversation_id: conversationId,
    }),
    [skillId, scenario, voiceMode, conversationId]
  );

  // v11: Thinking steps state (per message)
  const [thinkingStepsMap, setThinkingStepsMap] = useState<Map<string, ThinkingStep[]>>(new Map());
  const currentMessageIdRef = useRef<string>('');

  // AI SDK 4.x useChat hook
  const chat = useChat({
    api: '/api/v1/chat/v5/stream',
    // 使用默认 data 协议，支持 toolInvocations (0:, 9:, a: 格式) 和自定义数据 (2:[key, value])
    headers,
    body,
    onFinish: (message) => {
      onFinish?.(message);
    },
    onError: (error) => {
      console.error('Chat error:', error);
      onError?.(error);
    },
  });

  // v11: Parse thinking events from chat.data (AI SDK data parts)
  useEffect(() => {
    if (!chat.data || chat.data.length === 0) return;

    // Get the current assistant message ID
    const assistantMessages = chat.messages.filter((m) => m.role === 'assistant');
    const currentMsg = assistantMessages[assistantMessages.length - 1];
    if (!currentMsg) return;

    const msgId = currentMsg.id;
    if (msgId !== currentMessageIdRef.current) {
      // New message started, reset thinking steps for this message
      currentMessageIdRef.current = msgId;
    }

    // Process data parts looking for thinking events
    const newSteps: ThinkingStep[] = [];
    for (const item of chat.data) {
      // AI SDK data format: [key, value]
      if (Array.isArray(item) && item[0] === 'thinking' && item[1]) {
        const rawData = item[1] as Record<string, unknown>;
        const thinkingData: ThinkingStep = {
          id: String(rawData.id || 'think_0'),
          content: String(rawData.content || ''),
          phase: (rawData.phase as ThinkingStep['phase']) || 'analyzing',
          iteration: typeof rawData.iteration === 'number' ? rawData.iteration : undefined,
        };
        newSteps.push(thinkingData);
      }
    }

    if (newSteps.length > 0) {
      setThinkingStepsMap((prev) => {
        const updated = new Map(prev);
        const existing = updated.get(msgId) || [];
        // Merge new steps, avoiding duplicates by id
        const merged = [...existing];
        for (const step of newSteps) {
          const existingIndex = merged.findIndex((s) => s.id === step.id && s.phase === step.phase);
          if (existingIndex >= 0) {
            merged[existingIndex] = step;
          } else {
            merged.push(step);
          }
        }
        updated.set(msgId, merged);
        return updated;
      });
    }
  }, [chat.data, chat.messages]);

  // Load history messages when conversation_id changes
  useEffect(() => {
    // Only load when conversation_id changes
    if (conversationId !== prevConversationIdRef.current) {
      prevConversationIdRef.current = conversationId;

      if (conversationId && conversationDetail?.messages) {
        // Convert backend messages to AI SDK format
        const historyMessages: Message[] = conversationDetail.messages.map((msg) => ({
          id: msg.id,
          role: msg.role as 'user' | 'assistant',
          content: msg.content,
          createdAt: new Date(msg.created_at),
        }));
        chat.setMessages(historyMessages);
      } else if (!conversationId) {
        // New chat - clear messages
        chat.setMessages([]);
      }
    }
  }, [conversationId, conversationDetail, chat]);

  // Wrapper for sending messages
  const sendVibeMessage = useCallback(
    async (content: string) => {
      return chat.append({
        role: 'user',
        content,
      });
    },
    [chat]
  );

  // Clear messages and send (for quick prompts)
  const sendQuickPrompt = useCallback(
    async (content: string) => {
      chat.setMessages([]);
      return sendVibeMessage(content);
    },
    [chat, sendVibeMessage]
  );

  // Tool approval (placeholder for AI SDK 4.x compatibility)
  // In AI SDK 4.x, tool results are handled server-side
  const approveToolCall = useCallback(
    (toolCallId: string, approved: boolean) => {
      console.log(`Tool ${toolCallId} ${approved ? 'approved' : 'rejected'}`);
      // AI SDK 4.x handles tool execution server-side
    },
    []
  );

  // v11: Helper to get thinking steps for a specific message
  const getThinkingSteps = useCallback(
    (messageId: string): ThinkingStep[] => {
      return thinkingStepsMap.get(messageId) || [];
    },
    [thinkingStepsMap]
  );

  return {
    // Core state
    messages: chat.messages,
    isLoading: chat.isLoading,
    error: chat.error,

    // Actions
    sendMessage: sendVibeMessage,
    sendQuickPrompt,
    stop: chat.stop,
    reload: chat.reload,
    approveToolCall,

    // For advanced use
    setMessages: chat.setMessages,
    append: chat.append,
    input: chat.input,
    setInput: chat.setInput,
    handleInputChange: chat.handleInputChange,
    handleSubmit: chat.handleSubmit,

    // v11: Thinking steps
    thinkingStepsMap,
    getThinkingSteps,

    // Metadata
    conversationId,
    skillId,
    scenario,
    voiceMode,
  };
}

export default useVibeChat;
