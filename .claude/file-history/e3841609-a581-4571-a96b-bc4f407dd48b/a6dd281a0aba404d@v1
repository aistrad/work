"""
Embedding Service - Vector embeddings using Gemini

Supports Matryoshka Representation Learning (MRL) for flexible dimensionality.
Default: 1536 dimensions (compatible with pgvector index limits)
"""
import os
from typing import List, Optional
import httpx
import numpy as np


class EmbeddingService:
    """
    Embedding service using Google Gemini.

    Default Dimension: 1536 (reduced from 3072 for pgvector compatibility)
    Supported Range: 128 - 3072
    Recommended: 768, 1536, 3072
    """

    GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
    GEMINI_MODEL = os.getenv("GEMINI_EMBEDDING_MODEL", "gemini-embedding-001")

    # Default to 1536 for pgvector compatibility (max 2000 for ivfflat/hnsw)
    DEFAULT_DIMENSION = int(os.getenv("GEMINI_EMBEDDING_DIMENSION", "1536"))
    DIMENSION = DEFAULT_DIMENSION

    BASE_URL = "https://generativelanguage.googleapis.com/v1beta"

    @classmethod
    async def embed_text(
        cls,
        text: str,
        output_dimensionality: Optional[int] = None
    ) -> List[float]:
        """
        Generate embedding for single text (for documents/storage).

        Args:
            text: Text to embed
            output_dimensionality: Output dimension (128-3072), defaults to 1536

        Returns:
            Normalized embedding vector
        """
        if not cls.GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEY not configured")

        dim = output_dimensionality or cls.DEFAULT_DIMENSION
        url = f"{cls.BASE_URL}/models/{cls.GEMINI_MODEL}:embedContent"

        payload = {
            "model": f"models/{cls.GEMINI_MODEL}",
            "content": {"parts": [{"text": text}]},
            "taskType": "RETRIEVAL_DOCUMENT",
            "outputDimensionality": dim
        }

        params = {"key": cls.GEMINI_API_KEY}

        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(url, json=payload, params=params)
            response.raise_for_status()
            data = response.json()

        embedding = data["embedding"]["values"]

        # Normalize if not default 3072 (MRL requirement)
        if dim != 3072:
            embedding = cls._normalize(embedding)

        return embedding

    @classmethod
    async def embed_query(
        cls,
        query: str,
        output_dimensionality: Optional[int] = None
    ) -> List[float]:
        """
        Generate embedding for search query (uses RETRIEVAL_QUERY task).

        Args:
            query: Query text
            output_dimensionality: Output dimension (128-3072), defaults to 1536

        Returns:
            Normalized embedding vector
        """
        if not cls.GEMINI_API_KEY:
            raise ValueError("GEMINI_API_KEY not configured")

        dim = output_dimensionality or cls.DEFAULT_DIMENSION
        url = f"{cls.BASE_URL}/models/{cls.GEMINI_MODEL}:embedContent"

        payload = {
            "model": f"models/{cls.GEMINI_MODEL}",
            "content": {"parts": [{"text": query}]},
            "taskType": "RETRIEVAL_QUERY",
            "outputDimensionality": dim
        }

        params = {"key": cls.GEMINI_API_KEY}

        async with httpx.AsyncClient(timeout=30.0) as client:
            response = await client.post(url, json=payload, params=params)
            response.raise_for_status()
            data = response.json()

        embedding = data["embedding"]["values"]

        # Normalize if not default 3072 (MRL requirement)
        if dim != 3072:
            embedding = cls._normalize(embedding)

        return embedding

    @classmethod
    async def embed_batch(
        cls,
        texts: List[str],
        output_dimensionality: Optional[int] = None
    ) -> List[List[float]]:
        """Generate embeddings for multiple texts"""
        embeddings = []
        for text in texts:
            embedding = await cls.embed_text(text, output_dimensionality)
            embeddings.append(embedding)
        return embeddings

    @classmethod
    def get_dimension(cls) -> int:
        """Return current embedding dimension"""
        return cls.DEFAULT_DIMENSION

    @staticmethod
    def _normalize(embedding: List[float]) -> List[float]:
        """
        L2 normalize embedding vector.
        Required for MRL embeddings when using non-default dimensions.
        """
        arr = np.array(embedding)
        norm = np.linalg.norm(arr)
        if norm > 0:
            arr = arr / norm
        return arr.tolist()
