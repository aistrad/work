"""
Profile Cache 性能基准测试
"""
import pytest
import asyncio
import time
from uuid import uuid4
from typing import List


class TestProfileCacheBenchmark:
    """缓存操作基准测试"""

    def test_cache_set_performance(self, profile_cache, mock_profile):
        """测试缓存写入性能 - 目标: < 1ms"""
        user_id = uuid4()

        # 预热
        asyncio.get_event_loop().run_until_complete(
            profile_cache.set(user_id, mock_profile)
        )

        # 测量
        times: List[float] = []
        for _ in range(100):
            user_id = uuid4()
            start = time.perf_counter()
            asyncio.get_event_loop().run_until_complete(
                profile_cache.set(user_id, mock_profile)
            )
            times.append((time.perf_counter() - start) * 1000)

        avg_ms = sum(times) / len(times)
        p95_ms = sorted(times)[95]

        print(f"\n  Cache SET: avg={avg_ms:.3f}ms, p95={p95_ms:.3f}ms")

        assert avg_ms < 1.0, f"Cache SET avg {avg_ms:.3f}ms exceeds 1ms target"
        assert p95_ms < 2.0, f"Cache SET p95 {p95_ms:.3f}ms exceeds 2ms target"

    def test_cache_get_hit_performance(self, profile_cache, mock_profile):
        """测试缓存命中读取性能 - 目标: < 0.5ms"""
        user_id = uuid4()

        # 预热 - 先写入
        asyncio.get_event_loop().run_until_complete(
            profile_cache.set(user_id, mock_profile)
        )

        # 测量读取
        times: List[float] = []
        for _ in range(100):
            start = time.perf_counter()
            asyncio.get_event_loop().run_until_complete(
                profile_cache.get(user_id)
            )
            times.append((time.perf_counter() - start) * 1000)

        avg_ms = sum(times) / len(times)
        p95_ms = sorted(times)[95]

        print(f"\n  Cache GET (hit): avg={avg_ms:.3f}ms, p95={p95_ms:.3f}ms")

        assert avg_ms < 0.5, f"Cache GET avg {avg_ms:.3f}ms exceeds 0.5ms target"
        assert p95_ms < 1.0, f"Cache GET p95 {p95_ms:.3f}ms exceeds 1ms target"

    def test_cache_get_miss_performance(self, profile_cache):
        """测试缓存未命中性能 - 目标: < 0.5ms"""
        times: List[float] = []

        for _ in range(100):
            user_id = uuid4()  # 每次用新 ID，保证 miss
            start = time.perf_counter()
            asyncio.get_event_loop().run_until_complete(
                profile_cache.get(user_id)
            )
            times.append((time.perf_counter() - start) * 1000)

        avg_ms = sum(times) / len(times)
        p95_ms = sorted(times)[95]

        print(f"\n  Cache GET (miss): avg={avg_ms:.3f}ms, p95={p95_ms:.3f}ms")

        assert avg_ms < 0.5, f"Cache GET miss avg {avg_ms:.3f}ms exceeds 0.5ms target"

    def test_cache_concurrent_access(self, profile_cache, mock_profile):
        """测试并发访问性能 - 100 并发"""
        users = [uuid4() for _ in range(100)]

        # 预热 - 写入所有
        async def warmup():
            tasks = [profile_cache.set(u, mock_profile) for u in users]
            await asyncio.gather(*tasks)

        asyncio.get_event_loop().run_until_complete(warmup())

        # 测量并发读取
        async def concurrent_reads():
            tasks = [profile_cache.get(u) for u in users]
            return await asyncio.gather(*tasks)

        times: List[float] = []
        for _ in range(10):
            start = time.perf_counter()
            asyncio.get_event_loop().run_until_complete(concurrent_reads())
            times.append((time.perf_counter() - start) * 1000)

        avg_ms = sum(times) / len(times)

        print(f"\n  Cache 100 concurrent reads: avg={avg_ms:.3f}ms")

        # 100 并发读取应在 50ms 内完成
        assert avg_ms < 50, f"100 concurrent reads {avg_ms:.3f}ms exceeds 50ms target"

    def test_cache_invalidate_by_prefix(self, profile_cache, mock_profile):
        """测试前缀失效性能"""
        user_id = uuid4()

        # 写入多个 key
        async def setup():
            await profile_cache.set_by_key(f"{user_id}:bazi", mock_profile)
            await profile_cache.set_by_key(f"{user_id}:zodiac", mock_profile)
            await profile_cache.set_by_key(f"{user_id}:all", mock_profile)

        asyncio.get_event_loop().run_until_complete(setup())

        # 测量前缀失效
        times: List[float] = []
        for _ in range(100):
            start = time.perf_counter()
            asyncio.get_event_loop().run_until_complete(
                profile_cache.invalidate_by_prefix(str(user_id))
            )
            times.append((time.perf_counter() - start) * 1000)
            # 重新写入以便下次测试
            asyncio.get_event_loop().run_until_complete(setup())

        avg_ms = sum(times) / len(times)

        print(f"\n  Cache invalidate_by_prefix: avg={avg_ms:.3f}ms")

        assert avg_ms < 2.0, f"Invalidate prefix avg {avg_ms:.3f}ms exceeds 2ms target"

    def test_cache_stats_overhead(self, profile_cache):
        """测试统计信息获取开销"""
        times: List[float] = []

        for _ in range(1000):
            start = time.perf_counter()
            profile_cache.get_stats()
            times.append((time.perf_counter() - start) * 1000)

        avg_ms = sum(times) / len(times)

        print(f"\n  Cache get_stats: avg={avg_ms:.6f}ms")

        # 统计获取应该是即时的
        assert avg_ms < 0.1, f"get_stats avg {avg_ms:.6f}ms exceeds 0.1ms target"


class TestRouteCacheBenchmark:
    """路由缓存基准测试"""

    def test_route_cache_set_get(self, route_cache):
        """测试路由缓存读写性能"""
        from services.model_router.models import Model

        models = [
            Model(
                id=f"test:model_{i}",
                provider_id="test",
                model_name=f"test-model-{i}",
                capabilities=["chat"],
                priority=i
            )
            for i in range(10)
        ]

        # 测量写入
        start = time.perf_counter()
        asyncio.get_event_loop().run_until_complete(
            route_cache.set_models(models)
        )
        write_ms = (time.perf_counter() - start) * 1000

        # 测量读取
        times: List[float] = []
        for _ in range(100):
            start = time.perf_counter()
            asyncio.get_event_loop().run_until_complete(
                route_cache.get_models()
            )
            times.append((time.perf_counter() - start) * 1000)

        avg_ms = sum(times) / len(times)

        print(f"\n  Route cache SET: {write_ms:.3f}ms, GET avg: {avg_ms:.3f}ms")

        assert write_ms < 5.0, f"Route cache SET {write_ms:.3f}ms exceeds 5ms"
        assert avg_ms < 1.0, f"Route cache GET {avg_ms:.3f}ms exceeds 1ms"
