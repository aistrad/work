"""
CoreAgent v6 - 支持 Scenario 路由和 PostgreSQL 知识检索的智能体

v6 架构特性：
- Scenario 路由：根据用户消息匹配最佳场景
- PostgreSQL 知识检索：RAG + 案例匹配
- 7 阶段 SOP：P1-P2 强制，P3-P7 LLM 自由发挥
- 工具-卡片映射：标准化工具元数据
"""
import json
import logging
from typing import Optional, List, Dict, Any, AsyncGenerator
from dataclasses import dataclass
from enum import Enum

from services.llm import LLMClient, get_llm_client
from services.llm.client import LLMMessage
from services.knowledge.repository import get_knowledge_repository, KnowledgeRepository
from .skill_loader import (
    load_skill, load_scenario, get_skill_triggers,
    build_system_prompt, SkillConfig, ScenarioConfig,
    route_scenario as memory_route_scenario
)
from .sop_engine import SOPEngine, SOPAction, SOPPhase, check_sop_requirements
from .tool_registry import ToolRegistry, ToolContext

logger = logging.getLogger(__name__)


class AgentState(str, Enum):
    """Agent 执行状态"""
    IDLE = "idle"
    THINKING = "thinking"
    TOOL_CALLING = "tool_calling"
    COMPLETED = "completed"
    ERROR = "error"


@dataclass
class AgentEvent:
    """Agent 执行事件"""
    type: str  # thinking, content, tool_call, tool_result, done, error, sop_phase
    data: Any = None


@dataclass
class AgentContext:
    """Agent 执行上下文"""
    user_id: str
    user_tier: str = "free"
    profile: Optional[Dict[str, Any]] = None
    skill_data: Optional[Dict[str, Any]] = None
    history: Optional[List[Dict[str, str]]] = None
    skill: Optional[str] = None
    scenario: Optional[str] = None
    portrait: Optional[str] = None
    conversation_id: Optional[str] = None


# Skill 选择工具 - V6 架构：一次决定 skill + scenario + confidence
USE_SKILL_TOOL = {
    "type": "function",
    "function": {
        "name": "use_skill",
        "description": """激活专业技能来回答用户问题。一次决定 skill、scenario 和 confidence。

## Skill 路由
- 八字、命理、生辰、测算、算命、命盘 → skill: "bazi"
- 星座、星盘、占星、行星、上升 → skill: "zodiac"
- 职业、工作、跳槽、升职、创业 → skill: "career"
- 塔罗、牌阵、抽牌、占卜 → skill: "tarot"

## Bazi Scenario 目录
- basic_reading: 基础命盘解读（默认）
- career: 事业财运分析
- relationship: 感情婚姻分析
- compatibility: 八字合婚配对
- yearly_fortune: 流年运势预测
- timing: 择日择时
- wealth: 财运投资分析
- personality: 性格特质分析
- life_blueprint: 人生蓝图规划
- dayun: 大运分析
- quick_query: 快速问答

## Confidence 说明
- high: 用户意图明确，直接执行
- medium: 基本确定，可能需要追问细节
- low: 不确定，需要向用户确认

重要：如果用户消息中已经包含了出生信息，设置 birth_info_provided=true。""",
        "parameters": {
            "type": "object",
            "properties": {
                "skill": {
                    "type": "string",
                    "enum": ["bazi", "zodiac", "career", "tarot"],
                    "description": "要使用的技能"
                },
                "scenario": {
                    "type": "string",
                    "description": "场景 ID，参考上方场景目录"
                },
                "confidence": {
                    "type": "string",
                    "enum": ["high", "medium", "low"],
                    "description": "路由置信度"
                },
                "topic": {
                    "type": "string",
                    "enum": ["career", "relationship", "fortune", "health", "self", "general"],
                    "description": "用户关注的话题类型"
                },
                "birth_info_provided": {
                    "type": "boolean",
                    "description": "用户消息中是否已包含出生信息"
                }
            },
            "required": ["skill", "scenario", "confidence"]
        }
    }
}


class CoreAgent:
    """
    CoreAgent v6 - 支持 Scenario 路由和 PostgreSQL 知识检索

    Features:
    - Scenario routing via PostgreSQL
    - Knowledge retrieval (RAG + cases)
    - 7-phase SOP execution
    - Tool-card mapping
    """

    def __init__(
        self,
        llm: Optional[LLMClient] = None,
        max_iterations: int = 10,
        knowledge_repo: Optional[KnowledgeRepository] = None
    ):
        self.llm = llm or get_llm_client()
        self.max_iterations = max_iterations
        self.knowledge_repo = knowledge_repo or get_knowledge_repository()
        self.state = AgentState.IDLE
        self._active_skill: Optional[str] = None
        self._active_scenario: Optional[str] = None
        self._topic: Optional[str] = None
        self._current_message: str = ""

    @property
    def usage(self) -> Dict[str, int]:
        """获取 LLM 使用统计"""
        return self.llm.usage

    async def run(
        self,
        message: str,
        context: AgentContext
    ) -> AsyncGenerator[AgentEvent, None]:
        """执行 Agent 循环"""
        self.state = AgentState.IDLE
        self._current_message = message

        # 使用前端指定的 skill/scenario，或让 LLM 决定
        if context.skill:
            self._active_skill = context.skill
            self._active_scenario = context.scenario or await self._route_scenario(context.skill, message)
        else:
            self._active_skill = None
            self._active_scenario = None

        # 检查 SOP 要求
        if self._active_skill:
            action, sop_context = check_sop_requirements(
                skill_id=self._active_skill,
                scenario_id=self._active_scenario,
                profile=context.profile,
                skill_data=context.skill_data,
                message=message
            )

            yield AgentEvent(type="sop_phase", data={
                "skill": self._active_skill,
                "scenario": self._active_scenario,
                "action": action.value,
                "phase": sop_context.get("phase", SOPPhase.ANALYZE).value,
                "context": sop_context
            })

        # 构建初始消息
        messages = await self._build_initial_messages(message, context)

        for iteration in range(self.max_iterations):
            self.state = AgentState.THINKING
            yield AgentEvent(type="thinking", data={"iteration": iteration})

            tools = self._get_current_tools(context)

            try:
                content_buffer = ""
                tool_calls = []

                async for chunk in self.llm.stream(
                    messages=messages,
                    tools=tools,
                    tool_choice=None,
                    user_tier=context.user_tier
                ):
                    if chunk["type"] == "content":
                        content_buffer += chunk["content"]
                        yield AgentEvent(type="content", data={"content": chunk["content"]})
                    elif chunk["type"] == "tool_call":
                        tool_calls.append(chunk)

                if tool_calls:
                    self.state = AgentState.TOOL_CALLING

                    assistant_tool_calls = []
                    for tc in tool_calls:
                        assistant_tool_calls.append({
                            "id": tc["tool_call_id"],
                            "function": {
                                "name": tc["tool_name"],
                                "arguments": tc["tool_args"]
                            }
                        })
                    messages.append(LLMMessage(
                        role="assistant",
                        content=content_buffer or "",
                        tool_calls=assistant_tool_calls
                    ))
                    content_buffer = ""

                    tool_results = []
                    for tc in tool_calls:
                        tool_name = tc["tool_name"]
                        tool_args = tc["tool_args"]
                        tool_call_id = tc["tool_call_id"]

                        yield AgentEvent(type="tool_call", data={
                            "id": tool_call_id,
                            "name": tool_name,
                            "arguments": tool_args
                        })

                        result = await self._execute_tool(tool_name, tool_args, context)
                        tool_results.append({
                            "tool_call_id": tool_call_id,
                            "result": result
                        })

                        yield AgentEvent(type="tool_result", data={
                            "id": tool_call_id,
                            "name": tool_name,
                            "result": result
                        })

                    for tr in tool_results:
                        result_content = tr["result"]
                        if isinstance(result_content, dict):
                            result_content = json.dumps(result_content, ensure_ascii=False)
                        messages.append(LLMMessage(
                            role="tool",
                            content=str(result_content),
                            tool_call_id=tr["tool_call_id"]
                        ))
                else:
                    self.state = AgentState.COMPLETED
                    yield AgentEvent(type="done", data={"content": content_buffer})
                    return

            except Exception as e:
                self.state = AgentState.ERROR
                logger.error(f"Agent error: {e}")
                yield AgentEvent(type="error", data={"error": str(e)})
                return

        self.state = AgentState.COMPLETED
        yield AgentEvent(type="done", data={"max_iterations_reached": True})

    async def _route_scenario(self, skill_id: str, message: str) -> Optional[str]:
        """场景路由 - 根据消息匹配最佳场景"""
        try:
            matches = await self.knowledge_repo.route_scenario(skill_id, message)
            if matches:
                return matches[0].scenario_id
        except Exception as e:
            logger.warning(f"Scenario routing failed: {e}")

        # 回退到默认场景
        skill = load_skill(skill_id)
        return skill.default_scenario if skill else "basic_reading"

    async def _build_initial_messages(
        self,
        message: str,
        context: AgentContext
    ) -> List[LLMMessage]:
        """构建初始消息列表"""
        system_prompt = await self._build_system_prompt(message, context)

        messages = [LLMMessage(role="system", content=system_prompt)]

        if context.history:
            for msg in context.history[-10:]:
                messages.append(LLMMessage(
                    role=msg.get("role", "user"),
                    content=msg.get("content", "")
                ))

        messages.append(LLMMessage(role="user", content=message))
        return messages

    async def _build_system_prompt(self, message: str, context: AgentContext) -> str:
        """构建 System Prompt"""
        parts = []

        # 基础 prompt
        if self._active_skill:
            user_ctx = {
                "birth_info": context.profile.get("birth_info") if context.profile else None,
                "portrait": context.portrait
            }
            base_prompt = build_system_prompt(
                self._active_skill,
                self._active_scenario,
                user_ctx
            )
            parts.append(base_prompt)

            # 知识检索
            try:
                knowledge = await self.knowledge_repo.search_knowledge(
                    self._active_skill, message, top_k=5
                )
                if knowledge:
                    knowledge_text = "\n## 相关知识\n\n"
                    for chunk in knowledge:
                        knowledge_text += f"**{chunk.book_name}** ({chunk.chapter or ''})\n{chunk.chunk_text[:500]}...\n\n"
                    parts.append(knowledge_text)
            except Exception as e:
                logger.warning(f"Knowledge retrieval failed: {e}")

            # 案例匹配
            try:
                cases = await self.knowledge_repo.match_cases(
                    self._active_skill,
                    scenario_id=self._active_scenario,
                    top_k=2
                )
                if cases:
                    cases_text = "\n## 相关案例\n\n"
                    for case in cases:
                        cases_text += f"**{case.name}**\n{json.dumps(case.conclusion, ensure_ascii=False)}\n\n"
                    parts.append(cases_text)
            except Exception as e:
                logger.warning(f"Case matching failed: {e}")
        else:
            # 无 skill 时，添加触发规则
            triggers = get_skill_triggers()
            if triggers:
                trigger_rules = "## 技能触发规则\n\n当用户消息包含以下关键词时，调用 `use_skill` 工具：\n"
                for skill_name, keywords in triggers.items():
                    trigger_rules += f"- **{skill_name}**: {', '.join(keywords)}\n"
                parts.append(trigger_rules)

        # 用户命盘数据
        if context.skill_data and self._active_skill:
            skill_data = context.skill_data.get(self._active_skill, {})
            if skill_data:
                parts.append(f"\n## 用户命盘数据\n{json.dumps(skill_data, ensure_ascii=False, indent=2)}")

        return "\n".join(parts)

    def _get_current_tools(self, context: AgentContext) -> List[Dict[str, Any]]:
        """获取当前可用工具"""
        if not context.skill and not self._active_skill:
            return [USE_SKILL_TOOL]

        skill_id = self._active_skill or context.skill
        scenario_id = self._active_scenario or context.scenario

        tools = get_tools_for_scenario(skill_id, scenario_id)
        return tools if tools else [USE_SKILL_TOOL]

    async def _execute_tool(
        self,
        tool_name: str,
        tool_args: str,
        context: AgentContext
    ) -> Dict[str, Any]:
        """执行工具调用"""
        try:
            args = json.loads(tool_args) if tool_args else {}
        except json.JSONDecodeError:
            args = {}

        if tool_name == "use_skill":
            return await self._handle_use_skill(args, context)

        if tool_name == "search_db":
            return await self._handle_search_db(args, context)

        if tool_name == "ask_user_question":
            return {"status": "question", "question": args.get("question"), "options": args.get("options", [])}

        # UI 工具
        from services.vibe_engine.tool_executor import execute_ui_tool, is_ui_tool
        if is_ui_tool(tool_name):
            return await execute_ui_tool(
                tool_name=tool_name,
                args=args,
                user_id=context.user_id,
                profile=context.profile,
                skill=self._active_skill or "bazi",
                skill_data=context.skill_data
            )

        return {"status": "unknown_tool", "tool": tool_name}

    async def _handle_search_db(
        self,
        args: Dict[str, Any],
        context: AgentContext
    ) -> Dict[str, Any]:
        """处理 search_db 工具调用"""
        table = args.get("table", "knowledge_chunks")
        query = args.get("query", "")
        filters = args.get("filters", {})
        top_k = args.get("top_k", 5)

        # 自动添加当前 skill_id 到 filters
        if self._active_skill and "skill_id" not in filters:
            filters["skill_id"] = self._active_skill
        if self._active_scenario and "scenario_id" not in filters:
            filters["scenario_id"] = self._active_scenario

        results = await self.knowledge_repo.search_db(
            table=table,
            query=query,
            filters=filters,
            top_k=top_k
        )

        return {
            "status": "success",
            "table": table,
            "query": query,
            "count": len(results),
            "results": results
        }

    async def _handle_use_skill(
        self,
        args: Dict[str, Any],
        context: AgentContext
    ) -> Dict[str, Any]:
        """处理 skill 选择 - V6: 一次决定 skill + scenario + confidence"""
        skill = args.get("skill")
        scenario = args.get("scenario", "basic_reading")
        confidence = args.get("confidence", "high")
        topic = args.get("topic", "general")

        if not skill:
            return {"status": "error", "message": "No skill specified"}

        self._active_skill = skill
        self._active_scenario = scenario
        self._topic = topic

        # 低置信度时，返回确认请求
        if confidence == "low":
            return {
                "status": "need_confirm",
                "skill": skill,
                "scenario": scenario,
                "confidence": confidence,
                "message": f"我理解您可能想使用 {skill} 的 {scenario} 服务，请确认是否正确？"
            }

        # 检查是否需要出生信息
        needs_birth = skill in ["bazi", "zodiac"]
        has_birth = context.profile and context.profile.get("birth_info")
        birth_provided = args.get("birth_info_provided", False)

        if needs_birth and not has_birth and not birth_provided:
            return {
                "status": "need_info",
                "skill": skill,
                "scenario": scenario,
                "confidence": confidence,
                "topic": topic,
                "info_type": "birth",
                "message": "技能已激活。请调用 request_info 工具收集出生信息。"
            }

        return {
            "status": "activated",
            "skill": skill,
            "scenario": scenario,
            "confidence": confidence,
            "topic": topic,
            "message": f"已激活 {skill} 技能，场景: {scenario}"
        }


def create_agent(
    llm: Optional[LLMClient] = None,
    max_iterations: int = 10
) -> CoreAgent:
    """创建 CoreAgent 实例"""
    return CoreAgent(llm=llm, max_iterations=max_iterations)
