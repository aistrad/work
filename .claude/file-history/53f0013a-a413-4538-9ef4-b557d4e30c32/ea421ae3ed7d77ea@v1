"""
Chat Routes - Conversation endpoints for VibeLife v3.0
Based on: vibelife spec v3.0

Features:
- SSE streaming responses
- Voice mode toggle (warm / sarcastic)
- Skill-based conversations (bazi / zodiac)
- Guest mode for demo
"""
import json
from typing import Optional, List
from uuid import UUID, uuid4

from fastapi import APIRouter, HTTPException, Depends, Query
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from sse_starlette.sse import EventSourceResponse

from services.vibe_engine import (
    get_llm_service,
    get_context_builder,
    get_portrait_service,
    VoiceMode,
    Skill,
    create_user_message,
)

router = APIRouter(prefix="/chat", tags=["Chat"])


# ═══════════════════════════════════════════════════════════════════════════
# Request/Response Models
# ═══════════════════════════════════════════════════════════════════════════

class ChatRequest(BaseModel):
    """Chat request model"""
    message: str = Field(..., description="User message")
    skill: str = Field(..., description="Skill: bazi or zodiac")
    conversation_id: Optional[UUID] = Field(None, description="Existing conversation ID")
    voice_mode: Optional[str] = Field("warm", description="Voice mode: warm or sarcastic")


class ChatResponse(BaseModel):
    """Chat response model (for non-streaming)"""
    content: str
    conversation_id: UUID
    skill: str
    voice_mode: str
    metadata: Optional[dict] = None


class GuestChatRequest(BaseModel):
    """Guest chat request (no auth required)"""
    message: str
    skill: str = "bazi"


# ═══════════════════════════════════════════════════════════════════════════
# Helper Functions
# ═══════════════════════════════════════════════════════════════════════════

def parse_skill(skill_str: str) -> Skill:
    """Parse skill string to enum"""
    skill_lower = skill_str.lower()
    if skill_lower in ("bazi", "八字"):
        return Skill.BAZI
    elif skill_lower in ("zodiac", "星座"):
        return Skill.ZODIAC
    else:
        raise HTTPException(status_code=400, detail=f"Unknown skill: {skill_str}")


def parse_voice_mode(mode_str: str) -> VoiceMode:
    """Parse voice mode string to enum"""
    mode_lower = mode_str.lower()
    if mode_lower in ("warm", "温暖"):
        return VoiceMode.WARM
    elif mode_lower in ("sarcastic", "吐槽"):
        return VoiceMode.SARCASTIC
    else:
        return VoiceMode.WARM  # Default


async def get_user_profile(user_id: Optional[UUID]) -> dict:
    """Get user profile from database (placeholder)"""
    # TODO: Implement actual database lookup
    from services.vibe_engine import DEFAULT_PROFILE
    return DEFAULT_PROFILE.copy()


async def get_conversation_history(
    conversation_id: Optional[UUID],
    limit: int = 20
) -> List[dict]:
    """Get conversation history from database (placeholder)"""
    # TODO: Implement actual database lookup
    return []


async def save_message(
    conversation_id: UUID,
    role: str,
    content: str,
    metadata: Optional[dict] = None
) -> None:
    """Save message to database (placeholder)"""
    # TODO: Implement actual database save
    pass


# ═══════════════════════════════════════════════════════════════════════════
# Endpoints
# ═══════════════════════════════════════════════════════════════════════════

@router.post("/stream")
async def chat_stream(request: ChatRequest):
    """
    Send a message and get streaming response (SSE).

    Returns Server-Sent Events with chunks of the response.
    Final event contains [DONE] marker.
    """
    skill = parse_skill(request.skill)
    voice_mode = parse_voice_mode(request.voice_mode or "warm")

    # Get or create conversation
    conversation_id = request.conversation_id or uuid4()

    # Get services
    llm = get_llm_service()
    context_builder = get_context_builder()

    async def generate():
        try:
            # Get user profile (for logged-in users)
            profile = await get_user_profile(None)  # TODO: Get actual user

            # Get conversation history
            history = await get_conversation_history(conversation_id)

            # Build context
            system_prompt, messages = await context_builder.build(
                skill=skill,
                voice_mode=voice_mode,
                current_message=request.message,
                profile=profile,
                history=history
            )

            # Save user message
            await save_message(conversation_id, "user", request.message)

            # Stream response
            full_content = ""
            async for chunk in llm.stream(messages):
                full_content += chunk
                # Send chunk as SSE event
                yield {
                    "event": "message",
                    "data": json.dumps({
                        "type": "chunk",
                        "content": chunk
                    })
                }

            # Save assistant message
            await save_message(conversation_id, "assistant", full_content)

            # Send completion event
            yield {
                "event": "message",
                "data": json.dumps({
                    "type": "done",
                    "conversation_id": str(conversation_id),
                    "skill": skill.value,
                    "voice_mode": voice_mode.value
                })
            }

        except Exception as e:
            yield {
                "event": "error",
                "data": json.dumps({
                    "type": "error",
                    "message": str(e)
                })
            }

    return EventSourceResponse(generate())


@router.post("/", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    Send a message and get non-streaming response.
    For clients that don't support SSE.
    """
    skill = parse_skill(request.skill)
    voice_mode = parse_voice_mode(request.voice_mode or "warm")

    # Get or create conversation
    conversation_id = request.conversation_id or uuid4()

    # Get services
    llm = get_llm_service()
    context_builder = get_context_builder()

    try:
        # Get user profile
        profile = await get_user_profile(None)

        # Get conversation history
        history = await get_conversation_history(conversation_id)

        # Build context
        system_prompt, messages = await context_builder.build(
            skill=skill,
            voice_mode=voice_mode,
            current_message=request.message,
            profile=profile,
            history=history
        )

        # Save user message
        await save_message(conversation_id, "user", request.message)

        # Get response
        response = await llm.chat(messages)

        # Save assistant message
        await save_message(conversation_id, "assistant", response.content)

        return ChatResponse(
            content=response.content,
            conversation_id=conversation_id,
            skill=skill.value,
            voice_mode=voice_mode.value,
            metadata={
                "model": response.model,
                "usage": response.usage
            }
        )

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/guest")
async def chat_guest(request: GuestChatRequest):
    """
    Guest chat endpoint (no authentication required).
    For landing page demo with limited functionality.
    """
    skill = parse_skill(request.skill)

    llm = get_llm_service()
    context_builder = get_context_builder()

    try:
        # Build simple context (no profile, no history)
        system_prompt, messages = await context_builder.build(
            skill=skill,
            voice_mode=VoiceMode.WARM,
            current_message=request.message,
            profile=None,
            history=None
        )

        # Get response (limited tokens for guest)
        response = await llm.chat(messages, max_tokens=1024)

        return {
            "content": response.content,
            "is_guest": True,
            "skill": skill.value,
            "suggestion": "注册后可以获得完整的个性化分析和对话历史保存"
        }

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@router.post("/guest/stream")
async def chat_guest_stream(request: GuestChatRequest):
    """
    Guest streaming chat endpoint.
    For landing page demo with SSE.
    """
    skill = parse_skill(request.skill)

    llm = get_llm_service()
    context_builder = get_context_builder()

    async def generate():
        try:
            # Build simple context
            system_prompt, messages = await context_builder.build(
                skill=skill,
                voice_mode=VoiceMode.WARM,
                current_message=request.message,
                profile=None,
                history=None
            )

            # Stream response
            async for chunk in llm.stream(messages, max_tokens=1024):
                yield {
                    "event": "message",
                    "data": json.dumps({
                        "type": "chunk",
                        "content": chunk
                    })
                }

            yield {
                "event": "message",
                "data": json.dumps({
                    "type": "done",
                    "is_guest": True,
                    "skill": skill.value
                })
            }

        except Exception as e:
            yield {
                "event": "error",
                "data": json.dumps({
                    "type": "error",
                    "message": str(e)
                })
            }

    return EventSourceResponse(generate())


# ═══════════════════════════════════════════════════════════════════════════
# Voice Mode Toggle
# ═══════════════════════════════════════════════════════════════════════════

class VoiceModeRequest(BaseModel):
    """Voice mode toggle request"""
    conversation_id: UUID
    voice_mode: str  # warm | sarcastic


@router.post("/voice-mode")
async def toggle_voice_mode(request: VoiceModeRequest):
    """
    Toggle voice mode for a conversation.
    Changes Vibe's personality between warm and sarcastic.
    """
    voice_mode = parse_voice_mode(request.voice_mode)

    # TODO: Update conversation voice_mode in database

    return {
        "success": True,
        "conversation_id": str(request.conversation_id),
        "voice_mode": voice_mode.value,
        "message": "语气已切换" if voice_mode == VoiceMode.SARCASTIC else "已切换到温暖模式"
    }


# ═══════════════════════════════════════════════════════════════════════════
# Conversation Management
# ═══════════════════════════════════════════════════════════════════════════

@router.get("/conversations")
async def list_conversations(
    skill: Optional[str] = None,
    limit: int = Query(20, ge=1, le=100)
):
    """
    List user's conversations.
    TODO: Implement with authentication.
    """
    # TODO: Implement with actual database query
    return {
        "conversations": [],
        "total": 0
    }


@router.get("/conversations/{conversation_id}")
async def get_conversation(conversation_id: UUID):
    """
    Get conversation details with messages.
    """
    # TODO: Implement with actual database query
    return {
        "id": str(conversation_id),
        "messages": [],
        "skill": None,
        "voice_mode": "warm",
        "created_at": None
    }


@router.delete("/conversations/{conversation_id}")
async def delete_conversation(conversation_id: UUID):
    """
    Delete a conversation.
    """
    # TODO: Implement with actual database delete
    return {"success": True, "message": "Conversation deleted"}
