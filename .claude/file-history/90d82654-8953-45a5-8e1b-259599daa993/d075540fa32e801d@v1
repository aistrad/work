"""
Prologue Generator - 综合判断卷首语
Based on: vibelife spec v3.0, section 4.6

The prologue is the "hook" content that's always free.
It should be:
- Personal and insightful
- Written in the Vibe voice (warm or sarcastic based on mode)
- Compelling enough to drive conversion to full report
"""

import json
import logging
from dataclasses import dataclass
from typing import Optional, Dict, Any
from enum import Enum

from ..vibe_engine import get_llm_service, create_system_message, create_user_message, VoiceMode

logger = logging.getLogger(__name__)


class PrologueStyle(str, Enum):
    WARM = "warm"        # 温暖模式
    SARCASTIC = "sarcastic"  # 吐槽模式


# ═══════════════════════════════════════════════════════════════════════════
# Prompts
# ═══════════════════════════════════════════════════════════════════════════

PROLOGUE_SYSTEM_WARM = """你是 Vibe，VibeLife 的 AI 知己。你正在为用户写一段「综合判断卷首语」。

风格要求（温暖模式）：
- 像一个懂你的朋友在认真地和你说话
- 用第二人称「你」
- 要有共情，让用户感觉被理解
- 语言温暖但不油腻
- 要有洞察力，点出用户可能没意识到的问题
- 结尾要自然引导用户想看完整报告

格式要求：
- 300-400字
- 开头直接称呼用户（用昵称或「小鱼」这类代称）
- 不要用标题、分隔线
- 像是一封私人短信
- 结尾签名「—— Vibe」"""

PROLOGUE_SYSTEM_SARCASTIC = """你是 Vibe，VibeLife 的 AI 知己。你正在为用户写一段「综合判断卷首语」。

风格要求（吐槽模式）：
- 像一个毒舌但关心你的朋友
- 用第二人称「你」
- 直接指出用户的问题，不要绕弯子
- 幽默、犀利、有趣
- 吐槽归吐槽，底层是关心
- 结尾要自然引导用户想看完整报告

格式要求：
- 300-400字
- 开头可以用「得了吧」「行吧」这类口语
- 不要用标题、分隔线
- 像是朋友在吐槽你
- 结尾签名「—— Vibe」"""

PROLOGUE_USER_TEMPLATE = """请为以下用户生成综合判断卷首语：

用户档案：
{profile_json}

访谈摘要：
{interview_summary}

技能类型：{skill}

请直接输出卷首语内容，不要添加任何 JSON 包装或代码块。"""


# ═══════════════════════════════════════════════════════════════════════════
# Prologue Generator
# ═══════════════════════════════════════════════════════════════════════════

class PrologueGenerator:
    """Generator for report prologue (卷首语)"""

    def __init__(self):
        self._llm = None

    @property
    def llm(self):
        if self._llm is None:
            self._llm = get_llm_service()
        return self._llm

    async def generate(
        self,
        profile: Dict[str, Any],
        skill: str,
        interview_summary: Optional[str] = None,
        style: PrologueStyle = PrologueStyle.WARM,
    ) -> str:
        """
        Generate the prologue (综合判断卷首语).

        Args:
            profile: User profile data
            skill: "bazi" or "zodiac"
            interview_summary: Optional interview result summary
            style: Writing style (warm or sarcastic)

        Returns:
            Generated prologue text
        """
        # Select system prompt based on style
        system_prompt = (
            PROLOGUE_SYSTEM_WARM if style == PrologueStyle.WARM
            else PROLOGUE_SYSTEM_SARCASTIC
        )

        # Build user prompt
        user_prompt = PROLOGUE_USER_TEMPLATE.format(
            profile_json=json.dumps(profile, ensure_ascii=False, indent=2),
            interview_summary=interview_summary or "用户未完成访谈",
            skill="八字" if skill == "bazi" else "星座",
        )

        messages = [
            create_system_message(system_prompt),
            create_user_message(user_prompt),
        ]

        try:
            response = await self.llm.chat(messages)
            return response.content.strip()
        except Exception as e:
            logger.error(f"Prologue generation failed: {e}")
            return self._get_fallback_prologue(profile, skill, style)

    def _get_fallback_prologue(
        self,
        profile: Dict[str, Any],
        skill: str,
        style: PrologueStyle,
    ) -> str:
        """Generate fallback prologue when LLM fails"""
        basic = profile.get("basic", {})
        name = basic.get("nickname", "朋友")

        if style == PrologueStyle.WARM:
            return f"""嗨，{name}，

感谢你愿意让我了解你。

看完你的信息，我想说：你比你以为的更有力量。有些事情现在看起来很难，但以你的性格，是能跨过去的。

接下来的报告，我会详细告诉你为什么我这么说。

—— Vibe"""
        else:
            return f"""行吧，{name}，

看了你的情况，我就直说了：你想太多，做太少。

不是说你不好，是说你明明有能力，非要自己跟自己较劲。

下面的报告我会说得更具体。你先别急着反驳，看完再说。

—— Vibe"""


# ═══════════════════════════════════════════════════════════════════════════
# Convenience Function
# ═══════════════════════════════════════════════════════════════════════════

async def generate_prologue(
    profile: Dict[str, Any],
    skill: str,
    interview_summary: Optional[str] = None,
    style: str = "warm",
) -> str:
    """
    Convenience function to generate prologue.

    Args:
        profile: User profile data
        skill: "bazi" or "zodiac"
        interview_summary: Optional interview summary
        style: "warm" or "sarcastic"

    Returns:
        Generated prologue text
    """
    generator = PrologueGenerator()
    style_enum = PrologueStyle(style)
    return await generator.generate(profile, skill, interview_summary, style_enum)
