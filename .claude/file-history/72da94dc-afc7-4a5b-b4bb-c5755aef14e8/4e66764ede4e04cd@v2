# VibeLife Knowledge System Optimization Plan

## ç›®æ ‡
åŸºäº PostgreSQL + pgvectorï¼Œè®¾è®¡**æç®€é«˜æ•ˆ**çš„çŸ¥è¯†åº“ç³»ç»Ÿï¼š
- æ”¯æŒ PDF/TXT/MD æ–‡æœ¬æ–‡æ¡£ä¸Šä¼ 
- æ¯ä¸ª skill module æŒ‡å®šçŸ¥è¯†æºæ–‡ä»¶å¤¹ï¼Œæ¯æ—¥å‡Œæ™¨ 4:00 è‡ªåŠ¨åŒæ­¥
- ä¸­è‹±æ–‡æ··åˆæŸ¥è¯¢ä¼˜åŒ– (70% ä¸­æ–‡ / 30% è‹±æ–‡)
- æç®€æ¶æ„ï¼šæ—  Redisã€Celeryã€ESï¼Œçº¯ PostgreSQL Native

---

## ç”¨æˆ·ç¡®è®¤çš„è®¾è®¡å†³ç­–

| å†³ç­–é¡¹ | é€‰æ‹© |
|--------|------|
| å‘é‡ç»´åº¦ | **ä¿æŒ Gemini 3072ç»´** |
| æ–‡ä»¶åˆ é™¤ç­–ç•¥ | **è½¯åˆ é™¤/å½’æ¡£** (æ ‡è®° archived, ä¿ç•™æ•°æ®) |
| QAè¡¨å¤„ç† | **åˆå¹¶åˆ° chunks è¡¨** (content_type='qa') |
| æ‰«æé¢‘ç‡ | **æ¯æ—¥å‡Œæ™¨ 4:00** |

---

## è®¾è®¡å†³ç­–è¯¦è§£

### 1. æ–‡ä»¶ç›®å½•ç®€åŒ–
æ¯ä¸ª skill ä¸€ä¸ªçŸ¥è¯†æºæ–‡ä»¶å¤¹ï¼š

```
/home/aiscend/work/vibelife/knowledge/
â”œâ”€â”€ bazi/           # å…«å­—æŠ€èƒ½çŸ¥è¯†åº“
â”‚   â”œâ”€â”€ å¤©å¹²åœ°æ”¯.md
â”‚   â”œâ”€â”€ åç¥è¯¦è§£.pdf
â”‚   â””â”€â”€ æ¡ˆä¾‹åˆ†æ.txt
â”œâ”€â”€ zodiac/         # æ˜Ÿåº§æŠ€èƒ½çŸ¥è¯†åº“
â””â”€â”€ mbti/           # MBTIæŠ€èƒ½çŸ¥è¯†åº“
```

### 2. QA å¯¹ç®€åŒ–
- ä» Markdown è‡ªåŠ¨æå– `Q: ... A: ...` æ ¼å¼
- ä½œä¸º `content_type='qa'` å­˜å…¥ `knowledge_chunks`
- åˆ é™¤ `knowledge_qa_pairs` è¡¨

### 3. ä¸­è‹±æ–‡æ··åˆæœç´¢
åº”ç”¨å±‚ Jieba åˆ†è¯ + PG `simple` é…ç½®ï¼š
```
è¾“å…¥: "æ¯”è‚©ä»£è¡¨ç‹¬ç«‹èƒ½åŠ›strong independence"
åˆ†è¯: "æ¯”è‚© ä»£è¡¨ ç‹¬ç«‹ èƒ½åŠ› strong independence"
å­˜å‚¨: search_text_preprocessed åˆ—
ç´¢å¼•: to_tsvector('simple', ...) è‡ªåŠ¨ç”Ÿæˆ
```

### 4. è½¯åˆ é™¤ç­–ç•¥
æ–‡ä»¶è¢«åˆ é™¤æ—¶ï¼š
- `status = 'archived'`
- ä¿ç•™æ•°æ®ç”¨äºå®¡è®¡/å›æ»š
- ä¸å‚ä¸æ£€ç´¢

---

## æ•°æ®åº“ Schema è®¾è®¡

```sql
-- ===============================================
-- æ–‡ä»¶: migrations/002_knowledge_v2.sql
-- ===============================================

-- æ–‡æ¡£è¡¨ (å…¼ä½œä»»åŠ¡é˜Ÿåˆ—)
CREATE TABLE IF NOT EXISTS knowledge_documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    skill_id TEXT NOT NULL,
    filename TEXT NOT NULL,
    file_path TEXT NOT NULL,         -- å®Œæ•´æ–‡ä»¶è·¯å¾„
    file_hash TEXT NOT NULL,         -- MD5 ç”¨äºæ£€æµ‹å˜æ›´
    file_type TEXT NOT NULL,         -- pdf, md, txt
    content_md TEXT,                 -- è½¬æ¢åçš„ Markdown (å½’æ¡£)
    status TEXT DEFAULT 'pending',   -- pending/processing/completed/failed/archived
    error_message TEXT,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(skill_id, filename)
);

-- æ–°ç‰ˆçŸ¥è¯†å—è¡¨ (åˆå¹¶ QA)
CREATE TABLE IF NOT EXISTS knowledge_chunks_v2 (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id UUID REFERENCES knowledge_documents(id) ON DELETE SET NULL,
    skill_id TEXT NOT NULL,
    chunk_index INT NOT NULL DEFAULT 0,
    content TEXT NOT NULL,
    content_type TEXT DEFAULT 'knowledge',  -- knowledge, qa, theory, pattern, case
    source_section TEXT,
    metadata JSONB DEFAULT '{}',

    -- Jieba åˆ†è¯åå­˜å…¥ (ä¸­è‹±æ–‡æ··åˆ)
    search_text_preprocessed TEXT,

    -- è‡ªåŠ¨ç”Ÿæˆå…¨æ–‡ç´¢å¼• (GENERATED ALWAYS)
    search_vector tsvector GENERATED ALWAYS AS (
        to_tsvector('simple', COALESCE(search_text_preprocessed, ''))
    ) STORED,

    -- Gemini 3072ç»´å‘é‡
    embedding vector(3072),

    created_at TIMESTAMPTZ DEFAULT NOW()
);

-- ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_docs_status ON knowledge_documents(status);
CREATE INDEX IF NOT EXISTS idx_docs_skill ON knowledge_documents(skill_id);
CREATE INDEX IF NOT EXISTS idx_chunks_v2_skill ON knowledge_chunks_v2(skill_id);
CREATE INDEX IF NOT EXISTS idx_chunks_v2_doc ON knowledge_chunks_v2(document_id);
CREATE INDEX IF NOT EXISTS idx_chunks_v2_type ON knowledge_chunks_v2(content_type);
CREATE INDEX IF NOT EXISTS idx_chunks_v2_fts ON knowledge_chunks_v2 USING gin(search_vector);
CREATE INDEX IF NOT EXISTS idx_chunks_v2_vec ON knowledge_chunks_v2 USING hnsw(embedding vector_cosine_ops);

-- è¿ç§»æ—§ QA æ•°æ®åˆ° chunks_v2
INSERT INTO knowledge_chunks_v2 (skill_id, content, content_type, search_text_preprocessed, embedding, created_at)
SELECT
    skill_id,
    'Q: ' || question || E'\nA: ' || answer,
    'qa',
    question || ' ' || answer,
    question_embedding,
    created_at
FROM knowledge_qa_pairs
WHERE question_embedding IS NOT NULL
ON CONFLICT DO NOTHING;

-- è¿ç§»æ—§ knowledge_chunks æ•°æ®
INSERT INTO knowledge_chunks_v2 (skill_id, content, content_type, source_section, metadata, embedding, created_at)
SELECT
    skill_id,
    content,
    COALESCE(content_type, 'knowledge'),
    source_section,
    metadata,
    embedding,
    created_at
FROM knowledge_chunks
WHERE embedding IS NOT NULL
ON CONFLICT DO NOTHING;
```

---

## æ··åˆæœç´¢ SQL å‡½æ•° (RRF ä¸‹æ²‰åˆ°æ•°æ®åº“)

```sql
-- ===============================================
-- æ–‡ä»¶: migrations/002_knowledge_v2.sql (ç»­)
-- ===============================================

CREATE OR REPLACE FUNCTION hybrid_search_v2(
    query_text_processed TEXT,    -- Jieba åˆ†è¯åçš„æŸ¥è¯¢
    query_embedding vector(3072),
    match_skill_id TEXT,
    top_k INT DEFAULT 5,
    rrf_k INT DEFAULT 60
)
RETURNS TABLE (
    id UUID,
    content TEXT,
    content_type TEXT,
    source_section TEXT,
    score FLOAT,
    match_type TEXT
) LANGUAGE sql STABLE AS $$
WITH semantic AS (
    SELECT id, ROW_NUMBER() OVER (ORDER BY embedding <=> query_embedding) as rank
    FROM knowledge_chunks_v2
    WHERE skill_id = match_skill_id AND embedding IS NOT NULL
    ORDER BY embedding <=> query_embedding
    LIMIT top_k * 2
),
keyword AS (
    SELECT id, ROW_NUMBER() OVER (
        ORDER BY ts_rank(search_vector, plainto_tsquery('simple', query_text_processed)) DESC
    ) as rank
    FROM knowledge_chunks_v2
    WHERE skill_id = match_skill_id
      AND search_vector @@ plainto_tsquery('simple', query_text_processed)
    LIMIT top_k * 2
)
SELECT
    COALESCE(s.id, k.id) as id,
    c.content,
    c.content_type,
    c.source_section,
    (COALESCE(1.0/(rrf_k + s.rank), 0.0) * 0.7 +
     COALESCE(1.0/(rrf_k + k.rank), 0.0) * 0.3)::FLOAT as score,
    CASE
        WHEN s.id IS NOT NULL AND k.id IS NOT NULL THEN 'hybrid'
        WHEN s.id IS NOT NULL THEN 'vector'
        ELSE 'keyword'
    END as match_type
FROM semantic s
FULL OUTER JOIN keyword k ON s.id = k.id
JOIN knowledge_chunks_v2 c ON c.id = COALESCE(s.id, k.id)
ORDER BY score DESC
LIMIT top_k;
$$;
```

---

## æ ¸å¿ƒæ–‡ä»¶å®ç°

### 1. åå° Worker (æ›¿ä»£ Celery)

**æ–‡ä»¶**: `apps/api/workers/ingestion.py`

```python
"""
Knowledge Ingestion Worker - åŸºäº PG SKIP LOCKED çš„ä»»åŠ¡é˜Ÿåˆ—
"""
import asyncio
import hashlib
import jieba
import pymupdf4llm
from pathlib import Path
from langchain_text_splitters import RecursiveCharacterTextSplitter, MarkdownHeaderTextSplitter

class IngestionWorker:
    def __init__(self, pool, embedding_service):
        self.pool = pool
        self.embedding_service = embedding_service

    async def run_loop(self):
        """åå°å¾ªç¯ï¼šè½®è¯¢ DB é˜Ÿåˆ—ï¼ŒåŸå­æŠ¢å ä»»åŠ¡"""
        print("ğŸš€ Knowledge Ingestion Worker Started...")
        while True:
            try:
                async with self.pool.acquire() as conn:
                    # åŸå­æŠ¢å ä»»åŠ¡ (SKIP LOCKED é˜²æ­¢å¹¶å‘å†²çª)
                    task = await conn.fetchrow("""
                        UPDATE knowledge_documents
                        SET status = 'processing', updated_at = NOW()
                        WHERE id = (
                            SELECT id FROM knowledge_documents
                            WHERE status = 'pending'
                            ORDER BY created_at ASC
                            LIMIT 1
                            FOR UPDATE SKIP LOCKED
                        )
                        RETURNING id, file_path, file_type, skill_id
                    """)

                if not task:
                    await asyncio.sleep(2)  # ç©ºé—²ç­‰å¾…
                    continue

                await self.process_document(task)

            except Exception as e:
                print(f"Worker Error: {e}")
                await asyncio.sleep(5)

    async def process_document(self, task):
        """æ ¸å¿ƒå¤„ç†ï¼šè½¬MD â†’ åˆ†å— â†’ åˆ†è¯ â†’ å‘é‡åŒ– â†’ å…¥åº“"""
        try:
            file_path = task['file_path']
            md_content = ""

            # A. è½¬æ¢ä¸º Markdown
            if task['file_type'] == 'pdf':
                md_content = pymupdf4llm.to_markdown(file_path, write_images=False)
            else:
                with open(file_path, 'r', encoding='utf-8') as f:
                    md_content = f.read()

            # B. æ™ºèƒ½åˆ†å—
            headers_split = MarkdownHeaderTextSplitter(
                [("#", "H1"), ("##", "H2"), ("###", "H3")]
            ).split_text(md_content)
            splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)
            chunks = splitter.split_documents(headers_split)
            chunk_texts = [c.page_content for c in chunks]

            # C. æ‰¹é‡å‘é‡åŒ–
            embeddings = await self.embedding_service.embed_batch(chunk_texts)

            # D. Jieba åˆ†è¯ + å…¥åº“
            insert_data = []
            for i, (text, vec) in enumerate(zip(chunk_texts, embeddings)):
                seg_text = " ".join(jieba.cut_for_search(text))
                insert_data.append((
                    task['id'], task['skill_id'], i, text, seg_text, str(vec)
                ))

            async with self.pool.acquire() as conn:
                async with conn.transaction():
                    await conn.executemany("""
                        INSERT INTO knowledge_chunks_v2
                        (document_id, skill_id, chunk_index, content, search_text_preprocessed, embedding)
                        VALUES ($1, $2, $3, $4, $5, $6)
                    """, insert_data)

                    await conn.execute("""
                        UPDATE knowledge_documents
                        SET status = 'completed', content_md = $1, updated_at = NOW()
                        WHERE id = $2
                    """, md_content, task['id'])

        except Exception as e:
            async with self.pool.acquire() as conn:
                await conn.execute("""
                    UPDATE knowledge_documents
                    SET status = 'failed', error_message = $1, updated_at = NOW()
                    WHERE id = $2
                """, str(e), task['id'])
```

### 2. æ–‡ä»¶å¤¹åŒæ­¥è„šæœ¬

**æ–‡ä»¶**: `apps/api/scripts/sync_knowledge.py`

```python
"""
Knowledge Folder Sync - æ¯æ—¥å‡Œæ™¨ 4:00 cron è§¦å‘
Usage: python scripts/sync_knowledge.py
"""
import asyncio
import hashlib
from pathlib import Path

SKILL_KNOWLEDGE_PATHS = {
    "bazi": "/home/aiscend/work/vibelife/knowledge/bazi",
    "zodiac": "/home/aiscend/work/vibelife/knowledge/zodiac",
    "mbti": "/home/aiscend/work/vibelife/knowledge/mbti"
}

SUPPORTED_EXTENSIONS = {'.pdf', '.md', '.txt'}

def compute_file_hash(filepath: str) -> str:
    with open(filepath, 'rb') as f:
        return hashlib.md5(f.read()).hexdigest()

async def sync_skill_folder(skill_id: str, folder_path: str, conn):
    """åŒæ­¥å•ä¸ªæŠ€èƒ½çš„çŸ¥è¯†æ–‡ä»¶å¤¹"""
    path = Path(folder_path)
    if not path.exists():
        print(f"âš ï¸  Folder not found: {folder_path}")
        return

    # 1. æ‰«ææ–‡ä»¶ç³»ç»Ÿ
    current_files = {}
    for f in path.iterdir():
        if f.suffix.lower() in SUPPORTED_EXTENSIONS:
            current_files[f.name] = {
                'path': str(f),
                'hash': compute_file_hash(str(f)),
                'type': f.suffix[1:].lower()
            }

    # 2. æŸ¥è¯¢æ•°æ®åº“ç°æœ‰è®°å½•
    db_records = await conn.fetch("""
        SELECT filename, file_hash, status FROM knowledge_documents
        WHERE skill_id = $1 AND status != 'archived'
    """, skill_id)
    db_files = {r['filename']: r for r in db_records}

    # 3. æ–°å¢æ–‡ä»¶ (æ–‡ä»¶ç³»ç»Ÿæœ‰ï¼ŒDBæ— )
    for filename, info in current_files.items():
        if filename not in db_files:
            await conn.execute("""
                INSERT INTO knowledge_documents
                (skill_id, filename, file_path, file_hash, file_type, status)
                VALUES ($1, $2, $3, $4, $5, 'pending')
            """, skill_id, filename, info['path'], info['hash'], info['type'])
            print(f"âœ… New: {filename}")

    # 4. ä¿®æ”¹æ–‡ä»¶ (hash å˜åŒ–)
    for filename, info in current_files.items():
        if filename in db_files and db_files[filename]['file_hash'] != info['hash']:
            # åˆ é™¤æ—§ chunksï¼Œé‡æ–°å…¥é˜Ÿ
            await conn.execute("""
                DELETE FROM knowledge_chunks_v2
                WHERE document_id = (SELECT id FROM knowledge_documents WHERE skill_id = $1 AND filename = $2)
            """, skill_id, filename)
            await conn.execute("""
                UPDATE knowledge_documents
                SET file_hash = $3, status = 'pending', updated_at = NOW()
                WHERE skill_id = $1 AND filename = $2
            """, skill_id, filename, info['hash'])
            print(f"ğŸ”„ Modified: {filename}")

    # 5. åˆ é™¤æ–‡ä»¶ (DBæœ‰ï¼Œæ–‡ä»¶ç³»ç»Ÿæ— ) â†’ è½¯åˆ é™¤/å½’æ¡£
    for filename, record in db_files.items():
        if filename not in current_files and record['status'] != 'archived':
            await conn.execute("""
                UPDATE knowledge_documents
                SET status = 'archived', updated_at = NOW()
                WHERE skill_id = $1 AND filename = $2
            """, skill_id, filename)
            print(f"ğŸ“¦ Archived: {filename}")

async def main():
    from stores.db import get_db_pool, close_db_pool
    pool = await get_db_pool()
    async with pool.acquire() as conn:
        for skill_id, folder in SKILL_KNOWLEDGE_PATHS.items():
            print(f"\nğŸ“‚ Syncing {skill_id}: {folder}")
            await sync_skill_folder(skill_id, folder, conn)
    await close_db_pool()
    print("\nâœ… Sync complete!")

if __name__ == "__main__":
    asyncio.run(main())
```

### 3. æ›´æ–° RetrievalService

**æ–‡ä»¶**: `apps/api/services/knowledge/retrieval.py` (ä¿®æ”¹)

```python
# ç§»é™¤ Python å±‚ RRFï¼Œæ”¹ç”¨ SQL å‡½æ•°
class RetrievalService:
    @classmethod
    async def search(cls, query: str, skill_id: str, top_k: int = 5) -> List[Dict]:
        # 1. Jieba åˆ†è¯
        query_seg = " ".join(jieba.cut(query))

        # 2. ç”Ÿæˆ query embedding
        query_embedding = await EmbeddingService.embed_query(query)

        # 3. è°ƒç”¨ SQL å‡½æ•° (RRF åœ¨æ•°æ®åº“å®Œæˆ)
        async with get_connection() as conn:
            results = await conn.fetch("""
                SELECT * FROM hybrid_search_v2($1, $2, $3, $4)
            """, query_seg, str(query_embedding), skill_id, top_k)

        return [dict(r) for r in results]
```

---

## Crontab é…ç½®

```cron
# æ–‡ä»¶: apps/api/scripts/crontab.example (è¿½åŠ )

# çŸ¥è¯†åº“æ–‡ä»¶å¤¹åŒæ­¥ - æ¯æ—¥å‡Œæ™¨ 4:00
0 4 * * * cd /home/aiscend/work/vibelife/apps/api && python3 scripts/sync_knowledge.py >> /var/log/vibelife/knowledge_sync.log 2>&1
```

---

## æ–°å¢ä¾èµ–

**æ–‡ä»¶**: `apps/api/requirements.txt` (è¿½åŠ )

```
jieba>=0.42.1              # ä¸­æ–‡åˆ†è¯
pymupdf4llm>=0.0.17        # PDF â†’ Markdown (ä¿ç•™è¡¨æ ¼)
langchain-text-splitters>=0.0.1  # æ™ºèƒ½åˆ†å—
```

---

## å®ç°ä»»åŠ¡æ¸…å• (æŒ‰é¡ºåº)

### Phase 1: æ•°æ®åº“è¿ç§»
- [ ] åˆ›å»º `migrations/002_knowledge_v2.sql`
- [ ] æ‰§è¡Œè¿ç§»ï¼šåˆ›å»º `knowledge_documents` è¡¨
- [ ] æ‰§è¡Œè¿ç§»ï¼šåˆ›å»º `knowledge_chunks_v2` è¡¨
- [ ] æ‰§è¡Œè¿ç§»ï¼šè¿ç§»æ—§ QA æ•°æ®
- [ ] æ‰§è¡Œè¿ç§»ï¼šè¿ç§»æ—§ chunks æ•°æ®
- [ ] æ‰§è¡Œè¿ç§»ï¼šåˆ›å»º `hybrid_search_v2` SQL å‡½æ•°
- [ ] éªŒè¯ç´¢å¼•ç”Ÿæ•ˆ

### Phase 2: Worker å®ç°
- [ ] å®‰è£…ä¾èµ–ï¼š`jieba`, `pymupdf4llm`, `langchain-text-splitters`
- [ ] åˆ›å»º `apps/api/workers/__init__.py`
- [ ] åˆ›å»º `apps/api/workers/ingestion.py`
- [ ] åœ¨ `main.py` lifespan ä¸­å¯åŠ¨ worker

### Phase 3: æ–‡ä»¶å¤¹åŒæ­¥
- [ ] åˆ›å»º `knowledge/` ç›®å½•ç»“æ„
- [ ] åˆ›å»º `scripts/sync_knowledge.py`
- [ ] æ·»åŠ åˆ° crontab

### Phase 4: æœåŠ¡é›†æˆ
- [ ] ä¿®æ”¹ `services/knowledge/retrieval.py` ä½¿ç”¨ SQL å‡½æ•°
- [ ] æ·»åŠ  jieba åˆ†è¯åˆ°æŸ¥è¯¢æµç¨‹
- [ ] ç§»é™¤ Python å±‚ RRF é€»è¾‘
- [ ] æ›´æ–° `knowledge_repo.py` é€‚é…æ–°è¡¨

### Phase 5: API æ¥å£ (å¯é€‰)
- [ ] POST `/knowledge/upload` - æ‰‹åŠ¨ä¸Šä¼ 
- [ ] GET `/knowledge/documents` - æ–‡æ¡£åˆ—è¡¨
- [ ] GET `/knowledge/documents/{id}/status` - å¤„ç†çŠ¶æ€

---

## å¾…ä¿®æ”¹æ–‡ä»¶æ¸…å•

| æ–‡ä»¶ | æ“ä½œ |
|------|------|
| `migrations/002_knowledge_v2.sql` | **æ–°å»º** |
| `apps/api/workers/__init__.py` | **æ–°å»º** |
| `apps/api/workers/ingestion.py` | **æ–°å»º** |
| `apps/api/scripts/sync_knowledge.py` | **æ–°å»º** |
| `apps/api/requirements.txt` | ä¿®æ”¹ (è¿½åŠ ä¾èµ–) |
| `apps/api/main.py` | ä¿®æ”¹ (å¯åŠ¨ worker) |
| `apps/api/services/knowledge/retrieval.py` | ä¿®æ”¹ (ä½¿ç”¨ SQL å‡½æ•°) |
| `apps/api/stores/knowledge_repo.py` | ä¿®æ”¹ (é€‚é…æ–°è¡¨) |
| `apps/api/scripts/crontab.example` | ä¿®æ”¹ (è¿½åŠ  cron)
