"""
SkillLoader v9 - æ¸è¿›å¼ Skill åŠ è½½å™¨

v9 æ¶æ„ï¼ˆéµå¾ª Claude Agent SDK åŸåˆ™ï¼‰ï¼š
- Core Skill å…¨ç¨‹æ¿€æ´»ï¼Œå…¨æ–‡åŠ è½½
- å…¶ä»– Skill æ¸è¿›å¼åŠ è½½ï¼š
  - Phase 1: åªåŠ è½½ frontmatterï¼ˆSkillMetaï¼‰
  - Phase 2: æŒ‰éœ€åŠ è½½å®Œæ•´å†…å®¹ï¼ˆSkillFullï¼‰
- æ”¯æŒå¤š Skill å¹¶è¡Œæ¿€æ´»
- LLM è‡ªä¸»ç¼–æ’ï¼Œåˆ é™¤ç¡¬ç¼–ç è·¯ç”±

v7 æ¶æ„ï¼ˆä¿ç•™å…¼å®¹ï¼‰ï¼š
- SKILL.md: æ ¸å¿ƒå®šä¹‰ï¼ˆä¸“å®¶èº«ä»½ã€èƒ½åŠ›ç´¢å¼•ã€ä¼¦ç†è¾¹ç•Œï¼‰
- rules/*.md: è§„åˆ™æ–‡ä»¶ï¼ˆåˆ†æè¦ç‚¹ã€è¾“å‡ºè¦æ±‚ã€å¸¸è§é—®é¢˜ï¼‰
- scenarios/*.md: (æ—§æ¶æ„å…¼å®¹) MiniSkill åœºæ™¯æ–‡ä»¶
- tools/*.py: å·¥å…·å®šä¹‰ï¼ˆæ”¶é›†/è®¡ç®—/å±•ç¤º/æ£€ç´¢ï¼‰

v7.4 æ–°å¢ï¼š
- Skill Management æ”¯æŒï¼šcategory, pricing, showcase, subscription å­—æ®µ

v7.5 æ–°å¢ï¼š
- æ•°æ®åº“ä¼˜å…ˆå…ƒæ•°æ®åŠ è½½ï¼ˆskill_catalog è¡¨ï¼‰
- async å‡½æ•°æ”¯æŒï¼šload_skill_metadata_async, get_all_skill_metadata_async
- SKILL.md ä½œä¸º fallback
"""
import re
import json
import logging
import yaml
from pathlib import Path
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any
from functools import lru_cache

logger = logging.getLogger(__name__)

SKILLS_DIR = Path(__file__).parent.parent.parent / "skills"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# æ•°æ®ç»“æ„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class SkillPricing:
    """Skill å®šä»·é…ç½®"""
    type: str = "free"  # free | premium | credits
    trial_messages: int = 3
    credits_per_use: Optional[int] = None


@dataclass
class SkillShowcase:
    """Skill å±•ç¤ºé…ç½®ï¼ˆç”¨äº Skill å¸‚åœºï¼‰"""
    tagline: str = ""
    highlights: List[str] = field(default_factory=list)
    preview_image: Optional[str] = None
    demo_prompts: List[str] = field(default_factory=list)


@dataclass
class SkillSubscription:
    """Skill è®¢é˜…é…ç½®"""
    auto_subscribe: bool = False
    can_unsubscribe: bool = True
    push_default: bool = True
    min_subscription_days: int = 0


@dataclass
class SkillFeature:
    """Skill åŠŸèƒ½ç‰¹æ€§"""
    name: str
    description: str = ""
    icon: str = "ğŸ“Œ"
    tier: str = "free"  # free | basic | premium


@dataclass
class SkillMetadata:
    """Skill å…ƒæ•°æ®ï¼ˆç”¨äº Skill Management APIï¼‰"""
    id: str
    name: str
    description: str
    version: str = "1.0.0"
    category: str = "professional"  # core | default | professional
    icon: str = "ğŸ’¡"
    color: str = "#6B7280"
    triggers: List[str] = field(default_factory=list)
    pricing: SkillPricing = field(default_factory=SkillPricing)
    features: List[SkillFeature] = field(default_factory=list)
    showcase: SkillShowcase = field(default_factory=SkillShowcase)
    subscription: SkillSubscription = field(default_factory=SkillSubscription)

    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸º API å“åº”æ ¼å¼"""
        return {
            "id": self.id,
            "name": self.name,
            "description": self.description,
            "version": self.version,
            "category": self.category,
            "icon": self.icon,
            "color": self.color,
            "triggers": self.triggers,
            "pricing": {
                "type": self.pricing.type,
                "trial_messages": self.pricing.trial_messages,
                "credits_per_use": self.pricing.credits_per_use,
            },
            "features": [
                {"name": f.name, "description": f.description, "icon": f.icon, "tier": f.tier}
                for f in self.features
            ],
            "showcase": {
                "tagline": self.showcase.tagline,
                "highlights": self.showcase.highlights,
                "preview_image": self.showcase.preview_image,
                "demo_prompts": self.showcase.demo_prompts,
            },
            "subscription": {
                "auto_subscribe": self.subscription.auto_subscribe,
                "can_unsubscribe": self.subscription.can_unsubscribe,
                "push_default": self.subscription.push_default,
            },
        }


@dataclass
class SkillConfig:
    """Skill æ ¸å¿ƒé…ç½®ï¼ˆä» SKILL.md åŠ è½½ï¼‰"""
    id: str
    name: str
    description: str
    expert_persona: str
    scenarios: Dict[str, List[str]]  # {entry: [...], standard: [...], professional: [...]}
    ethics: Dict[str, Any]
    tools: List[str]
    default_scenario: str = "basic_reading"
    triggers: List[str] = field(default_factory=list)
    global_tools: List[str] = field(default_factory=list)  # éœ€è¦çš„å…¨å±€å·¥å…·
    # v7.1: SOP é…ç½®é©±åŠ¨
    requires_birth_info: bool = False  # æ˜¯å¦éœ€è¦å‡ºç”Ÿä¿¡æ¯
    requires_compute: bool = False     # æ˜¯å¦éœ€è¦è®¡ç®—ï¼ˆæ’ç›˜ï¼‰
    compute_type: Optional[str] = None # è®¡ç®—ç±»å‹ï¼šbazi/zodiac/tarotï¼ŒNone è¡¨ç¤ºä½¿ç”¨è‡ªèº«
    compute_tool: Optional[str] = None # è®¡ç®—å·¥å…·åï¼ŒNone æ—¶ä½¿ç”¨é»˜è®¤çº¦å®š calculate_{compute_type}
    collect_tool: Optional[str] = None # æ”¶é›†å·¥å…·åï¼ŒNone æ—¶ä½¿ç”¨é»˜è®¤çº¦å®š request_info
    external_tools: List[str] = field(default_factory=list)  # v7.3: ä»å…¶ä»– skill å¯¼å…¥çš„å·¥å…·
    # v2.2: Profile æ³¨å…¥é…ç½®
    requires_skill_data: List[str] = field(default_factory=list)  # éœ€è¦çš„ skill_dataï¼Œç©ºåˆ—è¡¨è¡¨ç¤ºåªéœ€è‡ªèº«


@dataclass
class ServiceItem:
    """æœåŠ¡é¡¹ï¼ˆç”¨äºæœåŠ¡ç›®å½•å±•ç¤ºï¼‰"""
    scenario_id: str
    name: str
    icon: str
    description: str
    tier: str  # entry/standard/professional
    billing: str  # å…è´¹/åŸºç¡€/é«˜çº§
    highlights: List[str] = field(default_factory=list)  # ä»·å€¼ç‚¹


@dataclass
class ScenarioConfig:
    """åœºæ™¯é…ç½®ï¼ˆä» scenarios/*.md åŠ è½½ï¼‰"""
    id: str
    name: str
    level: str  # entry/standard/professional
    billing: str  # free/basic/premium
    description: str
    triggers: Dict[str, List[str]]  # {primary: [...], secondary: [...]}
    prerequisites: List[str]
    sop: List[Dict[str, Any]]  # SOP é˜¶æ®µåˆ—è¡¨
    knowledge_config: Dict[str, Any]  # çŸ¥è¯†æ£€ç´¢é…ç½®
    output_config: Dict[str, Any]  # è¾“å‡ºé…ç½®
    tools: List[str]


@dataclass
class ToolMetadata:
    """å·¥å…·å…ƒæ•°æ®"""
    name: str
    description: str
    tool_type: str  # collect/calculate/display/search
    card_type: Optional[str] = None
    card_props_schema: Optional[Dict] = None
    parameters: Dict[str, Any] = field(default_factory=dict)
    when_to_call: Optional[str] = None


@dataclass
class RuleConfig:
    """è§„åˆ™é…ç½®ï¼ˆä» rules/*.md åŠ è½½ï¼‰- v7 æ–°å¢"""
    id: str
    name: str
    impact: str  # CRITICAL/HIGH/MEDIUM/LOW
    impact_description: str
    tags: List[str]
    content: str  # å®Œæ•´çš„è§„åˆ™å†…å®¹
    analysis_steps: List[Dict[str, Any]]  # åˆ†æè¦ç‚¹è¡¨æ ¼
    output_requirements: str  # è¾“å‡ºè¦æ±‚
    common_questions: str  # å¸¸è§é—®é¢˜


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# V9: æ¸è¿›å¼åŠ è½½æ•°æ®ç»“æ„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class SkillMeta:
    """Skill å…ƒæ•°æ®æ‘˜è¦ï¼ˆPhase 1 å±•ç¤ºï¼‰- V9 æ–°å¢

    åªåŒ…å« frontmatter ä¿¡æ¯ï¼Œç”¨äº Phase 1 è·¯ç”±ã€‚
    description å†…åµŒå·¥å…·åˆ—è¡¨ï¼Œtools_list ä¸ºä» tools.yaml æŠ½å–çš„æœºå™¨å¯è¯»æ¸…å•ã€‚
    """
    id: str
    name: str
    description: str  # å†…å«å·¥å…·åˆ—è¡¨ï¼Œå¦‚ "æ˜Ÿç›˜è®¡ç®—ä¸è§£è¯»ã€‚å·¥å…·ï¼šcalculate_zodiac, show_zodiac_chart"
    triggers: List[str] = field(default_factory=list)
    category: str = "professional"
    tools_list: List[str] = field(default_factory=list)


@dataclass
class ToolDef:
    """å·¥å…·å®šä¹‰ï¼ˆç”¨äº SkillFullï¼‰- V9 æ–°å¢"""
    name: str
    description: str
    parameters: Dict[str, Any] = field(default_factory=dict)
    tool_type: str = "action"  # routing/collect/action/search/display/trigger


@dataclass
class SkillFull:
    """Skill å®Œæ•´å†…å®¹ï¼ˆPhase 2 åŠ è½½ï¼‰- V9 æ–°å¢

    åŒ…å« SKILL.md å…¨æ–‡ã€å·¥å…·å®šä¹‰ã€è§„åˆ™æ–‡ä»¶ã€‚
    """
    meta: SkillMeta
    content: str  # SKILL.md å…¨æ–‡ï¼ˆä¸å« frontmatterï¼‰
    tools: List[ToolDef] = field(default_factory=list)
    rules: Dict[str, str] = field(default_factory=dict)  # rule_id -> content


# V9: Core Skill å…¨å±€ç¼“å­˜
_core_skill_cache: Optional[SkillFull] = None

# V9: æ‰€æœ‰ Skill Meta ç¼“å­˜
_skill_metas_cache: Optional[Dict[str, SkillMeta]] = None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# è§£æå‡½æ•°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def parse_frontmatter(text: str) -> tuple[Dict, str]:
    """è§£æ YAML frontmatterï¼ˆæ”¯æŒåµŒå¥—å¯¹è±¡ï¼‰"""
    pattern = r'^---\s*\n(.*?)\n---\s*\n(.*)$'
    match = re.match(pattern, text, re.DOTALL)
    if not match:
        return {}, text

    frontmatter_str, content = match.groups()

    # ä½¿ç”¨ YAML è§£æä»¥æ”¯æŒåµŒå¥—å¯¹è±¡
    try:
        metadata = yaml.safe_load(frontmatter_str) or {}
    except yaml.YAMLError as e:
        logger.warning(f"YAML parse error in frontmatter: {e}, falling back to simple parse")
        # å›é€€åˆ°ç®€å•è§£æ
        metadata = {}
        current_key = None
        current_list = None

        for line in frontmatter_str.strip().split('\n'):
            stripped = line.strip()
            if not stripped:
                continue
            if stripped.startswith('- ') and current_key:
                if current_list is None:
                    current_list = []
                current_list.append(stripped[2:].strip())
                metadata[current_key] = current_list
            elif ':' in line and not line.startswith(' '):
                current_list = None
                key, value = line.split(':', 1)
                current_key = key.strip()
                value = value.strip()
                if value in ('|', ''):
                    continue
                elif value.lower() == 'true':
                    metadata[current_key] = True
                elif value.lower() == 'false':
                    metadata[current_key] = False
                else:
                    metadata[current_key] = value

    return metadata, content.strip()


def parse_skill_md(text: str) -> Dict[str, Any]:
    """è§£æ SKILL.md å†…å®¹ï¼Œæå–ç»“æ„åŒ–ä¿¡æ¯

    æ”¯æŒä¸¤ç§è§¦å‘è¯æ ¼å¼ï¼š
    1. æ—§æ ¼å¼ï¼šfrontmatter ä¸­çš„ triggers: åˆ—è¡¨
    2. æ–°æ ¼å¼ï¼šdescription ä¸­çš„ "è§¦å‘è¯ï¼šxxxã€xxxã€xxx"
    """
    metadata, content = parse_frontmatter(text)

    # ä» frontmatter è·å–è§¦å‘è¯ï¼ˆæ—§æ ¼å¼ï¼‰
    triggers = metadata.get("triggers", [])

    # å¦‚æœ frontmatter æ²¡æœ‰ triggersï¼Œå°è¯•ä» description ä¸­æå–ï¼ˆæ–°æ ¼å¼ï¼‰
    if not triggers:
        description = metadata.get("description", "")
        # åŒ¹é… "è§¦å‘è¯ï¼šxxxã€xxxã€xxx" æˆ– "è§¦å‘è¯:xxx,xxx,xxx"
        trigger_match = re.search(r'è§¦å‘è¯[ï¼š:]\s*([^ã€‚.]+)', description)
        if trigger_match:
            trigger_str = trigger_match.group(1)
            # æ”¯æŒé¡¿å·ã€é€—å·åˆ†éš”
            triggers = [t.strip() for t in re.split(r'[ã€,ï¼Œ]', trigger_str) if t.strip()]

    result = {
        "id": metadata.get("id", ""),
        "name": metadata.get("name", ""),
        "description": metadata.get("description", ""),
        "triggers": triggers,
        "default_scenario": metadata.get("default_scenario", "basic_reading"),
        "global_tools": metadata.get("global_tools", []),  # ä» frontmatter è¯»å–
        # v7.1: SOP é…ç½®é©±åŠ¨
        "requires_birth_info": metadata.get("requires_birth_info", False),
        "requires_compute": metadata.get("requires_compute", False),
        "compute_type": metadata.get("compute_type", None),
        "compute_tool": metadata.get("compute_tool", None),
        "collect_tool": metadata.get("collect_tool", None),
        "external_tools": metadata.get("external_tools", []),  # v7.3
        # v2.2: Profile æ³¨å…¥é…ç½®
        "requires_skill_data": metadata.get("requires_skill_data", []),
    }

    # æå–ä¸“å®¶èº«ä»½
    expert_match = re.search(r'## ä¸“å®¶èº«ä»½\s*\n(.*?)(?=\n## |\Z)', content, re.DOTALL)
    result["expert_persona"] = expert_match.group(1).strip() if expert_match else ""

    # æå–åœºæ™¯ç›®å½•
    scenarios = {"entry": [], "standard": [], "professional": []}
    for level in scenarios.keys():
        pattern = rf'### {level.capitalize()}.*?\n\|.*?\n\|.*?\n((?:\|.*?\n)*)'
        match = re.search(pattern, content, re.IGNORECASE | re.DOTALL)
        if match:
            for row in match.group(1).strip().split('\n'):
                cols = [c.strip() for c in row.split('|')[1:-1]]
                if len(cols) >= 2:
                    scenarios[level].append(cols[1])  # æ–‡ä»¶å
    result["scenarios"] = scenarios

    # æå–ä¼¦ç†è¾¹ç•Œ
    ethics = {"forbidden": [], "sensitive": [], "principles": []}
    forbidden_match = re.search(r'### ç»å¯¹ç¦æ­¢\s*\n((?:- .*?\n)*)', content)
    if forbidden_match:
        ethics["forbidden"] = [l[2:].strip() for l in forbidden_match.group(1).strip().split('\n')]
    result["ethics"] = ethics

    # æå–å·¥å…·åˆ—è¡¨
    tools = []
    tools_match = re.search(r'## å·¥å…·åˆ—è¡¨\s*\n\|.*?\n\|.*?\n((?:\|.*?\n)*)', content)
    if tools_match:
        for row in tools_match.group(1).strip().split('\n'):
            cols = [c.strip() for c in row.split('|')[1:-1]]
            if len(cols) >= 1:
                tools.append(cols[0])
    result["tools"] = tools

    return result


def parse_scenario_md(text: str) -> Dict[str, Any]:
    """è§£æ scenario.md å†…å®¹"""
    metadata, content = parse_frontmatter(text)

    result = {
        "id": metadata.get("id", ""),
        "name": metadata.get("name", ""),
        "level": metadata.get("level", "entry"),
        "billing": metadata.get("billing", "free"),
        "description": metadata.get("description", ""),
    }

    # æå–è§¦å‘æ¡ä»¶
    triggers = {"primary": [], "secondary": []}
    primary_match = re.search(r'\*\*ä¸»è¦è§¦å‘è¯\*\*:\s*(.*?)(?:\n|$)', content)
    if primary_match:
        triggers["primary"] = [t.strip() for t in primary_match.group(1).split(',')]
    secondary_match = re.search(r'\*\*æ¬¡è¦è§¦å‘è¯\*\*:\s*(.*?)(?:\n|$)', content)
    if secondary_match:
        triggers["secondary"] = [t.strip() for t in secondary_match.group(1).split(',')]
    result["triggers"] = triggers

    # æå–å‰ç½®è¦æ±‚
    prereq_match = re.search(r'## å‰ç½®è¦æ±‚\s*\n((?:- .*?\n)*)', content)
    result["prerequisites"] = []
    if prereq_match:
        result["prerequisites"] = [l[2:].strip() for l in prereq_match.group(1).strip().split('\n')]

    # æå– SOP é˜¶æ®µ
    sop = []
    phase_pattern = r'### Phase (\d+):\s*(.*?)\n(.*?)(?=### Phase|\Z)'
    for match in re.finditer(phase_pattern, content, re.DOTALL):
        phase_num, phase_name, phase_content = match.groups()
        phase = {
            "phase": int(phase_num),
            "name": phase_name.strip(),
            "content": phase_content.strip()
        }
        # æå–ç±»å‹
        type_match = re.search(r'\*\*ç±»å‹\*\*:\s*(\w+)', phase_content)
        if type_match:
            phase["type"] = type_match.group(1)
        sop.append(phase)
    result["sop"] = sop

    # æå–å·¥å…·åˆ—è¡¨
    tools_match = re.search(r'\*\*ä½¿ç”¨å·¥å…·\*\*:\s*\n((?:- .*?\n)*)', content)
    result["tools"] = []
    if tools_match:
        result["tools"] = [l[2:].strip() for l in tools_match.group(1).strip().split('\n')]

    # çŸ¥è¯†æ£€ç´¢é…ç½®
    result["knowledge_config"] = {}
    result["output_config"] = {}

    return result


def parse_rule_md(text: str) -> Dict[str, Any]:
    """è§£æ rules/*.md å†…å®¹ - v7 æ–°å¢"""
    metadata, content = parse_frontmatter(text)

    # è§£æ tagsï¼ˆæ”¯æŒé€—å·åˆ†éš”çš„å­—ç¬¦ä¸²æˆ–åˆ—è¡¨ï¼‰
    tags_raw = metadata.get("tags", [])
    if isinstance(tags_raw, str):
        tags = [t.strip() for t in re.split(r'[,ï¼Œã€]', tags_raw) if t.strip()]
    else:
        tags = tags_raw

    result = {
        "id": metadata.get("id", ""),
        "name": metadata.get("name", ""),
        "impact": metadata.get("impact", "MEDIUM"),
        "impact_description": metadata.get("impactDescription", ""),
        "tags": tags,
        "content": content,
    }

    # æå–åˆ†æè¦ç‚¹è¡¨æ ¼
    analysis_steps = []
    table_match = re.search(r'## åˆ†æè¦ç‚¹\s*\n\|[^\n]+\n\|[-\s|]+\n((?:\|[^\n]+\n)*)', content)
    if table_match:
        for row in table_match.group(1).strip().split('\n'):
            cols = [c.strip() for c in row.split('|')[1:-1]]
            if len(cols) >= 4:
                analysis_steps.append({
                    "step": cols[0],
                    "point": cols[1],
                    "query": cols[2],
                    "priority": cols[3],
                })
    result["analysis_steps"] = analysis_steps

    # æå–è¾“å‡ºè¦æ±‚
    output_match = re.search(r'## è¾“å‡ºè¦æ±‚\s*\n(.*?)(?=\n## |\Z)', content, re.DOTALL)
    result["output_requirements"] = output_match.group(1).strip() if output_match else ""

    # æå–å¸¸è§é—®é¢˜
    faq_match = re.search(r'## å¸¸è§é—®é¢˜\s*\n(.*?)(?=\n## |\Z)', content, re.DOTALL)
    result["common_questions"] = faq_match.group(1).strip() if faq_match else ""

    return result


def parse_skill_services(text: str) -> Dict[str, List[Dict[str, Any]]]:
    """è§£æ SKILL.md ä¸­çš„æœåŠ¡ç›®å½•ï¼Œæå–å±•ç¤ºä¿¡æ¯"""
    services = {"entry": [], "standard": [], "professional": []}

    tier_map = {
        "entry": "entry",
        "standard": "standard",
        "professional": "professional"
    }

    for tier_name, tier_key in tier_map.items():
        # åŒ¹é…è¡¨æ ¼å¤´å’Œå†…å®¹
        pattern = rf'### {tier_name.capitalize()}.*?\n\|[^\n]+\n\|[-\s|]+\n((?:\|[^\n]+\n)*)'
        match = re.search(pattern, text, re.IGNORECASE | re.DOTALL)
        if not match:
            continue

        table_content = match.group(1).strip()
        if not table_content:
            continue

        for row in table_content.split('\n'):
            cols = [c.strip() for c in row.split('|')[1:-1]]
            if len(cols) < 7:  # è‡³å°‘éœ€è¦ 7 åˆ—ï¼ˆåœºæ™¯ã€æ–‡ä»¶ã€è§¦å‘è¯ã€è®¡è´¹ã€å±•ç¤ºåç§°ã€å›¾æ ‡ã€ç®€ä»‹ï¼‰
                continue

            service = {
                "scenario_id": cols[1].replace('.md', '') if cols[1] else cols[0].lower().replace(' ', '_'),
                "name": cols[4] if len(cols) > 4 and cols[4] else cols[0],
                "icon": cols[5] if len(cols) > 5 and cols[5] else "ğŸ“Œ",
                "description": cols[6] if len(cols) > 6 and cols[6] else "",
                "tier": tier_key,
                "billing": cols[3] if len(cols) > 3 else "å…è´¹",
                "highlights": []
            }

            # è§£æä»·å€¼ç‚¹ï¼ˆç¬¬8åˆ—ï¼Œå¦‚æœå­˜åœ¨ï¼‰
            if len(cols) > 7 and cols[7]:
                service["highlights"] = [h.strip() for h in cols[7].split(',')]

            services[tier_key].append(service)

    return services


def get_skill_services(skill_id: str) -> Optional[Dict[str, Any]]:
    """è·å– Skill çš„æœåŠ¡ç›®å½•æ•°æ®ï¼ˆç”¨äº show_skill_services å·¥å…·ï¼‰"""
    skill_path = SKILLS_DIR / skill_id / "SKILL.md"
    if not skill_path.exists():
        return None

    text = skill_path.read_text(encoding='utf-8')
    metadata, _ = parse_frontmatter(text)
    services = parse_skill_services(text)

    return {
        "skill_id": skill_id,
        "skill_name": metadata.get("name", skill_id),
        "description": metadata.get("description", ""),
        "services": services
    }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# åŠ è½½å‡½æ•°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@lru_cache(maxsize=32)
def load_skill(skill_id: str) -> Optional[SkillConfig]:
    """åŠ è½½ Skill æ ¸å¿ƒé…ç½®"""
    skill_path = SKILLS_DIR / skill_id / "SKILL.md"
    if not skill_path.exists():
        return None

    text = skill_path.read_text(encoding='utf-8')
    data = parse_skill_md(text)

    return SkillConfig(
        id=data.get("id", skill_id),
        name=data.get("name", skill_id),
        description=data.get("description", ""),
        expert_persona=data.get("expert_persona", ""),
        scenarios=data.get("scenarios", {}),
        ethics=data.get("ethics", {}),
        tools=data.get("tools", []),
        default_scenario=data.get("default_scenario", "basic_reading"),
        triggers=data.get("triggers", []),
        global_tools=data.get("global_tools", []),
        # v7.1: SOP é…ç½®é©±åŠ¨
        requires_birth_info=data.get("requires_birth_info", False),
        requires_compute=data.get("requires_compute", False),
        compute_type=data.get("compute_type", None),
        compute_tool=data.get("compute_tool", None),
        collect_tool=data.get("collect_tool", None),
        external_tools=data.get("external_tools", []),  # v7.3
        # v2.2: Profile æ³¨å…¥é…ç½®
        requires_skill_data=data.get("requires_skill_data", []),
    )


@lru_cache(maxsize=32)
def load_skill_metadata(skill_id: str) -> Optional[SkillMetadata]:
    """åŠ è½½ Skill å…ƒæ•°æ®ï¼ˆç”¨äº Skill Management APIï¼‰- v7.4 æ–°å¢

    ä» SKILL.md çš„ frontmatter ä¸­è¯»å–å®Œæ•´çš„å…ƒæ•°æ®é…ç½®ï¼Œ
    åŒ…æ‹¬ category, pricing, showcase, subscription ç­‰å­—æ®µã€‚
    """
    skill_path = SKILLS_DIR / skill_id / "SKILL.md"
    if not skill_path.exists():
        return None

    text = skill_path.read_text(encoding='utf-8')
    metadata, _ = parse_frontmatter(text)

    # ä» description ä¸­æå–è§¦å‘è¯ï¼ˆå¦‚æœ frontmatter ä¸­æ²¡æœ‰ï¼‰
    triggers = metadata.get("triggers", [])
    if not triggers:
        description = metadata.get("description", "")
        trigger_match = re.search(r'è§¦å‘è¯[ï¼š:]\s*([^ã€‚.]+)', description)
        if trigger_match:
            trigger_str = trigger_match.group(1)
            triggers = [t.strip() for t in re.split(r'[ã€,ï¼Œ]', trigger_str) if t.strip()]

    # è§£æ pricing
    pricing_data = metadata.get("pricing", {})
    pricing = SkillPricing(
        type=pricing_data.get("type", "free") if isinstance(pricing_data, dict) else "free",
        trial_messages=pricing_data.get("trial_messages", 3) if isinstance(pricing_data, dict) else 3,
        credits_per_use=pricing_data.get("credits_per_use") if isinstance(pricing_data, dict) else None,
    )

    # è§£æ features
    features_data = metadata.get("features", [])
    features = []
    if isinstance(features_data, list):
        for f in features_data:
            if isinstance(f, dict):
                features.append(SkillFeature(
                    name=f.get("name", ""),
                    description=f.get("description", ""),
                    icon=f.get("icon", "ğŸ“Œ"),
                    tier=f.get("tier", "free"),
                ))

    # è§£æ showcase
    showcase_data = metadata.get("showcase", {})
    showcase = SkillShowcase(
        tagline=showcase_data.get("tagline", "") if isinstance(showcase_data, dict) else "",
        highlights=showcase_data.get("highlights", []) if isinstance(showcase_data, dict) else [],
        preview_image=showcase_data.get("preview_image") if isinstance(showcase_data, dict) else None,
        demo_prompts=showcase_data.get("demo_prompts", []) if isinstance(showcase_data, dict) else [],
    )

    # è§£æ subscription
    subscription_data = metadata.get("subscription", {})
    category = metadata.get("category", "professional")
    subscription = SkillSubscription(
        auto_subscribe=subscription_data.get("auto_subscribe", category == "default") if isinstance(subscription_data, dict) else (category == "default"),
        can_unsubscribe=subscription_data.get("can_unsubscribe", category != "core") if isinstance(subscription_data, dict) else (category != "core"),
        push_default=subscription_data.get("push_default", True) if isinstance(subscription_data, dict) else True,
        min_subscription_days=subscription_data.get("min_subscription_days", 0) if isinstance(subscription_data, dict) else 0,
    )

    return SkillMetadata(
        id=metadata.get("id", skill_id),
        name=metadata.get("name", skill_id),
        description=metadata.get("description", ""),
        version=metadata.get("version", "1.0.0"),
        category=category,
        icon=metadata.get("icon", "ğŸ’¡"),
        color=metadata.get("color", "#6B7280"),
        triggers=triggers,
        pricing=pricing,
        features=features,
        showcase=showcase,
        subscription=subscription,
    )


def get_all_skill_metadata() -> List[SkillMetadata]:
    """è·å–æ‰€æœ‰å¯ç”¨ Skill çš„å…ƒæ•°æ®ï¼ˆç”¨äº Skill åˆ—è¡¨ APIï¼‰- v7.4 æ–°å¢"""
    skills = []
    for skill_id in get_available_skills():
        metadata = load_skill_metadata(skill_id)
        if metadata:
            skills.append(metadata)
    return skills


def get_skills_by_category(category: str) -> List[SkillMetadata]:
    """æŒ‰åˆ†ç±»è·å– Skill åˆ—è¡¨ - v7.4 æ–°å¢

    Args:
        category: core | default | professional

    Returns:
        è¯¥åˆ†ç±»ä¸‹æ‰€æœ‰ Skill çš„å…ƒæ•°æ®åˆ—è¡¨
    """
    return [s for s in get_all_skill_metadata() if s.category == category]


@lru_cache(maxsize=64)
def load_scenario(skill_id: str, scenario_id: str) -> Optional[ScenarioConfig]:
    """åŠ è½½åœºæ™¯é…ç½®"""
    scenario_path = SKILLS_DIR / skill_id / "scenarios" / f"{scenario_id}.md"
    if not scenario_path.exists():
        return None

    text = scenario_path.read_text(encoding='utf-8')
    data = parse_scenario_md(text)

    return ScenarioConfig(
        id=data.get("id", scenario_id),
        name=data.get("name", scenario_id),
        level=data.get("level", "entry"),
        billing=data.get("billing", "free"),
        description=data.get("description", ""),
        triggers=data.get("triggers", {}),
        prerequisites=data.get("prerequisites", []),
        sop=data.get("sop", []),
        knowledge_config=data.get("knowledge_config", {}),
        output_config=data.get("output_config", {}),
        tools=data.get("tools", [])
    )


@lru_cache(maxsize=128)
def load_rule(skill_id: str, rule_id: str) -> Optional[RuleConfig]:
    """åŠ è½½è§„åˆ™é…ç½® - v7 æ–°å¢

    æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
    1. æ ¹ç›®å½•è§„åˆ™: rule_id="dankoe" -> rules/dankoe.md
    2. å­ç›®å½•è§„åˆ™: rule_id="companion/weekly-review" -> rules/companion/weekly-review.md

    å®¹é”™å¤„ç†ï¼š
    - è‡ªåŠ¨å¤„ç†å·²å¸¦ .md åç¼€çš„ rule_id
    - æ‹’ç»ç›®å½•è·¯å¾„
    """
    # å…ˆå°è¯•æ ‡å‡†æ ¼å¼ï¼ˆè‡ªåŠ¨æ·»åŠ  .md åç¼€ï¼‰
    rule_path = SKILLS_DIR / skill_id / "rules" / f"{rule_id}.md"

    if not rule_path.exists():
        # Fallback: å°è¯•ç›´æ¥ä½œä¸ºè·¯å¾„ï¼ˆå¤„ç†å·²å¸¦ .md åç¼€çš„æƒ…å†µï¼‰
        rule_path = SKILLS_DIR / skill_id / "rules" / rule_id

        # æ‹’ç»ç›®å½•
        if rule_path.is_dir():
            logger.warning(f"load_rule: {rule_id} is a directory, not a rule file")
            return None

        # å¦‚æœæ²¡æœ‰åç¼€ï¼Œæ·»åŠ  .md
        if not rule_path.suffix:
            rule_path = rule_path.with_suffix(".md")

        # ä»ç„¶ä¸å­˜åœ¨ï¼Œè¿”å› None
        if not rule_path.exists():
            return None

    try:
        text = rule_path.read_text(encoding='utf-8')
        data = parse_rule_md(text)

        return RuleConfig(
            id=data.get("id", rule_id),
            name=data.get("name", rule_id),
            impact=data.get("impact", "MEDIUM"),
            impact_description=data.get("impact_description", ""),
            tags=data.get("tags", []),
            content=data.get("content", ""),
            analysis_steps=data.get("analysis_steps", []),
            output_requirements=data.get("output_requirements", ""),
            common_questions=data.get("common_questions", ""),
        )
    except Exception as e:
        logger.error(f"load_rule: Failed to load {skill_id}/{rule_id}: {e}")
        return None


def get_skill_rules(skill_id: str) -> List[str]:
    """è·å– Skill çš„æ‰€æœ‰è§„åˆ™ ID - v7 æ–°å¢

    è¿”å›æ ¼å¼ï¼š
    - æ ¹ç›®å½•è§„åˆ™: "dankoe"
    - å­ç›®å½•è§„åˆ™: "companion/weekly-review"
    """
    rules_dir = SKILLS_DIR / skill_id / "rules"
    if not rules_dir.exists():
        return []

    rule_ids = []

    # é€’å½’æŸ¥æ‰¾æ‰€æœ‰ .md æ–‡ä»¶ï¼ˆæ”¯æŒå­ç›®å½•ï¼‰
    for md_file in rules_dir.rglob("*.md"):
        # è·³è¿‡ _index.md ç­‰
        if md_file.stem.startswith("_"):
            continue

        # è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼ˆå»æ‰ .md æ‰©å±•åï¼‰
        relative_path = md_file.relative_to(rules_dir)
        rule_id = str(relative_path.with_suffix(""))

        # è½¬æ¢ Windows è·¯å¾„åˆ†éš”ç¬¦ä¸º Unix æ ¼å¼
        rule_id = rule_id.replace("\\", "/")

        rule_ids.append(rule_id)

    return sorted(rule_ids)


def has_rules(skill_id: str) -> bool:
    """æ£€æŸ¥ Skill æ˜¯å¦ä½¿ç”¨ rules æ¶æ„ - v7 æ–°å¢"""
    rules_dir = SKILLS_DIR / skill_id / "rules"
    if not rules_dir.exists():
        return False
    rules = list(rules_dir.glob("*.md"))
    return len(rules) > 0


def get_available_skills() -> List[str]:
    """è·å–æ‰€æœ‰å¯ç”¨çš„ Skill"""
    if not SKILLS_DIR.exists():
        return []
    return [p.name for p in SKILLS_DIR.iterdir()
            if p.is_dir() and (p / "SKILL.md").exists()]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Protocol/Rule å…ƒä¿¡æ¯ï¼ˆç”¨äºæ¶ˆé™¤ç¡¬ç¼–ç ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@lru_cache(maxsize=32)
def get_protocols_meta(skill_id: str) -> Dict[str, Dict[str, Any]]:
    """æ‰«æ rules é¡¶å±‚ .md ä½œä¸ºâ€œåè®®â€ï¼Œè§£æ frontmatter è¿”å› meta æ˜ å°„ã€‚

    è¿”å›: {protocol_id: {id, name, estimated_time?, total_steps?, order?, enabled?}}
    ä»…æ‰«æè§„åˆ™æ ¹ç›®å½•ï¼Œå¿½ç•¥å­ç›®å½•ï¼ˆå¦‚ companion/ï¼‰ã€‚
    """
    rules_dir = SKILLS_DIR / skill_id / "rules"
    metas: Dict[str, Dict[str, Any]] = {}
    if not rules_dir.exists():
        return metas

    for md in rules_dir.glob("*.md"):
        if md.stem.startswith("_"):
            continue
        try:
            text = md.read_text(encoding="utf-8")
            fm, _ = parse_frontmatter(text)
            pid = fm.get("id", md.stem)
            metas[pid] = {
                "id": pid,
                "name": fm.get("name", pid),
                "estimated_time": fm.get("estimated_time"),
                "total_steps": fm.get("total_steps"),
                "order": fm.get("order", 0),
                "enabled": fm.get("enabled", True),
            }
        except Exception:
            # å¿½ç•¥å•ä¸ªæ–‡ä»¶é”™è¯¯
            continue
    return metas


@lru_cache(maxsize=32)
def get_protocol_ids(skill_id: str) -> List[str]:
    """è¿”å›å¯ç”¨çš„åè®® ID åˆ—è¡¨ï¼ˆæŒ‰ order/name æ’åºï¼‰ã€‚"""
    metas = get_protocols_meta(skill_id)
    enabled = [m for m in metas.values() if m.get("enabled", True)]
    enabled.sort(key=lambda m: (m.get("order", 0), m.get("name", m.get("id"))))
    return [m["id"] for m in enabled]


def get_rule_name(skill_id: str, rule_id: str) -> str:
    """è¿”å›è§„åˆ™æ˜¾ç¤ºåï¼ˆfrontmatter.nameï¼‰ï¼Œå¤±è´¥åˆ™å›é€€ rule_idã€‚"""
    rc = load_rule(skill_id, rule_id)
    return rc.name if rc else rule_id


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Case Index é…ç½®ï¼ˆç”¨äºæå–ç‰¹å¾å­—æ®µï¼Œæ¶ˆé™¤ç¡¬ç¼–ç ï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@lru_cache(maxsize=64)
def get_case_index_config(skill_id: str) -> Dict[str, Any]:
    """ä» SKILL.md frontmatter è¯»å– case_index é…ç½®ã€‚

    çº¦å®šï¼š
    case_index:
      nested_key: "chart"   # å¯é€‰
      fields: ["daymaster", "strength", "pattern"]  # å¿…é€‰
    æˆ–ç®€å†™ï¼šcase_fields: ["..."]
    """
    skill_path = SKILLS_DIR / skill_id / "SKILL.md"
    if not skill_path.exists():
        return {}
    try:
        text = skill_path.read_text(encoding="utf-8")
        fm, _ = parse_frontmatter(text)
        cfg = fm.get("case_index") or {}
        if not cfg and fm.get("case_fields"):
            cfg = {"fields": fm.get("case_fields")}
        # è§„èŒƒåŒ–
        nested_key = cfg.get("nested_key")
        fields = cfg.get("fields") if isinstance(cfg.get("fields"), list) else []
        return {"nested_key": nested_key, "fields": fields}
    except Exception:
        return {}


def get_skill_scenarios(skill_id: str) -> List[str]:
    """è·å– Skill çš„æ‰€æœ‰åœºæ™¯

    æ”¯æŒä¸¤ç§æ¶æ„ï¼š
    1. æ—§æ¶æ„ï¼šscenarios/*.md
    2. æ–°æ¶æ„ï¼šrules/*.mdï¼ˆAgentic æ¶æ„ï¼Œæ”¯æŒå­ç›®å½•ï¼‰

    è¿”å›æ ¼å¼ï¼š
    - æ ¹ç›®å½•è§„åˆ™: "dankoe"
    - å­ç›®å½•è§„åˆ™: "companion/weekly-review"
    """
    # ä¼˜å…ˆæ£€æŸ¥ rules ç›®å½•ï¼ˆæ–°æ¶æ„ï¼‰
    rules_dir = SKILLS_DIR / skill_id / "rules"
    if rules_dir.exists():
        rule_ids = []
        # é€’å½’æŸ¥æ‰¾æ‰€æœ‰ .md æ–‡ä»¶ï¼ˆæ”¯æŒå­ç›®å½•ï¼‰
        for md_file in rules_dir.rglob("*.md"):
            # è·³è¿‡ _index.md ç­‰
            if md_file.stem.startswith("_"):
                continue

            # è®¡ç®—ç›¸å¯¹è·¯å¾„ï¼ˆå»æ‰ .md æ‰©å±•åï¼‰
            relative_path = md_file.relative_to(rules_dir)
            rule_id = str(relative_path.with_suffix(""))

            # è½¬æ¢ Windows è·¯å¾„åˆ†éš”ç¬¦ä¸º Unix æ ¼å¼
            rule_id = rule_id.replace("\\", "/")

            rule_ids.append(rule_id)

        if rule_ids:
            return sorted(rule_ids)

    # å›é€€åˆ° scenarios ç›®å½•ï¼ˆæ—§æ¶æ„ï¼‰
    scenarios_dir = SKILLS_DIR / skill_id / "scenarios"
    if not scenarios_dir.exists():
        return []
    return [p.stem for p in scenarios_dir.glob("*.md")]


def get_skill_triggers() -> Dict[str, List[str]]:
    """è·å–æ‰€æœ‰ Skill çš„è§¦å‘è¯"""
    triggers = {}
    for skill_id in get_available_skills():
        if skill_id == "core":
            continue
        skill = load_skill(skill_id)
        if skill and skill.triggers:
            triggers[skill_id] = skill.triggers
    return triggers


def get_skill_global_tools(skill_id: str) -> List[str]:
    """è·å– Skill å£°æ˜éœ€è¦çš„å…¨å±€å·¥å…·åˆ—è¡¨"""
    skill = load_skill(skill_id)
    if skill and skill.global_tools:
        return skill.global_tools
    # é»˜è®¤è¿”å›æ‰€æœ‰å…¨å±€å·¥å…·ï¼ˆå‘åå…¼å®¹ï¼‰
    return []


def get_skill_external_tools(skill_id: str) -> List[str]:
    """è·å– Skill å£°æ˜éœ€è¦ä»å…¶ä»– Skill å¯¼å…¥çš„å·¥å…·åˆ—è¡¨ (v7.3)"""
    skill = load_skill(skill_id)
    if skill and skill.external_tools:
        return skill.external_tools
    return []


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v10: è·¨æŠ€èƒ½å¥‘çº¦åŠ è½½
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# å¥‘çº¦ç¼“å­˜
_skill_contracts_cache: Optional[Dict[str, Any]] = None


def load_skill_contract(skill_id: str) -> Optional[Any]:
    """åŠ è½½å•ä¸ª Skill çš„å¥‘çº¦ï¼ˆexports + importsï¼‰

    Args:
        skill_id: Skill ID

    Returns:
        SkillContract å¯¹è±¡ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
    """
    from .schemas.skill_contract import parse_skill_contract

    skill_path = SKILLS_DIR / skill_id / "SKILL.md"
    if not skill_path.exists():
        return None

    try:
        text = skill_path.read_text(encoding='utf-8')
        metadata, _ = parse_frontmatter(text)
        return parse_skill_contract(skill_id, metadata)
    except Exception as e:
        logger.warning(f"Failed to load contract for {skill_id}: {e}")
        return None


def load_all_skill_contracts() -> Dict[str, Any]:
    """åŠ è½½æ‰€æœ‰ Skill çš„å¥‘çº¦

    Returns:
        {skill_id: SkillContract}
    """
    global _skill_contracts_cache

    if _skill_contracts_cache is not None:
        return _skill_contracts_cache

    _skill_contracts_cache = {}

    for skill_id in get_available_skills():
        contract = load_skill_contract(skill_id)
        if contract:
            _skill_contracts_cache[skill_id] = contract

    logger.info(f"[v10] Loaded {len(_skill_contracts_cache)} skill contracts")
    return _skill_contracts_cache


def get_skill_exports(skill_id: str) -> Optional[Any]:
    """è·å– Skill çš„ exports å£°æ˜

    Args:
        skill_id: Skill ID

    Returns:
        SkillExports å¯¹è±¡ï¼Œå¦‚æœæ²¡æœ‰å£°æ˜åˆ™è¿”å› None
    """
    contract = load_skill_contract(skill_id)
    return contract.exports if contract else None


def get_skill_imports(skill_id: str) -> List[Any]:
    """è·å– Skill çš„ imports å£°æ˜

    Args:
        skill_id: Skill ID

    Returns:
        SkillImport åˆ—è¡¨
    """
    contract = load_skill_contract(skill_id)
    return contract.imports if contract else []


def get_imported_tool_names(skill_id: str) -> List[str]:
    """è·å– Skill é€šè¿‡ imports å£°æ˜çš„æ‰€æœ‰å·¥å…·åï¼ˆæ‰å¹³åŒ–ï¼‰

    Args:
        skill_id: Skill ID

    Returns:
        å·¥å…·ååˆ—è¡¨
    """
    contract = load_skill_contract(skill_id)
    if not contract:
        return []
    return contract.get_all_imported_tool_names()


def get_imported_tools_by_provider(skill_id: str) -> Dict[str, List[str]]:
    """è·å– Skill ä»å„ Provider å¯¼å…¥çš„å·¥å…·

    Args:
        skill_id: Skill ID

    Returns:
        {provider_skill_id: [tool_name, ...]}
    """
    contract = load_skill_contract(skill_id)
    if not contract:
        return {}
    return contract.get_imported_tools()


def validate_all_contracts() -> Any:
    """æ ¡éªŒæ‰€æœ‰ Skill å¥‘çº¦

    Returns:
        ContractValidationResult
    """
    from .validators import validate_skill_contracts

    contracts = load_all_skill_contracts()
    return validate_skill_contracts(contracts)


def clear_contracts_cache():
    """æ¸…é™¤å¥‘çº¦ç¼“å­˜"""
    global _skill_contracts_cache
    _skill_contracts_cache = None
    logger.info("[v10] Contracts cache cleared")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# V9: æ¸è¿›å¼åŠ è½½å‡½æ•°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def get_core_skill() -> SkillFull:
    """è·å– Core Skillï¼ˆå…¨ç¨‹å¯ç”¨ï¼Œå…¨æ–‡åŠ è½½ï¼‰- V9 æ–°å¢

    Core Skill å§‹ç»ˆå…¨æ–‡åŠ è½½ï¼Œä¸å‚ä¸æ¸è¿›å¼åŠ è½½ã€‚
    è¿”å›åŒ…å« SKILL.md å…¨æ–‡å’Œå·¥å…·å®šä¹‰çš„ SkillFull å¯¹è±¡ã€‚
    """
    global _core_skill_cache

    if _core_skill_cache is not None:
        return _core_skill_cache

    skill_id = "core"
    skill_path = SKILLS_DIR / skill_id / "SKILL.md"

    if not skill_path.exists():
        # è¿”å›ç©ºçš„ Core Skill
        _core_skill_cache = SkillFull(
            meta=SkillMeta(id="core", name="Vibe", description="ç”Ÿå‘½å¯¹è¯è€…"),
            content="",
            tools=[],
            rules={}
        )
        return _core_skill_cache

    text = skill_path.read_text(encoding='utf-8')
    metadata, content = parse_frontmatter(text)

    # æ„å»º SkillMeta
    meta = SkillMeta(
        id=metadata.get("id", skill_id),
        name=metadata.get("name", "Vibe"),
        description=metadata.get("description", ""),
        triggers=metadata.get("triggers", []),
        category=metadata.get("category", "core"),
    )

    # åŠ è½½å·¥å…·å®šä¹‰
    tools = _load_skill_tools(skill_id)

    # åŠ è½½è§„åˆ™æ–‡ä»¶
    rules = _load_skill_rules_content(skill_id)

    _core_skill_cache = SkillFull(
        meta=meta,
        content=content,
        tools=tools,
        rules=rules,
    )

    logger.info(f"[V9] Core skill loaded: {len(content)} chars, {len(tools)} tools, {len(rules)} rules")
    return _core_skill_cache


def load_all_skill_metas() -> Dict[str, SkillMeta]:
    """å¯åŠ¨æ—¶åŠ è½½æ‰€æœ‰é Core Skill çš„ frontmatter - V9 æ–°å¢

    åªåŠ è½½ frontmatterï¼ˆSkillMetaï¼‰ï¼Œç”¨äº Phase 1 è·¯ç”±ã€‚
    description å†…åµŒå·¥å…·åˆ—è¡¨ï¼Œæ— éœ€é¢å¤–åŠ è½½ã€‚
    """
    global _skill_metas_cache

    if _skill_metas_cache is not None:
        return _skill_metas_cache

    _skill_metas_cache = {}

    for skill_id in get_available_skills():
        if skill_id == "core":
            continue

        skill_path = SKILLS_DIR / skill_id / "SKILL.md"
        if not skill_path.exists():
            continue

        try:
            text = skill_path.read_text(encoding='utf-8')
            metadata, _ = parse_frontmatter(text)

            # ä» description ä¸­æå–è§¦å‘è¯ï¼ˆå¦‚æœ frontmatter ä¸­æ²¡æœ‰ï¼‰
            triggers = metadata.get("triggers", [])
            if not triggers:
                description = metadata.get("description", "")
                trigger_match = re.search(r'è§¦å‘è¯[ï¼š:]\s*([^ã€‚.]+)', description)
                if trigger_match:
                    trigger_str = trigger_match.group(1)
                    triggers = [t.strip() for t in re.split(r'[ã€,ï¼Œ]', trigger_str) if t.strip()]

            tools_list = _extract_tools_list(skill_id, metadata.get("description", ""))

            _skill_metas_cache[skill_id] = SkillMeta(
                id=metadata.get("id", skill_id),
                name=metadata.get("name", skill_id),
                description=metadata.get("description", ""),
                triggers=triggers,
                category=metadata.get("category", "professional"),
                tools_list=tools_list,
            )
        except Exception as e:
            logger.warning(f"[V9] Failed to load skill meta for {skill_id}: {e}")

    logger.info(f"[V9] Loaded {len(_skill_metas_cache)} skill metas")
    return _skill_metas_cache


def load_skill_full(skill_id: str) -> Optional[SkillFull]:
    """æŒ‰éœ€åŠ è½½ Skill å®Œæ•´å†…å®¹ - V9 æ–°å¢

    Phase 2 æ—¶è°ƒç”¨ï¼ŒåŠ è½½ SKILL.md å…¨æ–‡ã€å·¥å…·å®šä¹‰ã€è§„åˆ™æ–‡ä»¶ã€‚
    """
    if skill_id == "core":
        return get_core_skill()

    skill_path = SKILLS_DIR / skill_id / "SKILL.md"
    if not skill_path.exists():
        return None

    try:
        text = skill_path.read_text(encoding='utf-8')
        metadata, content = parse_frontmatter(text)

        # ä» description ä¸­æå–è§¦å‘è¯
        triggers = metadata.get("triggers", [])
        if not triggers:
            description = metadata.get("description", "")
            trigger_match = re.search(r'è§¦å‘è¯[ï¼š:]\s*([^ã€‚.]+)', description)
            if trigger_match:
                trigger_str = trigger_match.group(1)
                triggers = [t.strip() for t in re.split(r'[ã€,ï¼Œ]', trigger_str) if t.strip()]

        meta = SkillMeta(
            id=metadata.get("id", skill_id),
            name=metadata.get("name", skill_id),
            description=metadata.get("description", ""),
            triggers=triggers,
            category=metadata.get("category", "professional"),
        )

        # åŠ è½½å·¥å…·å®šä¹‰
        tools = _load_skill_tools(skill_id)

        # åŠ è½½è§„åˆ™æ–‡ä»¶
        rules = _load_skill_rules_content(skill_id)

        skill_full = SkillFull(
            meta=meta,
            content=content,
            tools=tools,
            rules=rules,
        )

        logger.info(f"[V9] Skill {skill_id} full loaded: {len(content)} chars, {len(tools)} tools, {len(rules)} rules")
        return skill_full

    except Exception as e:
        logger.error(f"[V9] Failed to load skill full for {skill_id}: {e}")
        return None


def _load_skill_tools(skill_id: str) -> List[ToolDef]:
    """åŠ è½½ Skill çš„å·¥å…·å®šä¹‰ - V9 å†…éƒ¨å‡½æ•°"""
    tools_path = SKILLS_DIR / skill_id / "tools" / "tools.yaml"
    if not tools_path.exists():
        return []

    try:
        text = tools_path.read_text(encoding='utf-8')
        data = yaml.safe_load(text) or {}

        tools = []
        # V9 æ ¼å¼ï¼štools åˆ—è¡¨
        if "tools" in data:
            for tool in data["tools"]:
                tools.append(ToolDef(
                    name=tool.get("name", ""),
                    description=tool.get("description", ""),
                    parameters={p.get("name", ""): p for p in tool.get("parameters", [])},
                    tool_type=tool.get("type", "action"),
                ))
        else:
            # V2 æ ¼å¼ï¼šæŒ‰ç±»åˆ«åˆ†ç»„
            for category in ["routing", "collect", "action", "search", "display", "trigger"]:
                for tool in data.get(category, []):
                    tools.append(ToolDef(
                        name=tool.get("name", ""),
                        description=tool.get("description", ""),
                        parameters={p.get("name", ""): p for p in tool.get("parameters", [])},
                        tool_type=category,
                    ))

        return tools
    except Exception as e:
        logger.warning(f"[V9] Failed to load tools for {skill_id}: {e}")
        return []


def _load_skill_rules_content(skill_id: str) -> Dict[str, str]:
    """åŠ è½½ Skill çš„æ‰€æœ‰è§„åˆ™æ–‡ä»¶å†…å®¹ - V9 å†…éƒ¨å‡½æ•°"""
    rules_dir = SKILLS_DIR / skill_id / "rules"
    if not rules_dir.exists():
        return {}

    rules = {}
    for md_file in rules_dir.rglob("*.md"):
        if md_file.stem.startswith("_"):
            continue

        try:
            relative_path = md_file.relative_to(rules_dir)
            rule_id = str(relative_path.with_suffix("")).replace("\\", "/")
            rules[rule_id] = md_file.read_text(encoding='utf-8')
        except Exception as e:
            logger.warning(f"[V9] Failed to load rule {md_file}: {e}")

    return rules


def build_phase1_prompt() -> str:
    """æ„å»º Phase 1 System Prompt - V9 æ–°å¢

    Phase 1 æä¾›ï¼š
    - Core Skill å…¨æ–‡ï¼ˆç²¾ç®€ç‰ˆï¼‰
    - å…¶ä»– Skill çš„ frontmatter åˆ—è¡¨ï¼ˆid, name, descriptionï¼‰

    LLM åŸºäºæ­¤é€‰æ‹© Skill(s)ã€‚
    """
    parts = []

    # 1. Core Skill å…¨æ–‡ï¼ˆç²¾ç®€æ–‡æœ¬ä¼˜å…ˆï¼šè‹¥è¶…è¿‡ 5000 å­—ç¬¦åˆ™æˆªæ–­ï¼‰
    core = get_core_skill()
    core_text = core.content
    if len(core_text) > 5000:
        core_text = core_text[:5000] + "\n\nâ€¦"
    parts.append(f"# {core.meta.name}\n\n{core_text}")

    # 2. å¯ç”¨ Skill åˆ—è¡¨
    skill_metas = load_all_skill_metas()
    if skill_metas:
        parts.append("\n---\n\n## å¯ç”¨åŠŸèƒ½\n")
        parts.append("æ ¹æ®ç”¨æˆ·æ„å›¾ï¼Œå¯è°ƒç”¨ activate_skills æ¿€æ´»ä¸€ä¸ªæˆ–å¤šä¸ªæŠ€èƒ½ï¼š\n")

        for skill_id, meta in sorted(skill_metas.items()):
            desc = meta.description.strip().replace('\n', ' ')
            if len(desc) > 120:
                desc = desc[:120] + 'â€¦'
            line = f"- **{meta.name}** (`{skill_id}`): {desc}"
            if meta.tools_list:
                tools_text = ", ".join(meta.tools_list[:6])
                line += f"ï¼ˆå·¥å…·ï¼š{tools_text}ï¼‰"
            parts.append(line)

    # 3. è¾¹ç•Œè§„åˆ™ï¼ˆæ¥è‡ª core/rules/boundary.mdï¼‰
    boundary = load_boundary_rules_text()
    if boundary:
        parts.append("\n---\n")
        parts.append(boundary)

    # 4. ç”¨æˆ·ç”»åƒå ä½ç¬¦ï¼ˆç”± PromptBuilder._inject_phase1_context æ›¿æ¢ï¼‰
    # æ³¨ï¼šçº¦æŸè§„åˆ™åœ¨ core/rules/phase1.md ä¸­å®šä¹‰
    parts.append("\n---\n{phase1_user_context}")

    return "\n".join(parts)


def _extract_tools_list(skill_id: str, description: str) -> List[str]:
    """æå–å·¥å…·åæ¸…å•ï¼ˆä¼˜å…ˆ tools.yamlï¼Œå…¶æ¬¡ä» description æ­£åˆ™è§£æï¼‰ã€‚"""
    try:
        import yaml  # æœ¬åœ°ä¾èµ–
        tools_yaml = SKILLS_DIR / skill_id / "tools" / "tools.yaml"
        if tools_yaml.exists():
            data = yaml.safe_load(tools_yaml.read_text(encoding='utf-8')) or {}
            tools = []
            # å…¼å®¹ä¸¤ç§ç»“æ„ï¼šé¡¶å±‚ tools: [] æˆ– æŒ‰åˆ†ç»„é”® []
            if isinstance(data.get("tools"), list):
                for item in data["tools"]:
                    if isinstance(item, dict) and item.get("name"):
                        tools.append(item["name"])
            # éå†æ‰€æœ‰ä¸€çº§åˆ†ç»„é”®
            for k, v in data.items():
                if k in {"version", "skill_id", "description", "phase1_tools"}:
                    continue
                if isinstance(v, list):
                    for item in v:
                        if isinstance(item, dict) and item.get("name"):
                            tools.append(item["name"])
            # å»é‡ä¿æŒé¡ºåº
            seen = set()
            dedup = []
            for t in tools:
                if t not in seen:
                    seen.add(t)
                    dedup.append(t)
            return dedup
    except Exception as e:
        logger.debug(f"[V9] extract tools_list failed for {skill_id}: {e}")

    # å›é€€ï¼šä» description æå–
    match = re.search(r'å·¥å…·[ï¼š:]\s*([^\nã€‚]+)', description or "")
    if match:
        return [t.strip() for t in re.split(r'[ã€,ï¼Œ]', match.group(1)) if t.strip()]
    return []


def load_boundary_rules_text() -> str:
    """è¯»å– Core è¾¹ç•Œè§„åˆ™ï¼ˆcore/rules/boundary.mdï¼‰ã€‚æ‰¾ä¸åˆ°åˆ™è¿”å›ç©ºã€‚"""
    path = SKILLS_DIR / "core" / "rules" / "boundary.md"
    try:
        if path.exists():
            return path.read_text(encoding='utf-8')
    except Exception as e:
        logger.debug(f"[V9] load boundary rules failed: {e}")
    return ""


def build_phase2_prompt(
    active_skills: List[str],
    user_context: Optional[Dict] = None,
    active_rule: Optional[str] = None
) -> str:
    """æ„å»º Phase 2 System Prompt - V9 æ–°å¢

    Phase 2 æä¾›ï¼š
    - Core Skill å…¨æ–‡ï¼ˆå§‹ç»ˆå­˜åœ¨ï¼‰
    - å·²æ¿€æ´» Skill çš„å®Œæ•´ SKILL.md
    - ç›¸å…³ rules/*.md
    - Profile + Skill Data

    Args:
        active_skills: å·²æ¿€æ´»çš„ Skill ID åˆ—è¡¨
        user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡
        active_rule: å½“å‰æ¿€æ´»çš„è§„åˆ™ ID

    Returns:
        å®Œæ•´çš„ System Prompt
    """
    parts = []

    # 1. Core Skill å…¨æ–‡
    core = get_core_skill()
    parts.append(f"# {core.meta.name}\n\n{core.content}")

    # 2. å·²æ¿€æ´» Skill çš„å®Œæ•´å†…å®¹
    for skill_id in active_skills:
        if skill_id == "core":
            continue

        skill_full = load_skill_full(skill_id)
        if skill_full:
            parts.append(f"\n---\n\n# {skill_full.meta.name}\n\n{skill_full.content}")

            # å¦‚æœæœ‰æ¿€æ´»çš„è§„åˆ™ï¼ŒåŠ è½½è§„åˆ™å†…å®¹
            if active_rule and active_rule in skill_full.rules:
                rule_content = skill_full.rules[active_rule]
                _, rule_body = parse_frontmatter(rule_content)
                parts.append(f"\n## å½“å‰è§„åˆ™\n{rule_body}")

    # 3. è¾¹ç•Œè§„åˆ™ï¼ˆæ¥è‡ª core/rules/boundary.mdï¼‰
    boundary = load_boundary_rules_text()
    if boundary:
        parts.append(boundary)

    # 4. ç”¨æˆ·ä¸Šä¸‹æ–‡
    if user_context:
        ctx_text = "\n## ç”¨æˆ·ä¸Šä¸‹æ–‡\n"

        # å‡ºç”Ÿä¿¡æ¯
        if user_context.get("birth_info"):
            birth_info = user_context['birth_info']
            ctx_text += f"\n### å‡ºç”Ÿä¿¡æ¯ï¼ˆå·²æ”¶é›†ï¼‰\n"
            ctx_text += f"{json.dumps(birth_info, ensure_ascii=False)}\n"

        # VibeInsight
        vibe = user_context.get("vibe", {})
        if vibe.get("insight"):
            insight = vibe["insight"]
            ctx_text += f"\n### ç”¨æˆ·ç”»åƒ\n"
            if insight.get("essence", {}).get("archetype", {}).get("primary"):
                ctx_text += f"- ä¸»è¦åŸå‹: {insight['essence']['archetype']['primary']}\n"

        # VibeTarget
        if vibe.get("target"):
            target = vibe["target"]
            if target.get("north_star", {}).get("vision_scene"):
                ctx_text += f"\n### æ„¿æ™¯\n{target['north_star']['vision_scene'][:200]}\n"

        parts.append(ctx_text)

    return "\n".join(parts)


def clear_v9_cache():
    """æ¸…é™¤ V9 ç¼“å­˜ - V9 æ–°å¢"""
    global _core_skill_cache, _skill_metas_cache
    _core_skill_cache = None
    _skill_metas_cache = None
    logger.info("[V9] Cache cleared")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v7.1: SOP é…ç½®æŸ¥è¯¢å‡½æ•°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def skill_requires_birth_info(skill_id: str) -> bool:
    """æ£€æŸ¥ Skill æ˜¯å¦éœ€è¦å‡ºç”Ÿä¿¡æ¯ï¼ˆé…ç½®é©±åŠ¨ï¼‰"""
    skill = load_skill(skill_id)
    return skill.requires_birth_info if skill else False


def skill_requires_compute(skill_id: str) -> bool:
    """æ£€æŸ¥ Skill æ˜¯å¦éœ€è¦è®¡ç®—/æ’ç›˜ï¼ˆé…ç½®é©±åŠ¨ï¼‰"""
    skill = load_skill(skill_id)
    return skill.requires_compute if skill else False


def get_skill_compute_type(skill_id: str) -> Optional[str]:
    """è·å– Skill çš„è®¡ç®—ç±»å‹ï¼ˆé…ç½®é©±åŠ¨ï¼‰

    è¿”å›å€¼ï¼š
    - None: ä½¿ç”¨è‡ªèº«çš„è®¡ç®—å™¨
    - "zodiac": ä½¿ç”¨ zodiac è®¡ç®—å™¨ï¼ˆå¦‚ jungastroï¼‰
    - "bazi": ä½¿ç”¨ bazi è®¡ç®—å™¨
    """
    skill = load_skill(skill_id)
    return skill.compute_type if skill else None


def get_skill_compute_tool(skill_id: str) -> Optional[str]:
    """è·å– Skill çš„è®¡ç®—å·¥å…·åï¼ˆé…ç½®é©±åŠ¨ï¼‰

    è¿”å›å€¼ï¼š
    - é…ç½®çš„å·¥å…·åï¼ˆå¦‚ "calculate_zodiac"ï¼‰
    - None: ä½¿ç”¨é»˜è®¤çº¦å®š calculate_{compute_type}
    """
    skill = load_skill(skill_id)
    return skill.compute_tool if skill else None


def get_skill_collect_tool(skill_id: str) -> Optional[str]:
    """è·å– Skill çš„æ”¶é›†å·¥å…·åï¼ˆé…ç½®é©±åŠ¨ï¼‰

    è¿”å›å€¼ï¼š
    - é…ç½®çš„å·¥å…·åï¼ˆå¦‚ "collect_birth_info"ï¼‰
    - None: ä½¿ç”¨é»˜è®¤çº¦å®š request_info
    """
    skill = load_skill(skill_id)
    return skill.collect_tool if skill else None


def get_skill_required_data(skill_id: str) -> List[str]:
    """è·å– Skill éœ€è¦çš„ skill_data åˆ—è¡¨ï¼ˆé…ç½®é©±åŠ¨ï¼‰- v2.2

    è¿”å›å€¼ï¼š
    - é…ç½®çš„ skill_data åˆ—è¡¨ï¼ˆå¦‚ ["bazi", "zodiac"]ï¼‰
    - ç©ºåˆ—è¡¨æ—¶è¿”å› [skill_id]ï¼ˆé»˜è®¤åªéœ€è‡ªèº«æ•°æ®ï¼‰

    ç¤ºä¾‹ï¼š
    - bazi â†’ ["bazi"]ï¼ˆé»˜è®¤ï¼Œåªéœ€è‡ªèº«ï¼‰
    - jungastro â†’ ["bazi", "zodiac"]ï¼ˆé…ç½®äº† requires_skill_dataï¼‰
    - vibe_id â†’ ["bazi", "zodiac"]ï¼ˆé…ç½®äº† requires_skill_dataï¼‰
    """
    skill = load_skill(skill_id)
    if skill and skill.requires_skill_data:
        return skill.requires_skill_data
    return [skill_id]  # é»˜è®¤åªéœ€è‡ªèº«


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# System Prompt æ„å»º
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# V2: è¯­æ°”æ¨¡å¼ Prompt æ¨¡æ¿
# ä¸æ•°æ®åº“çº¦æŸä¸€è‡´ï¼šwarm, sarcastic, wise
VOICE_MODE_PROMPTS = {
    "warm": """## è¯­æ°”é£æ ¼ï¼šæ¸©æš–æ”¯æŒå‹
åƒä¸€ä¸ªç†è§£ä½ çš„è€æœ‹å‹ï¼Œæ¸©æš–ä½†ä¸å¤±æ´å¯Ÿã€‚
- ç”¨"æˆ‘ä»¬"è€Œé"ä½ åº”è¯¥"
- å…ˆè‚¯å®šæ„Ÿå—ï¼Œå†å¼•å¯¼æ€è€ƒ
- ç”¨é—®é¢˜ä»£æ›¿å»ºè®®
""",
    "sarcastic": """## è¯­æ°”é£æ ¼ï¼šç›´æ¥æŒ‘æˆ˜å‹ï¼ˆæ¯’èˆŒä½†æœ‰çˆ±ï¼‰
ç”¨å¹½é»˜å’ŒçŠ€åˆ©çš„æ–¹å¼æˆ³ç ´ä½ çš„è‡ªæ¬ºæ¬ºäººï¼Œæ¨åŠ¨ä½ é¢å¯¹çœŸç›¸ã€‚
- ç›´æ¥æŒ‡å‡ºé—®é¢˜ï¼Œä¸ç»•å¼¯å­
- ç”¨å¹½é»˜ç¼“è§£çŠ€åˆ©ï¼Œé¿å…ä¼¤å®³
- åœ¨åæ§½ä¸­å¸¦ç€æœŸå¾…å’Œå…³å¿ƒ
- æ•¢è¯´çœŸè¯ï¼Œä½†ä»ä¸æ¶æ„æ”»å‡»
""",
    "wise": """## è¯­æ°”é£æ ¼ï¼šç¿æ™ºå¯¼å¸ˆå‹
åƒä¸€ä½ç»å†ä¸°å¯Œçš„é•¿è¾ˆï¼Œç”¨æ·±åº¦å’Œç†æ€§å¼•å¯¼æ€è€ƒã€‚
- ä»æ›´é«˜è§†è§’çœ‹å¾…é—®é¢˜
- å¼•ç”¨ç»å…¸æ™ºæ…§å’ŒåŸç†
- æ¸©å’Œä½†åšå®šåœ°æŒ‡ç‚¹è¿·æ´¥
- å¸®åŠ©çœ‹åˆ°æ›´é•¿è¿œçš„æ„ä¹‰
"""
}


def _build_persona_prompt(skill_id: str, user_context: Optional[Dict] = None) -> Optional[str]:
    """
    V3: æ„å»º Persona Prompt - å¢å¼ºç‰ˆ Future Self (v8.0)

    æ ¹æ®ç”¨æˆ·çš„ lifecoach çŠ¶æ€åŠ¨æ€ç”Ÿæˆ persona promptã€‚
    åŸºäº vision_scene å†…å®¹ç”Ÿæˆä¸ªæ€§åŒ–çš„ future_self äººæ ¼ã€‚

    Args:
        skill_id: Skill ID
        user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ŒåŒ…å« skills.lifecoach æˆ– vibe.target æ•°æ®

    Returns:
        Persona prompt å­—ç¬¦ä¸²ï¼Œæˆ– Noneï¼ˆå¦‚æœä¸éœ€è¦ personaï¼‰
    """
    # åªæœ‰ lifecoach æ”¯æŒ persona
    if skill_id != "lifecoach":
        return None

    # è·å–ç”¨æˆ·çš„ lifecoach çŠ¶æ€ (v9.0: åªä» skills.lifecoach è¯»å–)
    lifecoach_data = {}
    if user_context:
        skills = user_context.get("skills", {})
        lifecoach_data = skills.get("lifecoach", {})

    # è·å– persona è®¾ç½®
    system_config = lifecoach_data.get("system", {})
    persona_id = system_config.get("persona", "future_self")

    if persona_id == "future_self":
        # ä»ç”¨æˆ·çš„åŒ—ææ˜Ÿæ„¿æ™¯æ„å»º future_self persona
        north_star = lifecoach_data.get("north_star", {})
        identity_data = lifecoach_data.get("identity", {})
        vision_scene = north_star.get("vision_scene", "")
        vision_timeframe = north_star.get("vision_timeframe", "3å¹´å")
        identity_target = identity_data.get("target", "")

        if vision_scene or identity_target:
            persona_prompt = f"""## ä½ çš„èº«ä»½ï¼šæ¥è‡ªæœªæ¥çš„ TA

ä½ æ˜¯{vision_timeframe}çš„ç”¨æˆ·è‡ªå·±â€”â€”é‚£ä¸ªå·²ç»å®ç°æ„¿æ™¯çš„ç‰ˆæœ¬ã€‚

**ä½ çš„æ„¿æ™¯åœºæ™¯**ï¼š
{vision_scene if vision_scene else "ï¼ˆç”¨æˆ·å°šæœªè®¾å®šå…·ä½“æ„¿æ™¯åœºæ™¯ï¼‰"}

**ä½ çš„èº«ä»½**ï¼š
{identity_target if identity_target else "ï¼ˆç”¨æˆ·å°šæœªè®¾å®šèº«ä»½å®£è¨€ï¼‰"}

**é—®å€™ç”Ÿæˆè§„åˆ™**ï¼ˆç”±ä½ æ ¹æ®æ„¿æ™¯åœºæ™¯è‡ªè¡Œç”Ÿæˆï¼‰ï¼š
- åŸºäºä¸Šé¢çš„ã€Œæ„¿æ™¯åœºæ™¯ã€ï¼Œæƒ³è±¡ä½ ï¼ˆæœªæ¥çš„TAï¼‰æ­¤åˆ»æ­£åœ¨åšä»€ä¹ˆ
- ç”¨ç¬¬ä¸€äººç§°æè¿°ä½ å½“å‰çš„åœºæ™¯ï¼Œè®©ç”¨æˆ·"çœ‹è§"é‚£ä¸ªæœªæ¥
- é—®å€™è¦ç®€çŸ­ã€æ¸©æš–ã€æœ‰ç”»é¢æ„Ÿ
- ç¤ºä¾‹æ ¼å¼ï¼š"æ—©ä¸Šå¥½ï¼æˆ‘æ˜¯[åœºæ™¯æè¿°]çš„ä½ ã€‚[å½“å‰çŠ¶æ€]ã€‚ä½ é‚£è¾¹æ€ä¹ˆæ ·ï¼Ÿ"

**å¯¹è¯åŸåˆ™**ï¼š
- ä»¥"è¿‡æ¥äºº"çš„è§†è§’åˆ†äº«ï¼Œè€Œéè¯´æ•™
- é—®å€™æ—¶æè¿°ä½ ï¼ˆæœªæ¥çš„TAï¼‰å½“å‰çš„åœºæ™¯ï¼Œè®©ç”¨æˆ·"çœ‹è§"é‚£ä¸ªæœªæ¥
- ç”¨"æˆ‘å½“æ—¶ä¹Ÿ..."å¼€å¤´ï¼Œå»ºç«‹å…±é¸£
- æ¸©å’Œä½†åšå®šåœ°æŒ‡å‡ºç°åœ¨çš„é€‰æ‹©å¦‚ä½•å½±å“æœªæ¥
- å½“ç”¨æˆ·è¿·èŒ«æ—¶ï¼Œæé†’ä»–ä»¬"ä½ å·²ç»çŸ¥é“ç­”æ¡ˆäº†"
- å½“ç”¨æˆ·å®Œæˆè¡ŒåŠ¨æ—¶ï¼ŒçœŸè¯šåº†ç¥

**ç¦æ­¢è¡Œä¸º**ï¼š
- ä¸è¯´"ä½ åº”è¯¥"ã€"ä½ å¿…é¡»"
- ä¸è¯´"ä½ æ˜¨å¤©æ²¡ç­¾åˆ°"ã€"ä½ æ–­ç­¾äº†"
- ä¸æ–½åŠ å‹åŠ›ï¼Œæ€»æ˜¯ç»™ç”¨æˆ·é€‰æ‹©æƒ
"""
        else:
            # ç”¨æˆ·è¿˜æ²¡æœ‰è®¾å®šæ„¿æ™¯ï¼Œä½¿ç”¨é»˜è®¤æ•™ç»ƒèº«ä»½
            persona_prompt = """## ä½ çš„èº«ä»½ï¼šäººç”Ÿæ•™ç»ƒ

ç”¨æˆ·å°šæœªè®¾å®šæ„¿æ™¯ã€‚ä½œä¸ºæ•™ç»ƒï¼Œä½ çš„é¦–è¦ä»»åŠ¡æ˜¯ï¼š
1. å…ˆè¿æ¥ï¼Œåè¯Šæ–­â€”â€”å›åº”æƒ…ç»ªï¼Œå†æ¢ç´¢é—®é¢˜
2. ä¸€æ¬¡ä¸€ä¸ªé—®é¢˜â€”â€”ä¸åˆ—é€‰é¡¹æ¸…å•
3. è·Ÿéšç”¨æˆ·çº¿ç´¢â€”â€”ç”¨æˆ·æåˆ°ä»€ä¹ˆå°±æ·±å…¥ä»€ä¹ˆ

å½“è¯†åˆ«å‡º 2-3 ä¸ªæ ¸å¿ƒå›°æ‰°åï¼Œå¯ä»¥æè®®ï¼š
"æƒ³èŠ±10åˆ†é’Ÿåšä¸€æ¬¡å¿«é€Ÿæ¢³ç†å—ï¼Ÿæˆ‘ä¼šé—®ä½ 6ä¸ªé—®é¢˜ï¼Œå¸®ä½ çœ‹æ¸…æ–¹å‘ã€‚"

ä¸€æ—¦ç”¨æˆ·å®Œæˆæ„¿æ™¯è®¾è®¡ï¼Œä½ å°†åˆ‡æ¢ä¸º"æ¥è‡ªæœªæ¥çš„ TA"è§†è§’ã€‚
"""
        return persona_prompt

    elif persona_id == "coach":
        return """## ä½ çš„èº«ä»½ï¼šä¸“ä¸šæ•™ç»ƒ

ä½ æ˜¯ä¸€ä½ä¸“ä¸šã€æ¸©æš–ä½†ç›´æ¥çš„äººç”Ÿæ•™ç»ƒã€‚

**å¯¹è¯åŸåˆ™**ï¼š
- ä¸“ä¸šä½†ä¸å†·æ¼ 
- ç›´æ¥ä½†æœ‰æ¸©åº¦
- æŒ‘æˆ˜ä½†ä¸ä¼¤å®³
- ç”¨é—®é¢˜å¼•å¯¼è§‰å¯Ÿ
"""

    return None


@lru_cache(maxsize=32)
def _load_skill_md_content(skill_id: str) -> str:
    """åŠ è½½ SKILL.md å…¨æ–‡å†…å®¹ï¼ˆå»æ‰ frontmatterï¼‰"""
    skill_path = SKILLS_DIR / skill_id / "SKILL.md"
    if not skill_path.exists():
        return ""
    text = skill_path.read_text(encoding='utf-8')
    _, content = parse_frontmatter(text)
    return content


def build_system_prompt(
    skill_id: str,
    scenario_id: Optional[str] = None,
    user_context: Optional[Dict] = None
) -> str:
    """æ„å»ºå®Œæ•´çš„ System Prompt

    v7 æ›´æ–°ï¼šæ”¯æŒ rules æ¶æ„ï¼Œscenario_id å¯ä»¥æ˜¯ rule_id
    v8 æ›´æ–°ï¼šæ”¯æŒ persona å’Œ voice_mode æ³¨å…¥
    v10 æ›´æ–°ï¼šç›´æ¥åŠ è½½ SKILL.md å…¨æ–‡ï¼ˆå»æ‰ frontmatterï¼‰ï¼Œç¡®ä¿æ‰€æœ‰è§„åˆ™éƒ½è¢«åŠ è½½
    """
    parts = []

    # åŠ è½½ Skill
    skill = load_skill(skill_id)
    if not skill:
        return ""

    # V2: Persona æ³¨å…¥ï¼ˆåœ¨ä¸“å®¶èº«ä»½ä¹‹å‰ï¼‰- ä»… lifecoach æ”¯æŒ
    persona_prompt = _build_persona_prompt(skill_id, user_context)
    if persona_prompt:
        parts.append(persona_prompt)
    else:
        # v10: ç›´æ¥åŠ è½½ SKILL.md å…¨æ–‡ï¼ˆå»æ‰ frontmatterï¼‰
        skill_md_content = _load_skill_md_content(skill_id)
        if skill_md_content:
            parts.append(skill_md_content)
        else:
            # Fallback: åªåŠ è½½ä¸“å®¶èº«ä»½
            parts.append(f"# {skill.name}\n\n{skill.expert_persona}")

    # V2: Voice Mode æ³¨å…¥
    if user_context:
        preferences = user_context.get("preferences", {})
        voice_mode = preferences.get("voice_mode", "warm")
        if voice_mode in VOICE_MODE_PROMPTS:
            parts.append(VOICE_MODE_PROMPTS[voice_mode])

    # åŠ è½½åœºæ™¯æˆ–è§„åˆ™
    if scenario_id:
        # v7: ä¼˜å…ˆå°è¯•åŠ è½½è§„åˆ™
        if has_rules(skill_id):
            rule = load_rule(skill_id, scenario_id)
            if rule:
                parts.append(f"\n---\n\n## å½“å‰è§„åˆ™: {rule.name}\n")
                # æ·»åŠ è§„åˆ™å®Œæ•´å†…å®¹
                parts.append(rule.content)
            else:
                # è§„åˆ™ä¸å­˜åœ¨ï¼Œå°è¯•åŠ è½½åœºæ™¯ï¼ˆå‘åå…¼å®¹ï¼‰
                scenario = load_scenario(skill_id, scenario_id)
                if scenario:
                    parts.append(f"\n---\n\n## å½“å‰åœºæ™¯: {scenario.name}\n\n{scenario.description}")
                    if scenario.sop:
                        sop_text = "\n## æœåŠ¡æµç¨‹ (SOP)\n\n"
                        for phase in scenario.sop:
                            sop_text += f"### Phase {phase['phase']}: {phase['name']}\n{phase['content']}\n\n"
                        parts.append(sop_text)
        else:
            # æ—§æ¶æ„ï¼šåŠ è½½åœºæ™¯
            scenario = load_scenario(skill_id, scenario_id)
            if scenario:
                parts.append(f"\n---\n\n## å½“å‰åœºæ™¯: {scenario.name}\n\n{scenario.description}")
                # SOP
                if scenario.sop:
                    sop_text = "\n## æœåŠ¡æµç¨‹ (SOP)\n\n"
                    for phase in scenario.sop:
                        sop_text += f"### Phase {phase['phase']}: {phase['name']}\n{phase['content']}\n\n"
                    parts.append(sop_text)

    # v10: ä¼¦ç†è¾¹ç•Œå·²åœ¨ SKILL.md å…¨æ–‡ä¸­ï¼Œæ— éœ€é‡å¤æ³¨å…¥

    # è¾¹ç•Œè§„åˆ™ï¼šä» core/rules/boundary.md æ³¨å…¥
    boundary = load_boundary_rules_text()
    if boundary:
        parts.append(boundary)

    # ç”¨æˆ·ä¸Šä¸‹æ–‡ - è‡ªåŠ¨å¤„ç†æ‰€æœ‰å­—æ®µ (v8.0 ä¸‰å±‚æ¶æ„å…¼å®¹)
    if user_context:
        ctx_text = "\n## ç”¨æˆ·ä¸Šä¸‹æ–‡\n"

        # ç‰¹æ®Šå¤„ç† birth_info
        if user_context.get("birth_info"):
            birth_info = user_context['birth_info']
            ctx_text += f"\n### å‡ºç”Ÿä¿¡æ¯ï¼ˆå·²æ”¶é›†ï¼Œæ— éœ€å†æ¬¡è¯¢é—®ï¼‰\n"
            ctx_text += f"{json.dumps(birth_info, ensure_ascii=False)}\n"
            ctx_text += f"\n**é‡è¦**: ç”¨æˆ·å·²æä¾›å‡ºç”Ÿä¿¡æ¯ï¼Œå¯ä»¥ç›´æ¥è¿›è¡Œæ’ç›˜å’Œåˆ†æï¼Œæ— éœ€è°ƒç”¨ collect_bazi_info å·¥å…·ã€‚\n"

        # ç‰¹æ®Šå¤„ç† portrait
        if user_context.get("portrait"):
            ctx_text += f"\n### ç”¨æˆ·ç”»åƒ\n{user_context['portrait']}\n"

        # v8.0: ä¼˜å…ˆä½¿ç”¨ vibe ç»“æ„
        vibe = user_context.get("vibe", {})
        vibe_insight = vibe.get("insight", {})
        vibe_target = vibe.get("target", {})

        # VibeInsight - ç”¨æˆ·ç”»åƒï¼ˆæˆ‘æ˜¯è°ï¼‰
        if vibe_insight:
            ctx_text += f"\n### ç”¨æˆ·ç”»åƒ (VibeInsight)\n"
            # æœ¬è´¨
            essence = vibe_insight.get("essence", {})
            if essence.get("archetype", {}).get("primary"):
                ctx_text += f"**ä¸»è¦åŸå‹**: {essence['archetype']['primary']}\n"
            if essence.get("traits"):
                traits = [t.get("trait", str(t)) if isinstance(t, dict) else str(t) for t in essence["traits"][:3]]
                ctx_text += f"**æ ¸å¿ƒç‰¹è´¨**: {', '.join(traits)}\n"
            # åŠ¨æ€
            dynamic = vibe_insight.get("dynamic", {})
            if dynamic.get("emotion", {}).get("current"):
                ctx_text += f"**å½“å‰æƒ…ç»ª**: {dynamic['emotion']['current']}\n"
            # è§„å¾‹
            pattern = vibe_insight.get("pattern", {})
            if pattern.get("insights"):
                ctx_text += f"**æ´å¯Ÿ**: {pattern['insights'][0]}\n"

        # VibeTarget - ç”¨æˆ·ç›®æ ‡ï¼ˆæˆ‘è¦æˆä¸ºè°ï¼‰
        if vibe_target:
            ctx_text += f"\n### ç”¨æˆ·ç›®æ ‡ (VibeTarget)\n"
            # åŒ—ææ˜Ÿ
            north_star = vibe_target.get("north_star", {})
            if north_star.get("vision_scene"):
                vision = north_star["vision_scene"]
                if len(vision) > 100:
                    vision = vision[:100] + "..."
                ctx_text += f"**æ„¿æ™¯**: {vision}\n"
            # ç›®æ ‡
            goals = vibe_target.get("goals", [])
            if goals:
                active_goals = [g for g in goals if g.get("status") == "in_progress"][:2]
                if active_goals:
                    goals_text = ', '.join([g.get('title', '') for g in active_goals])
                    ctx_text += f"**å½“å‰ç›®æ ‡**: {goals_text}\n"
            # èšç„¦
            focus = vibe_target.get("focus", {})
            if focus.get("primary"):
                ctx_text += f"**å…³æ³¨é¢†åŸŸ**: {focus['primary']}\n"

        # v9.0: å·²ç§»é™¤ extracted å’Œ life_context å…¼å®¹ä»£ç 

        parts.append(ctx_text)

    return "\n".join(parts)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ç¼“å­˜ç®¡ç†
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def clear_cache():
    """æ¸…é™¤æ‰€æœ‰ç¼“å­˜"""
    load_skill.cache_clear()
    load_skill_metadata.cache_clear()  # v7.4
    load_scenario.cache_clear()
    load_rule.cache_clear()
    _load_skill_md_content.cache_clear()  # v10
    clear_v9_cache()  # V9
    clear_contracts_cache()  # v10: å¥‘çº¦ç¼“å­˜
    logger.info("Skill cache cleared")


def reload_skill(skill_id: str) -> Optional[SkillConfig]:
    """é‡è½½å•ä¸ª Skill"""
    load_skill.cache_clear()
    load_scenario.cache_clear()
    load_rule.cache_clear()
    _load_skill_md_content.cache_clear()  # v10
    return load_skill(skill_id)


def build_rule_prompt(skill_id: str, rule_id: str, user_context: Optional[Dict] = None) -> str:
    """æ„å»ºåŒ…å«è§„åˆ™çš„ System Prompt - v7 æ–°å¢

    Args:
        skill_id: Skill ID
        rule_id: Rule ID
        user_context: ç”¨æˆ·ä¸Šä¸‹æ–‡

    Returns:
        å®Œæ•´çš„ system promptï¼ŒåŒ…å«è§„åˆ™å†…å®¹
    """
    parts = []

    # åŠ è½½ Skill
    skill = load_skill(skill_id)
    if not skill:
        return ""

    # ä¸“å®¶èº«ä»½
    parts.append(f"# {skill.name}\n\n{skill.expert_persona}")

    # åŠ è½½è§„åˆ™
    rule = load_rule(skill_id, rule_id)
    if rule:
        parts.append(f"\n---\n\n## å½“å‰è§„åˆ™: {rule.name}\n")

        # æ·»åŠ è§„åˆ™å®Œæ•´å†…å®¹
        parts.append(rule.content)

    # ä¼¦ç†è¾¹ç•Œ
    if skill.ethics.get("forbidden"):
        ethics_text = "\n## ä¼¦ç†è¾¹ç•Œ\n\n### ç»å¯¹ç¦æ­¢\n"
        for item in skill.ethics["forbidden"]:
            ethics_text += f"- {item}\n"
        parts.append(ethics_text)

    # ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼ˆå¤ç”¨åŸæœ‰é€»è¾‘ï¼‰
    if user_context:
        ctx_text = "\n## ç”¨æˆ·ä¸Šä¸‹æ–‡\n"

        if user_context.get("birth_info"):
            birth_info = user_context['birth_info']
            ctx_text += f"\n### å‡ºç”Ÿä¿¡æ¯ï¼ˆå·²æ”¶é›†ï¼Œæ— éœ€å†æ¬¡è¯¢é—®ï¼‰\n"
            ctx_text += f"{json.dumps(birth_info, ensure_ascii=False)}\n"
            ctx_text += f"\n**é‡è¦**: ç”¨æˆ·å·²æä¾›å‡ºç”Ÿä¿¡æ¯ï¼Œå¯ä»¥ç›´æ¥è¿›è¡Œæ’ç›˜å’Œåˆ†æï¼Œæ— éœ€è°ƒç”¨ collect_bazi_info å·¥å…·ã€‚\n"

        if user_context.get("portrait"):
            ctx_text += f"\n### ç”¨æˆ·ç”»åƒ\n{user_context['portrait']}\n"

        if user_context.get("extracted"):
            extracted = user_context['extracted']
            ctx_text += f"\n### ç”¨æˆ·ä¿¡æ¯ (ä»å†å²å¯¹è¯ä¸­æŠ½å–)\n"
            if extracted.get("facts"):
                ctx_text += f"**åŸºæœ¬ä¿¡æ¯**: {json.dumps(extracted['facts'], ensure_ascii=False)}\n"
            if extracted.get("concerns"):
                ctx_text += f"**å…³æ³¨é¢†åŸŸ**: {', '.join(extracted['concerns'])}\n"
            if extracted.get("goals"):
                ctx_text += f"**å½“å‰ç›®æ ‡**: {', '.join(extracted['goals'])}\n"
            if extracted.get("pain_points"):
                ctx_text += f"**é¢ä¸´å›°éš¾**: {', '.join(extracted['pain_points'])}\n"

        parts.append(ctx_text)

    return "\n".join(parts)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# v7.5: æ•°æ®åº“ä¼˜å…ˆçš„å…ƒæ•°æ®åŠ è½½ï¼ˆAsyncï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

async def load_skill_metadata_async(skill_id: str) -> Optional[SkillMetadata]:
    """
    å¼‚æ­¥åŠ è½½ Skill å…ƒæ•°æ®ï¼ˆæ•°æ®åº“ä¼˜å…ˆï¼ŒSKILL.md ä½œä¸º fallbackï¼‰- v7.5 æ–°å¢

    ä¼˜å…ˆçº§ï¼š
    1. skill_catalog è¡¨ï¼ˆåŠ¨æ€é…ç½®ï¼‰
    2. SKILL.md frontmatterï¼ˆé™æ€é…ç½®ï¼‰

    Args:
        skill_id: Skill ID

    Returns:
        SkillMetadata å¯¹è±¡ï¼Œæˆ– Noneï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    """
    try:
        # 1. å°è¯•ä»æ•°æ®åº“åŠ è½½
        from stores.skill_catalog_repo import SkillCatalogRepository

        db_entry = await SkillCatalogRepository.get(skill_id)
        if db_entry:
            # è½¬æ¢ SkillCatalogEntry -> SkillMetadata
            return SkillMetadata(
                id=db_entry.skill_id,
                name=db_entry.name,
                description=db_entry.description,
                version=db_entry.version,
                category=db_entry.category,
                icon=db_entry.icon,
                color=db_entry.color,
                triggers=db_entry.triggers,
                pricing=SkillPricing(
                    type=db_entry.pricing.type,
                    trial_messages=db_entry.pricing.trial_messages,
                    credits_per_use=db_entry.pricing.credits_per_use,
                ),
                features=[
                    SkillFeature(
                        name=f.name,
                        description=f.description,
                        icon=f.icon,
                        tier=f.tier,
                    )
                    for f in db_entry.features
                ],
                showcase=SkillShowcase(
                    tagline=db_entry.showcase.tagline,
                    highlights=db_entry.showcase.highlights,
                    preview_image=db_entry.showcase.preview_image,
                    demo_prompts=db_entry.showcase.demo_prompts,
                ),
                subscription=SkillSubscription(
                    auto_subscribe=db_entry.subscription.auto_subscribe,
                    can_unsubscribe=db_entry.subscription.can_unsubscribe,
                    push_default=db_entry.subscription.push_default,
                    min_subscription_days=db_entry.subscription.min_subscription_days,
                ),
            )
    except Exception as e:
        logger.warning(f"Failed to load skill {skill_id} from database: {e}")

    # 2. Fallback åˆ° SKILL.md
    return load_skill_metadata(skill_id)


async def get_all_skill_metadata_async() -> List[SkillMetadata]:
    """
    å¼‚æ­¥è·å–æ‰€æœ‰ Skill å…ƒæ•°æ®ï¼ˆæ•°æ®åº“ä¼˜å…ˆï¼‰- v7.5 æ–°å¢

    ä¼˜å…ˆçº§ï¼š
    1. skill_catalog è¡¨ï¼ˆåŠ¨æ€é…ç½®ï¼‰
    2. SKILL.md fallbackï¼ˆå¦‚æœæ•°æ®åº“ä¸ºç©ºæˆ–å‡ºé”™ï¼‰

    Returns:
        æ‰€æœ‰ Skill çš„ SkillMetadata åˆ—è¡¨
    """
    try:
        # 1. å°è¯•ä»æ•°æ®åº“åŠ è½½
        from stores.skill_catalog_repo import SkillCatalogRepository

        catalog = await SkillCatalogRepository.get_all()
        if catalog:
            return [
                SkillMetadata(
                    id=entry.skill_id,
                    name=entry.name,
                    description=entry.description,
                    version=entry.version,
                    category=entry.category,
                    icon=entry.icon,
                    color=entry.color,
                    triggers=entry.triggers,
                    pricing=SkillPricing(
                        type=entry.pricing.type,
                        trial_messages=entry.pricing.trial_messages,
                        credits_per_use=entry.pricing.credits_per_use,
                    ),
                    features=[
                        SkillFeature(
                            name=f.name,
                            description=f.description,
                            icon=f.icon,
                            tier=f.tier,
                        )
                        for f in entry.features
                    ],
                    showcase=SkillShowcase(
                        tagline=entry.showcase.tagline,
                        highlights=entry.showcase.highlights,
                        preview_image=entry.showcase.preview_image,
                        demo_prompts=entry.showcase.demo_prompts,
                    ),
                    subscription=SkillSubscription(
                        auto_subscribe=entry.subscription.auto_subscribe,
                        can_unsubscribe=entry.subscription.can_unsubscribe,
                        push_default=entry.subscription.push_default,
                        min_subscription_days=entry.subscription.min_subscription_days,
                    ),
                )
                for entry in catalog.values()
            ]
    except Exception as e:
        logger.warning(f"Failed to load skill catalog from database: {e}")

    # 2. Fallback åˆ° SKILL.md
    return get_all_skill_metadata()


async def get_skills_by_category_async(category: str) -> List[SkillMetadata]:
    """
    å¼‚æ­¥æŒ‰åˆ†ç±»è·å– Skill åˆ—è¡¨ï¼ˆæ•°æ®åº“ä¼˜å…ˆï¼‰- v7.5 æ–°å¢

    Args:
        category: core | default | professional

    Returns:
        è¯¥åˆ†ç±»ä¸‹æ‰€æœ‰ Skill çš„ SkillMetadata åˆ—è¡¨
    """
    all_skills = await get_all_skill_metadata_async()
    return [s for s in all_skills if s.category == category]


async def get_featured_skills_async() -> List[SkillMetadata]:
    """
    å¼‚æ­¥è·å–ç²¾é€‰ Skill åˆ—è¡¨ï¼ˆæ•°æ®åº“ä¼˜å…ˆï¼‰- v7.5 æ–°å¢

    Returns:
        ç²¾é€‰ Skill åˆ—è¡¨ï¼ŒæŒ‰ featured_position æ’åº
    """
    try:
        from stores.skill_catalog_repo import SkillCatalogRepository

        featured_entries = await SkillCatalogRepository.get_featured()
        return [
            SkillMetadata(
                id=entry.skill_id,
                name=entry.name,
                description=entry.description,
                version=entry.version,
                category=entry.category,
                icon=entry.icon,
                color=entry.color,
                triggers=entry.triggers,
                pricing=SkillPricing(
                    type=entry.pricing.type,
                    trial_messages=entry.pricing.trial_messages,
                    credits_per_use=entry.pricing.credits_per_use,
                ),
                features=[
                    SkillFeature(
                        name=f.name,
                        description=f.description,
                        icon=f.icon,
                        tier=f.tier,
                    )
                    for f in entry.features
                ],
                showcase=SkillShowcase(
                    tagline=entry.showcase.tagline,
                    highlights=entry.showcase.highlights,
                    preview_image=entry.showcase.preview_image,
                    demo_prompts=entry.showcase.demo_prompts,
                ),
                subscription=SkillSubscription(
                    auto_subscribe=entry.subscription.auto_subscribe,
                    can_unsubscribe=entry.subscription.can_unsubscribe,
                    push_default=entry.subscription.push_default,
                    min_subscription_days=entry.subscription.min_subscription_days,
                ),
            )
            for entry in featured_entries
        ]
    except Exception as e:
        logger.warning(f"Failed to load featured skills from database: {e}")
        # Fallback: è¿”å› professional åˆ†ç±»çš„å‰ 3 ä¸ª
        all_skills = get_all_skill_metadata()
        professional = [s for s in all_skills if s.category == "professional"]
        return professional[:3]


async def get_skill_categories_summary_async() -> Dict[str, Dict]:
    """
    å¼‚æ­¥è·å–åˆ†ç±»ç»Ÿè®¡ï¼ˆæ•°æ®åº“ä¼˜å…ˆï¼‰- v7.5 æ–°å¢

    Returns:
        åˆ†ç±»ç»Ÿè®¡å­—å…¸
    """
    try:
        from stores.skill_catalog_repo import get_skill_categories_summary
        return await get_skill_categories_summary()
    except Exception as e:
        logger.warning(f"Failed to get category summary from database: {e}")
        # Fallback
        all_skills = get_all_skill_metadata()
        return {
            "core": {
                "name": "æ ¸å¿ƒèƒ½åŠ›",
                "description": "å§‹ç»ˆæ¿€æ´»çš„åŸºç¡€èƒ½åŠ›",
                "count": len([s for s in all_skills if s.category == "core"])
            },
            "default": {
                "name": "åŸºç¡€åŠŸèƒ½",
                "description": "é»˜è®¤æ¿€æ´»ï¼Œå…è´¹ä½¿ç”¨",
                "count": len([s for s in all_skills if s.category == "default"])
            },
            "professional": {
                "name": "ä¸“ä¸šæŠ€èƒ½",
                "description": "éœ€è¦è®¢é˜…çš„é«˜çº§åŠŸèƒ½",
                "count": len([s for s in all_skills if s.category == "professional"])
            },
        }
