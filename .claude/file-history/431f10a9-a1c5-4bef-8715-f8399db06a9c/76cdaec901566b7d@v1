"""
Retrieval Service - Hybrid search with RRF
"""
from typing import Optional, List, Dict, Any
from uuid import UUID

from stores import KnowledgeRepository
from .embedding import EmbeddingService


class RetrievalService:
    """
    Knowledge retrieval with hybrid search (Vector + FTS + RRF)
    """

    @classmethod
    async def search(
        cls,
        query: str,
        skill_id: str,
        top_k: int = 5,
        content_types: Optional[List[str]] = None,
        use_hybrid: bool = True
    ) -> List[Dict[str, Any]]:
        """
        Search knowledge base with hybrid retrieval.
        """
        # Generate query embedding
        query_embedding = await EmbeddingService.embed_query(query)

        if use_hybrid:
            # Hybrid search with RRF
            results = await KnowledgeRepository.hybrid_search(
                query=query,
                embedding=query_embedding,
                skill_id=skill_id,
                top_k=top_k,
                content_types=content_types
            )
        else:
            # Vector-only search
            results = await KnowledgeRepository.vector_search(
                embedding=query_embedding,
                skill_id=skill_id,
                top_k=top_k,
                content_types=content_types
            )

        return results

    @classmethod
    async def search_qa(
        cls,
        query: str,
        skill_id: str,
        top_k: int = 3
    ) -> List[Dict[str, Any]]:
        """Search QA pairs by question similarity"""
        query_embedding = await EmbeddingService.embed_query(query)

        results = await KnowledgeRepository.search_qa_pairs(
            embedding=query_embedding,
            skill_id=skill_id,
            top_k=top_k
        )

        return results

    @classmethod
    async def get_context_for_query(
        cls,
        query: str,
        skill_id: str,
        max_tokens: int = 2000
    ) -> str:
        """
        Get formatted context string for LLM from knowledge base.
        """
        # Search both chunks and QA pairs
        chunks = await cls.search(query, skill_id, top_k=3)
        qa_pairs = await cls.search_qa(query, skill_id, top_k=2)

        context_parts = []

        # Add relevant knowledge chunks
        if chunks:
            context_parts.append("## 相关知识")
            for chunk in chunks:
                content = chunk["content"][:500]  # Truncate
                source = chunk.get("source_file", "")
                context_parts.append(f"[{source}]\n{content}")

        # Add relevant QA pairs
        if qa_pairs:
            context_parts.append("\n## 相关问答")
            for qa in qa_pairs:
                context_parts.append(f"Q: {qa['question']}\nA: {qa['answer']}")

        return "\n\n".join(context_parts)

    @classmethod
    async def index_content(
        cls,
        skill_id: str,
        content: str,
        content_type: str,
        source_file: Optional[str] = None,
        metadata: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Index new content into knowledge base.
        """
        # Generate embedding
        embedding = await EmbeddingService.embed_text(content)

        # Create chunk
        chunk = await KnowledgeRepository.create_chunk(
            skill_id=skill_id,
            content=content,
            content_type=content_type,
            source_file=source_file,
            metadata=metadata,
            embedding=embedding
        )

        return chunk

    @classmethod
    async def index_qa_pair(
        cls,
        skill_id: str,
        question: str,
        answer: str,
        chunk_id: Optional[UUID] = None
    ) -> Dict[str, Any]:
        """
        Index a QA pair.
        """
        # Generate question embedding
        question_embedding = await EmbeddingService.embed_query(question)

        qa = await KnowledgeRepository.create_qa_pair(
            skill_id=skill_id,
            question=question,
            answer=answer,
            chunk_id=chunk_id,
            question_embedding=question_embedding
        )

        return qa
