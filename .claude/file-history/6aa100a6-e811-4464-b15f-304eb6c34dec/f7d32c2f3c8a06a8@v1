"""
Hotspot Worker - 每日热点抓取 Worker

运行模式:
1. 单次运行: python workers/hotspot_worker.py --once
2. 测试模式: python workers/hotspot_worker.py --dry-run

功能:
- 从 Google News RSS 获取新闻热点
- 关键词预过滤（保留与 VibeLife Skill 相关的新闻）
- 写入 .claude/skills/vibelife-xhs/data/hotspots.yaml

建议 Cron:
    0 6 * * * python3 workers/hotspot_worker.py --once
"""

import argparse
import asyncio
import logging
import sys
from datetime import datetime
from pathlib import Path

import yaml

# 添加项目根目录到 path
sys.path.insert(0, str(Path(__file__).parent.parent))

from services.news.fetcher import NewsFetcher, NewsItem

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
)
logger = logging.getLogger(__name__)

# hotspots.yaml 路径
HOTSPOTS_FILE = Path(__file__).parent.parent.parent.parent / ".claude/skills/vibelife-xhs/data/hotspots.yaml"


def news_items_to_yaml(items: list[NewsItem]) -> dict:
    """将新闻条目转换为 YAML 格式"""
    today = datetime.now().strftime("%Y-%m-%d")

    hotspots = []
    for item in items:
        hotspot = {
            "title": item.title,
            "link": item.link,
            "source": item.source,
            "keywords": item.matched_keywords,
            "potential_skills": item.potential_skills,
        }
        if item.published_at:
            hotspot["published_at"] = item.published_at.strftime("%Y-%m-%d %H:%M")
        if item.description:
            # 截断过长的描述
            hotspot["description"] = item.description[:200] + "..." if len(item.description) > 200 else item.description
        hotspots.append(hotspot)

    return {
        "date": today,
        "fetched_at": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "total_count": len(hotspots),
        "hotspots": hotspots,
    }


async def run_once(dry_run: bool = False) -> int:
    """执行一次热点抓取"""
    logger.info(f"Starting hotspot fetch at {datetime.now()}")

    # 初始化抓取器
    fetcher = NewsFetcher(max_items_per_feed=15)

    # 抓取新闻
    items = await fetcher.fetch_all()
    logger.info(f"Fetched {len(items)} relevant news items")

    if dry_run:
        logger.info("Dry run mode - not saving to file")
        for item in items[:10]:
            logger.info(f"  - [{', '.join(item.potential_skills)}] {item.title}")
        return len(items)

    # 转换为 YAML 格式
    data = news_items_to_yaml(items)

    # 确保目录存在
    HOTSPOTS_FILE.parent.mkdir(parents=True, exist_ok=True)

    # 写入文件
    with open(HOTSPOTS_FILE, "w", encoding="utf-8") as f:
        yaml.dump(data, f, allow_unicode=True, default_flow_style=False, sort_keys=False)

    logger.info(f"Saved {len(items)} hotspots to {HOTSPOTS_FILE}")
    return len(items)


def main():
    parser = argparse.ArgumentParser(description="Hotspot Worker - 每日热点抓取")
    parser.add_argument(
        "--once",
        action="store_true",
        help="执行一次后退出",
    )
    parser.add_argument(
        "--dry-run",
        action="store_true",
        help="测试模式，只抓取不保存",
    )

    args = parser.parse_args()

    result = asyncio.run(run_once(args.dry_run))
    logger.info(f"Completed with {result} hotspots")


if __name__ == "__main__":
    main()
