"""
Prompt Builder v10 - System Prompt 构建

从 core.py 拆分出来的 Prompt 构建逻辑，支持：
- Phase 1/Phase 2 分阶段 Prompt
- 会话恢复 Prompt（断点续传）
- SOP 规则注入
- 案例匹配

与 ContextManager 协作：
- 读取会话上下文
- 注入断点信息
"""
import json
import logging
from typing import Optional, Dict, Any, List

from .skill_loader import (
    load_skill, build_system_prompt,
    get_skill_required_data
)
# 简化：仅保留 inject_placeholders 的最小实现以兼容调用
def inject_placeholders(template: str, context: Optional[Dict[str, Any]] = None) -> str:
    if not template:
        return template
    replacements = dict(context or {})
    result = template
    for k, v in replacements.items():
        result = result.replace("{" + k + "}", str(v))
    return result
from .context_manager import SessionContext

logger = logging.getLogger(__name__)


class PromptBuilder:
    """
    System Prompt 构建器

    职责：
    1. 根据 Phase 构建不同的 Prompt
    2. 注入会话恢复上下文
    3. 注入 SOP 规则
    4. 动态加载案例
    5. v10.1: 用户画像注入（让 Coach 了解用户）
    """

    # 需要详细用户画像的 Skill（注入 goals, patterns, findings）
    PORTRAIT_FULL_SKILLS = {"lifecoach", "career"}

    # 需要出生信息的 Skill
    BIRTH_INFO_SKILLS = {"bazi", "zodiac", "jungastro"}

    def __init__(self):
        self.case_index = None  # Lazy init

    async def build(
        self,
        skill_id: Optional[str],
        rule_id: Optional[str],
        message: str,
        profile: Optional[Dict[str, Any]] = None,
        skill_data: Optional[Dict[str, Any]] = None,
        session_context: Optional[SessionContext] = None,
        protocol_prompt: Optional[str] = None
    ) -> str:
        """
        构建 System Prompt

        Args:
            skill_id: 当前技能 ID
            rule_id: 当前规则 ID
            message: 用户消息
            profile: 用户 Profile
            skill_data: Skill 数据
            session_context: 会话上下文（断点续传）
            protocol_prompt: 协议专用 Prompt（可选）

        Returns:
            完整的 System Prompt
        """
        parts = []

        # ═══════════════════════════════════════════════════════════════
        # 协议模式：使用协议专用 Prompt
        # ═══════════════════════════════════════════════════════════════
        if protocol_prompt:
            skill = load_skill("lifecoach")
            if skill:
                parts.append(f"# {skill.name}\n\n{skill.expert_persona}")
            parts.append("\n---\n")
            parts.append(protocol_prompt)
            return "\n".join(parts)

        if skill_id:
            # ═══════════════════════════════════════════════════════════════
            # Phase 2: Skill 执行阶段 - 完整上下文
            # ═══════════════════════════════════════════════════════════════

            # 基础 Skill Prompt
            user_ctx = dict(profile) if profile else {}
            base_prompt = build_system_prompt(skill_id, rule_id, user_ctx)
            parts.append(base_prompt)

            # ═══════════════════════════════════════════════════════════════
            # Profile 注入（简化版 v2.2）- 两层架构
            # ═══════════════════════════════════════════════════════════════
            profile_context = self._build_profile_context(profile, skill_data, skill_id)
            if profile_context:
                parts.append(profile_context)

            # 会话恢复上下文（断点续传核心）
            if session_context and session_context.has_checkpoint:
                resume_context = session_context.to_prompt_context()
                if resume_context:
                    parts.append(resume_context)

            # LLM-First: 移除硬编码 SOP 规则，由 SKILL.md 驱动

            # 案例匹配
            cases_text = await self._match_cases(skill_id, skill_data)
            if cases_text:
                parts.append(cases_text)

        else:
            # ═══════════════════════════════════════════════════════════════
            # Phase 1: Skill 选择阶段 - v11 个性化路由
            # ═══════════════════════════════════════════════════════════════

            # LLM-First: 构建最小 Phase 1 提示（不依赖 routing.yaml）
            from .skill_loader import build_phase1_prompt
            core_prompt = build_phase1_prompt()
            # 注入用户画像和订阅信息（用于个性化路由）
            if profile:
                core_prompt = self._inject_phase1_context(core_prompt, profile)
            parts.append(core_prompt)

        return "\n".join(parts)

    def _build_profile_context(
        self,
        profile: Optional[Dict[str, Any]],
        skill_data: Optional[Dict[str, Any]],
        skill_id: str
    ) -> str:
        """
        构建 Profile 上下文（v3.0 三层架构）

        三层架构：
        - Layer 1: Identity（共享）- 基本信息
        - Layer 2: Skills（当前 Skill 专属）- skills.{skill_id}
        - Layer 3: Vibe（共享深度信息）- vibe.insight + vibe.target
        """
        parts = []

        # ═══════════════════════════════════════════════════════════════
        # Layer 1: Identity（所有 Skill 共享，~200 tokens）
        # ═══════════════════════════════════════════════════════════════
        if profile:
            identity = profile.get("identity", {})

            base_info = []

            # 用户名
            name = identity.get("display_name")
            if name:
                base_info.append(f"- 用户名：{name}")

            # 出生信息（如有）
            birth = identity.get("birth_info", {})
            if birth:
                birth_date = birth.get("birth_date") or birth.get("date")
                if birth_date:
                    base_info.append(f"- 出生日期：{birth_date}")
                birth_time = birth.get("birth_time") or birth.get("time")
                if birth_time:
                    base_info.append(f"- 出生时间：{birth_time}")
                birth_place = birth.get("birth_place") or birth.get("location")
                if birth_place:
                    base_info.append(f"- 出生地点：{birth_place}")

            if base_info:
                parts.append("## 用户信息\n\n" + "\n".join(base_info))

        # ═══════════════════════════════════════════════════════════════
        # Layer 2: Skills（当前 Skill 专属，~300 tokens）
        # ═══════════════════════════════════════════════════════════════
        if skill_data:
            # 获取该 Skill 需要的 skill_data（从 SKILL.md 配置读取）
            skill_ids = get_skill_required_data(skill_id)

            for sid in skill_ids:
                data = skill_data.get(sid, {})
                if data:
                    # 过滤掉内部字段（以 _ 开头）
                    filtered_data = {k: v for k, v in data.items() if not k.startswith("_")}
                    if filtered_data:
                        parts.append(f"\n## {sid} 数据\n\n```json\n{json.dumps(filtered_data, ensure_ascii=False, indent=2)}\n```")

        # ═══════════════════════════════════════════════════════════════
        # Layer 3: Vibe（共享深度信息，~200 tokens）
        # ═══════════════════════════════════════════════════════════════
        if profile:
            vibe = profile.get("vibe", {})

            # VibeInsight - 我是谁
            insight = vibe.get("insight", {})
            if insight:
                insight_parts = []

                # 本质
                essence = insight.get("essence", {})
                if essence:
                    archetype = essence.get("archetype", {})
                    if archetype.get("primary"):
                        insight_parts.append(f"- 主要原型：{archetype['primary']}")
                    traits = essence.get("traits", [])
                    if traits:
                        trait_text = ", ".join([t.get("trait", str(t)) if isinstance(t, dict) else str(t) for t in traits[:3]])
                        insight_parts.append(f"- 核心特质：{trait_text}")

                # 动态
                dynamic = insight.get("dynamic", {})
                if dynamic:
                    emotion = dynamic.get("emotion", {})
                    if emotion.get("current"):
                        insight_parts.append(f"- 当前情绪：{emotion['current']}")
                    energy = dynamic.get("energy", {})
                    if energy.get("level"):
                        insight_parts.append(f"- 能量水平：{energy['level']}")

                # 规律
                pattern = insight.get("pattern", {})
                if pattern:
                    insights_list = pattern.get("insights", [])
                    if insights_list:
                        insight_parts.append(f"- 洞察：{insights_list[0]}")

                if insight_parts:
                    parts.append("\n## 用户画像\n\n" + "\n".join(insight_parts))

            # VibeTarget - 我要成为谁
            target = vibe.get("target", {})
            if target:
                target_parts = []

                # 北极星
                north_star = target.get("north_star", {})
                if north_star.get("vision_scene"):
                    vision = north_star["vision_scene"]
                    if len(vision) > 100:
                        vision = vision[:100] + "..."
                    target_parts.append(f"- 愿景：{vision}")

                # 目标
                goals = target.get("goals", [])
                if goals:
                    active_goals = [g for g in goals if g.get("status") == "in_progress"][:2]
                    if active_goals:
                        goals_text = ", ".join([g.get("title", "") for g in active_goals])
                        target_parts.append(f"- 当前目标：{goals_text}")

                # 聚焦
                focus = target.get("focus", {})
                if focus.get("primary"):
                    target_parts.append(f"- 关注领域：{focus['primary']}")

                if target_parts:
                    parts.append("\n## 用户目标\n\n" + "\n".join(target_parts))

        return "\n".join(parts) if parts else ""

    # LLM-First v10.3: 移除 _build_sop_rules, _compute_status, _extract_chart_summary
    # 这些硬编码逻辑违反 LLM-First 原则，现在由 SKILL.md 中的规则驱动 LLM 自主判断

    async def _match_cases(
        self,
        skill_id: str,
        skill_data: Optional[Dict[str, Any]]
    ) -> str:
        """匹配相关案例"""
        if not skill_data:
            return ""

        try:
            from .case_index import get_case_index, extract_features

            if self.case_index is None:
                self.case_index = get_case_index()

            features = extract_features(skill_data)
            if not features:
                return ""

            cases = await self.case_index.get_matched_cases(skill_id, features, top_k=2)
            if not cases:
                return ""

            cases_text = "\n## 相关案例\n\n"
            for case in cases:
                cases_text += f"### {case.name}\n{case.content}\n\n"

            return cases_text

        except Exception as e:
            logger.warning(f"[PromptBuilder] Case matching failed: {e}")
            return ""

    # ═══════════════════════════════════════════════════════════════════════════
    # Phase 1 个性化路由 (v11 新增)
    # ═══════════════════════════════════════════════════════════════════════════

    def _inject_phase1_context(self, prompt: str, profile: Dict[str, Any]) -> str:
        """
        注入 Phase 1 上下文（v11 个性化路由）

        将以下占位符替换为实际内容：
        - {user_portrait} - 用户画像
        - {subscribed_skills} - 已订阅服务
        - {recommendable_skills} - 可推荐服务
        - {personalization_hint} - 个性化提示
        - {boundary_rules_shared} - 能力边界规则 (v2.0)
        """
        # v2.0: 注入能力边界规则
        prompt = inject_placeholders(prompt, {})

        # 用户画像
        user_portrait = self._build_user_portrait(profile)
        prompt = prompt.replace("{user_portrait}", user_portrait)

        # 已订阅服务
        subscribed = profile.get("subscribed_skills", [])
        subscribed_text = self._build_subscribed_skills_text(subscribed)
        prompt = prompt.replace("{subscribed_skills}", subscribed_text)

        # 可推荐服务
        recommendable_text = self._build_recommendable_skills_text(subscribed)
        prompt = prompt.replace("{recommendable_skills}", recommendable_text)

        # LLM-First: 移除个性化提示硬编码，让 LLM 直接读取 profile 自主判断
        prompt = prompt.replace("{personalization_hint}", "")

        return prompt

    def _build_user_portrait(self, profile: Dict[str, Any]) -> str:
        """构建用户画像（~100 tokens）"""
        if not profile:
            return ""

        lines = []

        # 身份
        identity = profile.get("identity", {})
        if identity.get("display_name"):
            lines.append(f"- 用户名：{identity['display_name']}")

        # v2.0: 出生信息（用于直接回答 Profile 查询）
        birth_info = identity.get("birth_info", {})
        if birth_info:
            birth_date = birth_info.get("birth_date") or birth_info.get("date")
            if birth_date:
                lines.append(f"- 出生日期：{birth_date}")
            birth_time = birth_info.get("birth_time") or birth_info.get("time")
            if birth_time:
                lines.append(f"- 出生时间：{birth_time}")
            birth_place = birth_info.get("birth_place") or birth_info.get("location")
            if birth_place:
                lines.append(f"- 出生地点：{birth_place}")

        # Vibe.insight（原型）
        vibe = profile.get("vibe", {})
        insight = vibe.get("insight", {})
        essence = insight.get("essence", {})

        archetype = essence.get("archetype", {})
        if archetype.get("primary"):
            lines.append(f"- 原型：{archetype['primary']}")

        traits = essence.get("traits", [])
        if traits:
            trait_names = [t.get("trait", str(t)) if isinstance(t, dict) else str(t) for t in traits[:3]]
            lines.append(f"- 特质：{', '.join(trait_names)}")

        # Vibe.target（关注领域）
        target = vibe.get("target", {})

        north_star = target.get("north_star", {})
        if north_star.get("statement"):
            statement = north_star["statement"]
            if len(statement) > 50:
                statement = statement[:50] + "..."
            lines.append(f"- 愿景：{statement}")

        focus = target.get("focus", {})
        if focus.get("primary"):
            lines.append(f"- 关注：{focus['primary']}")

        if not lines:
            return ""

        return "## 用户画像\n\n" + "\n".join(lines)

    def _build_subscribed_skills_text(self, subscribed: List[str]) -> str:
        """构建已订阅服务列表（LLM-First，不依赖 routing.yaml）"""
        from .skill_loader import load_skill

        if not subscribed:
            return "用户暂未订阅任何服务。"

        lines = ["用户已订阅的服务，可直接激活：\n"]

        for skill_id in subscribed:
            skill = load_skill(skill_id)
            if skill:
                desc = (skill.description or "").strip().replace('\n', ' ')
                if len(desc) > 30:
                    desc = desc[:30] + "..."
                lines.append(f"- **{skill_id}**: {desc}")

        return "\n".join(lines)

    def _build_recommendable_skills_text(self, subscribed: List[str]) -> str:
        """构建可推荐服务列表（LLM-First，不依赖 routing.yaml）"""
        from .skill_loader import load_skill, get_available_skills

        all_skills = [s for s in get_available_skills() if s != "core"]
        not_subscribed = [s for s in all_skills if s not in subscribed]

        if not not_subscribed:
            return "用户已订阅所有服务。"

        lines = ["用户未订阅但可能感兴趣：\n"]

        for skill_id in not_subscribed[:4]:  # 最多显示 4 个
            skill = load_skill(skill_id)
            if skill:
                desc = (skill.description or "").strip().replace('\n', ' ')
                if len(desc) > 30:
                    desc = desc[:30] + "..."
                lines.append(f"- **{skill_id}**: {desc}")

        return "\n".join(lines)

    # LLM-First v10.3: 移除 _build_personalization_hint
    # 硬编码的关键词匹配路由违反 LLM-First 原则
    # LLM 应该直接读取 profile 数据自主判断路由，无需代码层面的提示

    def _get_fallback_phase1_prompt(self) -> str:
        """Fallback Phase 1 Prompt"""
        return """# Vibe

你是 Vibe，生命对话者。你的任务是理解用户意图，引导 Ta 到合适的服务。

## 行为准则

1. **识别意图 → 调用工具**：不要只用文字回复，要调用工具
2. **简短回应 + 工具**：调用工具时配合一句暖心的话
3. **不确定 → 推荐**：调用 recommend_skills 让用户选择

## 语气

温暖、简洁、不啰嗦。像一个懂你的老朋友。

示例：
- "嗨～ 今天想聊点什么？"
- "好的，让我来帮你看看～"
- "迷茫的时候来找我就对了。"
"""

    # LLM-First v10.3: 移除 _get_ready_prompt, _get_need_birth_prompt, _get_need_compute_prompt
    # 这些硬编码的状态提示违反 LLM-First 原则
    # 由 SKILL.md 中的规则驱动 LLM 自主判断下一步操作

    def build_session_resume_prompt(
        self,
        session_context: SessionContext,
        rule_name: Optional[str] = None
    ) -> str:
        """
        构建会话恢复 Prompt（用于 SOP 模板）

        专门用于断点续传场景
        """
        if not session_context or not session_context.has_checkpoint:
            return ""

        cp = session_context.checkpoint
        session = session_context.session

        lines = ["## 会话恢复模式\n"]

        if cp:
            lines.append(f"用户上次完成了 {cp.step} 个步骤。\n")

            if cp.collected_data:
                lines.append("**已收集信息**：")
                for key, value in cp.collected_data.items():
                    lines.append(f"- {key}: {value}")
                lines.append("")

            next_step = cp.step + 1
            lines.append(f"**下一步**：")
            lines.append(f"继续第 {next_step} 个问题\n")

        lines.append("**处理方式**：")
        lines.append("1. 简短问候：「欢迎回来！上次我们聊到了...」")
        lines.append("2. 快速回顾（1-2 句）")
        lines.append("3. 直接问下一个问题")

        return "\n".join(lines)


# ═══════════════════════════════════════════════════════════════════════════
# Singleton
# ═══════════════════════════════════════════════════════════════════════════

_prompt_builder: Optional[PromptBuilder] = None


def get_prompt_builder() -> PromptBuilder:
    """获取 PromptBuilder 单例"""
    global _prompt_builder
    if _prompt_builder is None:
        _prompt_builder = PromptBuilder()
    return _prompt_builder
