     1→"""
     2→Agent Runtime - Main agent processing pipeline
     3→"""
     4→from typing import Optional, List, Dict, Any, AsyncGenerator
     5→from uuid import UUID
     6→from dataclasses import dataclass
     7→
     8→from .persona import PersonaManager
     9→from .router import SkillRouter, Intent
    10→from services.vibe_engine import LLMOrchestrator, LLMMessage, EmotionEngine, MemorySystem, InsightGenerator
    11→from services.knowledge import RetrievalService, EmbeddingService
    12→from stores import SkillRepository, UserRepository
    13→
    14→
    15→@dataclass
    16→class AgentResponse:
    17→    """Agent response"""
    18→    content: str
    19→    conversation_id: UUID
    20→    intent: Optional[Intent] = None
    21→    tools_used: Optional[List[str]] = None
    22→    knowledge_used: bool = False
    23→    insight: Optional[Dict[str, Any]] = None
    24→    suggestions: Optional[List[str]] = None
    25→
    26→
    27→class AgentRuntime:
    28→    """
    29→    Main agent runtime - orchestrates the full processing pipeline.
    30→
    31→    Pipeline:
    32→    1. Context Assembly - Load user profile, history, memories
    33→    2. Intent Classification - Identify intent and route
    34→    3. Knowledge Retrieval - Get relevant knowledge
    35→    4. Tool Invocation - Call skill tools if needed
    36→    5. Insight Generation - Check for insight triggers
    37→    6. Response Composition - Generate response with persona
    38→    """
    39→
    40→    # ─────────────────────────────────────────────────────────────────
    41→    # Main Entry Point
    42→    # ─────────────────────────────────────────────────────────────────
    43→
    44→    @classmethod
    45→    async def process_message(
    46→        cls,
    47→        user_id: UUID,
    48→        skill_id: str,
    49→        message: str,
    50→        conversation_id: Optional[UUID] = None
    51→    ) -> AgentResponse:
    52→        """
    53→        Process a user message through the full pipeline.
    54→        """
    55→        # ─────────────────────────────────────────────────────────────
    56→        # 1. Context Assembly
    57→        # ─────────────────────────────────────────────────────────────
    58→
    59→        # Get or create conversation
    60→        if not conversation_id:
    61→            conv = await SkillRepository.create_conversation(user_id, skill_id)
    62→            conversation_id = conv["id"]
    63→
    64→        # Get user profile
    65→        profile = await SkillRepository.get_or_create_profile(user_id, skill_id)
    66→        user_data = await UserRepository.get_by_id(user_id)
    67→
    68→        user_context = {
    69→            "vibe_id": user_data.get("vibe_id") if user_data else None,
    70→            "display_name": user_data.get("display_name") if user_data else None,
    71→            "birth_datetime": user_data.get("birth_datetime") if user_data else None,
    72→            "birth_location": user_data.get("birth_location") if user_data else None,
    73→            **profile.get("profile_data", {})
    74→        }
    75→
    76→        # Get conversation history
    77→        history = await MemorySystem.get_conversation_history(conversation_id, limit=10)
    78→
    79→        # ─────────────────────────────────────────────────────────────
    80→        # 2. Intent Classification
    81→        # ─────────────────────────────────────────────────────────────
    82→
    83→        intent, intent_confidence = SkillRouter.classify_intent(message, skill_id)
    84→
    85→        # Check if required context is available
    86→        is_ready, missing = SkillRouter.check_context_ready(intent, user_context)
    87→
    88→        # ─────────────────────────────────────────────────────────────
    89→        # 3. Knowledge Retrieval
    90→        # ─────────────────────────────────────────────────────────────
    91→
    92→        knowledge_context = ""
    93→        knowledge_used = False
    94→
    95→        try:
    96→            knowledge_context = await RetrievalService.get_context_for_query(
    97→                message, skill_id
    98→            )
    99→            knowledge_used = bool(knowledge_context)
   100→        except Exception as e:
   101→            print(f"Knowledge retrieval failed: {e}")
   102→
   103→        # ─────────────────────────────────────────────────────────────
   104→        # 4. Tool Invocation (if needed)
   105→        # ─────────────────────────────────────────────────────────────
   106→
   107→        tools_used = []
   108→        tool_results = {}
   109→
   110→        required_tools = SkillRouter.get_tools_for_intent(intent)
   111→
   112→        if required_tools and is_ready:
   113→            for tool_name in required_tools:
   114→                try:
   115→                    result = await cls._invoke_tool(tool_name, user_context)
   116→                    if result:
   117→                        tool_results[tool_name] = result
   118→                        tools_used.append(tool_name)
   119→                except Exception as e:
   120→                    print(f"Tool {tool_name} failed: {e}")
   121→
   122→        # ─────────────────────────────────────────────────────────────
   123→        # 5. Emotion Analysis
   124→        # ─────────────────────────────────────────────────────────────
   125→
   126→        emotion_result = await EmotionEngine.analyze(message)
   127→
   128→        # ─────────────────────────────────────────────────────────────
   129→        # 6. Response Generation
   130→        # ─────────────────────────────────────────────────────────────
   131→
   132→        # Build system prompt
   133→        persona = PersonaManager.get_persona(skill_id)
   134→
   135→        system_prompt = LLMOrchestrator.build_system_prompt(
   136→            persona=persona,
   137→            skill_context=knowledge_context if knowledge_used else None,
   138→            user_context=cls._format_user_context(user_context),
   139→            guidelines=cls._get_situation_guideline(intent, emotion_result, is_ready, missing)
   140→        )
   141→
   142→        # Add tool results to context if any
   143→        if tool_results:
   144→            tool_context = "\n\n## 工具计算结果\n" + "\n".join([
   145→                f"### {name}\n{result}"
   146→                for name, result in tool_results.items()
   147→            ])
   148→            system_prompt += tool_context
   149→
   150→        # Build messages
   151→        messages = LLMOrchestrator.build_messages(
   152→            system_prompt,
   153→            [{"role": m["role"], "content": m["content"]} for m in history[-6:]],
   154→            message
   155→        )
   156→
   157→        # Generate response
   158→        response = await LLMOrchestrator.chat(messages)
   159→
   160→        # ─────────────────────────────────────────────────────────────
   161→        # 7. Save Message
   162→        # ─────────────────────────────────────────────────────────────
   163→
   164→        # Save user message
   165→        await SkillRepository.add_message(
   166→            conversation_id=conversation_id,
   167→            role="user",
   168→            content=message,
   169→            intent=intent.value if intent else None
   170→        )
   171→
   172→        # Save assistant message
   173→        await SkillRepository.add_message(
   174→            conversation_id=conversation_id,
   175→            role="assistant",
   176→            content=response.content,
   177→            tools_used=tools_used if tools_used else None,
   178→            knowledge_used=["knowledge_base"] if knowledge_used else None
   179→        )
   180→
   181→        # ─────────────────────────────────────────────────────────────
   182→        # 8. Insight Generation
   183→        # ─────────────────────────────────────────────────────────────
   184→
   185→        insight = await InsightGenerator.maybe_generate_insight(
   186→            user_id=user_id,
   187→            skill_id=skill_id,
   188→            message=message,
   189→            conversation_id=conversation_id,
   190→            emotion_result=emotion_result,
   191→            user_context=user_context,
   192→            llm_orchestrator=LLMOrchestrator
   193→        )
   194→
   195→        # ─────────────────────────────────────────────────────────────
   196→        # 9. Generate Suggestions
   197→        # ─────────────────────────────────────────────────────────────
   198→
   199→        suggestions = cls._generate_suggestions(intent, skill_id)
   200→
   201→        return AgentResponse(
   202→            content=response.content,
   203→            conversation_id=conversation_id,
   204→            intent=intent,
   205→            tools_used=tools_used if tools_used else None,
   206→            knowledge_used=knowledge_used,
   207→            insight=insight,
   208→            suggestions=suggestions
   209→        )
   210→
   211→    # ─────────────────────────────────────────────────────────────────
   212→    # Streaming Version
   213→    # ─────────────────────────────────────────────────────────────────
   214→
   215→    @classmethod
   216→    async def stream_message(
   217→        cls,
   218→        user_id: UUID,
   219→        skill_id: str,
   220→        message: str,
   221→        conversation_id: Optional[UUID] = None
   222→    ) -> AsyncGenerator[str, None]:
   223→        """
   224→        Process message with streaming response.
   225→        """
   226→        # Setup (same as non-streaming)
   227→        if not conversation_id:
   228→            conv = await SkillRepository.create_conversation(user_id, skill_id)
   229→            conversation_id = conv["id"]
   230→
   231→        profile = await SkillRepository.get_or_create_profile(user_id, skill_id)
   232→        user_data = await UserRepository.get_by_id(user_id)
   233→
   234→        user_context = {
   235→            "birth_datetime": user_data.get("birth_datetime") if user_data else None,
   236→            "birth_location": user_data.get("birth_location") if user_data else None,
   237→            **profile.get("profile_data", {})
   238→        }
   239→
   240→        history = await MemorySystem.get_conversation_history(conversation_id, limit=10)
   241→        intent, _ = SkillRouter.classify_intent(message, skill_id)
   242→
   243→        # Knowledge retrieval
   244→        knowledge_context = ""
   245→        try:
   246→            knowledge_context = await RetrievalService.get_context_for_query(
   247→                message, skill_id
   248→            )
   249→        except Exception:
   250→            pass
   251→
   252→        # Build prompt
   253→        persona = PersonaManager.get_persona(skill_id)
   254→        system_prompt = LLMOrchestrator.build_system_prompt(
   255→            persona=persona,
   256→            skill_context=knowledge_context if knowledge_context else None,
   257→            user_context=cls._format_user_context(user_context)
   258→        )
   259→
   260→        messages = LLMOrchestrator.build_messages(
   261→            system_prompt,
   262→            [{"role": m["role"], "content": m["content"]} for m in history[-6:]],
   263→            message
   264→        )
   265→
   266→        # Save user message
   267→        await SkillRepository.add_message(
   268→            conversation_id=conversation_id,
   269→            role="user",
   270→            content=message,
   271→            intent=intent.value if intent else None
   272→        )
   273→
   274→        # Stream response
   275→        full_response = ""
   276→        async for chunk in LLMOrchestrator.stream(messages):
   277→            full_response += chunk
   278→            yield chunk
   279→
   280→        # Save assistant message
   281→        await SkillRepository.add_message(
   282→            conversation_id=conversation_id,
   283→            role="assistant",
   284→            content=full_response
   285→        )
   286→
   287→    # ─────────────────────────────────────────────────────────────────
   288→    # Helper Methods
   289→    # ─────────────────────────────────────────────────────────────────
   290→
   291→    @staticmethod
   292→    def _format_user_context(context: Dict[str, Any]) -> str:
   293→        """Format user context for prompt"""
   294→        parts = []
   295→        if context.get("display_name"):
   296→            parts.append(f"用户名: {context['display_name']}")
   297→        if context.get("birth_datetime"):
   298→            parts.append(f"出生时间: {context['birth_datetime']}")
   299→        if context.get("birth_location"):
   300→            parts.append(f"出生地点: {context['birth_location']}")
   301→
   302→        # Add skill-specific data
   303→        for key, value in context.items():
   304→            if key not in ["vibe_id", "display_name", "birth_datetime", "birth_location"]:
   305→                if value:
   306→                    parts.append(f"{key}: {value}")
   307→
   308→        return "\n".join(parts) if parts else "暂无用户信息"
   309→
   310→    @staticmethod
   311→    def _get_situation_guideline(
   312→        intent: Intent,
   313→        emotion_result,
   314→        is_ready: bool,
   315→        missing: List[str]
   316→    ) -> str:
   317→        """Get response guideline based on situation"""
   318→        guidelines = []
   319→
   320→        # Missing info
   321→        if not is_ready and missing:
   322→            missing_names = {
   323→                "birth_datetime": "出生日期时间",
   324→                "birth_location": "出生地点",
   325→                "bazi_chart": "八字命盘"
   326→            }
   327→            missing_str = "、".join([missing_names.get(m, m) for m in missing])
   328→            guidelines.append(f"需要询问用户: {missing_str}")
   329→
   330→        # Emotional state
   331→        if emotion_result and emotion_result.intensity > 0.6:
   332→            if emotion_result.primary.value in ["sadness", "anger", "fear"]:
   333→                guidelines.append("用户情绪较低落，先表达共情和理解")
   334→            elif emotion_result.primary.value == "joy":
   335→                guidelines.append("用户心情不错，可以更轻松地交流")
   336→
   337→        # Intent-specific
   338→        if intent == Intent.GREETING:
   339→            guidelines.append("这是开场，简短友好地介绍自己能帮什么")
   340→        elif intent == Intent.EMOTIONAL:
   341→            guidelines.append("用户需要情感支持，先倾听和共情")
   342→
   343→        return "\n".join(guidelines) if guidelines else ""
   344→
   345→    @staticmethod
   346→    def _generate_suggestions(intent: Intent, skill_id: str) -> List[str]:
   347→        """Generate follow-up suggestions"""
   348→        suggestions_map = {
   349→            "bazi": {
   350→                Intent.BAZI_CHART: ["看看今年运势", "分析性格特点", "事业发展建议"],
   351→                Intent.GREETING: ["帮我看看命盘", "今年运势如何", "分析我的性格"],
   352→            },
   353→            "zodiac": {
   354→                Intent.ZODIAC_NATAL: ["这周运势如何", "水逆对我影响大吗", "感情运怎么样"],
   355→                Intent.GREETING: ["看看我的星盘", "这周运势", "最近要注意什么"],
   356→            },
   357→            "mbti": {
   358→                Intent.MBTI_TYPE: ["我适合什么工作", "如何和XX类型相处", "我的成长方向"],
   359→                Intent.GREETING: ["帮我测一下类型", "INFP是什么样的", "我和XX合适吗"],
   360→            }
   361→        }
   362→
   363→        skill_suggestions = suggestions_map.get(skill_id, {})
   364→        return skill_suggestions.get(intent, skill_suggestions.get(Intent.GREETING, []))
   365→
   366→    @staticmethod
   367→    async def _invoke_tool(tool_name: str, context: Dict[str, Any]) -> Optional[str]:
   368→        """Invoke a skill tool"""
   369→        # Tool invocation would be implemented here
   370→        # For now, return None to indicate no tool result
   371→        return None
   372→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
