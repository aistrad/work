The file /home/aiscend/.claude/plans/swift-herding-peacock.md has been updated. Here's the result of running `cat -n` on a snippet of the edited file:
     1→# Scenario 与 Case 抽取流程优化计划
     2→
     3→> 前置工作（已完成）：通用模板优化，新增 thinking_frameworks_used, reasoning_chain, guidance_patterns 三个字段
     4→
     5→---
     6→
     7→## 一、现状分析
     8→
     9→### 1.1 当前抽取架构
    10→
    11→```
    12→┌─────────────────────────────────────────────────────────────────────────┐
    13→│                     当前架构（两次独立处理）                              │
    14→├─────────────────────────────────────────────────────────────────────────┤
    15→│                                                                         │
    16→│  knowledge_chunks 表                                                    │
    17→│        │                                                                │
    18→│        ├───→ [Stage 4a] case_extractor.py ───→ cases 表                │
    19→│        │         └─ LLM Call #1                                        │
    20→│        │                                                                │
    21→│        └───→ [Stage 4b] scenario_generator.py ───→ scenario_candidates │
    22→│                  └─ LLM Call #2                                        │
    23→│                                                                         │
    24→│  问题：                                                                 │
    25→│  • 同一 chunk 被处理两次，浪费 LLM 调用                                  │
    26→│  • 无增量处理，每次全量跑                                                │
    27→│  • Scenario 无法追溯来源 chunk                                          │
    28→│  • 更新 Prompt 后无法选择性重新处理                                      │
    29→│                                                                         │
    30→└─────────────────────────────────────────────────────────────────────────┘
    31→```
    32→
    33→### 1.2 关键文件清单
    34→
    35→| 文件 | 职责 | 行数 |
    36→|------|------|------|
    37→| `apps/api/workers/case_extractor.py` | Case 提取 | 346 行 |
    38→| `apps/api/workers/scenario_generator.py` | Scenario 生成 | 463 行 |
    39→| `apps/api/scripts/build_knowledge.py` | 流水线编排 | 342 行 |
    40→| `.claude/skills/vibelife-skill/templates/prompts/CASE_EXTRACTION_PROMPT.md` | Case Prompt 模板 | ~150 行 |
    41→
    42→### 1.3 数据流分析
    43→
    44→**Case 抽取 (case_extractor.py:316-329)**：
    45→```python
    46→# 数据源查询
    47→SELECT id, chunk_text as content
    48→FROM knowledge_chunks
    49→WHERE skill_id = $1
    50→AND chunk_type IN ('case', 'theory', 'rule')  # 过滤条件
    51→LIMIT $2
    52→```
    53→
    54→**Scenario 生成 (scenario_generator.py:430-441)**：
    55→```python
    56→# 数据源查询
    57→SELECT id, chunk_text as content, chunk_type
    58→FROM knowledge_chunks
    59→WHERE skill_id = $1
    60→ORDER BY chunk_type DESC  # 优先 method
    61→LIMIT $2
    62→```
    63→
    64→---
    65→
    66→## 二、优化目标
    67→
    68→```
    69→┌─────────────────────────────────────────────────────────────────────────┐
    70→│                     目标架构（统一抽取 + 增量处理）                       │
    71→├─────────────────────────────────────────────────────────────────────────┤
    72→│                                                                         │
    73→│  knowledge_chunks 表                                                    │
    74→│        │                                                                │
    75→│        ▼                                                                │
    76→│  [Stage 4] unified_extractor.py                                        │
    77→│        │   └─ 单次 LLM 调用同时提取 Case + Scenario                     │
    78→│        │   └─ 增量处理：只处理 extraction_status = 'pending'            │
    79→│        │   └─ 版本控制：记录 extraction_version                         │
    80→│        │                                                                │
    81→│        ├───→ cases 表 (source_chunk_id 关联)                           │
    82→│        │                                                                │
    83→│        └───→ scenario_candidates 表 (source_chunk_id 关联)             │
    84→│                                                                         │
    85→│  优势：                                                                 │
    86→│  • LLM 调用减半                                                         │
    87→│  • 增量处理，只处理新增/需更新的 chunks                                  │
    88→│  • Case 和 Scenario 可通过 source_chunk_id 关联                        │
    89→│  • 版本控制支持 Prompt 更新后选择性重新处理                              │
    90→│                                                                         │
    91→└─────────────────────────────────────────────────────────────────────────┘
    92→```
    93→
    94→---
    95→
    96→## 三、实施方案
    97→
    98→### 3.1 数据库 Schema 变更
    99→
   100→**knowledge_chunks 表新增字段**：
   101→
   102→```sql
   103→-- 增量处理支持
   104→ALTER TABLE knowledge_chunks ADD COLUMN IF NOT EXISTS
   105→    extraction_status VARCHAR(20) DEFAULT 'pending';
   106→-- Values: pending, extracted, skipped, needs_reextract
   107→
   108→-- 版本控制
   109→ALTER TABLE knowledge_chunks ADD COLUMN IF NOT EXISTS
   110→    extraction_version INT DEFAULT 0;
   111→
   112→-- 最后处理时间
   113→ALTER TABLE knowledge_chunks ADD COLUMN IF NOT EXISTS
   114→    last_extracted_at TIMESTAMP;
   115→
   116→-- 索引
   117→CREATE INDEX IF NOT EXISTS idx_chunks_extraction_status
   118→    ON knowledge_chunks(skill_id, extraction_status);
   119→```
   120→
   121→**scenario_candidates 表新增字段**：
   122→
   123→```sql
   124→-- 来源追溯
   125→ALTER TABLE scenario_candidates ADD COLUMN IF NOT EXISTS
   126→    source_chunk_ids VARCHAR[] DEFAULT '{}';
   127→```
   128→
   129→### 3.2 统一抽取 Prompt 设计
   130→
   131→**新建文件**: `.claude/skills/vibelife-skill/templates/prompts/UNIFIED_EXTRACTION_PROMPT.md`
   132→
   133→```markdown
   134→你是一个专业的知识抽取专家。请从以下文本中同时识别：
   135→1. **案例 (Case)**：具体的分析实例
   136→2. **场景 (Scenario)**：可服务用户的服务流程
   137→
   138→## Skill类型: {skill_id}
   139→
   140→## 思维架构体系
   141→{thinking_frameworks}
   142→
   143→## 待分析文本
   144→{text}
   145→
   146→## 输出格式
   147→
   148→```json
   149→{
   150→  "cases": [
   151→    {
   152→      "name": "案例名称",
   153→      "core_data": {...},
   154→      "features": {...},
   155→      "thinking_frameworks_used": ["架构1", "架构2"],
   156→      "reasoning_chain": [...],
   157→      "guidance_patterns": [...],
   158→      "tags": [...],
   159→      "scenario_ids": [...]
   160→    }
   161→  ],
   162→  "scenarios": [
   163→    {
   164→      "scenario_id": "英文ID",
   165→      "name": "中文名称",
   166→      "level": "entry|standard|professional",
   167→      "primary_triggers": [...],
   168→      "sop_phases": [...]
   169→    }
   170→  ],
   171→  "extraction_notes": "抽取备注（可选）"
   172→}
   173→```
   174→
   175→如果文本不包含案例或场景，对应数组返回空 `[]`。
   176→```
   177→
   178→### 3.3 新建统一抽取器
   179→
   180→**新建文件**: `apps/api/workers/unified_extractor.py`
   181→
   182→核心逻辑：
   183→
   184→```python
   185→class UnifiedExtractor:
   186→    """
   187→    Stage 4: Unified Case & Scenario Extraction
   188→
   189→    Features:
   190→    - Single LLM call extracts both Case and Scenario
   191→    - Incremental processing via extraction_status
   192→    - Version control via extraction_version
   193→    - Source tracking via source_chunk_id(s)
   194→    """
   195→
   196→    async def extract_from_chunk(self, chunk: dict, skill_id: str) -> dict:
   197→        """Single LLM call for both Case and Scenario extraction"""
   198→        ...
   199→
   200→    async def process_pending_chunks(
   201→        self,
   202→        skill_id: str,
   203→        limit: int = 100,
   204→        reextract_version: int = None  # 重新抽取指定版本以下的
   205→    ) -> dict:
   206→        """
   207→        Incremental processing:
   208→        - Only process extraction_status = 'pending'
   209→        - Or extraction_version < reextract_version
   210→        """
   211→        ...
   212→
   213→    async def mark_chunks_for_reextract(
   214→        self,
   215→        skill_id: str,
   216→        chunk_types: list[str] = None,
   217→        before_version: int = None
   218→    ):
   219→        """Mark chunks for re-extraction (e.g., after Prompt update)"""
   220→        ...
   221→```
   222→
   223→### 3.4 流水线整合
   224→
   225→**修改**: `apps/api/scripts/build_knowledge.py`
   226→
   227→```python
   228→# 原来
   229→async def run_stage_4a(self, limit: int = 100):
   230→    """Stage 4a: Extract cases"""
   231→    ...
   232→
   233→async def run_stage_4b(self, limit: int = 50):
   234→    """Stage 4b: Generate scenario candidates"""
   235→    ...
   236→
   237→# 新增
   238→async def run_stage_4(self, limit: int = 100, reextract_version: int = None):
   239→    """
   240→    Stage 4: Unified Extraction (Cases + Scenarios)
   241→
   242→    Args:
   243→        limit: Max chunks to process per run
   244→        reextract_version: If set, reextract chunks with version < this
   245→    """
   246→    from workers.unified_extractor import UnifiedExtractor
   247→
   248→    extractor = UnifiedExtractor()
   249→    results = await extractor.process_pending_chunks(
   250→        self.skill_id,
   251→        limit=limit,
   252→        reextract_version=reextract_version
   253→    )
   254→
   255→    logger.info(f"Stage 4 complete: {results['cases_count']} cases, {results['scenarios_count']} scenarios")
   256→    return results
   257→```
   258→
   259→### 3.5 CLI 参数扩展
   260→
   261→```bash
   262→# 增量处理（默认行为）
   263→python build_knowledge.py --skill bazi --stages 4
   264→
   265→# 强制重新抽取所有
   266→python build_knowledge.py --skill bazi --stages 4 --reextract-all
   267→
   268→# 重新抽取指定版本以下的
   269→python build_knowledge.py --skill bazi --stages 4 --reextract-below 2
   270→
   271→# 标记特定类型需要重新抽取
   272→python build_knowledge.py --skill bazi --mark-reextract --chunk-types method,theory
   273→```
   274→
   275→---
   276→
   277→## 四、增量逻辑详解
   278→
   279→### 4.1 状态机
   280→
   281→```
   282→                    ┌──────────────┐
   283→                    │   pending    │ ◄── 新 chunk 入库
   284→                    └──────┬───────┘
   285→                           │
   286→                           ▼ extract_from_chunk()
   287→                    ┌──────────────┐
   288→              ┌─────│  extracted   │
   289→              │     └──────┬───────┘
   290→              │            │
   291→              │            ▼ Prompt 更新 / 手动标记
   292→              │     ┌──────────────┐
   293→              │     │needs_reextract│
   294→              │     └──────┬───────┘
   295→              │            │
   296→              └────────────┘ 循环重新抽取
   297→
   298→              ┌──────────────┐
   299→              │   skipped    │ ◄── 内容太短 / 无有效内容
   300→              └──────────────┘
   301→```
   302→
   303→### 4.2 融合策略
   304→
   305→**场景 A：新增 knowledge chunk**
   306→```
   307→1. 新 chunk 入库 → extraction_status = 'pending'
   308→2. Stage 4 运行 → 检测到 pending → 抽取 → 状态更新为 'extracted'
   309→3. 结果写入 cases / scenario_candidates，记录 source_chunk_id
   310→```
   311→
   312→**场景 B：Prompt/Schema 更新**
   313→```
   314→1. 更新 UNIFIED_EXTRACTION_PROMPT.md
   315→2. 全局版本号 +1（存在 skill_metadata 表）
   316→3. 运行: --reextract-below NEW_VERSION
   317→4. 符合条件的 chunks 状态变为 'needs_reextract'
   318→5. Stage 4 重新处理这些 chunks
   319→6. 新结果 UPSERT 到 cases / scenario_candidates
   320→```
   321→
   322→**场景 C：删除源 chunk**
   323→```
   324→1. 删除 knowledge_chunks 记录
   325→2. 级联删除（或标记）相关 cases / scenario_candidates
   326→   WHERE source_chunk_id = deleted_chunk_id
   327→```
   328→
   329→### 4.3 关联查询
   330→
   331→```sql
   332→-- 查看某个 Case 来源于哪个 Chunk
   333→SELECT c.*, k.book_name, k.chapter
   334→FROM cases c
   335→JOIN knowledge_chunks k ON k.id = c.source_chunk_id
   336→WHERE c.id = 'CASE_bazi_xxxx';
   337→
   338→-- 查看某个 Chunk 产出了哪些 Cases 和 Scenarios
   339→SELECT
   340→    k.id as chunk_id,
   341→    array_agg(DISTINCT c.id) as case_ids,
   342→    array_agg(DISTINCT s.scenario_id) as scenario_ids
   343→FROM knowledge_chunks k
   344→LEFT JOIN cases c ON c.source_chunk_id = k.id
   345→LEFT JOIN scenario_candidates s ON k.id = ANY(s.source_chunk_ids)
   346→WHERE k.skill_id = 'bazi'
   347→GROUP BY k.id;
   348→```
   349→
   350→---
   351→
   352→## 五、关键文件修改清单
   353→
   354→| 文件 | 操作 | 说明 |
   355→|------|------|------|
   356→| `apps/api/stores/migrations/002_extraction_incremental.sql` | 新建 | Schema 变更 |
   357→| `apps/api/workers/unified_extractor.py` | 新建 | 统一抽取器 |
   358→| `.claude/skills/vibelife-skill/templates/prompts/UNIFIED_EXTRACTION_PROMPT.md` | 新建 | 统一 Prompt |
   359→| `apps/api/scripts/build_knowledge.py` | 修改 | 新增 run_stage_4() |
   360→| `apps/api/routes/knowledge_builder.py` | 修改 | 新增 API 端点 |
   361→
   362→**保留兼容**（不删除）：
   363→- `apps/api/workers/case_extractor.py` - 保留用于单独调试
   364→- `apps/api/workers/scenario_generator.py` - 保留用于单独调试
   365→
   366→---
   367→
   368→## 六、验证方案
   369→
   370→### 6.1 单元测试
   371→
   372→```python
   373→# test_unified_extractor.py
   374→
   375→async def test_extract_from_chunk_returns_both():
   376→    """验证单次调用能同时返回 Case 和 Scenario"""
   377→    ...
   378→
   379→async def test_incremental_only_processes_pending():
   380→    """验证增量逻辑只处理 pending 状态"""
   381→    ...
   382→
   383→async def test_reextract_updates_existing():
   384→    """验证重新抽取会 UPSERT 已有结果"""
   385→    ...
   386→```
   387→
   388→### 6.2 端到端测试
   389→
   390→```bash
   391→# 1. 准备测试数据
   392→INSERT INTO knowledge_chunks (...) VALUES (...);  -- 3 条测试 chunks
   393→
   394→# 2. 首次运行
   395→python build_knowledge.py --skill bazi --stages 4
   396→
   397→# 3. 验证结果
   398→SELECT COUNT(*) FROM cases WHERE skill_id = 'bazi';
   399→SELECT COUNT(*) FROM scenario_candidates WHERE skill_id = 'bazi';
   400→SELECT extraction_status FROM knowledge_chunks WHERE skill_id = 'bazi';
   401→-- 应该都是 'extracted'
   402→
   403→# 4. 再次运行（应该跳过已处理的）
   404→python build_knowledge.py --skill bazi --stages 4
   405→-- 日志应显示 "0 chunks to process"
   406→
   407→# 5. 标记重新抽取
   408→python build_knowledge.py --skill bazi --mark-reextract --chunk-types method
   409→
   410→# 6. 再次运行（应该只处理标记的）
   411→python build_knowledge.py --skill bazi --stages 4
   412→-- 日志应显示处理了标记的 chunks
   413→```
   414→
   415→---
   416→
   417→## 七、后续可选优化
   418→
   419→1. **批量 LLM 调用**：将多个 chunks 合并到一个 Prompt 中处理
   420→2. **异步队列**：使用 Celery/Redis 实现后台异步抽取
   421→3. **质量评分**：为每个 Case/Scenario 生成质量评分
   422→4. **去重检测**：检测相似的 Case/Scenario 避免重复
   423→
   424→---
   425→
   426→# 附录：原通用模板优化计划（已完成）
   427→
   428→## 从《东方代码启示录》案例中抽象的核心洞察
   429→
   430→### 洞察 1：专家存储的是"推理链条"而非"结论"
   431→
   432→**学习案例**（乾隆皇帝八字分析）：