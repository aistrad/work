The file /home/aiscend/.claude/plans/swift-herding-peacock.md has been updated. Here's the result of running `cat -n` on a snippet of the edited file:
   247→-- Scenario 直接从文件加载，scenario_index 只存索引
   248→-- 无需数据库修改，但需要更新加载逻辑
   249→```
   250→
   251→### 3.3 统一抽取 Prompt 设计
   252→
   253→**新建文件**: `.claude/skills/vibelife-skill/templates/prompts/UNIFIED_EXTRACTION_PROMPT.md`
   254→
   255→```markdown
   256→你是一个专业的知识抽取专家。请从以下文本中同时识别：
   257→1. **案例 (Case)**：具体的分析实例，包含完整的推理过程
   258→2. **场景 (Scenario)**：可服务用户的服务流程定义
   259→
   260→## Skill类型: {skill_id}
   261→
   262→## 思维架构体系
   263→{thinking_frameworks}
   264→
   265→## 源文件信息
   266→- 文件: {source_file}
   267→- 章节: {source_section}
   268→
   269→## 待分析文本
   270→{text}
   271→
   272→## 输出格式
   273→
   274→```json
   275→{
   276→  "cases": [
   277→    {
   278→      "name": "案例名称",
   279→      "core_data": {...},
   280→      "features": {...},
   281→      "thinking_frameworks_used": ["架构1", "架构2"],
   282→      "reasoning_chain": [
   283→        {"step": 1, "framework": "...", "observation": "...", "analysis": "...", "conclusion": "..."}
   284→      ],
   285→      "guidance_patterns": [
   286→        {"pattern_name": "...", "condition": "...", "advice": "...", "source": "..."}
   287→      ],
   288→      "tags": [...],
   289→      "scenario_ids": [...]
   290→    }
   291→  ],
   292→  "scenarios": [
   293→    {
   294→      "scenario_id": "英文ID",
   295→      "name": "中文名称",
   296→      "level": "entry|standard|professional",
   297→      "primary_triggers": ["触发词1", "触发词2"],
   298→      "secondary_triggers": ["次要触发词"],
   299→      "sop_phases": [
   300→        {"phase": 1, "name": "信息收集", "description": "...", "tools": [...]}
   301→      ]
   302→    }
   303→  ],
   304→  "extraction_notes": "抽取备注（可选）"
   305→}
   306→```
   307→
   308→如果文本不包含案例或场景，对应数组返回空 `[]`。
   309→```
   310→
   311→### 3.4 新建统一抽取器
   312→
   313→**新建文件**: `apps/api/workers/unified_extractor.py`
   314→
   315→核心逻辑（基于 MD 文件）：
   316→
   317→```python
   318→class UnifiedExtractor:
   319→    """
   320→    Stage 4: Unified Case & Scenario Extraction from MD Files
   321→
   322→    Features:
   323→    - Reads directly from MD source files (not DB chunks)
   324→    - Single LLM call extracts both Case and Scenario
   325→    - Incremental processing via extraction_log.json
   326→    - Large files split by sections (< 30K tokens per call)
   327→    - Output: Cases → DB, Scenarios → files
   328→    """
   329→
   330→    def __init__(self, skill_id: str):
   331→        self.skill_id = skill_id
   332→        self.converted_dir = DATA_DIR / "knowledge" / skill_id / "converted"
   333→        self.extracted_dir = DATA_DIR / "knowledge" / skill_id / "extracted"
   334→        self.log_path = self.extracted_dir / "extraction_log.json"
   335→
   336→    def _load_extraction_log(self) -> dict:
   337→        """Load or initialize extraction log"""
   338→        ...
   339→
   340→    def _split_by_sections(self, content: str, max_tokens: int = 30000) -> list[dict]:
   341→        """Split large MD file by sections (headers)"""
   342→        ...
   343→
   344→    async def extract_from_file(self, file_path: Path) -> dict:
   345→        """
   346→        Extract Cases and Scenarios from a single MD file.
   347→        For large files, split by sections.
   348→        """
   349→        content = file_path.read_text()
   350→
   351→        if self._estimate_tokens(content) > 30000:
   352→            sections = self._split_by_sections(content)
   353→            results = {"cases": [], "scenarios": []}
   354→            for section in sections:
   355→                section_result = await self._call_llm(section["content"], section["name"])
   356→                results["cases"].extend(section_result["cases"])
   357→                results["scenarios"].extend(section_result["scenarios"])
   358→            return results
   359→        else:
   360→            return await self._call_llm(content, file_path.stem)
   361→
   362→    async def process_pending_files(self, force_reextract: bool = False) -> dict:
   363→        """
   364→        Incremental processing:
   365→        - Check MD5 hash for file changes
   366→        - Only process changed/new files
   367→        - Update extraction_log.json
   368→        """
   369→        log = self._load_extraction_log()
   370→        md_files = list(self.converted_dir.rglob("*.md"))
   371→
   372→        results = {"cases_count": 0, "scenarios_count": 0, "files_processed": 0}
   373→
   374→        for md_file in md_files:
   375→            rel_path = str(md_file.relative_to(self.converted_dir))
   376→            current_md5 = self._compute_md5(md_file)
   377→
   378→            # Skip if already processed and unchanged
   379→            if not force_reextract and rel_path in log["files"]:
   380→                if log["files"][rel_path]["md5"] == current_md5:
   381→                    continue
   382→
   383→            # Extract
   384→            extraction = await self.extract_from_file(md_file)
   385→
   386→            # Save Cases to DB
   387→            saved_cases = await self._save_cases_to_db(
   388→                extraction["cases"],
   389→                source_file=rel_path
   390→            )
   391→
   392→            # Save Scenarios to files
   393→            saved_scenarios = await self._save_scenarios_to_files(
   394→                extraction["scenarios"],
   395→                source_file=rel_path
   396→            )
   397→
   398→            # Update log
   399→            log["files"][rel_path] = {
   400→                "status": "extracted",
   401→                "md5": current_md5,
   402→                "extracted_at": datetime.now().isoformat(),
   403→                "cases_count": len(extraction["cases"]),
   404→                "scenarios_count": len(extraction["scenarios"])
   405→            }
   406→
   407→            results["cases_count"] += saved_cases
   408→            results["scenarios_count"] += saved_scenarios
   409→            results["files_processed"] += 1
   410→
   411→        self._save_extraction_log(log)
   412→        return results
   413→
   414→    async def _save_cases_to_db(self, cases: list, source_file: str) -> int:
   415→        """Insert cases to PostgreSQL with status='pending'"""
   416→        ...
   417→
   418→    async def _save_scenarios_to_files(self, scenarios: list, source_file: str) -> int:
   419→        """
   420→        Save scenarios to extracted/scenarios/ directory as .md files.
   421→        These are candidates for human review.
   422→        """
   423→        for scenario in scenarios:
   424→            output_path = self.extracted_dir / "scenarios" / f"{scenario['scenario_id']}.md"
   425→            md_content = self._render_scenario_md(scenario)
   426→            output_path.write_text(md_content)
   427→        return len(scenarios)
   428→```
   429→
   430→### 3.4 流水线整合
   431→
   432→**修改**: `apps/api/scripts/build_knowledge.py`