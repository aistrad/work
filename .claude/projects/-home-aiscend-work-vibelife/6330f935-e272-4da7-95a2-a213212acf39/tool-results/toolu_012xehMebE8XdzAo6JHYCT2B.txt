     1→"""
     2→CoreAgent v6 - 支持 Scenario 路由和 PostgreSQL 知识检索的智能体
     3→
     4→v6 架构特性：
     5→- Scenario 路由：根据用户消息匹配最佳场景
     6→- PostgreSQL 知识检索：RAG + 案例匹配
     7→- 7 阶段 SOP：P1-P2 强制，P3-P7 LLM 自由发挥
     8→- 工具-卡片映射：标准化工具元数据
     9→"""
    10→import json
    11→import logging
    12→import time
    13→from typing import Optional, List, Dict, Any, AsyncGenerator
    14→from dataclasses import dataclass
    15→from enum import Enum
    16→
    17→from services.llm import LLMClient, get_llm_client
    18→from services.llm.client import LLMMessage
    19→from services.knowledge.repository import get_knowledge_repository, KnowledgeRepository
    20→from .skill_loader import (
    21→    load_skill, get_skill_triggers,
    22→    build_system_prompt,
    23→    get_available_skills, get_skill_scenarios,
    24→    skill_requires_birth_info,
    25→    skill_requires_compute,
    26→    get_skill_compute_type,
    27→    get_skill_compute_tool,
    28→)
    29→from .tool_registry import ToolRegistry, ToolContext
    30→
    31→logger = logging.getLogger(__name__)
    32→
    33→
    34→class AgentState(str, Enum):
    35→    """Agent 执行状态"""
    36→    IDLE = "idle"
    37→    THINKING = "thinking"
    38→    TOOL_CALLING = "tool_calling"
    39→    COMPLETED = "completed"
    40→    ERROR = "error"
    41→
    42→
    43→@dataclass
    44→class AgentEvent:
    45→    """Agent 执行事件"""
    46→    type: str  # thinking, content, tool_call, tool_result, done, error, sop_phase
    47→    data: Any = None
    48→
    49→
    50→@dataclass
    51→class AgentContext:
    52→    """Agent 执行上下文"""
    53→    user_id: str
    54→    user_tier: str = "free"
    55→    profile: Optional[Dict[str, Any]] = None
    56→    skill_data: Optional[Dict[str, Any]] = None
    57→    history: Optional[List[Dict[str, str]]] = None
    58→    skill: Optional[str] = None
    59→    scenario: Optional[str] = None
    60→    portrait: Optional[str] = None
    61→    conversation_id: Optional[str] = None
    62→    voice_mode: Optional[str] = "warm"
    63→    recent_insights: Optional[List[Any]] = None
    64→
    65→
    66→def build_use_skill_tool() -> Dict[str, Any]:
    67→    """
    68→    动态构建 use_skill 工具定义
    69→
    70→    从 SKILL.md 自动读取：
    71→    - 可用的 Skills 列表
    72→    - 每个 Skill 的语义描述（用于 LLM 理解）
    73→    - 每个 Skill 的场景列表
    74→
    75→    v7.3: 改为语义描述驱动，让 LLM 基于理解而非关键词匹配来选择 skill
    76→    """
    77→    available_skills = [s for s in get_available_skills() if s != "core"]
    78→
    79→    # 构建 Skill 路由说明（语义描述 + 触发词辅助）
    80→    skill_routing = "## Skill 路由（基于语义理解选择最匹配的 skill）\n\n"
    81→    for skill_id in available_skills:
    82→        skill = load_skill(skill_id)
    83→        if skill:
    84→            # 提取 description 中触发词之前的部分作为语义描述
    85→            desc = skill.description
    86→            if "触发词" in desc:
    87→                desc = desc.split("触发词")[0].strip().rstrip("。")
    88→            # 限制长度
    89→            if len(desc) > 100:
    90→                desc = desc[:100] + "..."
    91→            skill_routing += f"### {skill_id}\n{desc}\n"
    92→            # 触发词作为辅助提示
    93→            if skill.triggers:
    94→                trigger_str = "、".join(skill.triggers[:5])
    95→                skill_routing += f"常见关键词：{trigger_str}\n"
    96→            skill_routing += "\n"
    97→
    98→    # 构建场景目录（只列出主要场景，避免 description 过长）
    99→    scenario_catalog = "\n## 场景目录（常用）\n"
   100→    for skill_id in available_skills:
   101→        scenarios = get_skill_scenarios(skill_id)
   102→        if scenarios:
   103→            # 只列出前5个场景
   104→            top_scenarios = scenarios[:5]
   105→            scenario_catalog += f"\n### {skill_id}\n"
   106→            for s in top_scenarios:
   107→                scenario_catalog += f"- {s}\n"
   108→            if len(scenarios) > 5:
   109→                scenario_catalog += f"- ... (共 {len(scenarios)} 个场景)\n"
   110→
   111→    description = f"""激活专业技能来回答用户问题。一次决定 skill、scenario 和 confidence。
   112→
   113→{skill_routing}
   114→{scenario_catalog}
   115→
   116→## Confidence 说明
   117→- high: 用户意图明确，直接执行
   118→- medium: 基本确定，可能需要追问细节
   119→- low: 不确定，需要向用户确认
   120→
   121→重要：如果用户消息中已经包含了出生信息，设置 birth_info_provided=true。"""
   122→
   123→    return {
   124→        "type": "function",
   125→        "function": {
   126→            "name": "use_skill",
   127→            "description": description,
   128→            "parameters": {
   129→                "type": "object",
   130→                "properties": {
   131→                    "skill": {
   132→                        "type": "string",
   133→                        "enum": available_skills,
   134→                        "description": "要使用的技能"
   135→                    },
   136→                    "scenario": {
   137→                        "type": "string",
   138→                        "description": "场景 ID，参考上方场景目录"
   139→                    },
   140→                    "confidence": {
   141→                        "type": "string",
   142→                        "enum": ["high", "medium", "low"],
   143→                        "description": "路由置信度"
   144→                    },
   145→                    "topic": {
   146→                        "type": "string",
   147→                        "enum": ["career", "relationship", "fortune", "health", "self", "general"],
   148→                        "description": "用户关注的话题类型"
   149→                    },
   150→                    "birth_info_provided": {
   151→                        "type": "boolean",
   152→                        "description": "用户消息中是否已包含出生信息"
   153→                    }
   154→                },
   155→                "required": ["skill", "scenario", "confidence"]
   156→            }
   157→        }
   158→    }
   159→
   160→
   161→# 缓存动态生成的工具定义
   162→_USE_SKILL_TOOL_CACHE: Optional[Dict[str, Any]] = None
   163→
   164→
   165→def get_use_skill_tool() -> Dict[str, Any]:
   166→    """获取 use_skill 工具定义（带缓存）"""
   167→    global _USE_SKILL_TOOL_CACHE
   168→    if _USE_SKILL_TOOL_CACHE is None:
   169→        _USE_SKILL_TOOL_CACHE = build_use_skill_tool()
   170→    return _USE_SKILL_TOOL_CACHE
   171→
   172→
   173→class CoreAgent:
   174→    """
   175→    CoreAgent v6 - 支持 Scenario 路由和 PostgreSQL 知识检索
   176→
   177→    Features:
   178→    - Scenario routing via PostgreSQL
   179→    - Knowledge retrieval (RAG + cases)
   180→    - 7-phase SOP execution
   181→    - Tool-card mapping
   182→    """
   183→
   184→    def __init__(
   185→        self,
   186→        llm: Optional[LLMClient] = None,
   187→        max_iterations: int = 10,
   188→        knowledge_repo: Optional[KnowledgeRepository] = None
   189→    ):
   190→        self.llm = llm or get_llm_client()
   191→        self.max_iterations = max_iterations
   192→        self.knowledge_repo = knowledge_repo or get_knowledge_repository()
   193→        self.state = AgentState.IDLE
   194→        self._active_skill: Optional[str] = None
   195→        self._active_scenario: Optional[str] = None
   196→        self._topic: Optional[str] = None
   197→        self._current_message: str = ""
   198→
   199→    @property
   200→    def usage(self) -> Dict[str, int]:
   201→        """获取 LLM 使用统计"""
   202→        return self.llm.usage
   203→
   204→    async def run(
   205→        self,
   206→        message: str,
   207→        context: AgentContext
   208→    ) -> AsyncGenerator[AgentEvent, None]:
   209→        """执行 Agent 循环"""
   210→        self.state = AgentState.IDLE
   211→        self._current_message = message
   212→        self._perf_log = {"iterations": 0, "llm_calls": []}
   213→
   214→        # 使用前端指定的 skill/scenario，或让 LLM 决定
   215→        if context.skill:
   216→            self._active_skill = context.skill
   217→            self._active_scenario = context.scenario or await self._route_scenario(context.skill, message)
   218→        else:
   219→            self._active_skill = None
   220→            self._active_scenario = None
   221→
   222→        # v7.2: 移除 SOPEngine，改为 LLM 驱动
   223→        # SOP 规则和状态将通过 System Prompt 传达给 LLM
   224→        # LLM 自主决定是否需要收集信息或计算
   225→        if self._active_skill:
   226→            # 计算当前状态，用于前端显示和 Prompt 构建
   227→            sop_status = self._compute_sop_status(context)
   228→
   229→            yield AgentEvent(type="sop_phase", data={
   230→                "skill": self._active_skill,
   231→                "scenario": self._active_scenario,
   232→                "status": sop_status,
   233→                "message": "LLM 驱动模式"
   234→            })
   235→
   236→        # [PERF T6] 构建初始消息
   237→        t_prompt_start = time.time()
   238→        messages = await self._build_initial_messages(message, context)
   239→        self._perf_log["prompt_build_ms"] = int((time.time() - t_prompt_start) * 1000)
   240→        self._perf_log["system_prompt_len"] = len(messages[0].content) if messages else 0
   241→        logger.info(f"[PERF Agent] Prompt built: {self._perf_log['prompt_build_ms']}ms, len={self._perf_log['system_prompt_len']}")
   242→
   243→        for iteration in range(self.max_iterations):
   244→            self.state = AgentState.THINKING
   245→            yield AgentEvent(type="thinking", data={"iteration": iteration})
   246→            self._perf_log["iterations"] = iteration + 1
   247→
   248→            tools = self._get_current_tools(context)
   249→
   250→            try:
   251→                content_buffer = ""
   252→                tool_calls = []
   253→
   254→                # [PERF T7/T9] LLM 调用
   255→                t_llm_start = time.time()
   256→                first_token_time = None
   257→
   258→                async for chunk in self.llm.stream(
   259→                    messages=messages,
   260→                    tools=tools,
   261→                    tool_choice=None,
   262→                    user_tier=context.user_tier
   263→                ):
   264→                    # 记录首 token 时间
   265→                    if first_token_time is None:
   266→                        first_token_time = time.time()
   267→                        ttft = int((first_token_time - t_llm_start) * 1000)
   268→                        logger.info(f"[PERF Agent] LLM #{iteration+1} TTFT: {ttft}ms")
   269→
   270→                    if chunk["type"] == "content":
   271→                        content_buffer += chunk["content"]
   272→                        yield AgentEvent(type="content", data={"content": chunk["content"]})
   273→                    elif chunk["type"] == "tool_call":
   274→                        tool_calls.append(chunk)
   275→
   276→                # [PERF] LLM 调用完成
   277→                llm_total = int((time.time() - t_llm_start) * 1000)
   278→                self._perf_log["llm_calls"].append({
   279→                    "iteration": iteration + 1,
   280→                    "ttft_ms": int((first_token_time - t_llm_start) * 1000) if first_token_time else 0,
   281→                    "total_ms": llm_total,
   282→                    "has_tools": len(tool_calls) > 0
   283→                })
   284→                logger.info(f"[PERF Agent] LLM #{iteration+1} total: {llm_total}ms, tools={len(tool_calls)}")
   285→
   286→                if tool_calls:
   287→                    self.state = AgentState.TOOL_CALLING
   288→
   289→                    assistant_tool_calls = []
   290→                    for tc in tool_calls:
   291→                        assistant_tool_calls.append({
   292→                            "id": tc["tool_call_id"],
   293→                            "function": {
   294→                                "name": tc["tool_name"],
   295→                                "arguments": tc["tool_args"]
   296→                            }
   297→                        })
   298→                    messages.append(LLMMessage(
   299→                        role="assistant",
   300→                        content=content_buffer or "",
   301→                        tool_calls=assistant_tool_calls
   302→                    ))
   303→                    content_buffer = ""
   304→
   305→                    # [PERF T8] 工具执行
   306→                    t_tools_start = time.time()
   307→                    tool_results = []
   308→                    for tc in tool_calls:
   309→                        tool_name = tc["tool_name"]
   310→                        tool_args = tc["tool_args"]
   311→                        tool_call_id = tc["tool_call_id"]
   312→
   313→                        yield AgentEvent(type="tool_call", data={
   314→                            "id": tool_call_id,
   315→                            "name": tool_name,
   316→                            "arguments": tool_args
   317→                        })
   318→
   319→                        t_tool_start = time.time()
   320→                        result = await self._execute_tool(tool_name, tool_args, context)
   321→                        tool_exec_ms = int((time.time() - t_tool_start) * 1000)
   322→                        logger.info(f"[PERF Agent] Tool {tool_name}: {tool_exec_ms}ms")
   323→
   324→                        tool_results.append({
   325→                            "tool_call_id": tool_call_id,
   326→                            "result": result
   327→                        })
   328→
   329→                        yield AgentEvent(type="tool_result", data={
   330→                            "id": tool_call_id,
   331→                            "name": tool_name,
   332→                            "result": result
   333→                        })
   334→
   335→                    tools_total = int((time.time() - t_tools_start) * 1000)
   336→                    logger.info(f"[PERF Agent] All tools: {tools_total}ms")
   337→
   338→                    for tr in tool_results:
   339→                        result_content = tr["result"]
   340→                        if isinstance(result_content, dict):
   341→                            result_content = json.dumps(result_content, ensure_ascii=False)
   342→                        messages.append(LLMMessage(
   343→                            role="tool",
   344→                            content=str(result_content),
   345→                            tool_call_id=tr["tool_call_id"]
   346→                        ))
   347→                else:
   348→                    self.state = AgentState.COMPLETED
   349→                    logger.info(f"[PERF Agent] Done: {self._perf_log}")
   350→                    yield AgentEvent(type="done", data={"content": content_buffer})
   351→                    return
   352→
   353→            except Exception as e:
   354→                self.state = AgentState.ERROR
   355→                logger.error(f"Agent error: {e}")
   356→                yield AgentEvent(type="error", data={"error": str(e)})
   357→                return
   358→
   359→        self.state = AgentState.COMPLETED
   360→        yield AgentEvent(type="done", data={"max_iterations_reached": True})
   361→
   362→    def _filter_valid_history(self, history: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
   363→        """
   364→        过滤历史消息，确保 tool 消息配对完整。
   365→
   366→        Anthropic API 要求每个 tool_result 必须有对应的 tool_use。
   367→        如果历史消息不完整（如只有 tool 消息没有对应的 assistant tool_calls），
   368→        需要过滤掉这些孤立的消息。
   369→        """
   370→        if not history:
   371→            return []
   372→
   373→        # 收集所有有效的 tool_call_ids（来自 assistant 的 tool_calls）
   374→        valid_tool_ids = set()
   375→        for msg in history:
   376→            if msg.get("role") == "assistant" and msg.get("tool_calls"):
   377→                for tc in msg["tool_calls"]:
   378→                    tc_id = tc.get("id")
   379→                    if tc_id:
   380→                        valid_tool_ids.add(tc_id)
   381→
   382→        # 过滤消息
   383→        filtered = []
   384→        for msg in history:
   385→            role = msg.get("role", "user")
   386→
   387→            # tool 消息需要检查是否有对应的 tool_use
   388→            if role == "tool":
   389→                tool_call_id = msg.get("tool_call_id")
   390→                if tool_call_id and tool_call_id in valid_tool_ids:
   391→                    filtered.append(msg)
   392→                else:
   393→                    # 孤立的 tool 消息，跳过
   394→                    logger.warning(f"Skipping orphan tool message: {tool_call_id}")
   395→            else:
   396→                # user/assistant 消息直接保留
   397→                filtered.append(msg)
   398→
   399→        return filtered
   400→
   401→    async def _route_scenario(self, skill_id: str, message: str) -> Optional[str]:
   402→        """场景路由 - 根据消息匹配最佳场景"""
   403→        try:
   404→            matches = await self.knowledge_repo.route_scenario(skill_id, message)
   405→            if matches:
   406→                return matches[0].scenario_id
   407→        except Exception as e:
   408→            logger.warning(f"Scenario routing failed: {e}")
   409→
   410→        # 回退到默认场景
   411→        skill = load_skill(skill_id)
   412→        return skill.default_scenario if skill else "basic_reading"
   413→
   414→    async def _build_initial_messages(
   415→        self,
   416→        message: str,
   417→        context: AgentContext
   418→    ) -> List[LLMMessage]:
   419→        """构建初始消息列表"""
   420→        system_prompt = await self._build_system_prompt(message, context)
   421→
   422→        messages = [LLMMessage(role="system", content=system_prompt)]
   423→
   424→        if context.history:
   425→            # 过滤并验证历史消息，确保 tool 消息配对完整
   426→            filtered_history = self._filter_valid_history(context.history[-10:])
   427→            for msg in filtered_history:
   428→                messages.append(LLMMessage(
   429→                    role=msg.get("role", "user"),
   430→                    content=msg.get("content", ""),
   431→                    tool_call_id=msg.get("tool_call_id"),
   432→                    tool_calls=msg.get("tool_calls")
   433→                ))
   434→
   435→        messages.append(LLMMessage(role="user", content=message))
   436→        return messages
   437→
   438→    def _compute_sop_status(self, context: AgentContext) -> Dict[str, Any]:
   439→        """
   440→        v7.2: 计算 SOP 状态（替代 SOPEngine）
   441→
   442→        返回当前状态信息，用于：
   443→        1. 前端显示
   444→        2. System Prompt 构建
   445→        """
   446→        skill_id = self._active_skill
   447→
   448→        # 检查是否需要出生信息
   449→        needs_birth = skill_requires_birth_info(skill_id) if skill_id else False
   450→        has_birth = bool(
   451→            context.profile and
   452→            context.profile.get("birth_info", {}).get("birth_date")
   453→        )
   454→
   455→        # 检查是否需要计算
   456→        needs_compute = skill_requires_compute(skill_id) if skill_id else False
   457→        compute_type = get_skill_compute_type(skill_id) if skill_id else None
   458→        actual_compute_type = compute_type or skill_id
   459→
   460→        # 检查是否有命盘数据
   461→        has_chart = False
   462→        if context.skill_data and actual_compute_type:
   463→            skill_data = context.skill_data.get(actual_compute_type, {})
   464→            # 通用检查：chart 或 cards
   465→            has_chart = bool(skill_data.get("chart") or skill_data.get("cards"))
   466→
   467→        return {
   468→            "skill_id": skill_id,
   469→            "needs_birth_info": needs_birth,
   470→            "has_birth_info": has_birth,
   471→            "needs_compute": needs_compute,
   472→            "has_chart_data": has_chart,
   473→            "compute_type": actual_compute_type,
   474→            "ready_for_analysis": (not needs_birth or has_birth) and (not needs_compute or has_chart)
   475→        }
   476→
   477→    def _build_sop_rules(self, context: AgentContext) -> str:
   478→        """
   479→        v7.2: 构建 SOP 规则（替代 SOPEngine）
   480→
   481→        将 SOP 规则通过 System Prompt 传达给 LLM，
   482→        让 LLM 自主决定执行流程。
   483→        """
   484→        skill_id = self._active_skill
   485→        if not skill_id:
   486→            return ""
   487→
   488→        # 获取配置
   489→        needs_birth = skill_requires_birth_info(skill_id)
   490→        needs_compute = skill_requires_compute(skill_id)
   491→        compute_type = get_skill_compute_type(skill_id) or skill_id
   492→
   493→        # 计算当前状态
   494→        status = self._compute_sop_status(context)
   495→
   496→        rules = "\n## SOP 执行规则（必须遵守）\n\n"
   497→
   498→        # P1: 信息收集
   499→        if needs_birth:
   500→            if not status["has_birth_info"]:
   501→                rules += """### P1: 信息收集 ⚠️ 需要执行
   502→用户尚未提供出生信息。你必须：
   503→1. 首先调用 `request_info` 工具（infoType: "birth"）展示收集表单
   504→2. 不要用文字询问，必须使用工具
   505→3. 收集到信息后再进行下一步
   506→
   507→"""
   508→            else:
   509→                rules += """### P1: 信息收集 ✅ 已完成
   510→用户已提供出生信息。
   511→
   512→"""
   513→
   514→        # P2: 计算排盘
   515→        if needs_compute:
   516→            if not status["has_chart_data"]:
   517→                # v7.3: 从 SKILL.md 配置读取 compute_tool，不再硬编码
   518→                compute_tool = get_skill_compute_tool(skill_id)
   519→                if not compute_tool:
   520→                    # 默认约定：calculate_{compute_type}
   521→                    compute_tool = f"calculate_{compute_type}"
   522→
   523→                rules += f"""### P2: 计算排盘 ⚠️ 需要执行
   524→用户尚未有命盘数据。你必须：
   525→1. 调用 `{compute_tool}` 工具生成命盘数据
   526→2. 计算完成后再进行分析
   527→
   528→"""
   529→            else:
   530→                rules += """### P2: 计算排盘 ✅ 已完成
   531→用户已有命盘数据。
   532→
   533→"""
   534→
   535→        # P3-P7: LLM 自由发挥
   536→        rules += """### P3-P7: 分析与输出
   537→完成信息收集和计算后，按以下流程执行：
   538→1. **扫描**: 快速识别命盘中的关键模式和特征
   539→2. **追问**: 根据需要向用户提出针对性问题
   540→3. **分析**: 深度分析，结合知识库检索结果
   541→4. **输出**: 调用展示工具（show_xxx）呈现分析结果
   542→5. **讨论**: 回答用户的追问
   543→
   544→"""
   545→
   546→        # 当前状态摘要
   547→        rules += "### 当前状态\n"
   548→        rules += f"- 出生信息: {'✅ 已有' if status['has_birth_info'] else '❌ 未收集'}\n"
   549→        rules += f"- 命盘数据: {'✅ 已计算' if status['has_chart_data'] else '❌ 未计算'}\n"
   550→        rules += f"- 可以分析: {'✅ 是' if status['ready_for_analysis'] else '❌ 否，请先完成上述步骤'}\n"
   551→
   552→        return rules
   553→
   554→    async def _build_system_prompt(self, message: str, context: AgentContext) -> str:
   555→        """构建 System Prompt - v7.2: 包含 SOP 规则"""
   556→        parts = []
   557→
   558→        # 基础 prompt
   559→        if self._active_skill:
   560→            # 传递完整 profile，让 skill_loader 自动处理所有字段
   561→            user_ctx = dict(context.profile) if context.profile else {}
   562→            user_ctx["portrait"] = context.portrait
   563→            base_prompt = build_system_prompt(
   564→                self._active_skill,
   565→                self._active_scenario,
   566→                user_ctx
   567→            )
   568→            parts.append(base_prompt)
   569→
   570→            # v7.2: 添加 SOP 规则（替代 SOPEngine）
   571→            sop_rules = self._build_sop_rules(context)
   572→            if sop_rules:
   573→                parts.append(sop_rules)
   574→
   575→            # 知识检索
   576→            try:
   577→                knowledge = await self.knowledge_repo.search_knowledge(
   578→                    self._active_skill, message, top_k=5
   579→                )
   580→                if knowledge:
   581→                    knowledge_text = "\n## 相关知识\n\n"
   582→                    for chunk in knowledge:
   583→                        knowledge_text += f"**{chunk.book_name}** ({chunk.chapter or ''})\n{chunk.chunk_text[:500]}...\n\n"
   584→                    parts.append(knowledge_text)
   585→            except Exception as e:
   586→                logger.warning(f"Knowledge retrieval failed: {e}")
   587→
   588→            # 案例匹配 - 使用智能匹配器
   589→            try:
   590→                from .case_matcher import match_cases_smart
   591→                cases = await match_cases_smart(
   592→                    self.knowledge_repo,
   593→                    skill_id=self._active_skill,
   594→                    scenario_id=self._active_scenario,
   595→                    skill_data=context.skill_data,
   596→                    top_k=2
   597→                )
   598→                if cases:
   599→                    cases_text = "\n## 相关案例\n\n"
   600→                    for case in cases:
   601→                        cases_text += f"**{case.name}**\n{json.dumps(case.conclusion, ensure_ascii=False)}\n\n"
   602→                    parts.append(cases_text)
   603→            except Exception as e:
   604→                logger.warning(f"Case matching failed: {e}")
   605→        else:
   606→            # 无 skill 时，添加触发规则
   607→            triggers = get_skill_triggers()
   608→            if triggers:
   609→                trigger_rules = "## 技能触发规则\n\n当用户消息包含以下关键词时，调用 `use_skill` 工具：\n"
   610→                for skill_name, keywords in triggers.items():
   611→                    trigger_rules += f"- **{skill_name}**: {', '.join(keywords)}\n"
   612→                parts.append(trigger_rules)
   613→
   614→        # 用户命盘数据（使用 compute_type 读取，支持跨 skill 复用）
   615→        if context.skill_data and self._active_skill:
   616→            compute_type = get_skill_compute_type(self._active_skill) or self._active_skill
   617→            skill_data = context.skill_data.get(compute_type, {})
   618→            if skill_data:
   619→                parts.append(f"\n## 用户命盘数据\n{json.dumps(skill_data, ensure_ascii=False, indent=2)}")
   620→
   621→        return "\n".join(parts)
   622→
   623→    def _get_current_tools(self, context: AgentContext) -> List[Dict[str, Any]]:
   624→        """获取当前可用工具 - V6: 从统一注册表获取"""
   625→        if not context.skill and not self._active_skill:
   626→            return [get_use_skill_tool()]
   627→
   628→        skill_id = self._active_skill or context.skill
   629→
   630→        # 从统一注册表获取工具（YAML 为数据源）
   631→        tools = ToolRegistry.get_tools_for_skill(skill_id)
   632→        return tools if tools else [get_use_skill_tool()]
   633→
   634→    async def _execute_tool(
   635→        self,
   636→        tool_name: str,
   637→        tool_args: str,
   638→        context: AgentContext
   639→    ) -> Dict[str, Any]:
   640→        """执行工具调用 - V6.1: 完全使用统一注册表"""
   641→        try:
   642→            args = json.loads(tool_args) if tool_args else {}
   643→        except json.JSONDecodeError:
   644→            args = {}
   645→
   646→        # 特殊处理 use_skill（路由工具）
   647→        if tool_name == "use_skill":
   648→            return await self._handle_use_skill(args, context)
   649→
   650→        # 创建工具上下文
   651→        tool_context = ToolContext(
   652→            user_id=context.user_id,
   653→            user_tier=context.user_tier,
   654→            profile=context.profile or {},
   655→            skill_data=context.skill_data or {},
   656→            skill_id=self._active_skill,
   657→            scenario_id=self._active_scenario,
   658→            conversation_id=context.conversation_id
   659→        )
   660→
   661→        # 使用统一注册表执行工具
   662→        if ToolRegistry.has_handler(tool_name):
   663→            return await ToolRegistry.execute(tool_name, args, tool_context)
   664→
   665→        # 未找到处理器
   666→        logger.warning(f"No handler found for tool: {tool_name}")
   667→        return {"status": "unknown_tool", "tool": tool_name, "message": f"工具 {tool_name} 暂未实现"}
   668→
   669→    async def _handle_use_skill(
   670→        self,
   671→        args: Dict[str, Any],
   672→        context: AgentContext
   673→    ) -> Dict[str, Any]:
   674→        """处理 skill 选择 - V6: 一次决定 skill + scenario + confidence"""
   675→        skill = args.get("skill")
   676→        scenario = args.get("scenario", "basic_reading")
   677→        confidence = args.get("confidence", "high")
   678→        topic = args.get("topic", "general")
   679→
   680→        if not skill:
   681→            return {"status": "error", "message": "No skill specified"}
   682→
   683→        self._active_skill = skill
   684→        self._active_scenario = scenario
   685→        self._topic = topic
   686→
   687→        # 低置信度时，返回确认请求
   688→        if confidence == "low":
   689→            return {
   690→                "status": "need_confirm",
   691→                "skill": skill,
   692→                "scenario": scenario,
   693→                "confidence": confidence,
   694→                "message": f"我理解您可能想使用 {skill} 的 {scenario} 服务，请确认是否正确？"
   695→            }
   696→
   697→        # 检查是否需要出生信息（v7.1: 配置驱动）
   698→        needs_birth = skill_requires_birth_info(skill)
   699→        has_birth = context.profile and context.profile.get("birth_info")
   700→        birth_provided = args.get("birth_info_provided", False)
   701→
   702→        if needs_birth and not has_birth and not birth_provided:
   703→            return {
   704→                "status": "need_info",
   705→                "skill": skill,
   706→                "scenario": scenario,
   707→                "confidence": confidence,
   708→                "topic": topic,
   709→                "info_type": "birth",
   710→                "message": "技能已激活。请调用 request_info 工具收集出生信息。"
   711→            }
   712→
   713→        return {
   714→            "status": "activated",
   715→            "skill": skill,
   716→            "scenario": scenario,
   717→            "confidence": confidence,
   718→            "topic": topic,
   719→            "message": f"已激活 {skill} 技能，场景: {scenario}"
   720→        }
   721→
   722→
   723→def create_agent(
   724→    llm: Optional[LLMClient] = None,
   725→    max_iterations: int = 10
   726→) -> CoreAgent:
   727→    """创建 CoreAgent 实例"""
   728→    return CoreAgent(llm=llm, max_iterations=max_iterations)
   729→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
