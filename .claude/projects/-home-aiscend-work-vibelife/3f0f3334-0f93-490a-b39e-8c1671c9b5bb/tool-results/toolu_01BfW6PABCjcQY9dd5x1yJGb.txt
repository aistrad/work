     1→"""
     2→Chat Routes V5 - Unified chat endpoint with CoreAgent
     3→Based on: Claude Agent SDK style architecture
     4→
     5→Features:
     6→- Single /chat/stream endpoint
     7→- CoreAgent with LLM-based skill selection
     8→- Quota check at entry + usage recording
     9→- OpenAI compatible SSE format (works with AI SDK 4.x useChat)
    10→- Memory integration (Insights + Portrait + Life Context)
    11→"""
    12→import json
    13→import logging
    14→import asyncio
    15→from typing import Optional
    16→from uuid import UUID, uuid4
    17→
    18→from fastapi import APIRouter, Depends, HTTPException, Request
    19→from fastapi.responses import StreamingResponse
    20→from pydantic import BaseModel, Field
    21→from sse_starlette.sse import EventSourceResponse
    22→
    23→from services.identity import get_optional_user, CurrentUser
    24→from services.agent import CoreAgent, AgentContext, QuotaTracker, create_agent, get_adapter
    25→from stores.profile_cache import get_cached_profile_with_skill
    26→from stores import message_repo
    27→
    28→router = APIRouter(prefix="/chat/v5", tags=["Chat V5"])
    29→logger = logging.getLogger(__name__)
    30→
    31→
    32→# ═══════════════════════════════════════════════════════════════════════════
    33→# Request/Response Models
    34→# ═══════════════════════════════════════════════════════════════════════════
    35→
    36→class MessageItem(BaseModel):
    37→    """Single message in AI SDK format"""
    38→    role: str
    39→    content: str
    40→
    41→class ChatRequestV5(BaseModel):
    42→    """V5 Chat request - supports both simple and AI SDK 6 format"""
    43→    message: Optional[str] = Field(None, description="User message (simple format)")
    44→    messages: Optional[list[MessageItem]] = Field(None, description="Messages array (AI SDK 6 format)")
    45→    conversation_id: Optional[UUID] = Field(None, description="Conversation ID")
    46→    skill: Optional[str] = Field(None, description="Skill ID (bazi/zodiac/career/tarot)")
    47→    voice_mode: Optional[str] = Field(None, description="Voice mode (warm/sarcastic)")
    48→
    49→    def get_user_message(self) -> str:
    50→        """Extract user message from either format"""
    51→        if self.message:
    52→            return self.message
    53→        if self.messages:
    54→            # Get the last user message from the array
    55→            for msg in reversed(self.messages):
    56→                if msg.role == "user":
    57→                    return msg.content
    58→        return ""
    59→
    60→    def get_history(self) -> list[dict]:
    61→        """Extract conversation history from messages array (excluding last user message)"""
    62→        if not self.messages or len(self.messages) <= 1:
    63→            return []
    64→        # Return all messages except the last one (which is the current user message)
    65→        return [{"role": m.role, "content": m.content} for m in self.messages[:-1]]
    66→
    67→
    68→class GuestChatRequestV5(BaseModel):
    69→    """Guest chat request - supports both simple and AI SDK 6 format"""
    70→    message: Optional[str] = Field(None, description="User message (simple format)")
    71→    messages: Optional[list[MessageItem]] = Field(None, description="Messages array (AI SDK 6 format)")
    72→
    73→    def get_user_message(self) -> str:
    74→        """Extract user message from either format"""
    75→        if self.message:
    76→            return self.message
    77→        if self.messages:
    78→            for msg in reversed(self.messages):
    79→                if msg.role == "user":
    80→                    return msg.content
    81→        return ""
    82→
    83→
    84→# ═══════════════════════════════════════════════════════════════════════════
    85→# Helper Functions
    86→# ═══════════════════════════════════════════════════════════════════════════
    87→
    88→async def get_user_context(user_id: Optional[UUID]) -> tuple:
    89→    """Get user profile and skill data"""
    90→    if user_id:
    91→        try:
    92→            # Get merged profile with all skill data
    93→            result = await get_cached_profile_with_skill(user_id, "bazi")
    94→            return result.get("profile", {}), result.get("skill_data", {})
    95→        except Exception as e:
    96→            logger.error(f"Failed to get user context: {e}")
    97→    return {}, {}
    98→
    99→
   100→async def get_conversation_history(conversation_id: Optional[UUID], limit: int = 10) -> list:
   101→    """Get recent conversation history"""
   102→    if not conversation_id:
   103→        return []
   104→    try:
   105→        messages = await message_repo.get_messages_for_context(conversation_id, limit)
   106→        return messages
   107→    except Exception as e:
   108→        logger.error(f"Failed to get history: {e}")
   109→        return []
   110→
   111→
   112→async def save_message(conversation_id: UUID, role: str, content: str) -> None:
   113→    """Save message to database"""
   114→    try:
   115→        await message_repo.create_message(
   116→            conversation_id=conversation_id,
   117→            role=role,
   118→            content=content
   119→        )
   120→    except Exception as e:
   121→        logger.warning(f"Failed to save message: {e}")
   122→
   123→
   124→# ═════════════════════════════════���═════════════════════════════════════════
   125→# Endpoints
   126→# ═══════════════════════════════════════════════════════════════════════════
   127→
   128→@router.post("/stream")
   129→async def chat_stream_v5(
   130→    request: ChatRequestV5,
   131→    req: Request,
   132→    current_user: Optional[CurrentUser] = Depends(get_optional_user)
   133→):
   134→    """
   135→    V5 Chat endpoint with CoreAgent.
   136→
   137→    Features:
   138→    - CoreAgent decides skill via LLM (no keyword matching)
   139→    - Supports multi-skill fusion
   140→    - Quota check at entry
   141→    - Vercel AI SDK 6 compatible SSE
   142→
   143→    Test mode:
   144→    - Add header `X-Test-Tier: paid` to simulate paid user
   145→    - Add header `X-Test-Tier: free` to simulate free user
   146→    """
   147→    user_id = current_user.user_id if current_user else None
   148→    user_tier = "free"
   149→
   150→    # Test mode: allow tier override via header
   151→    test_tier = req.headers.get("x-test-tier")
   152→    if test_tier and test_tier in ("free", "paid", "guest"):
   153→        user_tier = test_tier
   154→        logger.info(f"Test mode: using tier={test_tier}")
   155→    elif user_id:
   156→        from services.entitlement import EntitlementService
   157→        entitlements = await EntitlementService.get_entitlements(user_id)
   158→        user_tier = entitlements.get("tier", "free")
   159→
   160→    # [A] Entry quota check
   161→    quota_ok, quota_message = await QuotaTracker.check(
   162→        user_id=str(user_id) if user_id else "guest",
   163→        tier=user_tier
   164→    )
   165→
   166→    if not quota_ok:
   167→        return EventSourceResponse(_quota_exceeded_response(quota_message, user_tier))
   168→
   169→    conversation_id = request.conversation_id or uuid4()
   170→
   171→    async def generate():
   172→        try:
   173→            # Get user context
   174→            profile, skill_data = await get_user_context(user_id)
   175→            # Use messages from request as history (AI SDK sends full conversation)
   176→            history = request.get_history()
   177→
   178→            # Build agent context (profile 已���含所有用户数据，无需额外获取)
   179→            context = AgentContext(
   180→                user_id=str(user_id) if user_id else "guest",
   181→                user_tier=user_tier,
   182→                profile=profile,
   183→                skill_data=skill_data,
   184→                history=history,
   185→                skill=request.skill,
   186→                voice_mode=request.voice_mode,
   187→                recent_insights=None,  # 已废弃，数据从 profile.extracted 获取
   188→                portrait=None,  # 已废弃，数据从 profile.extracted 获取
   189→                conversation_id=str(conversation_id)
   190→            )
   191→
   192→            # Save user message
   193→            user_message = request.get_user_message()
   194→            if not user_message:
   195→                # AI SDK 4.x error format: 3:"error message"
   196→                yield f'3:{json.dumps("No user message provided")}\n'
   197→                yield f'd:{json.dumps({"finishReason": "error", "usage": {"promptTokens": 0, "completionTokens": 0}})}\n'
   198→                return
   199→
   200→            await save_message(conversation_id, "user", user_message)
   201→
   202→            # Create agent and adapter
   203→            agent = create_agent()
   204→            adapter = get_adapter("simple")
   205→
   206→            # Stream through adapter (converts AgentEvent → AI SDK 4.x format)
   207→            full_content = ""
   208→            async for event in adapter.adapt(agent.run(user_message, context)):
   209→                # SimpleToolAdapter returns "0:\"text\"\n" format strings
   210→                if isinstance(event, str):
   211→                    yield event
   212→                    # Extract actual content from AI SDK 4.x format: 0:"content"\n
   213→                    if event.startswith('0:'):
   214→                        try:
   215→                            content = json.loads(event[2:].rstrip('\n'))
   216→                            # Skip tool markers for saved content
   217→                            if not (isinstance(content, str) and content.startswith('[[TOOL:')):
   218→                                full_content += content
   219→                        except:
   220→                            pass
   221→                else:
   222→                    # Other adapters return dicts - convert to SSE string for StreamingResponse
   223→                    data_str = event.get("data", "") if isinstance(event, dict) else str(event)
   224→                    yield f"data: {data_str}\n\n"
   225→                    if '"delta"' in data_str and '"content"' in data_str:
   226→                        try:
   227→                            data = json.loads(data_str)
   228→                            delta = data.get("choices", [{}])[0].get("delta", {})
   229→                            full_content += delta.get("content", "")
   230→                        except:
   231→                            pass
   232→
   233→            # Save assistant message
   234→            if full_content:
   235→                await save_message(conversation_id, "assistant", full_content)
   236→
   237→            # [C] Record usage
   238→            await QuotaTracker.record(
   239→                user_id=str(user_id) if user_id else "guest",
   240→                usage=agent.usage
   241→            )
   242→
   243→            # [D] Insight generation 已废弃，用户信息通过 profile_extractor 定时抽取
   244→
   245→        except Exception as e:
   246→            logger.error(f"Chat error: {e}", exc_info=True)
   247→            yield f"\n\n❌ Error: {str(e)}"
   248→
   249→    # 使用 StreamingResponse 输出 AI SDK 4.x data stream 格式
   250→    return StreamingResponse(
   251→        generate(),
   252→        media_type="text/plain; charset=utf-8",
   253→        headers={
   254→            "X-Content-Type-Options": "nosniff",
   255→            "X-Vercel-AI-Data-Stream": "v1"  # AI SDK 4.x 必需的 header
   256→        }
   257→    )
   258→
   259→
   260→@router.post("/guest/stream")
   261→async def guest_chat_stream_v5(request: GuestChatRequestV5):
   262→    """
   263→    Guest chat endpoint (no auth, limited functionality).
   264→    """
   265→    async def generate():
   266→        try:
   267→            context = AgentContext(
   268→                user_id="guest",
   269→                user_tier="guest",
   270→                profile={},
   271→                skill_data={}
   272→            )
   273→
   274→            agent = create_agent(max_iterations=5)
   275→            adapter = get_adapter("text")
   276→
   277→            user_message = request.get_user_message()
   278→            if not user_message:
   279→                yield {"data": json.dumps({"type": "error", "errorText": "No user message provided"})}
   280→                return
   281→
   282→            # Stream through adapter
   283→            async for event in adapter.adapt(agent.run(user_message, context)):
   284→                yield event
   285→
   286→        except Exception as e:
   287→            logger.error(f"Guest chat error: {e}")
   288→            yield {"data": json.dumps({"type": "error", "errorText": str(e)})}
   289→
   290→    headers = {"x-vercel-ai-ui-message-stream": "v1"}
   291→    return EventSourceResponse(generate(), headers=headers)
   292→
   293→
   294→async def _quota_exceeded_response(message: str, tier: str):
   295→    """Generate quota exceeded SSE response"""
   296→    yield {
   297→        "event": "error",
   298→        "data": json.dumps({
   299→            "type": "quota_exceeded",
   300→            "message": message,
   301→            "tier": tier,
   302→            "upgrade_url": "/membership"
   303→        })
   304→    }
   305→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
