     1→# VibeLife V6 Architecture
     2→
     3→> Version: 4.1 (v6.1) | 2026-01-14
     4→> 详细文档: [docs/archive/v6/VibeLife-Expert-System-v6.md](./VibeLife-Expert-System-v6.md)
     5→
     6→**v6.1 变更 (2026-01-14)**:
     7→- Stage 4 改为统一抽取 + LLM 自动审核 (`unified_extractor.py`)
     8→- Case 自动入库: `reasoning_chain` + `guidance_patterns`, score >= 0.6
     9→- Scenario 自动发布: quality >= 0.6 + similarity < 0.5
    10→- 废弃 `scenario_candidates` 和 `scenario_index` 表
    11→- 删除 `scenario_generator.py` 和 `scenario_reviewer.py`
    12→
    13→## 项目概述
    14→
    15→VibeLife 是一个 AI 驱动的命理咨询平台，支持八字、星座、塔罗、职业咨询等多种技能。
    16→
    17→## 技术架构
    18→
    19→```
    20→┌─────────────────────────────────────────────────────────────────┐
    21→│           Python CoreAgent 主导 + Next.js 代理 + AI SDK 6        │
    22→├─────────────────────────────────────────────────────────────────┤
    23→│                                                                 │
    24→│  Browser (AI SDK 6)                                             │
    25→│  ├─ useVibeChat + DefaultChatTransport                          │
    26→│  └─ 请求 /api/v1/* (相对路径)                                    │
    27→│                                                                 │
    28→│  Next.js (香港火山云)                                            │
    29→│  ├─ rewrites 代理: /api/v1/* → Python API                       │
    30→│  └─ 环境变量: VIBELIFE_API_INTERNAL                              │
    31→│                                                                 │
    32→│  Python Backend (本机 aiscend/vibelife)                          │
    33→│  ├─ /chat/v5/stream         → CoreAgent 主入口                  │
    34→│  │      ├─ LLM 智能选择 Skill (无关键词匹配)                     │
    35→│  │      ├─ Tool calling + 执行                                  │
    36→│  │      └─ AI SDK 6 Data Stream Protocol SSE                    │
    37→│  ├─ /bazi/chart             → 八字命盘 API                      │
    38→│  ├─ /zodiac/chart           → 星盘 API                          │
    39→│  ├─ /fortune/*              → 运势数据 API                      │
    40→│  └─ /users/me/profile       → 用户画像                          │
    41→│                                                                 │
    42→└─────────────────────────────────────────────────────────────────┘
    43→
    44→部署环境:
    45→- 测试环境 (aiscend): Python API 端口 8100
    46→- 生产环境 (vibelife): Python API 端口 8000
    47→```
    48→
    49→## 核心设计原则
    50→
    51→### Anthropic Agent 设计原则
    52→
    53→1. **Agentic Loop**: "LLMs using tools based on environmental feedback in a loop"
    54→2. **不要用代码硬编码决策逻辑，让 LLM 自己判断**
    55→3. **Tool Use 最佳实践 (ACI)**:
    56→   - 站在模型角度思考工具是否易用
    57→   - 工具定义应包含示例用法、边界情况
    58→   - 参数命名要清晰
    59→
    60→### 三大原则
    61→
    62→| 原则 | 说明 |
    63→|------|------|
    64→| **Simplicity** | 保持简单，避免过度工程 |
    65→| **Transparency** | 显式展示 agent 规划步骤 |
    66→| **Documentation & Testing** | 精心设计工具文档，充分测试 |
    67→
    68→## 关键文件
    69→
    70→```
    71→apps/api/
    72→├── routes/chat_v5.py          # V5 Chat 端点 (CoreAgent)
    73→├── services/agent/core.py     # CoreAgent 实现
    74→├── services/llm/client.py     # 统一 LLM 客户端
    75→└── skills/                    # Skill 定义
    76→
    77→apps/web/
    78→├── src/hooks/useVibeChat.ts   # AI SDK 6 集成 (使用相对路径)
    79→├── src/components/chat/       # Chat UI 组件
    80→└── next.config.js             # rewrites 代理配置
    81→```
    82→
    83→## LLM 调用规范
    84→
    85→**唯一配置源**: `config/models.yaml`
    86→
    87→```
    88→config/models.yaml                    ← 唯一配置源 (Single Source of Truth)
    89→        │
    90→        ├─ services/llm/config.py     ← LLMConfig 配置加载模块
    91→        │
    92→        └─ services/llm/client.py     ← LLMClient 统一调用
    93→```
    94→
    95→**使用方法**:
    96→```python
    97→from services.llm.config import LLMConfig
    98→
    99→# 获取 provider 配置
   100→provider = LLMConfig.get_provider("deepseek")
   101→print(provider.base_url)       # https://api.deepseek.com/anthropic
   102→print(provider.api_key)        # 从环境变量读取
   103→print(provider.is_anthropic()) # True
   104→
   105→# 解析模型路由 (含 fallback 链)
   106→selection = LLMConfig.resolve(user_tier="paid", task="chat")
   107→print(selection.model)         # deepseek-chat
   108→print(selection.fallback_chain) # ['glm-4.7', 'claude-opus', 'glm-4-flash']
   109→```
   110→
   111→**验证配置**:
   112→```bash
   113→python scripts/validate_llm_config.py
   114→```
   115→
   116→**禁止**:
   117→- 前端硬编码模型名称或 API 地址
   118→- 在代码中硬编码 tier 名称或限制值
   119→- 在 Python 代码中硬编码 base_url 默认值（应从 models.yaml 读取）
   120→
   121→## Anthropic 兼容 API 配置
   122→
   123→DeepSeek 和 GLM 都提供了 Anthropic 兼容的 API 端点，可以复用 Claude SDK 的消息格式和工具调用逻辑。
   124→
   125→### DeepSeek V3
   126→
   127→**官方文档**: https://api-docs.deepseek.com/guides/anthropic_api
   128→
   129→**端点配置**:
   130→```python
   131→base_url = "https://api.deepseek.com/anthropic"
   132→model = "deepseek-chat"  # 或 deepseek-reasoner
   133→```
   134→
   135→**环境变量** (用于 Claude Code CLI):
   136→```bash
   137→export ANTHROPIC_BASE_URL=https://api.deepseek.com/anthropic
   138→export ANTHROPIC_AUTH_TOKEN=${DEEPSEEK_API_KEY}
   139→export ANTHROPIC_MODEL=deepseek-chat
   140→export API_TIMEOUT_MS=600000
   141→```
   142→
   143→**Python 调用示例**:
   144→```python
   145→# 使用 Anthropic SDK
   146→import anthropic
   147→
   148→client = anthropic.Anthropic(
   149→    base_url="https://api.deepseek.com/anthropic",
   150→    api_key=os.getenv("DEEPSEEK_API_KEY")
   151→)
   152→
   153→message = client.messages.create(
   154→    model="deepseek-chat",
   155→    max_tokens=1000,
   156→    messages=[{"role": "user", "content": "Hello"}]
   157→)
   158→```
   159→
   160→**支持特性**:
   161→- ✅ 流式响应 (stream)
   162→- ✅ 工具调用 (tool_use, tool_result)
   163→- ✅ System prompt
   164→- ✅ Temperature (0.0 ~ 2.0)
   165→- ❌ 图片/文档输入
   166→
   167→### GLM 4.7
   168→
   169→**官方文档**: https://docs.bigmodel.cn/cn/coding-plan/tool/claude
   170→
   171→**端点配置**:
   172→```python
   173→base_url = "https://open.bigmodel.cn/api/anthropic/v1"  # 注意需要 /v1
   174→model = "glm-4.7"  # 或 GLM-4.5-Air
   175→```
   176→
   177→**环境变量** (用于 Claude Code CLI):
   178→```bash
   179→export ANTHROPIC_BASE_URL=https://open.bigmodel.cn/api/anthropic
   180→export ANTHROPIC_AUTH_TOKEN=${GLM_API_KEY}
   181→export ANTHROPIC_MODEL=glm-4.7
   182→export API_TIMEOUT_MS=3000000
   183→```
   184→
   185→**Python 调用示例**:
   186→```python
   187→# 使用 Anthropic SDK
   188→import anthropic
   189→
   190→client = anthropic.Anthropic(
   191→    base_url="https://open.bigmodel.cn/api/anthropic/v1",
   192→    api_key=os.getenv("GLM_API_KEY")
   193→)
   194→
   195→message = client.messages.create(
   196→    model="glm-4.7",
   197→    max_tokens=1000,
   198→    messages=[{"role": "user", "content": "Hello"}]
   199→)
   200→```
   201→
   202→**模型映射**:
   203→| Anthropic 模型 | GLM 模型 |
   204→|---------------|---------|
   205→| claude-opus | GLM-4.7 |
   206→| claude-sonnet | GLM-4.7 |
   207→| claude-haiku | GLM-4.5-Air |
   208→
   209→### LLMClient 实现
   210→
   211→`services/llm/client.py` 中统一处理 Anthropic 兼容 API：
   212→
   213→```python
   214→# 支持的 Anthropic 兼容 provider
   215→ANTHROPIC_COMPATIBLE_PROVIDERS = ("claude", "anthropic", "deepseek", "glm", "zhipu")
   216→
   217→# base_url 配置
   218→url_map = {
   219→    "deepseek": "https://api.deepseek.com/anthropic",
   220→    "glm": "https://open.bigmodel.cn/api/anthropic/v1",
   221→    "zhipu": "https://open.bigmodel.cn/api/anthropic/v1",
   222→    "claude": os.getenv("CLAUDE_BASE_URL", "https://api.anthropic.com"),
   223→}
   224→
   225→# 流式调用自动路由到 Anthropic 格式
   226→async def _stream_provider(self, provider, model, messages, tools, ...):
   227→    if provider in ANTHROPIC_COMPATIBLE_PROVIDERS:
   228→        async for chunk in self._stream_claude(model, messages, tools, max_tokens, provider=provider):
   229→            yield chunk
   230→```
   231→
   232→**测试状态**:
   233→| Provider | 模型 | 工具调用 | 流式响应 | 测试状态 |
   234→|----------|------|---------|---------|----------|
   235→| deepseek | deepseek-chat | ✅ | ✅ | ✅ 通过 |
   236→| glm | glm-4.7 | ✅ | ✅ | ✅ 通过 |
   237→
   238→## 测试环境
   239→
   240→- API: http://127.0.0.1:8100
   241→- Web: http://127.0.0.1:8232
   242→- 启动: `scripts/start-test.sh`
   243→
   244→## Vercel AI SDK 6 精华
   245→
   246→> 官方文档: https://sdk.vercel.ai/docs
   247→> 博客: https://vercel.com/blog/ai-sdk-6
   248→
   249→### 核心变化 (v5 → v6)
   250→
   251→| 特性 | AI SDK 5 | AI SDK 6 |
   252→|------|----------|----------|
   253→| **请求方式** | `api` 字符串 | `transport` 对象 |
   254→| **发送消息** | `append({ content })` | `sendMessage({ text })` |
   255→| **状态管理** | `isLoading` | `status: 'idle'|'submitted'|'streaming'` |
   256→| **工具结果** | 手动处理 | `addToolResult()` 内置 |
   257→
   258→### Transport 架构 (核心创新)
   259→
   260→AI SDK 6 引入 Transport 层，解耦前端 Hook 和后端通信：
   261→
   262→```typescript
   263→import { useChat } from '@ai-sdk/react';
   264→import { DefaultChatTransport } from 'ai';
   265→
   266→// 创建 Transport（可自定义 headers、body）
   267→const transport = new DefaultChatTransport({
   268→  api: '/api/v1/chat/v5/stream',
   269→  headers: { Authorization: `Bearer ${token}` },
   270→  body: { skill: 'bazi', voice_mode: 'warm' },
   271→});
   272→
   273→// useChat 使用 transport
   274→const { messages, sendMessage, status } = useChat({ transport });
   275→```
   276→
   277→**优势**:
   278→- 前端无需关心后端 URL 变化
   279→- 支持自定义认证、请求体
   280→- 可替换为 WebSocket 等其他传输方式
   281→
   282→### Data Stream Protocol (SSE 格式)
   283→
   284→后端输出 SSE 必须符合此协议，前端才能正确解析：
   285→
   286→| 前缀 | 含义 | 示例 |
   287→|------|------|------|
   288→| `0:` | 文本增量 | `0:"Hello"` |
   289→| `9:` | 工具调用 | `9:{"toolCallId":"x","toolName":"show_chart","args":{}}` |
   290→| `a:` | 工具结果 | `a:{"toolCallId":"x","result":{...}}` |
   291→| `d:` | 完成信号 | `d:{"finishReason":"stop"}` |
   292→| `e:` | 元数据 | `e:{"conversation_id":"xxx"}` |
   293→| `3:` | 错误 | `3:"Error message"` |
   294→
   295→**Python 后端实现**:
   296→```python
   297→# 文本增量
   298→yield {"data": f'0:{json.dumps(content)}'}
   299→
   300→# 工具调用
   301→yield {"data": f'9:{json.dumps({"toolCallId": id, "toolName": name, "args": args})}'}
   302→
   303→# 工具结果
   304→yield {"data": f'a:{json.dumps({"toolCallId": id, "result": result})}'}
   305→
   306→# 完成
   307→yield {"data": f'd:{json.dumps({"finishReason": "stop"})}'}
   308→```
   309→
   310→### useChat Hook (前端)
   311→
   312→```typescript
   313→const {
   314→  messages,           // 消息列表
   315→  status,             // 'idle' | 'submitted' | 'streaming'
   316→  sendMessage,        // 发送消息 ({ text: string })
   317→  addToolResult,      // 添加工具结果
   318→  stop,               // 停止生成
   319→  setMessages,        // 重置消息
   320→  regenerate,         // 重新生成
   321→} = useChat({ transport });
   322→
   323→// 计算 isLoading
   324→const isLoading = status === 'submitted' || status === 'streaming';
   325→```
   326→
   327→### 工具调用流程
   328→
   329→```
   330→1. 用户发送消息
   331→2. 后端返回 9:{toolCallId, toolName, args}
   332→3. 前端渲染工具 UI（Generative UI）
   333→4. 工具执行完成后调用 addToolResult()
   334→5. 后端继续处理，返回最终响应
   335→```
   336→
   337→**前端工具结果提交**:
   338→```typescript
   339→// 成功
   340→addToolResult({ toolCallId, tool: toolName, output: result });
   341→
   342→// 失败/取消
   343→addToolResult({
   344→  toolCallId,
   345→  tool: toolName,
   346→  state: 'output-error',
   347→  errorText: '用户已取消'
   348→});
   349→```
   350→
   351→### VibeLife 集成方式
   352→
   353→```
   354→┌─────────────────────────────────────────────────────────────────┐
   355→│                    AI SDK 6 集成架构                             │
   356→├─────────────────────────────────────────────────────────────────┤
   357→│                                                                 │
   358→│  useVibeChat (前端 Hook)                                        │
   359→│  ├─ DefaultChatTransport → /api/v1/chat/v5/stream              │
   360→│  ├─ 自动处理 SSE 解析                                           │
   361→│  └─ addToolResult() 提交工具结果                                │
   362→│                                                                 │
   363→│  Next.js rewrites (代理层)                                      │
   364→│  └─ /api/v1/* → Python API                                     │
   365→│                                                                 │
   366→│  Python CoreAgent (后端)                                        │
   367→│  ├─ 输出 AI SDK 6 Data Stream Protocol                         │
   368→│  ├─ 0: 文本 / 9: 工具调用 / a: 工具结果 / d: 完成               │
   369→│  └─ SSE via sse-starlette                                      │
   370→│                                                                 │
   371→└─────────────────────────────────────────────────────────────────┘
   372→```
   373→
   374→### 关键依赖版本
   375→
   376→```json
   377→{
   378→  "ai": "^6.0.20",
   379→  "@ai-sdk/react": "^3.0.20",
   380→  "@ai-sdk/deepseek": "^2.0.4",
   381→  "@ai-sdk/openai-compatible": "^2.0.4"
   382→}
   383→```
   384→
   385→**注意**: `@ai-sdk/openai-compatible` 必须 >= 2.0.4，旧版本不兼容 AI SDK 6。
   386→
   387→## 参考文档
   388→
   389→- [Vercel AI SDK 6 Docs](https://sdk.vercel.ai/docs)
   390→- [AI SDK 6 Stream Protocol](https://sdk.vercel.ai/docs/ai-sdk-ui/stream-protocol)
   391→- [Anthropic Building Effective Agents](https://www.anthropic.com/engineering/building-effective-agents)
   392→- [Claude Agent SDK Overview](https://platform.claude.com/docs/en/agent-sdk/overview)
   393→- [Claude Agent SDK Python](https://platform.claude.com/docs/en/agent-sdk/python)
   394→
   395→# VibeLife V6 Architecture - 方案 B
   396→
   397→> Version: 4.0 | 2026-01-14
   398→> 参考:
   399→> - [Anthropic Building Effective Agents](https://www.anthropic.com/engineering/building-effective-agents)
   400→> - [Claude Agent SDK Overview](https://platform.claude.com/docs/en/agent-sdk/overview)
   401→> - [Claude Agent SDK Python](https://platform.claude.com/docs/en/agent-sdk/python)
   402→> - [Claude Agent SDK Demos](https://github.com/anthropics/claude-agent-sdk-demos)
   403→
   404→## Claude Agent SDK 核心概念
   405→
   406→### SDK vs Client SDK
   407→
   408→| 特性 | Client SDK | Agent SDK |
   409→|------|-----------|-----------|
   410→| **工具执行** | 你自己实现 tool loop | Claude 自动处理 |
   411→| **内置工具** | 无 | Read, Write, Edit, Bash, Glob, Grep, WebSearch, WebFetch |
   412→| **适用场景** | 直接 API 调用 | 构建自主 Agent |
   413→
   414→```python
   415→# Client SDK: 你自己实现 tool loop
   416→response = client.messages.create(...)
   417→while response.stop_reason == "tool_use":
   418→    result = your_tool_executor(response.tool_use)
   419→    response = client.messages.create(tool_result=result, ...)
   420→
   421→# Agent SDK: Claude 自动处理工具
   422→async for message in query(prompt="Fix the bug in auth.py"):
   423→    print(message)
   424→```
   425→
   426→### query() vs ClaudeSDKClient
   427→
   428→| 特性 | query() | ClaudeSDKClient |
   429→|------|---------|-----------------|
   430→| **Session** | 每次创建新 session | 复用同一 session |
   431→| **对话** | 单次交互 | 多轮对话保持上下文 |
   432→| **中断** | ❌ 不支持 | ✅ 支持 |
   433→| **Hooks** | ❌ 不支持 | ✅ 支持 |
   434→| **自定义工具** | ❌ 不支持 | ✅ 支持 |
   435→| **适用场景** | 一次性任务 | 连续对话 |
   436→
   437→### 内置工具
   438→
   439→| 工具 | 功能 |
   440→|------|------|
   441→| **Read** | 读取文件 |
   442→| **Write** | 创建文件 |
   443→| **Edit** | 精确编辑文件 |
   444→| **Bash** | 执行终端命令 |
   445→| **Glob** | 按模式查找文件 |
   446→| **Grep** | 正则搜索文件内容 |
   447→| **WebSearch** | 搜索网络 |
   448→| **WebFetch** | 获取网页内容 |
   449→| **AskUserQuestion** | 向用户提问 |
   450→
   451→### Subagents (子代理)
   452→
   453→```python
   454→# 定义专门的子代理
   455→options = ClaudeAgentOptions(
   456→    allowed_tools=["Read", "Glob", "Grep", "Task"],
   457→    agents={
   458→        "code-reviewer": AgentDefinition(
   459→            description="Expert code reviewer for quality and security reviews.",
   460→            prompt="Analyze code quality and suggest improvements.",
   461→            tools=["Read", "Glob", "Grep"]
   462→        )
   463→    }
   464→)
   465→```
   466→
   467→### Hooks (钩子)
   468→
   469→在 agent 生命周期的关键点运行自定义代码：
   470→
   471→| Hook | 触发时机 |
   472→|------|---------|
   473→| **PreToolUse** | 工具执行前 |
   474→| **PostToolUse** | 工具执行后 |
   475→| **UserPromptSubmit** | 用户提交 prompt 时 |
   476→| **Stop** | 停止执行时 |
   477→| **SubagentStop** | 子代理停止时 |
   478→
   479→```python
   480→async def validate_bash_command(input_data, tool_use_id, context):
   481→    if 'rm -rf /' in input_data.get('tool_input', {}).get('command', ''):
   482→        return {
   483→            'hookSpecificOutput': {
   484→                'permissionDecision': 'deny',
   485→                'permissionDecisionReason': 'Dangerous command blocked'
   486→            }
   487→        }
   488→    return {}
   489→
   490→options = ClaudeAgentOptions(
   491→    hooks={
   492→        'PreToolUse': [HookMatcher(matcher='Bash', hooks=[validate_bash_command])]
   493→    }
   494→)
   495→```
   496→
   497→---
   498→
   499→## Anthropic Agent 设计原则
   500→
   501→### Workflows vs Agents
   502→
   503→| 类型 | 定义 | 适用场景 |
   504→|------|------|---------|
   505→| **Workflows** | LLM 和工具通过**预定义代码路径**编排 | 流程固定、可预测的任务 |
   506→| **Agents** | LLM **动态指导**自己的流程和工具使用 | 需要灵活决策的任务 |
   507→
   508→**VibeLife V6 采用 Agent 模式**：CoreAgent 动态选择 Skill、决定是否收集信息、选择合适的工具。
   509→
   510→### Agentic Loop 核心
   511→
   512→```
   513→┌─────────────────────────────────────────────────────────────┐
   514→│  "LLMs using tools based on environmental feedback in a loop" │
   515→└─────────────────────────────────────────────────────────────┘
   516→
   517→用户消息 → LLM 思考 → 工具调用 → 环境反馈 → LLM 继续思考 → ...
   518→                ↑                              │
   519→                └──────────────────────────────┘
   520→```
   521→
   522→**关键点**：
   523→- 每步从环境获取 "ground truth"（工具调用结果）
   524→- LLM 根据反馈动态调整下一步行动
   525→- **不要用代码硬编码决策逻辑，让 LLM 自己判断**
   526→
   527→### Tool Use 最佳实践 (ACI - Agent-Computer Interface)
   528→
   529→1. **站在模型角度思考工具是否易用**
   530→   - 工具定义应包含示例用法、边界情况、输入格式要求
   531→   - 参数命名要清晰，像给初级开发者写 docstring
   532→
   533→2. **Poka-yoke（防错设计）**
   534→   - 修改参数使错误更难发生
   535→   - 例：强制使用绝对路径而非相对路径
   536→
   537→3. **给模型足够 token "think"**
   538→   - 不要急于让模型输出结果
   539→   - 允许模型在工具调用前思考
   540→
   541→4. **格式贴近自然文本**
   542→   - 避免复杂的格式要求（如精确计数、字符串转义）
   543→
   544→### 三大原则
   545→
   546→| 原则 | 说明 |
   547→|------|------|
   548→| **Simplicity** | 保持简单，避免过度工程 |
   549→| **Transparency** | 显式展示 agent 规划步骤 |
   550→| **Documentation & Testing** | 精心设计工具文档，充分测试 |
   551→
   552→### Agentic Loop 实现模式 (来自 anthropic-cookbook)
   553→
   554→```python
   555→def agent_loop(task: str, tools: list, max_iterations: int = 10):
   556→    messages = [{"role": "user", "content": task}]
   557→
   558→    for _ in range(max_iterations):
   559→        response = client.messages.create(
   560→            model="claude-sonnet-4-20250514",
   561→            messages=messages,
   562→            tools=tools
   563→        )
   564→
   565→        # 检查是否需要执行工具
   566→        if response.stop_reason == "tool_use":
   567→            tool_results = []
   568→            for block in response.content:
   569→                if block.type == "tool_use":
   570→                    result = execute_tool(block.name, block.input)
   571→                    tool_results.append({
   572→                        "type": "tool_result",
   573→                        "tool_use_id": block.id,
   574→                        "content": result
   575→                    })
   576→
   577→            # 添加 assistant 消息和工具结果
   578→            messages.append({"role": "assistant", "content": response.content})
   579→            messages.append({"role": "user", "content": tool_results})
   580→        else:
   581→            # 结束循环，返回最终响应
   582→            return response.content
   583→
   584→    return messages[-1]
   585→```
   586→
   587→**关键点**：
   588→- `stop_reason == "tool_use"` 判断是否需要执行工具
   589→- 工具结果作为 `tool_result` 添加到消息中
   590→- 循环直到 `stop_reason` 不是 `tool_use`
   591→- **让 LLM 决定何时停止，不要用代码硬编码停止条件**
   592→
   593→### Tool 定义规范
   594→
   595→```python
   596→tools = [
   597→    {
   598→        "name": "search",
   599→        "description": "Search for information. Include examples and edge cases.",
   600→        "input_schema": {
   601→            "type": "object",
   602→            "properties": {
   603→                "query": {
   604→                    "type": "string",
   605→                    "description": "The search query. Example: 'Python async tutorial'"
   606→                }
   607→            },
   608→            "required": ["query"]
   609→        }
   610→    }
   611→]
   612→```
   613→
   614→**工具描述最佳实践**：
   615→- 包含示例用法
   616→- 说明边界情况
   617→- 参数命名清晰
   618→- 像给初级开发者写 docstring
   619→
   620→---
   621→
   622→## 架构说明
   623→
   624→**当前使用方案 B**（Python CoreAgent 主导 + AI SDK 6 兼容 SSE）
   625→
   626→> 详细设计文档见: [VibeLife-Expert-System-v6.md](./VibeLife-Expert-System-v6.md)
   627→
   628→## 运行时架构
   629→
   630→```
   631→┌─────────────────────────────────────────────────────────────────┐
   632→│                    VibeLife V6 运行时架构                         │
   633→├─────────────────────────────────────────────────────────────────┤
   634→│                                                                 │
   635→│  1. LLM 路由 (use_skill 一次决定 skill + scenario + confidence) │
   636→│  2. 加载 SKILL.md + scenario.md (构建 System Prompt)            │
   637→│  3. 执行 SOP (LLM 根据需要动态调用全局工具 + Skill 级工具)       │
   638→│  4. 输出交付                                                    │
   639→│                                                                 │
   640→└─────────────────────────────────────────────────────────────────┘
   641→```
   642→
   643→## 架构流程
   644→
   645→```
   646→┌─────────────────────────────────────────────────────────────────┐
   647→│       Python CoreAgent 主导 + Next.js 代理 + AI SDK 6 兼容       │
   648→├─────────────────────────────────────────────────────────────────┤
   649→│                                                                 │
   650→│  Browser (AI SDK 6)                                             │
   651→│  ├─ useVibeChat + DefaultChatTransport                          │
   652→│  └─ 请求 /api/v1/* (相对路径，通过 Next.js 代理)                  │
   653→│                                                                 │
   654→│  Next.js (香港火山云)                                            │
   655→│  ├─ rewrites: /api/v1/* → VIBELIFE_API_INTERNAL                 │
   656→│  └─ 透明代理 SSE 流式响应                                        │
   657→│                                                                 │
   658→│  Python Backend (本机)                                           │
   659→│  ├─ /chat/v5/stream         → CoreAgent 主入口                  │
   660→│  │      ├─ LLM 智能选择 Skill (无关键词匹配)                     │
   661→│  │      ├─ Tool calling + 执行                                  │
   662→│  │      └─ AI SDK 6 Data Stream Protocol SSE                    │
   663→│  ├─ /bazi/chart             → 八字命盘 API                      │
   664→│  ├─ /zodiac/chart           → 星盘 API                          │
   665→│  ├─ /fortune/*              → 运势数据 API                      │
   666→│  └─ /users/me/profile       → 用户画像                          │
   667→│                                                                 │
   668→└─────────────────────────────────────────────────────────────────┘
   669→
   670→时序图:
   671→┌─────────┐     ┌─────────────┐     ┌─────────────┐     ┌─────────┐
   672→│Browser  │     │Next.js      │     │Python API   │     │LLM API  │
   673→│         │     │(香港火山云)  │     │(本机)       │     │(DeepSeek)│
   674→└────┬────┘     └──────┬──────┘     └──────┬──────┘     └────┬────┘
   675→     │                 │                   │                 │
   676→     │ 1.发送消息      │                   │                 │
   677→     │  /api/v1/chat/  │                   │                 │
   678→     │  v5/stream      │                   │                 │
   679→     │────────────────>│ 2.rewrites 代理   │                 │
   680→     │                 │──────────────────>│ 3.CoreAgent     │
   681→     │                 │                   │────────────────>│
   682→     │                 │                   │<────────────────│
   683→     │                 │<──────────────────│ 4.SSE响应       │
   684→     │<────────────────│ 5.转发SSE         │                 │
   685→```
   686→
   687→## 核心设计
   688→
   689→1. **Python CoreAgent 主导** - 后端统一处理 LLM 调用、Skill 选择、Tool 执行
   690→2. **AI SDK 6 兼容 SSE** - 输出符合 AI SDK 6 Data Stream Protocol 的 SSE 格式
   691→3. **前端零改动** - 复用现有 useVibeChat + DefaultChatTransport
   692→4. **LLM 智能路由** - CoreAgent 通过 LLM 判断用户意图，选择合适的 Skill
   693→5. **统一 LLM 调用** - 所有 LLM 调用通过 `services/llm/client.py`
   694→
   695→## Context 构建
   696→
   697→```python
   698→# Python: /api/v1/context/build
   699→ContextBuilder.build(
   700→    skill=skill,           # bazi/zodiac
   701→    voice_mode=voice_mode, # warm/sarcastic/wise
   702→    current_message=msg,
   703→    profile=profile,       # 用户画像
   704→    skill_data=skill_data, # 命盘数据
   705→    history=history,       # 对话历史
   706→)
   707→→ (system_prompt, messages)
   708→```
   709→
   710→- 话题检测: career/relationship/fortune/self/general
   711→- 智能裁剪: 根据话题选择相关 Profile 字段
   712→- Identity Prism: 始终注入核心画像摘要
   713→
   714→## 工具系统
   715→
   716→### 工具层级架构
   717→
   718→| 层级 | 定义位置 | 加载时机 | 示例 |
   719→|------|---------|---------|------|
   720→| 全局工具 | 系统��� | 始终可用 | search_db, ask_user_question, show_insight |
   721→| Skill 级工具 | SKILL.md | 路由到该 skill 后加载 | calculate_bazi, show_bazi_chart |
   722→
   723→### 全局工具
   724→
   725→```typescript
   726→const globalTools = {
   727→  search_db,           // 统一数据库查询（知识/案例）
   728→  ask_user_question,   // 主动追问用户
   729→  show_service_menu,   // 展示服务目录
   730→  show_insight,        // 通用洞察卡片
   731→  show_report,         // 通用报告
   732→};
   733→```
   734→
   735→### Skill 级工具示例
   736→
   737→**bazi skill:**
   738→```typescript
   739→const baziTools = {
   740→  collect_bazi_info,   // 收集出生信息
   741→  calculate_bazi,      // 排盘计算
   742→  show_bazi_chart,     // 展示命盘图
   743→  show_bazi_fortune,   // 展示运势分析
   744→  show_bazi_kline,     // 展示运势K线
   745→};
   746→```
   747→
   748→工具执行调用 Python 数据 API，结果返回前端渲染 Generative UI。
   749→
   750→## 文件结构
   751→
   752→```
   753→apps/api/
   754→├── routes/
   755→│   ├── chat_v5.py        # V5 Chat 端点 (CoreAgent 主入口)
   756→│   ├── context.py        # /context/build API
   757→│   ├── fortune.py        # 运势数据 API
   758→│   ├── report.py         # 报告 API
   759→│   └── relationship.py   # 关系分析 API
   760→├── services/
   761→│   ├── agent/            # CoreAgent 实现
   762→│   └── vibe_engine/
   763→│       ├── context.py    # ContextBuilder
   764→│       ├── tools.py      # 工具定义
   765→│       └── profile_cache.py
   766→
   767→apps/web/
   768→├── src/hooks/useVibeChat.ts   # AI SDK 6 集成 (相对路径)
   769→├── src/components/chat/       # Chat UI 组件
   770→└── next.config.js             # rewrites 代理配置
   771→```
   772→
   773→## 端点
   774→
   775→| 端点 | 说明 |
   776→|------|------|
   777→| `/api/v1/context/build` | Context 构建 API (核心) |
   778→| `/api/v1/context/messages/save` | 消息持久化 |
   779→| `/api/v1/context/quota/record` | 配额记录 |
   780→| `/api/v1/bazi/chart` | 八字命盘 API |
   781→| `/api/v1/zodiac/chart` | 星盘 API |
   782→| `/api/v1/zodiac/transit` | 行运分析 API |
   783→| `/api/v1/fortune/*` | 运势数据 API |
   784→| `/api/v1/report/*` | 报告 API |
   785→| `/api/v1/relationship/*` | 关系分析 API |
   786→
   787→## LLM 调用规范
   788→
   789→**前后端统一使用 `config/models.yaml` 作为唯一配置源**
   790→
   791→```
   792→config/models.yaml       ← 唯一配置源
   793→        │
   794→        ├─ Python: services/llm/client.py (LLMClient)
   795→        │
   796→        └─ Next.js: /context/build API 返回 llm_config
   797→           - provider: 提供商 (deepseek/glm/google/openai-compatible)
   798→           - model: 模型 ID
   799→           - base_url: deepseek/glm/openai-compatible 需要
   800→           - api_key: 从后端配置获取（前端无需 process.env）
   801→```
   802→
   803→**llm_config 结构**:
   804→```python
   805→class LLMConfig(BaseModel):
   806→    provider: str
   807→    model: str
   808→    base_url: Optional[str] = None
   809→    api_key: str  # 从后端配置获取
   810→```
   811→
   812→**Provider 映射规则**:
   813→| provider | 模型 ID 格式 | SDK | base_url | 测试状态 |
   814→|----------|-------------|-----|----------|----------|
   815→| deepseek | `deepseek-chat` (官方) | @ai-sdk/deepseek | 不需要 | ✅ 通过 |
   816→| glm | `glm-4.7` 等 | @ai-sdk/openai-compatible | 必需 | ✅ 通过 |
   817→| google | `gemini-xxx` | @ai-sdk/google | 不需要 | - |
   818→
   819→**关键发现**:
   820→- GLM 必须使用 `@ai-sdk/openai-compatible` 而不是 `@ai-sdk/openai`
   821→- 需要升级 `@ai-sdk/openai-compatible` 到 2.0.4（旧版本 0.2.16 不兼容 AI SDK 6）
   822→- DeepSeek 官方 API 使用 `@ai-sdk/deepseek`，火山引擎使用 `@ai-sdk/openai`
   823→
   824→**前端代码**:
   825→```typescript
   826→// API key 从后端 llm_config 获取，无需 process.env
   827→function getLLMModel(config: { provider: string; model: string; base_url?: string; api_key: string }) {
   828→  switch (config.provider) {
   829→    case 'deepseek':
   830→      // 官方 API 使用 @ai-sdk/deepseek
   831→      const isOfficialAPI = !config.base_url || config.base_url.includes('api.deepseek.com');
   832→      if (isOfficialAPI) {
   833→        return createDeepSeek({ apiKey: config.api_key })(config.model);
   834→      }
   835→      // 火山引擎等第三方使用 @ai-sdk/openai
   836→      return createOpenAI({ baseURL: config.base_url, apiKey: config.api_key })(config.model);
   837→    case 'glm':
   838→      // GLM 必须使用 @ai-sdk/openai-compatible
   839→      return createOpenAICompatible({
   840→        name: 'glm',
   841→        baseURL: config.base_url,
   842→        apiKey: config.api_key,
   843→      })(config.model);
   844→    case 'google':
   845→      return createGoogleGenerativeAI({ apiKey: config.api_key })(config.model);
   846→  }
   847→}
   848→```
   849→
   850→**优势**:
   851→- 修改 API key 只需重启后端，前端无需重启
   852→- 配置集中管理，避免前后端不一致
   853→- 支持运行时动态切换模型
   854→
   855→**禁止**:
   856→- 前端硬编码模型名称或 API 地址
   857→- 前端从 process.env 读取 API key（应从 llm_config 获取）
   858→
   859→## 数据流
   860→
   861→```
   862→用户输入 → useVibeChat → /api/v1/chat/v5/stream (相对路径)
   863→                              │
   864→                              ▼
   865→                         Next.js rewrites
   866→                              │
   867→                              ▼
   868→                    Python API /chat/v5/stream
   869→                              │
   870→                              ├─ [A] 入口配额检查
   871→                              │      → 配额不足返回 429
   872→                              │
   873→                              ├─ [B] CoreAgent 处理
   874→                              │      ├─ 构建 context (profile + skill_data)
   875→                              │      ├─ LLM 调用 (DeepSeek/GLM)
   876→                              │      ├─ Tool calling + 执行
   877→                              │      └─ 流式输出 SSE
   878→                              │
   879→                              └─ [C] 保存消息 + 记录配额
   880→                              │
   881→                              ▼
   882→                    SSE 响应 (AI SDK 6 Protocol)
   883→                              │
   884→                              ▼
   885→                    Next.js 转发 → Browser 渲染
   886→```
   887→
   888→## 可靠性设计
   889→
   890→### 入口配额检查
   891→- 在调用 LLM 前先检查配额，避免浪费资源
   892→- 配额不足返回 HTTP 429 + `QUOTA_EXCEEDED` 错误码
   893→
   894→### 消息保存重试
   895→- `onFinish` 回调中的保存操作带重试机制（最多 3 次）
   896→- 重试间隔：500ms → 1000ms → 1500ms
   897→- 用户消息、助手消息、配额记录并行保存
   898→
   899→## 与 AI SDK 6 集成
   900→
   901→| 效果 | 实现方式 |
   902→|------|---------|
   903→| 打字机效果 | `streamText` 原生支持 |
   904→| 工具调用 | `tool()` + `execute` |
   905→| Generative UI | 工具结果 + 前端组件 |
   906→| 多轮对话 | Context API 返回 messages |
   907→
   908→---
   909→
   910→## Skill 系统
   911→
   912→```
   913→apps/api/skills/
   914→├── core/     # 始终激活 - Vibe 人格
   915→├── bazi/     # 八字命理
   916→└── zodiac/   # 西方占星
   917→```
   918→
   919→Skill 内容通过 ContextBuilder 注入到 system_prompt。
   920→
   921→---
   922→
   923→## 对话引擎 (DialogueEngine)
   924→
   925→> 详细设计见: [dialogue-engine.md](./dialogue-engine.md)
   926→
   927→配置文件驱动的对话流程引擎，用于 Onboarding 等特殊场景。
   928→
   929→### 架构
   930→
   931→```
   932→apps/api/services/dialogue/
   933→├── engine.py              # 流程引擎核心
   934→├── rhythm.py              # 节奏控制
   935→├── extractors.py          # 信息提取器
   936→└── flows/
   937→    ├── onboarding.yaml    # 新用户引导
   938→    └── deep_talk.yaml     # 深度对话
   939→```
   940→
   941→### 步骤类型
   942→
   943→| 类型 | 说明 |
   944→|------|------|
   945→| `template` | 预写模板，支持变量插值 |
   946→| `generate` | 调用 LLM 生成 |
   947→| `extract` | 从用户输入提取信息 |
   948→| `tool` | 调用前端工具 (Generative UI) |
   949→| `action` | 执行后端动作 |
   950→
   951→---
   952→
   953→## 权益系统 (Entitlement)
   954→
   955→**配置文件**: `apps/api/services/entitlement/service.py`
   956→
   957→**单一配置源**:
   958→```python
   959→# SINGLE SOURCE OF TRUTH
   960→TIER_CONFIG = {
   961→    "free": {"daily_limit": 3},
   962→    "paid": {"daily_limit": 200},
   963→}
   964→DEFAULT_TIER = "paid"
   965→```
   966→
   967→**Tier 配置**:
   968→| Tier | 每日对话限制 | 说明 |
   969→|------|-------------|------|
   970→| free | 3 | 免费用户 |
   971→| paid | 200 | 付费用户 |
   972→
   973→**规范**:
   974→- 所有 tier 相关的值必须从 `TIER_CONFIG` 读取
   975→- 禁止在代码中硬编码 tier 名称或限制值
   976→- 新用户默认 tier 由 `DEFAULT_TIER` 控制
   977→- `upgrade_to_paid()` 和 `downgrade_to_free()` 从配置读取 limit
   978→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
