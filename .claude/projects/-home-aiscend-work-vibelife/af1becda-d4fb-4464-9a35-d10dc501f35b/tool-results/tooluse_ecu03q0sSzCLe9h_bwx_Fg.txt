     1→"""
     2→Context Builder - LLM context construction for chat
     3→Based on: vibelife spec v3.0, section 4.5
     4→
     5→Core Principle:
     6→"充分利用模型的上下文能力，减少系统复杂度。"
     7→
     8→- 不做对话摘要，直接使用原始对话
     9→- 不做过度压缩，保留信息丰富度
    10→- 根据话题动态选择 Profile 相关部分
    11→"""
    12→import json
    13→from typing import Optional, List, Dict, Any, Tuple
    14→from uuid import UUID
    15→from dataclasses import dataclass
    16→from enum import Enum
    17→import logging
    18→
    19→from .llm import LLMMessage, create_system_message, create_user_message, create_assistant_message
    20→
    21→logger = logging.getLogger(__name__)
    22→
    23→
    24→class VoiceMode(str, Enum):
    25→    """Vibe persona voice modes"""
    26→    WARM = "warm"       # 温暖模式：共情、支持、鼓励
    27→    SARCASTIC = "sarcastic"  # 吐槽模式：直接、犀利、有趣
    28→
    29→
    30→class Skill(str, Enum):
    31→    """Available skills"""
    32→    BAZI = "bazi"
    33→    ZODIAC = "zodiac"
    34→
    35→
    36→class Topic(str, Enum):
    37→    """Conversation topics for profile selection"""
    38→    CAREER = "career"
    39→    RELATIONSHIP = "relationship"
    40→    SELF = "self"
    41→    FORTUNE = "fortune"
    42→    GENERAL = "general"
    43→
    44→
    45→# ═══════════════════════════════════════════════════════════════════════════
    46→# System Prompts (按 spec 3.4 Persona 语言规范)
    47→# ═══════════════════════════════════════════════════════════════════════════
    48→
    49→VIBE_PERSONA_BASE = """# Vibe 人设
    50→
    51→你是 Vibe，用户的知己——懂命理、懂心理，更懂用户。
    52→你不是冰冷的分析师，是温暖的朋友。
    53→你不是预测命运的大师，是帮用户看见自己的镜子。
    54→
    55→## 核心原则
    56→- 用「你」而非「您」
    57→- 说「我感觉到」「我发现」而非「分析结果显示」
    58→- 说「你天生...」而非「根据八字理论」
    59→- 说「你更可能...」而非「你注定...」
    60→- 说「在这个阶段，适合...」而非「你一定会...」
    61→
    62→## 绝对禁止
    63→- 以恐惧驱动的句式
    64→- 具体事件预测（「你明年会结婚」）
    65→- 贩卖焦虑（「不买就错过窗口期」）
    66→- 宿命论（「这是命」）
    67→- 使用晦涩的专业术语而不解释
    68→"""
    69→
    70→WARM_MODE_SUFFIX = """
    71→## 当前语气：温暖模式
    72→- 共情、支持、鼓励
    73→- 用词：「我感觉到...」「你可能...」「值得尝试...」
    74→- 像一个温暖的朋友在聊天
    75→"""
    76→
    77→SARCASTIC_MODE_SUFFIX = """
    78→## 当前语气：吐槽模式
    79→- 直接、犀利、有趣
    80→- 用词：「得了吧」「说白了」「典型的...」
    81→- 像一个毒舌但真心的朋友在吐槽
    82→- 但吐槽背后是关心和真诚
    83→"""
    84→
    85→BAZI_SKILL_CONTEXT = """
    86→## 技能：八字命理
    87→
    88→你精通八字命理，能够：
    89→- 解读日主特质和命盘结构
    90→- 分析十神关系和格局
    91→- 解读大运流年影响
    92→- 提供基于命理的人生建议
    93→
    94→记住：
    95→- 用现代语言解释传统概念
    96→- 将命理洞察与用户实际生活结合
    97→- 强调「命理是镜子，不是牢笼」
    98→"""
    99→
   100→ZODIAC_SKILL_CONTEXT = """
   101→## 技能：星座占星
   102→
   103→你精通西方占星，能够：
   104→- 解读太阳/月亮/上升星座
   105→- 分析星盘宫位和行星相位
   106→- 解读当前天象和过境影响
   107→- 提供基于占星的人生建议
   108→
   109→记住：
   110→- 将星座特质与性格分析结合
   111→- 关注行星过境对当下的影响
   112→- 让占星成为自我认知的工具
   113→"""
   114→
   115→
   116→# ═══════════════════════════════════════════════════════════════════════════
   117→# Context Builder
   118→# ═══════════════════════════════════════════════════════════════════════════
   119→
   120→@dataclass
   121→class ContextConfig:
   122→    """Context building configuration"""
   123→    max_history_messages: int = 20  # 最多保留的历史消息数
   124→    max_profile_tokens: int = 1000  # Profile 部分最大 token 估算
   125→    max_knowledge_chunks: int = 3   # 最多检索的知识库条数
   126→    token_budget: int = 8000        # 总 token 预算
   127→
   128→
   129→class ContextBuilder:
   130→    """
   131→    Builds LLM context from multiple sources.
   132→
   133→    Context composition:
   134→    1. System Prompt (Persona + Voice Mode + Skill)
   135→    2. User Profile (topic-relevant sections)
   136→    3. Knowledge retrieval (if available)
   137→    4. Conversation history (raw, not summarized)
   138→    """
   139→
   140→    def __init__(self, config: Optional[ContextConfig] = None):
   141→        self.config = config or ContextConfig()
   142→
   143→    def build_system_prompt(
   144→        self,
   145→        skill: Skill,
   146→        voice_mode: VoiceMode = VoiceMode.WARM,
   147→        extra_context: Optional[str] = None
   148→    ) -> str:
   149→        """
   150→        Build system prompt with persona, skill, and voice mode.
   151→        """
   152→        parts = [VIBE_PERSONA_BASE]
   153→
   154→        # Add skill context
   155→        if skill == Skill.BAZI:
   156→            parts.append(BAZI_SKILL_CONTEXT)
   157→        elif skill == Skill.ZODIAC:
   158→            parts.append(ZODIAC_SKILL_CONTEXT)
   159→
   160→        # Add voice mode
   161→        if voice_mode == VoiceMode.WARM:
   162→            parts.append(WARM_MODE_SUFFIX)
   163→        elif voice_mode == VoiceMode.SARCASTIC:
   164→            parts.append(SARCASTIC_MODE_SUFFIX)
   165→
   166→        # Add extra context if provided
   167→        if extra_context:
   168→            parts.append(f"\n## 额外上下文\n{extra_context}")
   169→
   170→        return "\n".join(parts)
   171→
   172→    def classify_topic(self, message: str) -> Topic:
   173→        """
   174→        Classify the topic of user's message.
   175→        Used for selecting relevant profile sections.
   176→        """
   177→        message_lower = message.lower()
   178→
   179→        # Career keywords
   180→        career_keywords = [
   181→            "工作", "职业", "事业", "创业", "辞职", "跳槽", "升职",
   182→            "加薪", "同事", "老板", "面试", "求职", "转型", "发展"
   183→        ]
   184→        if any(kw in message_lower for kw in career_keywords):
   185→            return Topic.CAREER
   186→
   187→        # Relationship keywords
   188→        relationship_keywords = [
   189→            "感情", "爱情", "恋爱", "对象", "男友", "女友", "老公", "老婆",
   190→            "结婚", "离婚", "分手", "暧昧", "追", "喜欢", "爱", "情感",
   191→            "朋友", "家人", "父母", "孩子", "亲戚"
   192→        ]
   193→        if any(kw in message_lower for kw in relationship_keywords):
   194→            return Topic.RELATIONSHIP
   195→
   196→        # Fortune keywords
   197→        fortune_keywords = [
   198→            "运势", "运气", "大运", "流年", "今年", "明年", "最近",
   199→            "什么时候", "时机", "适合", "不顺", "倒霉", "顺利"
   200→        ]
   201→        if any(kw in message_lower for kw in fortune_keywords):
   202→            return Topic.FORTUNE
   203→
   204→        # Self keywords
   205→        self_keywords = [
   206→            "我是", "性格", "特点", "优点", "缺点", "适合",
   207→            "了解自己", "看看我", "分析我", "我这个人"
   208→        ]
   209→        if any(kw in message_lower for kw in self_keywords):
   210→            return Topic.SELF
   211→
   212→        return Topic.GENERAL
   213→
   214→    def select_profile_sections(
   215→        self,
   216→        profile: Dict[str, Any],
   217→        topic: Topic
   218→    ) -> Dict[str, Any]:
   219→        """
   220→        Select relevant profile sections based on topic.
   221→        Reduces context size while keeping relevant info.
   222→        """
   223→        selected = {}
   224→
   225→        # Always include basic info (if exists)
   226→        if "basic" in profile:
   227→            selected["basic"] = profile["basic"]
   228→
   229→        # Always include identity_prism (if exists)
   230→        if "identity_prism" in profile:
   231→            selected["identity_prism"] = profile["identity_prism"]
   232→
   233→        # Topic-specific selections
   234→        life_context = profile.get("life_context", {})
   235→        ai_insights = profile.get("ai_insights", {})
   236→
   237→        if topic == Topic.CAREER:
   238→            if "career" in life_context:
   239→                selected["career"] = life_context["career"]
   240→            if "growth_areas" in ai_insights:
   241→                selected["growth_areas"] = ai_insights["growth_areas"]
   242→
   243→        elif topic == Topic.RELATIONSHIP:
   244→            if "relationship" in life_context:
   245→                selected["relationship"] = life_context["relationship"]
   246→            if "relationship_patterns" in ai_insights:
   247→                selected["relationship_patterns"] = ai_insights["relationship_patterns"]
   248→            if "communication_style" in ai_insights:
   249→                selected["communication_style"] = ai_insights["communication_style"]
   250→
   251→        elif topic == Topic.FORTUNE:
   252→            if "current_focus" in life_context:
   253→                selected["current_focus"] = life_context["current_focus"]
   254→            if "recent_events" in life_context:
   255→                selected["recent_events"] = life_context["recent_events"]
   256→
   257→        elif topic == Topic.SELF:
   258→            # For self-understanding, include more AI insights
   259→            if ai_insights:
   260→                selected["ai_insights"] = ai_insights
   261→
   262→        else:  # GENERAL
   263→            # Include a summary of everything
   264→            if "current_focus" in life_context:
   265→                selected["current_focus"] = life_context["current_focus"]
   266→            if "personality_traits" in ai_insights:
   267→                selected["personality_traits"] = ai_insights["personality_traits"]
   268→
   269→        return selected
   270→
   271→    def format_profile_context(self, profile_sections: Dict[str, Any]) -> str:
   272→        """Format profile sections as context string"""
   273→        if not profile_sections:
   274→            return ""
   275→
   276→        lines = ["<user_profile>"]
   277→
   278→        for key, value in profile_sections.items():
   279→            if isinstance(value, dict):
   280→                lines.append(f"## {key}")
   281→                for k, v in value.items():
   282→                    if isinstance(v, list):
   283→                        lines.append(f"- {k}: {', '.join(str(x) for x in v)}")
   284→                    else:
   285→                        lines.append(f"- {k}: {v}")
   286→            elif isinstance(value, list):
   287→                lines.append(f"## {key}")
   288→                for item in value:
   289→                    if isinstance(item, dict):
   290→                        lines.append(f"- {json.dumps(item, ensure_ascii=False)}")
   291→                    else:
   292→                        lines.append(f"- {item}")
   293→            else:
   294→                lines.append(f"## {key}: {value}")
   295→
   296→        lines.append("</user_profile>")
   297→        return "\n".join(lines)
   298→
   299→    def format_knowledge_context(self, knowledge_chunks: List[Dict]) -> str:
   300→        """Format retrieved knowledge as context string"""
   301→        if not knowledge_chunks:
   302→            return ""
   303→
   304→        lines = ["<knowledge>"]
   305→        for chunk in knowledge_chunks:
   306→            content = chunk.get("content", "")
   307→            category = chunk.get("category", "")
   308→            if category:
   309→                lines.append(f"[{category}] {content}")
   310→            else:
   311→                lines.append(content)
   312→        lines.append("</knowledge>")
   313→
   314→        return "\n".join(lines)
   315→
   316→    def format_history(
   317→        self,
   318→        messages: List[Dict[str, str]],
   319→        max_messages: Optional[int] = None
   320→    ) -> List[LLMMessage]:
   321→        """
   322→        Format conversation history as LLM messages.
   323→        Uses raw messages without summarization.
   324→        """
   325→        max_messages = max_messages or self.config.max_history_messages
   326→
   327→        # Take most recent messages
   328→        recent = messages[-max_messages:] if len(messages) > max_messages else messages
   329→
   330→        formatted = []
   331→        for msg in recent:
   332→            role = msg.get("role", "user")
   333→            content = msg.get("content", "")
   334→
   335→            if role == "user":
   336→                formatted.append(create_user_message(content))
   337→            elif role == "assistant":
   338→                formatted.append(create_assistant_message(content))
   339→
   340→        return formatted
   341→
   342→    async def build(
   343→        self,
   344→        skill: Skill,
   345→        voice_mode: VoiceMode,
   346→        current_message: str,
   347→        profile: Optional[Dict[str, Any]] = None,
   348→        history: Optional[List[Dict[str, str]]] = None,
   349→        knowledge_chunks: Optional[List[Dict]] = None,
   350→        extra_context: Optional[str] = None
   351→    ) -> Tuple[str, List[LLMMessage]]:
   352→        """
   353→        Build complete context for LLM call.
   354→
   355→        Returns:
   356→            Tuple of (system_prompt, messages)
   357→        """
   358→        # 1. Build system prompt
   359→        system_prompt = self.build_system_prompt(skill, voice_mode, extra_context)
   360→
   361→        # 2. Classify topic and select relevant profile sections
   362→        topic = self.classify_topic(current_message)
   363→
   364→        context_parts = []
   365→
   366→        # 3. Add profile context
   367→        if profile:
   368→            profile_sections = self.select_profile_sections(profile, topic)
   369→            profile_context = self.format_profile_context(profile_sections)
   370→            if profile_context:
   371→                context_parts.append(profile_context)
   372→
   373→        # 4. Add knowledge context
   374→        if knowledge_chunks:
   375→            knowledge_context = self.format_knowledge_context(knowledge_chunks)
   376→            if knowledge_context:
   377→                context_parts.append(knowledge_context)
   378→
   379→        # 5. Append context to system prompt
   380→        if context_parts:
   381→            system_prompt = system_prompt + "\n\n" + "\n\n".join(context_parts)
   382→
   383→        # 6. Build message list
   384→        messages = [create_system_message(system_prompt)]
   385→
   386→        # 7. Add conversation history (raw)
   387→        if history:
   388→            history_messages = self.format_history(history)
   389→            messages.extend(history_messages)
   390→
   391→        # 8. Add current user message
   392→        messages.append(create_user_message(current_message))
   393→
   394→        return system_prompt, messages
   395→
   396→
   397→# ═══════════════════════════════════════════════════════════════════════════
   398→# Global Instance
   399→# ═══════════════════════════════════════════════════════════════════════════
   400→
   401→_context_builder: Optional[ContextBuilder] = None
   402→
   403→
   404→def get_context_builder() -> ContextBuilder:
   405→    """Get or create global context builder instance"""
   406→    global _context_builder
   407→    if _context_builder is None:
   408→        _context_builder = ContextBuilder()
   409→    return _context_builder
   410→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
