     1→"""
     2→Chat Routes - Conversation endpoints for VibeLife v3.0
     3→Based on: vibelife spec v3.0
     4→
     5→Features:
     6→- SSE streaming responses
     7→- Voice mode toggle (warm / sarcastic)
     8→- Skill-based conversations (bazi / zodiac)
     9→- Guest mode for demo
    10→- AI Interview endpoints
    11→- File upload + extraction
    12→"""
    13→import json
    14→from typing import Optional, List
    15→from uuid import UUID, uuid4
    16→
    17→from fastapi import APIRouter, HTTPException, Depends, Query, UploadFile, File
    18→from fastapi.responses import StreamingResponse
    19→from pydantic import BaseModel, Field
    20→from sse_starlette.sse import EventSourceResponse
    21→
    22→from services.identity import get_optional_user, CurrentUser
    23→from services.vibe_engine import (
    24→    get_llm_service,
    25→    get_context_builder,
    26→    get_portrait_service,
    27→    VoiceMode,
    28→    Skill,
    29→    create_user_message,
    30→)
    31→from services.interview import get_interview_service, InterviewSession
    32→from services.extraction import get_extraction_service
    33→from stores import conversation_repo, message_repo, profile_repo
    34→
    35→router = APIRouter(prefix="/chat", tags=["Chat"])
    36→
    37→
    38→# ═══════════════════════════════════════════════════════════════════════════
    39→# Request/Response Models
    40→# ═══════════════════════════════════════════════════════════════════════════
    41→
    42→class ChatRequest(BaseModel):
    43→    """Chat request model"""
    44→    message: str = Field(..., description="User message")
    45→    skill: str = Field(..., description="Skill: bazi or zodiac")
    46→    conversation_id: Optional[UUID] = Field(None, description="Existing conversation ID")
    47→    voice_mode: Optional[str] = Field("warm", description="Voice mode: warm or sarcastic")
    48→
    49→
    50→class ChatResponse(BaseModel):
    51→    """Chat response model (for non-streaming)"""
    52→    content: str
    53→    conversation_id: UUID
    54→    skill: str
    55→    voice_mode: str
    56→    metadata: Optional[dict] = None
    57→
    58→
    59→class GuestChatRequest(BaseModel):
    60→    """Guest chat request (no auth required)"""
    61→    message: str
    62→    skill: str = "bazi"
    63→
    64→
    65→# ═══════════════════════════════════════════════════════════════════════════
    66→# Helper Functions
    67→# ═══════════════════════════════════════════════════════════════════════════
    68→
    69→def parse_skill(skill_str: str) -> Skill:
    70→    """Parse skill string to enum"""
    71→    skill_lower = skill_str.lower()
    72→    if skill_lower in ("bazi", "八字"):
    73→        return Skill.BAZI
    74→    elif skill_lower in ("zodiac", "星座"):
    75→        return Skill.ZODIAC
    76→    else:
    77→        raise HTTPException(status_code=400, detail=f"Unknown skill: {skill_str}")
    78→
    79→
    80→def parse_voice_mode(mode_str: str) -> VoiceMode:
    81→    """Parse voice mode string to enum"""
    82→    mode_lower = mode_str.lower()
    83→    if mode_lower in ("warm", "温暖"):
    84→        return VoiceMode.WARM
    85→    elif mode_lower in ("sarcastic", "吐槽"):
    86→        return VoiceMode.SARCASTIC
    87→    else:
    88→        return VoiceMode.WARM  # Default
    89→
    90→
    91→async def get_user_profile(user_id: Optional[UUID]) -> dict:
    92→    """Get user profile from database"""
    93→    if user_id:
    94→        try:
    95→            profile_data = await profile_repo.get_profile_data(user_id)
    96→            return profile_data
    97→        except Exception:
    98→            pass
    99→
   100→    # Return default profile for guests
   101→    from services.vibe_engine import DEFAULT_PROFILE
   102→    return DEFAULT_PROFILE.copy()
   103→
   104→
   105→async def get_conversation_history(
   106→    conversation_id: Optional[UUID],
   107→    limit: int = 20
   108→) -> List[dict]:
   109→    """Get conversation history from database"""
   110→    if not conversation_id:
   111→        return []
   112→
   113→    try:
   114→        messages = await message_repo.get_messages_for_context(conversation_id, limit)
   115→        return messages
   116→    except Exception:
   117→        return []
   118→
   119→
   120→async def save_message(
   121→    conversation_id: UUID,
   122→    role: str,
   123→    content: str,
   124→    metadata: Optional[dict] = None
   125→) -> None:
   126→    """Save message to database"""
   127→    try:
   128→        await message_repo.create_message(
   129→            conversation_id=conversation_id,
   130→            role=role,
   131→            content=content,
   132→            metadata=metadata
   133→        )
   134→    except Exception as e:
   135→        # Log but don't fail the request
   136→        import logging
   137→        logging.warning(f"Failed to save message: {e}")
   138→
   139→
   140→# ═══════════════════════════════════════════════════════════════════════════
   141→# Endpoints
   142→# ═══════════════════════════════════════════════════════════════════════════
   143→
   144→@router.post("/stream")
   145→async def chat_stream(
   146→    request: ChatRequest,
   147→    current_user: Optional[CurrentUser] = Depends(get_optional_user)
   148→):
   149→    """
   150→    Send a message and get streaming response (SSE).
   151→
   152→    Returns Server-Sent Events with chunks of the response.
   153→    Final event contains [DONE] marker.
   154→    """
   155→    skill = parse_skill(request.skill)
   156→    voice_mode = parse_voice_mode(request.voice_mode or "warm")
   157→
   158→    # Get or create conversation
   159→    conversation_id = request.conversation_id or uuid4()
   160→
   161→    # Get user ID if authenticated
   162→    user_id = current_user.user_id if current_user else None
   163→
   164→    # Get services
   165→    llm = get_llm_service()
   166→    context_builder = get_context_builder()
   167→
   168→    async def generate():
   169→        try:
   170→            # Get user profile (for logged-in users)
   171→            profile = await get_user_profile(user_id)
   172→
   173→            # Get conversation history
   174→            history = await get_conversation_history(conversation_id)
   175→
   176→            # Build context
   177→            system_prompt, messages = await context_builder.build(
   178→                skill=skill,
   179→                voice_mode=voice_mode,
   180→                current_message=request.message,
   181→                profile=profile,
   182→                history=history
   183→            )
   184→
   185→            # Save user message
   186→            await save_message(conversation_id, "user", request.message)
   187→
   188→            # Stream response
   189→            full_content = ""
   190→            async for chunk in llm.stream(messages):
   191→                full_content += chunk
   192→                # Send chunk as SSE event
   193→                yield {
   194→                    "event": "message",
   195→                    "data": json.dumps({
   196→                        "type": "chunk",
   197→                        "content": chunk
   198→                    })
   199→                }
   200→
   201→            # Save assistant message
   202→            await save_message(conversation_id, "assistant", full_content)
   203→
   204→            # Send completion event
   205→            yield {
   206→                "event": "message",
   207→                "data": json.dumps({
   208→                    "type": "done",
   209→                    "conversation_id": str(conversation_id),
   210→                    "skill": skill.value,
   211→                    "voice_mode": voice_mode.value
   212→                })
   213→            }
   214→
   215→        except Exception as e:
   216→            yield {
   217→                "event": "error",
   218→                "data": json.dumps({
   219→                    "type": "error",
   220→                    "message": str(e)
   221→                })
   222→            }
   223→
   224→    return EventSourceResponse(generate())
   225→
   226→
   227→@router.post("/", response_model=ChatResponse)
   228→async def chat(
   229→    request: ChatRequest,
   230→    current_user: Optional[CurrentUser] = Depends(get_optional_user)
   231→):
   232→    """
   233→    Send a message and get non-streaming response.
   234→    For clients that don't support SSE.
   235→    """
   236→    skill = parse_skill(request.skill)
   237→    voice_mode = parse_voice_mode(request.voice_mode or "warm")
   238→
   239→    # Get or create conversation
   240→    conversation_id = request.conversation_id or uuid4()
   241→
   242→    # Get user ID if authenticated
   243→    user_id = current_user.user_id if current_user else None
   244→
   245→    # Get services
   246→    llm = get_llm_service()
   247→    context_builder = get_context_builder()
   248→
   249→    try:
   250→        # Get user profile
   251→        profile = await get_user_profile(user_id)
   252→
   253→        # Get conversation history
   254→        history = await get_conversation_history(conversation_id)
   255→
   256→        # Build context
   257→        system_prompt, messages = await context_builder.build(
   258→            skill=skill,
   259→            voice_mode=voice_mode,
   260→            current_message=request.message,
   261→            profile=profile,
   262→            history=history
   263→        )
   264→
   265→        # Save user message
   266→        await save_message(conversation_id, "user", request.message)
   267→
   268→        # Get response
   269→        response = await llm.chat(messages)
   270→
   271→        # Save assistant message
   272→        await save_message(conversation_id, "assistant", response.content)
   273→
   274→        return ChatResponse(
   275→            content=response.content,
   276→            conversation_id=conversation_id,
   277→            skill=skill.value,
   278→            voice_mode=voice_mode.value,
   279→            metadata={
   280→                "model": response.model,
   281→                "usage": response.usage
   282→            }
   283→        )
   284→
   285→    except Exception as e:
   286→        raise HTTPException(status_code=500, detail=str(e))
   287→
   288→
   289→@router.post("/guest")
   290→async def chat_guest(request: GuestChatRequest):
   291→    """
   292→    Guest chat endpoint (no authentication required).
   293→    For landing page demo with limited functionality.
   294→    """
   295→    skill = parse_skill(request.skill)
   296→
   297→    llm = get_llm_service()
   298→    context_builder = get_context_builder()
   299→
   300→    try:
   301→        # Build simple context (no profile, no history)
   302→        system_prompt, messages = await context_builder.build(
   303→            skill=skill,
   304→            voice_mode=VoiceMode.WARM,
   305→            current_message=request.message,
   306→            profile=None,
   307→            history=None
   308→        )
   309→
   310→        # Get response (limited tokens for guest)
   311→        response = await llm.chat(messages, max_tokens=1024)
   312→
   313→        return {
   314→            "content": response.content,
   315→            "is_guest": True,
   316→            "skill": skill.value,
   317→            "suggestion": "注册后可以获得完整的个性化分析和对话历史保存"
   318→        }
   319→
   320→    except Exception as e:
   321→        raise HTTPException(status_code=500, detail=str(e))
   322→
   323→
   324→@router.post("/guest/stream")
   325→async def chat_guest_stream(request: GuestChatRequest):
   326→    """
   327→    Guest streaming chat endpoint.
   328→    For landing page demo with SSE.
   329→    """
   330→    skill = parse_skill(request.skill)
   331→
   332→    llm = get_llm_service()
   333→    context_builder = get_context_builder()
   334→
   335→    async def generate():
   336→        try:
   337→            # Build simple context
   338→            system_prompt, messages = await context_builder.build(
   339→                skill=skill,
   340→                voice_mode=VoiceMode.WARM,
   341→                current_message=request.message,
   342→                profile=None,
   343→                history=None
   344→            )
   345→
   346→            # Stream response
   347→            async for chunk in llm.stream(messages, max_tokens=1024):
   348→                yield {
   349→                    "event": "message",
   350→                    "data": json.dumps({
   351→                        "type": "chunk",
   352→                        "content": chunk
   353→                    })
   354→                }
   355→
   356→            yield {
   357→                "event": "message",
   358→                "data": json.dumps({
   359→                    "type": "done",
   360→                    "is_guest": True,
   361→                    "skill": skill.value
   362→                })
   363→            }
   364→
   365→        except Exception as e:
   366→            yield {
   367→                "event": "error",
   368→                "data": json.dumps({
   369→                    "type": "error",
   370→                    "message": str(e)
   371→                })
   372→            }
   373→
   374→    return EventSourceResponse(generate())
   375→
   376→
   377→# ═══════════════════════════════════════════════════════════════════════════
   378→# Voice Mode Toggle
   379→# ═══════════════════════════════════════════════════════════════════════════
   380→
   381→class VoiceModeRequest(BaseModel):
   382→    """Voice mode toggle request"""
   383→    conversation_id: UUID
   384→    voice_mode: str  # warm | sarcastic
   385→
   386→
   387→@router.post("/voice-mode")
   388→async def toggle_voice_mode(request: VoiceModeRequest):
   389→    """
   390→    Toggle voice mode for a conversation.
   391→    Changes Vibe's personality between warm and sarcastic.
   392→    """
   393→    voice_mode = parse_voice_mode(request.voice_mode)
   394→
   395→    # TODO: Update conversation voice_mode in database
   396→
   397→    return {
   398→        "success": True,
   399→        "conversation_id": str(request.conversation_id),
   400→        "voice_mode": voice_mode.value,
   401→        "message": "语气已切换" if voice_mode == VoiceMode.SARCASTIC else "已切换到温暖模式"
   402→    }
   403→
   404→
   405→# ═══════════════════════════════════════════════════════════════════════════
   406→# Conversation Management
   407→# ═══════════════════════════════════════════════════════════════════════════
   408→
   409→@router.get("/conversations")
   410→async def list_conversations(
   411→    skill: Optional[str] = None,
   412→    limit: int = Query(20, ge=1, le=100)
   413→):
   414→    """
   415→    List user's conversations.
   416→    TODO: Implement with authentication.
   417→    """
   418→    # TODO: Implement with actual database query
   419→    return {
   420→        "conversations": [],
   421→        "total": 0
   422→    }
   423→
   424→
   425→@router.get("/conversations/{conversation_id}")
   426→async def get_conversation(conversation_id: UUID):
   427→    """
   428→    Get conversation details with messages.
   429→    """
   430→    # TODO: Implement with actual database query
   431→    return {
   432→        "id": str(conversation_id),
   433→        "messages": [],
   434→        "skill": None,
   435→        "voice_mode": "warm",
   436→        "created_at": None
   437→    }
   438→
   439→
   440→@router.delete("/conversations/{conversation_id}")
   441→async def delete_conversation(conversation_id: UUID):
   442→    """
   443→    Delete a conversation.
   444→    """
   445→    try:
   446→        await conversation_repo.delete_conversation(conversation_id)
   447→        return {"success": True, "message": "Conversation deleted"}
   448→    except Exception as e:
   449→        raise HTTPException(status_code=500, detail=str(e))
   450→
   451→
   452→# ═══════════════════════════════════════════════════════════════════════════
   453→# Interview Endpoints
   454→# ═══════════════════════════════════════════════════════════════════════════
   455→
   456→class InterviewStartRequest(BaseModel):
   457→    """Start interview request"""
   458→    skill: str = "bazi"
   459→    user_id: Optional[UUID] = None
   460→
   461→
   462→class InterviewAnswerRequest(BaseModel):
   463→    """Submit answer request"""
   464→    session_id: UUID
   465→    answer: str
   466→
   467→
   468→@router.post("/interview/start")
   469→async def start_interview(request: InterviewStartRequest):
   470→    """
   471→    Start an AI interview session.
   472→    Required before generating reports.
   473→    """
   474→    interview_service = get_interview_service()
   475→
   476→    session = interview_service.start_session(
   477→        skill=request.skill,
   478→        user_id=request.user_id
   479→    )
   480→
   481→    current_question = interview_service.get_current_question(session)
   482→
   483→    return {
   484→        "session": session.to_dict(),
   485→        "intro": interview_service.get_intro(),
   486→        "current_question": {
   487→            "id": current_question.id,
   488→            "text": current_question.question_text,
   489→            "type": current_question.question_type
   490→        } if current_question else None,
   491→        "progress": interview_service.get_progress(session)
   492→    }
   493→
   494→
   495→@router.post("/interview/answer")
   496→async def submit_interview_answer(request: InterviewAnswerRequest):
   497→    """
   498→    Submit an answer to the current interview question.
   499→    """
   500→    interview_service = get_interview_service()
   501→
   502→    session = interview_service.get_session(request.session_id)
   503→    if not session:
   504→        raise HTTPException(status_code=404, detail="Session not found")
   505→
   506→    next_question, is_complete = await interview_service.submit_answer(
   507→        session,
   508→        request.answer
   509→    )
   510→
   511→    response = {
   512→        "is_complete": is_complete,
   513→        "next_question": None,
   514→        "progress": interview_service.get_progress(session),
   515→        "result": None
   516→    }
   517→
   518→    if is_complete:
   519→        result = interview_service.get_result(session)
   520→        response["result"] = {
   521→            "success": result.success,
   522→            "extracted_profile": result.extracted_profile,
   523→            "summary": result.summary,
   524→            "questions_answered": result.questions_answered,
   525→            "total_questions": result.total_questions
   526→        }
   527→    elif next_question:
   528→        response["next_question"] = {
   529→            "id": next_question.id,
   530→            "text": next_question.question_text,
   531→            "type": next_question.question_type
   532→        }
   533→
   534→    return response
   535→
   536→
   537→@router.post("/interview/skip")
   538→async def skip_interview(session_id: UUID):
   539→    """
   540→    Skip the interview (user choice).
   541→    """
   542→    interview_service = get_interview_service()
   543→
   544→    session = interview_service.get_session(session_id)
   545→    if not session:
   546→        raise HTTPException(status_code=404, detail="Session not found")
   547→
   548→    warning = interview_service.skip_session(session)
   549→    result = interview_service.get_result(session)
   550→
   551→    return {
   552→        "warning": warning,
   553→        "result": {
   554→            "success": result.success,
   555→            "extracted_profile": result.extracted_profile,
   556→            "summary": result.summary,
   557→            "questions_answered": result.questions_answered,
   558→            "total_questions": result.total_questions
   559→        }
   560→    }
   561→
   562→
   563→@router.get("/interview/{session_id}")
   564→async def get_interview_session(session_id: UUID):
   565→    """
   566→    Get interview session status.
   567→    """
   568→    interview_service = get_interview_service()
   569→
   570→    session = interview_service.get_session(session_id)
   571→    if not session:
   572→        raise HTTPException(status_code=404, detail="Session not found")
   573→
   574→    current_question = interview_service.get_current_question(session)
   575→
   576→    return {
   577→        "session": session.to_dict(),
   578→        "current_question": {
   579→            "id": current_question.id,
   580→            "text": current_question.question_text,
   581→            "type": current_question.question_type
   582→        } if current_question else None,
   583→        "progress": interview_service.get_progress(session)
   584→    }
   585→
   586→
   587→# ═══════════════════════════════════════════════════════════════════════════
   588→# File Upload Endpoints
   589→# ═══════════════════════════════════════════════════════════════════════════
   590→
   591→@router.post("/upload")
   592→async def upload_file(
   593→    file: UploadFile = File(...),
   594→    context_hint: Optional[str] = None
   595→):
   596→    """
   597→    Upload a file for AI extraction.
   598→
   599→    Supported formats:
   600→    - Images (JPG, PNG): Screenshots from other apps, chat records
   601→    - Documents (PDF, DOCX, TXT): Resumes, diaries
   602→
   603→    Returns extracted information that can be merged into user profile.
   604→    """
   605→    # Read file data
   606→    file_data = await file.read()
   607→
   608→    # Check file size (10MB limit)
   609→    if len(file_data) > 10 * 1024 * 1024:
   610→        raise HTTPException(status_code=413, detail="文件过大，最大支持 10MB")
   611→
   612→    # Extract information
   613→    extraction_service = get_extraction_service()
   614→
   615→    result = await extraction_service.extract_from_file(
   616→        file_data=file_data,
   617→        filename=file.filename or "unknown",
   618→        mime_type=file.content_type,
   619→        context_hint=context_hint
   620→    )
   621→
   622→    return {
   623→        "success": result.success,
   624→        "file_type": result.file_type,
   625→        "content_type": result.content_type,
   626→        "summary": result.summary,
   627→        "confidence": result.confidence,
   628→        "extracted_data": result.extracted_data,
   629→        "profile_updates": result.profile_updates,
   630→        "error": result.error
   631→    }
   632→
   633→
   634→@router.post("/upload/batch")
   635→async def upload_files_batch(
   636→    files: List[UploadFile] = File(...)
   637→):
   638→    """
   639→    Upload multiple files for batch extraction.
   640→    """
   641→    if len(files) > 5:
   642→        raise HTTPException(status_code=400, detail="最多同时上传 5 个文件")
   643→
   644→    extraction_service = get_extraction_service()
   645→    results = []
   646→
   647→    for file in files:
   648→        file_data = await file.read()
   649→
   650→        if len(file_data) > 10 * 1024 * 1024:
   651→            results.append({
   652→                "filename": file.filename,
   653→                "success": False,
   654→                "error": "文件过大"
   655→            })
   656→            continue
   657→
   658→        result = await extraction_service.extract_from_file(
   659→            file_data=file_data,
   660→            filename=file.filename or "unknown",
   661→            mime_type=file.content_type
   662→        )
   663→
   664→        results.append({
   665→            "filename": file.filename,
   666→            "success": result.success,
   667→            "content_type": result.content_type,
   668→            "summary": result.summary,
   669→            "error": result.error
   670→        })
   671→
   672→    return {
   673→        "total": len(files),
   674→        "successful": sum(1 for r in results if r["success"]),
   675→        "results": results
   676→    }
   677→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
