     1→# VibeLife LLM 模型配置文件 - 唯一配置源 (Single Source of Truth)
     2→# 所有 LLM 相关配置都从此文件读取
     3→# 支持环境变量替换: ${VAR_NAME:default_value}
     4→#
     5→# 使用方法:
     6→#   from services.llm.config import LLMConfig
     7→#   provider = LLMConfig.get_provider("deepseek")
     8→#   selection = LLMConfig.resolve(user_tier="paid", task="chat")
     9→#
    10→# 验证配置:
    11→#   python scripts/validate_llm_config.py
    12→
    13→# ============================================================
    14→# LLM 环境变量映射 (每次调用时自动同步)
    15→# ============================================================
    16→env_mapping:
    17→  # 格式: yaml_key: actual_env_var
    18→  GLM_API_KEY: ZAI_GLM_KEY
    19→  CLAUDE_API_KEY: CC_API_KEY
    20→  # DEEPSEEK_API_KEY 直接使用，无需映射
    21→
    22→# ============================================================
    23→# 模型提供商配置
    24→# ============================================================
    25→providers:
    26→  deepseek:
    27→    name: "DeepSeek V3 (Anthropic 兼容)"
    28→    base_url: "${DEEPSEEK_BASE_URL:https://api.deepseek.com/anthropic}"
    29→    api_key_env: "DEEPSEEK_API_KEY"
    30→    api_protocol: "anthropic"
    31→    test_endpoint: "/messages"
    32→    enabled: true
    33→    timeout: 120
    34→
    35→  glm:
    36→    name: "智谱 GLM (Anthropic 兼容)"
    37→    base_url: "${GLM_BASE_URL:https://open.bigmodel.cn/api/anthropic/v1}"
    38→    api_key_env: "GLM_API_KEY"
    39→    api_protocol: "anthropic"
    40→    test_endpoint: "/messages"
    41→    enabled: true
    42→    timeout: 120
    43→    # OpenAI 兼容端点 (备用)
    44→    openai_base_url: "https://open.bigmodel.cn/api/paas/v4"
    45→
    46→  claude:
    47→    name: "Claude (代理)"
    48→    base_url: "${CLAUDE_BASE_URL:https://www.zz166.cn/api/v1}"
    49→    api_key_env: "CLAUDE_API_KEY"
    50→    api_protocol: "anthropic"
    51→    test_endpoint: "/messages"
    52→    enabled: true
    53→    timeout: 180
    54→
    55→  gemini:
    56→    name: "Google Gemini (代理)"
    57→    base_url: "${GEMINI_BASE_URL:https://new.12ai.org/v1}"
    58→    api_key_env: "GEMINI_API_KEY"
    59→    api_protocol: "openai"
    60→    test_endpoint: "/chat/completions"
    61→    backup_urls:
    62→      - "https://hk.12ai.org/v1"
    63→      - "https://cdn.12ai.org/v1"
    64→    backup_key_env: "GEMINI_BACKUP_KEY"
    65→    enabled: true
    66→    timeout: 60
    67→
    68→# ============================================================
    69→# 模型定义
    70→# ============================================================
    71→models:
    72→  # ----- DeepSeek 系列 (Primary) -----
    73→  deepseek-v3:
    74→    provider: deepseek
    75→    model_name: "deepseek-chat"
    76→    capabilities: [chat, analysis, tools]
    77→    tier: standard
    78→    description: "DeepSeek V3，强大的推理和工具调用能力"
    79→
    80→  deepseek-reasoner:
    81→    provider: deepseek
    82→    model_name: "deepseek-reasoner"
    83→    capabilities: [chat, analysis, reasoning]
    84→    tier: premium
    85→    description: "DeepSeek Reasoner，深度推理模型"
    86→
    87→  # ----- GLM 系列 (Fallback 1) -----
    88→  glm-4.7:
    89→    provider: glm
    90→    model_name: "${GLM_CHAT_MODEL:glm-4.7}"
    91→    capabilities: [chat, analysis, tools]
    92→    tier: standard
    93→    description: "GLM 主力模型，支持深度分析和工具调用"
    94→
    95→  glm-4v-plus:
    96→    provider: glm
    97→    model_name: "glm-4v-plus"
    98→    capabilities: [chat, vision]
    99→    tier: premium
   100→    description: "GLM 视觉模型"
   101→
   102→  # ----- Claude 系列 (Fallback 2) -----
   103→  claude-opus:
   104→    provider: claude
   105→    model_name: "${CLAUDE_MODEL:claude-opus-4-5-20251101}"
   106→    capabilities: [chat, analysis, tools]
   107→    tier: premium
   108→    description: "Claude Opus 4.5，最强大的推理和工具调用能力"
   109→
   110→  claude-sonnet:
   111→    provider: claude
   112→    model_name: "claude-sonnet-4-20250514"
   113→    capabilities: [chat, analysis, tools]
   114→    tier: standard
   115→    description: "Claude Sonnet 4，平衡性能与成本"
   116→
   117→  # ----- Gemini 系列 (图像专用) -----
   118→  gemini-flash:
   119→    provider: gemini
   120→    model_name: "${GEMINI_CHAT_MODEL:gemini-2.5-flash}"
   121→    capabilities: [chat, analysis]
   122→    tier: standard
   123→    description: "Gemini Flash，快速响应"
   124→
   125→  gemini-image:
   126→    provider: gemini
   127→    model_name: "${GEMINI_IMAGE_MODEL:gemini-2.5-flash-image}"
   128→    capabilities: [image_gen]
   129→    tier: premium
   130→    description: "Gemini 图像生成模型"
   131→
   132→# ============================================================
   133→# 默认路由配置 (统一顺序: deepseek → glm → opus)
   134→# ============================================================
   135→defaults:
   136→  chat:
   137→    primary: deepseek-v3
   138→    fallback: [glm-4.7, claude-opus]
   139→
   140→  analysis:
   141→    primary: deepseek-v3
   142→    fallback: [glm-4.7, claude-opus]
   143→
   144→  tools:
   145→    primary: deepseek-v3
   146→    fallback: [glm-4.7, claude-opus]
   147→
   148→  vision:
   149→    primary: glm-4v-plus
   150→    fallback: []
   151→
   152→  image_gen:
   153→    primary: gemini-image
   154→    fallback: []
   155→
   156→# ============================================================
   157→# 全局兜底模型
   158→# ============================================================
   159→global_fallback: glm-4.7
   160→
   161→# ============================================================
   162→# Fallback 触发条件配置
   163→# ============================================================
   164→fallback_triggers:
   165→  on_api_error: true
   166→  on_quota_exceeded: true
   167→  timeout: 180
   168→  max_retries: 2
   169→
   170→# ============================================================
   171→# 用户层级路由覆盖 (所有层级统一顺序)
   172→# ============================================================
   173→tier_overrides:
   174→  # 所有用户统一使用相同的模型顺序
   175→  paid:
   176→    chat:
   177→      primary: deepseek-v3
   178→      fallback: [glm-4.7, claude-opus]
   179→  free:
   180→    chat:
   181→      primary: deepseek-v3
   182→      fallback: [glm-4.7, claude-opus]
   183→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
