     1→"""
     2→Profile Extractor Worker - 从用户交互中抽取信息更新 Profile
     3→
     4→极简设计：
     5→- 单一抽取入口，替代 daily_extraction + portrait_service + insight_generator
     6→- 定时运行（每日），增量处理新消息
     7→- 输出结构化 JSON，写入 unified_profiles.profile.extracted
     8→"""
     9→import asyncio
    10→import json
    11→import logging
    12→import re
    13→from datetime import datetime, timedelta
    14→from typing import List, Dict, Any, Optional
    15→from uuid import UUID
    16→
    17→from stores.db import fetch, fetchrow
    18→from stores.unified_profile_repo import UnifiedProfileRepository, ColdLayerRepository
    19→from services.model_router.client import chat
    20→
    21→logger = logging.getLogger(__name__)
    22→
    23→# 抽取 Prompt
    24→EXTRACTION_PROMPT = """你是一个用户画像分析专家。分析用户的对话记录，提取关键信息。
    25→
    26→## 抽取规则
    27→
    28→1. **事实信息 (facts)**: 用户明确陈述的客观事实
    29→   - 姓名、职业、居住地
    30→   - 宠物、家人、朋友
    31→   - 重要经历
    32→
    33→2. **关注领域 (concerns)**: 用户反复提及或询问的话题
    34→   - 最多保留 5 个
    35→   - 按重要性排序
    36→
    37→3. **目标愿望 (goals)**: 用户表达的期望或计划
    38→   - 只记录明确表达的
    39→   - 不要推测
    40→
    41→4. **困难痛点 (pain_points)**: 用户抱怨或求助的问题
    42→   - 只记录当前有效的
    43→   - 过期的不要记录
    44→
    45→5. **生活事件 (life_events)**: 重要的人生节点
    46→   - 记录日期（如果提及）和事件
    47→   - 最多保留 5 个最近的
    48→
    49→6. **行为模式 (patterns)**: 从交互中观察到的规律
    50→   - 偏好的话题
    51→   - 对话风格
    52→
    53→## 输出格式
    54→
    55→返回 JSON，只包含从对话中明确提取到的信息：
    56→```json
    57→{
    58→  "facts": {"name": "...", "occupation": "...", "location": "...", "pets": [...], "relationships": [...]},
    59→  "concerns": ["..."],
    60→  "goals": ["..."],
    61→  "pain_points": ["..."],
    62→  "life_events": [{"date": "2024-01", "event": "..."}],
    63→  "patterns": {"preferred_topics": [...], "conversation_style": "..."}
    64→}
    65→```
    66→
    67→如果某个字段没有提取到信息，不要包含该字段。
    68→如果完全没有新信息，返回空对象 {}"""
    69→
    70→
    71→async def get_active_users(days: int = 7) -> List[UUID]:
    72→    """获取最近活跃的用户"""
    73→    query = """
    74→        SELECT DISTINCT c.user_id FROM conversations c
    75→        WHERE c.user_id IS NOT NULL
    76→        AND c.updated_at > NOW() - INTERVAL '%s days'
    77→    """
    78→    rows = await fetch(query, days)
    79→    return [row["user_id"] for row in rows]
    80→
    81→
    82→async def get_user_messages_since(
    83→    user_id: UUID,
    84→    since: Optional[datetime] = None,
    85→    limit: int = 100
    86→) -> List[Dict[str, Any]]:
    87→    """获取用户自指定时间以来的消息"""
    88→    if since is None:
    89→        since = datetime.now() - timedelta(days=30)
    90→
    91→    query = """
    92→        SELECT m.role, m.content, m.created_at
    93→        FROM messages m
    94→        JOIN conversations c ON m.conversation_id = c.id
    95→        WHERE c.user_id = $1 AND m.created_at > $2
    96→        ORDER BY m.created_at ASC
    97→        LIMIT $3
    98→    """
    99→    rows = await fetch(query, user_id, since, limit)
   100→    return [dict(row) for row in rows]
   101→
   102→
   103→async def _write_to_cold_layer(user_id: UUID, extracted: Dict[str, Any]) -> None:
   104→    """
   105→    将重要洞察和事件写入 Cold Layer
   106→
   107→    - life_events → vibe_profile_timeline
   108→    - patterns (重要发现) → vibe_profile_insights
   109→    """
   110→    if not extracted:
   111→        return
   112→
   113→    # 写入生活事件到时间线
   114→    life_events = extracted.get("life_events", [])
   115→    for event in life_events:
   116→        event_text = event.get("event", "")
   117→        event_date_str = event.get("date", "")
   118→
   119→        if event_text and event_date_str:
   120→            try:
   121→                # 解析日期 (支持 YYYY-MM 或 YYYY-MM-DD 格式)
   122→                if len(event_date_str) == 7:  # YYYY-MM
   123→                    event_date = datetime.strptime(event_date_str, "%Y-%m").date()
   124→                else:
   125→                    event_date = datetime.strptime(event_date_str[:10], "%Y-%m-%d").date()
   126→
   127→                await ColdLayerRepository.add_timeline_event(
   128→                    user_id=user_id,
   129→                    event_type="life_event",
   130→                    event_date=event_date,
   131→                    title=event_text[:200],
   132→                    data=event
   133→                )
   134→                logger.debug(f"Added timeline event for user {user_id}: {event_text[:50]}")
   135→            except Exception as e:
   136→                logger.warning(f"Failed to add timeline event: {e}")
   137→
   138→    # 写入重要模式到洞察
   139→    patterns = extracted.get("patterns", {})
   140→    if patterns:
   141→        # 从模式中提取重要发现
   142→        conversation_style = patterns.get("conversation_style")
   143→        if conversation_style and len(conversation_style) > 20:
   144→            try:
   145→                await ColdLayerRepository.add_insight(
   146→                    user_id=user_id,
   147→                    insight_type="pattern",
   148→                    content=f"对话风格: {conversation_style}",
   149→                    metadata={"source": "profile_extraction", "patterns": patterns}
   150→                )
   151→                logger.debug(f"Added pattern insight for user {user_id}")
   152→            except Exception as e:
   153→                logger.warning(f"Failed to add insight: {e}")
   154→
   155→
   156→def merge_extracted(current: Dict[str, Any], new: Dict[str, Any]) -> Dict[str, Any]:
   157→    """合并抽取结果"""
   158→    if not new:
   159→        return current
   160→
   161→    result = current.copy() if current else {}
   162→
   163→    # facts: 深度合并
   164→    if "facts" in new:
   165→        current_facts = result.get("facts", {})
   166→        for key, value in new["facts"].items():
   167→            if value:  # 只更新非空值
   168→                if isinstance(value, list) and isinstance(current_facts.get(key), list):
   169→                    # 列表合并去重
   170→                    combined = current_facts.get(key, []) + value
   171→                    current_facts[key] = list(dict.fromkeys(combined))[:10]
   172→                else:
   173→                    current_facts[key] = value
   174→        result["facts"] = current_facts
   175→
   176→    # 列表字段: 合并去重，保留最新 N 个
   177→    for field, limit in [("concerns", 5), ("goals", 5), ("pain_points", 5)]:
   178→        if field in new and new[field]:
   179→            current_list = result.get(field, [])
   180→            combined = new[field] + current_list  # 新的在前
   181→            result[field] = list(dict.fromkeys(combined))[:limit]
   182→
   183→    # life_events: 追加，按时间排序
   184→    if "life_events" in new and new["life_events"]:
   185→        current_events = result.get("life_events", [])
   186→        all_events = new["life_events"] + current_events
   187→
   188→        # 去重 by event
   189→        seen = set()
   190→        unique = []
   191→        for e in all_events:
   192→            event_key = e.get("event", "")
   193→            if event_key and event_key not in seen:
   194→                seen.add(event_key)
   195→                unique.append(e)
   196→
   197→        # 按日期排序，保留最新 10 个
   198→        result["life_events"] = sorted(
   199→            unique,
   200→            key=lambda x: x.get("date", ""),
   201→            reverse=True
   202→        )[:10]
   203→
   204→    # patterns: 合并
   205→    if "patterns" in new and new["patterns"]:
   206→        current_patterns = result.get("patterns", {})
   207→        for key, value in new["patterns"].items():
   208→            if value:
   209→                if isinstance(value, list) and isinstance(current_patterns.get(key), list):
   210→                    combined = value + current_patterns.get(key, [])
   211→                    current_patterns[key] = list(dict.fromkeys(combined))[:10]
   212→                else:
   213→                    current_patterns[key] = value
   214→        result["patterns"] = current_patterns
   215→
   216→    return result
   217→
   218→
   219→async def extract_user_profile(user_id: UUID) -> Dict[str, Any]:
   220→    """为单个用户抽取 Profile"""
   221→    logger.info(f"Extracting profile for user {user_id}")
   222→
   223→    # 1. 获取现有 extracted 数据
   224→    current_extracted = await UnifiedProfileRepository.get_extracted(user_id)
   225→    last_extracted_at = current_extracted.get("last_extracted_at") if current_extracted else None
   226→
   227→    # 2. 确定抽取起始时间
   228→    if last_extracted_at:
   229→        try:
   230→            since = datetime.fromisoformat(last_extracted_at.replace("Z", "+00:00"))
   231→        except (ValueError, AttributeError):
   232→            since = datetime.now() - timedelta(days=7)
   233→    else:
   234→        since = datetime.now() - timedelta(days=30)  # 首次抽取，取最近 30 天
   235→
   236→    # 3. 获取新消息
   237→    messages = await get_user_messages_since(user_id, since, limit=100)
   238→
   239→    if not messages:
   240→        logger.info(f"No new messages for user {user_id}")
   241→        return current_extracted or {}
   242→
   243→    # 4. 格式化消息
   244→    messages_text = "\n".join([
   245→        f"[{m['role']}] {m['content'][:300]}"
   246→        for m in messages
   247→        if m.get('content')
   248→    ])
   249→
   250→    if len(messages_text) < 50:
   251→        logger.info(f"Messages too short for user {user_id}")
   252→        return current_extracted or {}
   253→
   254→    # 5. 构建 prompt
   255→    prompt = f"""## 当前已有信息
   256→{json.dumps(current_extracted, ensure_ascii=False, indent=2) if current_extracted else "无"}
   257→
   258→## 新对话记录 (共 {len(messages)} 条)
   259→{messages_text[:6000]}
   260→
   261→请分析新对话，提取需要更新或新增的用户信息。只返回有变化的字段。"""
   262→
   263→    # 6. 调用 LLM 抽取
   264→    try:
   265→        response = await chat(
   266→            messages=[{"role": "user", "content": prompt}],
   267→            system=EXTRACTION_PROMPT,
   268→            capability="analysis",
   269→            user_id=str(user_id),
   270→            temperature=0.3,
   271→        )
   272→
   273→        # 7. 解析响应
   274→        content = response.content if hasattr(response, 'content') else str(response)
   275→
   276→        # 提取 JSON
   277→        json_match = re.search(r'\{[\s\S]*\}', content)
   278→        if not json_match:
   279→            logger.warning(f"No JSON found in response for user {user_id}")
   280→            return current_extracted or {}
   281→
   282→        new_extracted = json.loads(json_match.group())
   283→
   284→        # 8. 合并结果
   285→        merged = merge_extracted(current_extracted, new_extracted)
   286→        merged["last_extracted_at"] = datetime.now().isoformat()
   287→        merged["extraction_version"] = (current_extracted or {}).get("extraction_version", 0) + 1
   288→
   289→        # 9. 写入数据库
   290→        await UnifiedProfileRepository.update_extracted(user_id, merged)
   291→        logger.info(f"Updated extracted profile for user {user_id}")
   292→
   293→        # 10. 写入 Cold Layer (重要洞察和事件)
   294→        await _write_to_cold_layer(user_id, new_extracted)
   295→
   296→        return merged
   297→
   298→    except json.JSONDecodeError as e:
   299→        logger.error(f"JSON parse error for user {user_id}: {e}")
   300→        return current_extracted or {}
   301→    except Exception as e:
   302→        logger.error(f"Extraction failed for user {user_id}: {e}")
   303→        return current_extracted or {}
   304→
   305→
   306→async def run_profile_extraction(days: int = 7, batch_size: int = 10):
   307→    """
   308→    运行 Profile 抽取任务
   309→
   310→    Args:
   311→        days: 处理最近 N 天活跃的用户
   312→        batch_size: 每批处理的用户数
   313→    """
   314→    logger.info(f"Starting profile extraction task (days={days})")
   315→
   316→    # 获取活跃用户
   317→    active_users = await get_active_users(days=days)
   318→    logger.info(f"Found {len(active_users)} active users")
   319→
   320→    success_count = 0
   321→    error_count = 0
   322→
   323→    for i, user_id in enumerate(active_users):
   324→        try:
   325→            await extract_user_profile(user_id)
   326→            success_count += 1
   327→
   328→            # 限流：每处理 batch_size 个用户后暂停
   329→            if (i + 1) % batch_size == 0:
   330→                logger.info(f"Processed {i + 1}/{len(active_users)} users, pausing...")
   331→                await asyncio.sleep(2)
   332→
   333→        except Exception as e:
   334→            logger.error(f"Failed to extract for user {user_id}: {e}")
   335→            error_count += 1
   336→            continue
   337→
   338→    logger.info(f"Profile extraction completed: {success_count} success, {error_count} errors")
   339→
   340→
   341→async def main():
   342→    """命令行入口"""
   343→    import sys
   344→
   345→    # 简单参数解析
   346→    days = 7
   347→    if len(sys.argv) > 1:
   348→        try:
   349→            days = int(sys.argv[1])
   350→        except ValueError:
   351→            pass
   352→
   353→    await run_profile_extraction(days=days)
   354→
   355→
   356→if __name__ == "__main__":
   357→    # 配置日志
   358→    logging.basicConfig(
   359→        level=logging.INFO,
   360→        format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
   361→    )
   362→
   363→    asyncio.run(main())
   364→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
