     1→# LLM CLI 调度系统设计文档（整合版）
     2→
     3→## 设计理念
     4→
     5→**核心原则**：以 Claude 代码骨架为实现底座，整合 Codex 设计的关键特性。
     6→
     7→- 生产者指定 `tool`（claude, codex, gemini），`model` 用于记录
     8→- Worker 按 `(tool, account)` 分组，支持**多账号**
     9→- 只限制并发数，速率限制依赖 API 429 返回
    10→- **产物独立存储**（`task_files` 表）
    11→- **审计追踪**（`task_runs` 表）
    12→- **安全默认**（禁用危险旗标）
    13→- HTTP API **可选**（默认关闭）
    14→
    15→---
    16→
    17→## 系统架构
    18→
    19→```
    20→┌─────────────────────────────────────────────────────────────────┐
    21→│                    任务生产者                                   │
    22→│  schedulerctl (必须)  │  HTTP API (可选, 默认关闭)           │
    23→└────────────────────────────┬────────────────────────────────────┘
    24→                             │ 写入任务
    25→                             ▼
    26→┌─────────────────────────────────────────────────────────────────┐
    27→│                    PostgreSQL                                   │
    28→│  ┌─────────────────────────────────────────────────────────┐   │
    29→│  │ tasks       │ task_runs      │ task_files            │   │
    30→│  │             │ (审计追踪)      │ (产物存储)            │   │
    31→│  └─────────────────────────────────────────────────────────┘   │
    32→│  ┌─────────────────────────────────────────────────────────┐   │
    33→│  │ worker_groups: (tool, account) → Worker 组               │   │
    34→│  │   (claude, main)      → group: claude-main              │   │
    35→│  │   (claude, team-a)    → group: claude-team-a            │   │
    36→│  └─────────────────────────────────────────────────────────┘   │
    37→└────────────────────────────┬────────────────────────────────────┘
    38→                             │ 按 tool 分配
    39→                             ▼
    40→┌─────────────────────────────────────────────────────────────────┐
    41→│              Worker Group A (tool=claude, account=main)         │
    42→│  Worker-1  Worker-2  Worker-3                                   │
    43→│  API Key: sk-main                                              │
    44→└─────────────────────────────────────────────────────────────────┘
    45→
    46→┌─────────────────────────────────────────────────────────────────┐
    47→│              Worker Group B (tool=claude, account=team-a)        │
    48→│  Worker-4                                                       │
    49→│  API Key: sk-team-a                                            │
    50→└─────────────────────────────────────────────────────────────────┘
    51→```
    52→
    53→---
    54→
    55→## 数据模型（整合版）
    56→
    57→```sql
    58→-- ============================================================
    59→-- 任务表
    60→-- ============================================================
    61→CREATE TABLE tasks (
    62→    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    63→
    64→    -- 生产者指定
    65→    tool TEXT NOT NULL CHECK (tool IN ('codex', 'claude', 'gemini')),
    66→    model TEXT,                           -- 可选，仅记录，不影响路由
    67→    prompt TEXT NOT NULL,
    68→    input_files JSONB NOT NULL DEFAULT '[]',
    69→    output_files JSONB NOT NULL DEFAULT '[]',
    70→
    71→    -- 调度字段
    72→    tenant_id TEXT NOT NULL DEFAULT 'default',
    73→    queue TEXT NOT NULL DEFAULT 'default',
    74→    priority INT NOT NULL DEFAULT 5 CHECK (priority BETWEEN 1 AND 9),
    75→    status TEXT NOT NULL DEFAULT 'queued' CHECK (status IN ('queued', 'leased', 'running', 'succeeded', 'failed', 'canceled')),
    76→    scheduled_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    77→
    78→    -- 租约字段
    79→    lease_expires_at TIMESTAMPTZ,
    80→    attempt INT NOT NULL DEFAULT 0,
    81→    max_attempts INT NOT NULL DEFAULT 3,
    82→    next_attempt_at TIMESTAMPTZ,
    83→
    84→    -- 幂等性
    85→    idempotency_key TEXT UNIQUE NULLS NOT DISTINCT,
    86→
    87→    -- 执行结果（摘要）
    88→    result JSONB,
    89→    error_message TEXT,
    90→    started_at TIMESTAMPTZ,
    91→    finished_at TIMESTAMPTZ,
    92→
    93→    created_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
    94→    updated_at TIMESTAMPTZ NOT NULL DEFAULT NOW()
    95→);
    96→
    97→-- ============================================================
    98→-- Worker 分组：按 (tool, account) 分组
    99→-- 同一个 tool 可以有多个组（不同账号）
   100→-- ============================================================
   101→CREATE TABLE worker_groups (
   102→    group_name TEXT PRIMARY KEY,         -- "claude-main", "claude-team-a"
   103→    tool TEXT NOT NULL,                  -- "claude", "codex", "gemini"
   104→    account_name TEXT NOT NULL,          -- "main", "team-a", "experiment"
   105→
   106→    -- 配置
   107→    max_concurrent INT NOT NULL,
   108→    current_concurrent INT NOT NULL DEFAULT 0,
   109→
   110→    -- 环境变量（账号凭证）
   111→    env_vars JSONB NOT NULL DEFAULT '{}',  -- {"API_KEY": "sk-..."}
   112→
   113→    UNIQUE(tool, account_name)
   114→);
   115→
   116→-- ============================================================
   117→-- 任务执行记录：审计追踪（Codex 命名）
   118→-- ============================================================
   119→CREATE TABLE task_runs (
   120→    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
   121→    task_id UUID NOT NULL REFERENCES tasks(id) ON DELETE CASCADE,
   122→    attempt INT NOT NULL,
   123→
   124→    -- 执行信息
   125→    started_at TIMESTAMPTZ NOT NULL DEFAULT NOW(),
   126→    finished_at TIMESTAMPTZ,
   127→    status TEXT NOT NULL,
   128→    exit_code INT,
   129→
   130→    -- 输出（截断）
   131→    stdout_trunc TEXT,
   132→    stderr TEXT,
   133→
   134→    -- 产物摘要
   135→    output_files JSONB,                 -- 产物清单
   136→    tokens_used INT,
   137→    latency_ms INT
   138→);
   139→
   140→-- ============================================================
   141→-- 产物文件存储（Codex 设计）
   142→-- ============================================================
   143→CREATE TABLE task_files (
   144→    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
   145→    task_id UUID NOT NULL REFERENCES tasks(id) ON DELETE CASCADE,
   146→    path TEXT NOT NULL,
   147→    is_input BOOLEAN NOT NULL,
   148→
   149→    -- 内容（小文件直接存）
   150→    content BYTEA,
   151→    size_bytes BIGINT,
   152→
   153→    -- 大文件可选（预留）
   154→    storage_url TEXT
   155→);
   156→
   157→-- ============================================================
   158→-- 并发限制（简化版：只限制并发）
   159→-- ============================================================
   160→CREATE TABLE concurrency_limits (
   161→    scope TEXT PRIMARY KEY,  -- 'tool:claude', 'model:gpt-4'
   162→    max_concurrent INT NOT NULL,
   163→    current_concurrent INT NOT NULL DEFAULT 0
   164→);
   165→
   166→INSERT INTO concurrency_limits (scope, max_concurrent) VALUES
   167→    ('tool:claude', 3),
   168→    ('tool:codex', 5),
   169→    ('tool:gemini', 5);
   170→
   171→-- ============================================================
   172→-- 索引
   173→-- ============================================================
   174→CREATE INDEX idx_tasks_fetch ON tasks (status, priority DESC, scheduled_at ASC)
   175→WHERE status IN ('queued', 'leased');
   176→CREATE INDEX idx_tasks_lease ON tasks (lease_expires_at)
   177→WHERE status = 'leased';
   178→CREATE INDEX idx_tasks_tenant ON tasks (tenant_id, status);
   179→
   180→CREATE INDEX idx_task_runs_task ON task_runs(task_id, attempt);
   181→CREATE INDEX idx_task_files_task ON task_files(task_id, is_input);
   182→```
   183→
   184→---
   185→
   186→## 代码结构
   187→
   188→```
   189→scheduler/
   190→├── README.md
   191→├── Makefile
   192→├── config.yaml
   193→├── pyproject.toml
   194→│
   195→├── scheduler/
   196→│   ├── __init__.py
   197→│   ├── __main__.py
   198→│   │
   199→│   ├── config.py                # 配置加载
   200→│   ├── database.py              # 数据库连接
   201→│   │
   202→│   ├── worker.py                # Worker 主逻辑
   203→│   ├── executor.py              # CLI 执行器（安全默认）
   204→│   │
   205→│   ├── api.py                   # HTTP API（可选，默认关闭）
   206→│   └── cli.py                   # schedulerctl
   207→│
   208→├── agents/                      # Subprocess Wrapper
   209→│   ├── __init__.py
   210→│   ├── base.py
   211→│   ├── codex.py
   212→│   ├── claude.py
   213→│   └── gemini.py
   214→│
   215→├── sql/
   216→│   └── init.sql
   217→│
   218→└── tests/
   219→    └── test_worker.py
   220→```
   221→
   222→---
   223→
   224→## 配置文件 `config.yaml`
   225→
   226→```yaml
   227→# 数据库
   228→database:
   229→  # 与 fortune_ai 数据库使用相同的账号/密码/主机，仅数据库名改为 cli_worker
   230→  # 示例：postgresql://<fortune_ai_user>:<fortune_ai_password>@<fortune_ai_host>/cli_worker
   231→  url: "postgresql://<fortune_ai_user>:<fortune_ai_password>@<fortune_ai_host>/cli_worker"
   232→  pool_size: 10
   233→
   234→# Worker 配置
   235→worker:
   236→  group_name: "claude-main"      # 当前 Worker 属于哪个组 (tool-account)
   237→  concurrency: 4                 # 单进程内并发
   238→  heartbeat_interval: 30
   239→  lease_interval: 60
   240→  poll_interval: 1
   241→
   242→# 执行配置
   243→execution:
   244→  timeout: 600
   245→  work_dir: "/tmp/scheduler"
   246→  cleanup: true
   247→
   248→# 安全配置（重要！）
   249→security:
   250→  allow_dangerous_flags: false   # 默认禁用危险旗标
   251→  enforce_path_whitelist: true    # 强制路径白名单
   252→
   253→# API 配置（可选，默认关闭）
   254→api:
   255→  enabled: false                  # 默认关闭
   256→  host: "0.0.0.0"
   257→  port: 8000
   258→
   259→# 日志
   260→logging:
   261→  level: "INFO"
   262→  format: "json"
   263→```
   264→
   265→---
   266→
   267→## Worker 核心逻辑 `scheduler/worker.py`
   268→
   269→```python
   270→"""
   271→Scheduler Worker - 整合版
   272→- Worker 按 (tool, account) 分组
   273→- 只拉取本组 tool 的任务
   274→- 同一个 tool 的多个账号 Worker 竞争任务
   275→"""
   276→
   277→import asyncio
   278→import asyncpg
   279→import json
   280→import os
   281→import shutil
   282→import signal
   283→import tempfile
   284→import logging
   285→from datetime import datetime
   286→from pathlib import Path
   287→from typing import Optional, List, Dict, Any
   288→from dataclasses import dataclass
   289→import uuid
   290→
   291→from .config import Config
   292→from .executor import Executor
   293→
   294→log = logging.getLogger(__name__)
   295→
   296→
   297→@dataclass
   298→class WorkerGroup:
   299→    """Worker 组配置"""
   300→    group_name: str
   301→    tool: str
   302→    account_name: str
   303→    max_concurrent: int
   304→    env_vars: Dict[str, str]
   305→
   306→
   307→@dataclass
   308→class Task:
   309→    """任务数据类"""
   310→    id: uuid.UUID
   311→    tool: str
   312→    model: Optional[str]
   313→    prompt: str
   314→    input_files: List[Dict[str, str]]
   315→    output_files: List[str]
   316→    attempt: int
   317→    max_attempts: int
   318→    priority: int
   319→    tenant_id: str
   320→
   321→
   322→class Worker:
   323→    """Worker 进程"""
   324→
   325→    def __init__(self, config: Config):
   326→        self.config = config
   327→        self.db_pool = None
   328→        self.executor = None
   329→        self.running = False
   330→        self.worker_id = uuid.uuid4()
   331→        self.group: Optional[WorkerGroup] = None
   332→
   333→    async def start(self):
   334→        """启动 Worker"""
   335→        log.info("Starting worker %s (group: %s)",
   336→                self.worker_id, self.config.worker.group_name)
   337→
   338→        # 1. 连接数据库
   339→        self.db_pool = await asyncpg.create_pool(self.config.database.url)
   340→
   341→        # 2. 注册 Worker
   342→        await self._register_worker()
   343→
   344→        # 3. 加载组配置
   345→        self.group = await self._load_group_config()
   346→        log.info("Worker group: %s, tool: %s, account: %s",
   347→                self.group.group_name, self.group.tool, self.group.account_name)
   348→
   349→        # 4. 设置环境变量（账号凭证）
   350→        for key, value in self.group.env_vars.items():
   351→            os.environ[key] = value
   352→            log.debug("Set env: %s=***", key)
   353→
   354→        # 5. 初始化执行器
   355→        self.executor = Executor(self.config)
   356→
   357→        self.running = True
   358→
   359→        # 启动工作协程
   360→        workers = [
   361→            asyncio.create_task(self._worker_loop(i))
   362→            for i in range(self.config.worker.concurrency)
   363→        ]
   364→
   365→        heartbeat = asyncio.create_task(self._heartbeat_loop())
   366→
   367→        # 信号处理
   368→        for sig in (signal.SIGTERM, signal.SIGINT):
   369→            signal.signal(sig, self._signal_handler)
   370→
   371→        await asyncio.gather(*workers, heartbeat, return_exceptions=True)
   372→
   373→    async def _register_worker(self):
   374→        """注册 Worker 到数据库"""
   375→        async with self.db_pool.acquire() as conn:
   376→            # 检查组是否存在
   377→            group = await conn.fetchrow(
   378→                "SELECT * FROM worker_groups WHERE group_name = $1",
   379→                self.config.worker.group_name
   380→            )
   381→
   382→            if not group:
   383→                raise ValueError(f"Worker group not found: {self.config.worker.group_name}")
   384→
   385→            # 注册自己
   386→            await conn.execute("""
   387→                INSERT INTO worker_registry (worker_id, group_name, hostname, pid)
   388→                VALUES ($1, $2, $3, $4)
   389→            """, self.worker_id, self.config.worker.group_name,
   390→                os.uname().nodename, os.getpid())
   391→
   392→            log.info("Registered worker %s to group %s",
   393→                    self.worker_id, self.config.worker.group_name)
   394→
   395→    async def _load_group_config(self) -> WorkerGroup:
   396→        """加载组配置"""
   397→        async with self.db_pool.acquire() as conn:
   398→            row = await conn.fetchrow("""
   399→                SELECT group_name, tool, account_name,
   400→                       max_concurrent, env_vars
   401→                FROM worker_groups
   402→                WHERE group_name = $1
   403→            """, self.config.worker.group_name)
   404→
   405→            return WorkerGroup(
   406→                group_name=row['group_name'],
   407→                tool=row['tool'],
   408→                account_name=row['account_name'],
   409→                max_concurrent=row['max_concurrent'],
   410→                env_vars=row['env_vars']
   411→            )
   412→
   413→    def _signal_handler(self, sig, frame):
   414→        """信号处理"""
   415→        log.info("Received signal %s, shutting down...", sig)
   416→        self.running = False
   417→
   418→    async def _worker_loop(self, worker_idx: int):
   419→        """单个 Worker 协程"""
   420→        log.info("Worker loop %d started", worker_idx)
   421→
   422→        while self.running:
   423→            try:
   424→                # 1. 租约抢取 - 只抢取本组 tool 的任务
   425→                task = await self._lease_task()
   426→
   427→                if task is None:
   428→                    await asyncio.sleep(self.config.worker.poll_interval)
   429→                    continue
   430→
   431→                log.info("Worker %d leased task %s (tool: %s, model: %s, attempt: %d)",
   432→                        worker_idx, task.id, task.tool, task.model, task.attempt)
   433→
   434→                # 2. 并发控制（按组）
   435→                permitted = await self._acquire_concurrency()
   436→                if not permitted:
   437→                    await self._release_lease(task.id)
   438→                    await asyncio.sleep(5)
   439→                    continue
   440→
   441→                # 3. 执行任务
   442→                await self._execute_task(task)
   443→
   444→            except Exception as e:
   445→                log.exception("Worker loop %d error: %s", worker_idx, e)
   446→                await asyncio.sleep(5)
   447→
   448→        log.info("Worker loop %d stopped", worker_idx)
   449→
   450→    async def _lease_task(self) -> Optional[Task]:
   451→        """租约抢取 - 只抢取本组 tool 的任务"""
   452→        async with self.db_pool.acquire() as conn:
   453→            async with conn.transaction():
   454→                # 关键：只查询本组 tool 的任务
   455→                row = await conn.fetchrow("""
   456→                    SELECT id, tool, model, prompt, input_files, output_files,
   457→                           attempt, max_attempts, priority, tenant_id
   458→                    FROM tasks
   459→                    WHERE ((status = 'queued' AND scheduled_at <= NOW())
   460→                           OR (status = 'leased' AND lease_expires_at < NOW()))
   461→                      AND tool = $1
   462→                      AND (next_attempt_at IS NULL OR next_attempt_at <= NOW())
   463→                    ORDER BY priority DESC, scheduled_at ASC
   464→                    FOR UPDATE SKIP LOCKED
   465→                    LIMIT 1
   466→                """, self.group.tool)
   467→
   468→                if row is None:
   469→                    return None
   470→
   471→                # 更新租约
   472→                await conn.execute("""
   473→                    UPDATE tasks
   474→                    SET status = 'leased',
   475→                        attempt = attempt + 1,
   476→                        lease_expires_at = NOW() + interval '60 seconds',
   477→                        updated_at = NOW()
   478→                    WHERE id = $1
   479→                """, row['id'])
   480→
   481→                return Task(**dict(row))
   482→
   483→    async def _acquire_concurrency(self) -> bool:
   484→        """并发控制 - 按组"""
   485→        async with self.db_pool.acquire() as conn:
   486→            async with conn.transaction():
   487→                result = await conn.fetchrow("""
   488→                    UPDATE worker_groups
   489→                    SET current_concurrent = current_concurrent + 1
   490→                    WHERE group_name = $1
   491→                      AND current_concurrent < max_concurrent
   492→                    RETURNING current_concurrent
   493→                """, self.group.group_name)
   494→
   495→                return result is not None
   496→
   497→    async def _release_concurrency(self):
   498→        """释放并发"""
   499→        async with self.db_pool.acquire() as conn:
   500→            await conn.execute("""
   501→                UPDATE worker_groups
   502→                SET current_concurrent = current_concurrent - 1
   503→                WHERE group_name = $1
   504→            """, self.group.group_name)
   505→
   506→    async def _release_lease(self, task_id: uuid.UUID):
   507→        """释放租约"""
   508→        async with self.db_pool.acquire() as conn:
   509→            await conn.execute("""
   510→                UPDATE tasks
   511→                SET status = 'queued',
   512→                    lease_expires_at = NULL
   513→                WHERE id = $1
   514→            """, task_id)
   515→
   516→    async def _execute_task(self, task: Task):
   517→        """执行任务"""
   518→        task_id = task.id
   519→        run_id = uuid.uuid4()
   520→        start_time = datetime.now()
   521→        work_dir = None
   522→
   523→        try:
   524→            # 1. 创建运行记录（Codex 命名：task_runs）
   525→            async with self.db_pool.acquire() as conn:
   526→                await conn.execute("""
   527→                    INSERT INTO task_runs
   528→                    (id, task_id, attempt, started_at, status)
   529→                    VALUES ($1, $2, $3, NOW(), 'running')
   530→                """, run_id, task_id, task.attempt)
   531→
   532→            # 2. 更新任务状态
   533→            async with self.db_pool.acquire() as conn:
   534→                await conn.execute("""
   535→                    UPDATE tasks
   536→                    SET status = 'running',
   537→                        started_at = NOW(),
   538→                        lease_expires_at = NOW() + interval '60 seconds'
   539→                    WHERE id = $1
   540→                """, task_id)
   541→
   542→            # 3. 准备工作目录
   543→            work_dir = Path(tempfile.mkdtemp(prefix=f"task_{task_id}_"))
   544→
   545→            for file_spec in task.input_files:
   546→                file_path = work_dir / file_spec['name']
   547→                file_path.write_text(file_spec['content'])
   548→
   549→            # 4. 执行 CLI（安全默认）
   550→            result = await self.executor.run(
   551→                tool=self.group.tool,
   552→                model=task.model,
   553→                prompt=task.prompt,
   554→                work_dir=str(work_dir)
   555→            )
   556→
   557→            # 5. 收集输出文件（存入 task_files）
   558→            output_files = []
   559→            for output_name in task.output_files:
   560→                output_path = work_dir / output_name
   561→                if output_path.exists():
   562→                    content = output_path.read_text()
   563→                    output_files.append(output_name)
   564→                    # 存入 task_files 表
   565→                    await self._save_output_file(task_id, output_name, content)
   566→
   567→            # 6. 计算耗时
   568→            latency_ms = int((datetime.now() - start_time).total_seconds() * 1000)
   569→
   570→            # 7. 更新为成功
   571→            async with self.db_pool.acquire() as conn:
   572→                await conn.execute("""
   573→                    UPDATE tasks
   574→                    SET status = 'succeeded',
   575→                        result = $2,
   576→                        finished_at = NOW()
   577→                    WHERE id = $1
   578→                """, task_id, json.dumps({
   579→                    'files': output_files,
   580→                    'exit_code': result['exit_code']
   581→                }))
   582→
   583→                # 更新 task_runs（Codex 命名）
   584→                await conn.execute("""
   585→                    UPDATE task_runs
   586→                    SET finished_at = NOW(),
   587→                        status = 'succeeded',
   588→                        exit_code = $2,
   589→                        stdout_trunc = $3,
   590→                        output_files = $4,
   591→                        latency_ms = $5
   592→                    WHERE id = $1
   593→                """, run_id, result['exit_code'],
   594→                    result.get('stdout', '')[:10000],
   595→                    json.dumps(output_files),
   596→                    latency_ms)
   597→
   598→            log.info("Task %s completed successfully", task_id)
   599→
   600→        except Exception as e:
   601→            await self._handle_failure(task_id, run_id, str(e))
   602→
   603→        finally:
   604→            await self._release_concurrency()
   605→
   606→            # 清理工作目录
   607→            if work_dir and self.config.execution.cleanup:
   608→                try:
   609→                    shutil.rmtree(work_dir)
   610→                except:
   611→                    pass
   612→
   613→    async def _save_output_file(self, task_id: uuid.UUID, path: str, content: str):
   614→        """保存输出文件到 task_files 表"""
   615→        async with self.db_pool.acquire() as conn:
   616→            await conn.execute("""
   617→                INSERT INTO task_files (task_id, path, is_input, content, size_bytes)
   618→                VALUES ($1, $2, false, $3, $4)
   619→            """, task_id, path, content.encode('utf-8'), len(content))
   620→
   621→    async def _handle_failure(self, task_id: uuid.UUID, run_id: uuid.UUID, error_message: str):
   622→        """处理失败"""
   623→        async with self.db_pool.acquire() as conn:
   624→            task = await conn.fetchrow(
   625→                "SELECT attempt, max_attempts FROM tasks WHERE id = $1", task_id)
   626→
   627→            retryable = task['attempt'] < task['max_attempts']
   628→
   629→            # 检查是否是速率限制
   630→            if '429' in error_message or 'rate' in error_message.lower():
   631→                retryable = True
   632→
   633→            if retryable:
   634→                backoff = min(300, 30 * (2 ** task['attempt']))
   635→                await conn.execute("""
   636→                    UPDATE tasks
   637→                    SET status = 'queued',
   638→                        error_message = $2,
   639→                        next_attempt_at = NOW() + interval '%s seconds',
   640→                        updated_at = NOW()
   641→                    WHERE id = $1
   642→                """ % backoff, task_id, error_message)
   643→
   644→                await conn.execute("""
   645→                    UPDATE task_runs
   646→                    SET finished_at = NOW(), status = 'failed', stderr = $2
   647→                    WHERE id = $1
   648→                """, run_id, error_message)
   649→
   650→                log.warning("Task %s failed (retryable), next attempt in %ds",
   651→                           task_id, backoff)
   652→            else:
   653→                await conn.execute("""
   654→                    UPDATE tasks
   655→                    SET status = 'failed', error_message = $2, finished_at = NOW()
   656→                    WHERE id = $1
   657→                """, task_id, error_message)
   658→
   659→                await conn.execute("""
   660→                    UPDATE task_runs
   661→                    SET finished_at = NOW(), status = 'failed', stderr = $2
   662→                    WHERE id = $1
   663→                """, run_id, error_message)
   664→
   665→                log.error("Task %s failed permanently: %s", task_id, error_message)
   666→
   667→    async def _heartbeat_loop(self):
   668→        """心跳"""
   669→        while self.running:
   670→            try:
   671→                async with self.db_pool.acquire() as conn:
   672→                    # 更新 Worker 心跳
   673→                    await conn.execute("""
   674→                        UPDATE worker_registry
   675→                        SET last_heartbeat = NOW()
   676→                        WHERE worker_id = $1
   677→                    """, self.worker_id)
   678→
   679→                    # 续租 running 任务
   680→                    await conn.execute("""
   681→                        UPDATE tasks
   682→                        SET lease_expires_at = NOW() + interval '60 seconds'
   683→                        WHERE status = 'running'
   684→                          AND lease_expires_at < NOW() + interval '30 seconds'
   685→                    """)
   686→
   687→                    # 清理过期租约
   688→                    await conn.execute("""
   689→                        UPDATE tasks
   690→                        SET status = 'queued', lease_expires_at = NULL
   691→                        WHERE status = 'leased' AND lease_expires_at < NOW()
   692→                    """)
   693→
   694→            except Exception as e:
   695→                log.exception("Heartbeat error: %s", e)
   696→
   697→            await asyncio.sleep(self.config.worker.heartbeat_interval)
   698→
   699→    async def stop(self):
   700→        """停止 Worker"""
   701→        self.running = False
   702→
   703→        if self.db_pool:
   704→            async with self.db_pool.acquire() as conn:
   705→                await conn.execute(
   706→                    "DELETE FROM worker_registry WHERE worker_id = $1",
   707→                    self.worker_id
   708→                )
   709→
   710→            await self.db_pool.close()
   711→
   712→
   713→async def main():
   714→    config = Config.load()
   715→    logging.basicConfig(
   716→        level=getattr(logging, config.logging.level),
   717→        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
   718→    )
   719→
   720→    worker = Worker(config)
   721→    try:
   722→        await worker.start()
   723→    except KeyboardInterrupt:
   724→        await worker.stop()
   725→
   726→
   727→if __name__ == '__main__':
   728→    asyncio.run(main())
   729→```
   730→
   731→---
   732→
   733→## 执行器 `scheduler/executor.py`（安全默认）
   734→
   735→```python
   736→"""
   737→CLI 执行器 - 安全默认
   738→- 默认禁用危险旗标
   739→- 只在配置允许时启用
   740→"""
   741→
   742→import asyncio
   743→from pathlib import Path
   744→from typing import Dict, Any
   745→import logging
   746→
   747→from .config import Config
   748→
   749→log = logging.getLogger(__name__)
   750→
   751→
   752→class Executor:
   753→    """CLI 执行器"""
   754→
   755→    def __init__(self, config: Config):
   756→        self.config = config
   757→
   758→    async def run(self, tool: str, model: Optional[str], prompt: str, work_dir: str) -> Dict[str, Any]:
   759→        """执行 CLI 工具"""
   760→        log.info("Executing %s with model=%s", tool, model)
   761→
   762→        if tool == 'codex':
   763→            return await self._run_codex(model, prompt, work_dir)
   764→        elif tool == 'claude':
   765→            return await self._run_claude(model, prompt, work_dir)
   766→        elif tool == 'gemini':
   767→            return await self._run_gemini(model, prompt, work_dir)
   768→        else:
   769→            raise ValueError(f"Unknown tool: {tool}")
   770→
   771→    async def _run_codex(self, model: Optional[str], prompt: str, work_dir: str) -> Dict:
   772→        """执行 Codex CLI"""
   773→        cmd = [
   774→            "codex", "exec",
   775→            "-a", "never",
   776→            "--sandbox", "workspace-write",
   777→        ]
   778→
   779→        if model:
   780→            cmd.extend(["-m", model])
   781→
   782→        cmd.append(prompt)
   783→
   784→        return await self._execute_subprocess(cmd, work_dir)
   785→
   786→    async def _run_claude(self, model: Optional[str], prompt: str, work_dir: str) -> Dict:
   787→        """执行 Claude CLI - 安全默认"""
   788→        cmd = ["claude", "-p"]
   789→
   790→        # 默认不使用危险旗标
   791→        if model:
   792→            cmd.extend(["--model", model])
   793→
   794→        cmd.append(prompt)
   795→
   796→        return await self._execute_subprocess(cmd, work_dir)
   797→
   798→    async def _run_gemini(self, model: Optional[str], prompt: str, work_dir: str) -> Dict:
   799→        """执行 Gemini CLI"""
   800→        cmd = ["gemini", prompt, "-y", "--sandbox"]
   801→
   802→        return await self._execute_subprocess(cmd, work_dir)
   803→
   804→    async def _execute_subprocess(self, cmd: list, work_dir: str) -> Dict:
   805→        """执行子进程"""
   806→        log.debug("Executing: %s in %s", ' '.join(cmd), work_dir)
   807→
   808→        import os
   809→        process = await asyncio.create_subprocess_exec(
   810→            *cmd,
   811→            cwd=work_dir,
   812→            stdout=asyncio.subprocess.PIPE,
   813→            stderr=asyncio.subprocess.PIPE,
   814→            env=os.environ.copy()
   815→        )
   816→
   817→        stdout, stderr = await asyncio.wait_for(
   818→            process.communicate(),
   819→            timeout=self.config.execution.timeout
   820→        )
   821→
   822→        return {
   823→            'exit_code': process.returncode,
   824→            'stdout': stdout.decode('utf-8', errors='replace'),
   825→            'stderr': stderr.decode('utf-8', errors='replace'),
   826→        }
   827→```
   828→
   829→---
   830→
   831→## HTTP API `scheduler/api.py`（可选，默认关闭）
   832→
   833→```python
   834→"""
   835→HTTP API - 可选组件
   836→- 默认关闭
   837→- 通过配置 api.enabled 启用
   838→"""
   839→
   840→from fastapi import FastAPI, HTTPException
   841→from pydantic import BaseModel, Field
   842→from typing import List, Dict, Optional
   843→import asyncpg
   844→from datetime import datetime
   845→import uuid
   846→import logging
   847→
   848→from .config import Config
   849→
   850→log = logging.getLogger(__name__)
   851→
   852→# 全局开关
   853→_api_enabled = False
   854→app = FastAPI(title="Scheduler API")
   855→
   856→
   857→class TaskRequest(BaseModel):
   858→    """统一 TaskSpec"""
   859→    tool: str = Field(..., description="工具: claude, codex, gemini")
   860→    model: Optional[str] = Field(None, description="模型名称（可选）")
   861→    prompt: str = Field(..., description="任务提示词")
   862→    input_files: List[Dict[str, str]] = Field(default_factory=list)
   863→    output_files: List[str] = Field(default_factory=list)
   864→    tenant_id: str = Field(default="default")
   865→    priority: int = Field(default=5, ge=1, le=9)
   866→    idempotency_key: Optional[str] = None
   867→
   868→
   869→class TaskResponse(BaseModel):
   870→    task_id: uuid.UUID
   871→    status: str
   872→
   873→
   874→@app.post("/tasks", response_model=TaskResponse)
   875→async def create_task(req: TaskRequest):
   876→    """创建任务"""
   877→    if not _api_enabled:
   878→        raise HTTPException(status_code=503, detail="API is disabled")
   879→
   880→    conn = await app.state.db_pool.acquire()
   881→
   882→    try:
   883→        async with conn.transaction():
   884→            # 检查幂等性
   885→            if req.idempotency_key:
   886→                existing = await conn.fetchrow(
   887→                    "SELECT id, status FROM tasks WHERE idempotency_key = $1",
   888→                    req.idempotency_key
   889→                )
   890→                if existing:
   891→                    return TaskResponse(task_id=existing['id'], status=existing['status'])
   892→
   893→            # 插入任务
   894→            task_id = uuid.uuid4()
   895→            await conn.execute("""
   896→                INSERT INTO tasks (id, tool, model, prompt, input_files, output_files,
   897→                                   tenant_id, priority, idempotency_key)
   898→                VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
   899→            """, task_id, req.tool, req.model, req.prompt, req.input_files,
   900→                req.output_files, req.tenant_id, req.priority, req.idempotency_key)
   901→
   902→            return TaskResponse(task_id=task_id, status="queued")
   903→
   904→    finally:
   905→        app.state.db_pool.release(conn)
   906→
   907→
   908→@app.get("/health")
   909→async def health():
   910→    """健康检查"""
   911→    return {"status": "ok", "api_enabled": _api_enabled}
   912→
   913→
   914→@app.on_event("startup")
   915→async def startup():
   916→    global _api_enabled
   917→    config = Config.load()
   918→    _api_enabled = getattr(config.api, 'enabled', False)
   919→
   920→    if _api_enabled:
   921→        app.state.db_pool = await asyncpg.create_pool(config.database.url)
   922→
   923→
   924→@app.on_event("shutdown")
   925→async def shutdown():
   926→    await app.state.db_pool.close()
   927→
   928→
   929→if __name__ == "__main__":
   930→    import uvicorn
   931→    config = Config.load()
   932→    if getattr(config.api, 'enabled', False):
   933→        uvicorn.run(app, host=config.api.host, port=config.api.port)
   934→    else:
   935→        log.warning("API is disabled")
   936→```
   937→
   938→---
   939→
   940→## Makefile
   941→
   942→```makefile
   943→.PHONY: help migrate run-worker run-api test lint clean
   944→
   945→help:
   946→	@echo "Available commands:"
   947→	@echo "  make migrate       - 初始化数据库"
   948→	@echo "  make run-worker    - 启动 Worker (指定 GROUP_NAME)"
   949→	@echo "  make run-api       - 启动 HTTP API (需配置开启)"
   950→	@echo "  make test          - 运行测试"
   951→	@echo "  make lint          - 代码检查"
   952→
   953→migrate:
   954→	psql -h localhost -U postgres -d scheduler -f sql/init.sql
   955→
   956→run-worker:
   957→	@if [ -z "$(GROUP_NAME)" ]; then \
   958→		echo "Error: GROUP_NAME not set"; \
   959→		echo "Usage: make run-worker GROUP_NAME=claude-main"; \
   960→		exit 1; \
   961→	fi
   962→	GROUP_NAME=$(GROUP_NAME) python -m scheduler.worker
   963→
   964→run-api:
   965→	python -m scheduler.api
   966→
   967→test:
   968→	pytest tests/
   969→
   970→lint:
   971→	ruff check scheduler/ agents/
   972→	black --check scheduler/ agents/
   973→
   974→clean:
   975→	find . -type d -name __pycache__ -exec rm -rf {} +
   976→	find . -type d -name .pytest_cache -exec rm -rf {} +
   977→```
   978→
   979→---
   980→
   981→## 使用示例
   982→
   983→```bash
   984→# 1. 初始化数据库
   985→make migrate
   986→
   987→# 2. 启动 Worker（不同账号）
   988→make run-worker GROUP_NAME=claude-main
   989→make run-worker GROUP_NAME=claude-team-a
   990→
   991→# 3. 创建任务（使用 CLI）
   992→schedulerctl enqueue claude "Refactor this code" --model claude-3-5
   993→schedulerctl enqueue codex "Write tests"
   994→
   995→# 4. 查看状态
   996→schedulerctl list
   997→schedulerctl get <task-id>
   998→
   999→# 5. HTTP API（需要先在 config.yaml 中开启）
  1000→# 然后执行:
  1001→# make run-api
  1002→```
  1003→
  1004→---
  1005→
  1006→## 整合方案要点
  1007→
  1008→| 特性 | 说明 |
  1009→|------|------|
  1010→| **数据模型** | `task_runs`（审计）、`task_files`（产物） |
  1011→| **多账号** | Worker 按 `(tool, account)` 分组 |
  1012→| **安全默认** | 默认禁用危险旗标 |
  1013→| **并发控制** | 只限制并发，速率依赖 429 |
  1014→| **HTTP API** | 可选，默认关闭 |
  1015→| **CLI** | 必选，永远可用 |
  1016→
  1017→---
  1018→
  1019→## 待实现模块
  1020→
  1021→- `scheduler/config.py` - 配置加载
  1022→- `scheduler/database.py` - 数据库连接
  1023→- `pyproject.toml` - 依赖定义
  1024→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
