     1→"""
     2→Internal API Routes for Next.js Agent Runtime
     3→
     4→These endpoints are called by the Next.js server-side only (not exposed to browser).
     5→Trust boundary: userId is extracted from Cookie session, never passed from request body.
     6→
     7→Endpoints:
     8→- GET  /internal/context         - Aggregate user context (L0+L1+history)
     9→- POST /internal/chat/run/start  - Record run_id + user message
    10→- POST /internal/chat/run/finalize - Transaction commit all side effects
    11→"""
    12→from __future__ import annotations
    13→
    14→import json
    15→import uuid
    16→from typing import Any, Dict, List, Optional
    17→
    18→from fastapi import APIRouter, HTTPException, Request
    19→from pydantic import BaseModel, Field
    20→
    21→from api.deps import require_auth
    22→from services import chat_service
    23→from services.soul_os import get_full_context_for_chat
    24→
    25→router = APIRouter(prefix="/internal", tags=["internal"])
    26→
    27→
    28→# =============================================================================
    29→# Request/Response Models
    30→# =============================================================================
    31→
    32→
    33→class ContextResponse(BaseModel):
    34→    """Response for /internal/context"""
    35→    user_id: int
    36→    system_prompt: str
    37→    persona_style: str
    38→    user_context: Dict[str, Any]
    39→    evidence: Dict[str, Any]
    40→    anti_dependency: Dict[str, Any]
    41→    history: List[Dict[str, Any]]
    42→
    43→
    44→class RunStartRequest(BaseModel):
    45→    """Request for /internal/chat/run/start"""
    46→    session_id: Optional[str] = Field(None, description="Existing session ID or null to create new")
    47→    message: str = Field(..., min_length=1, max_length=10000)
    48→    model: str = Field(default="glm-4.7-flash")
    49→    correlation_id: Optional[str] = Field(None, description="Frontend correlation ID for tracing")
    50→
    51→
    52→class RunStartResponse(BaseModel):
    53→    """Response for /internal/chat/run/start"""
    54→    run_id: str
    55→    session_id: str
    56→    user_message_id: int
    57→
    58→
    59→class RunFinalizeRequest(BaseModel):
    60→    """Request for /internal/chat/run/finalize"""
    61→    run_id: str = Field(..., description="Run ID from start")
    62→    session_id: str = Field(...)
    63→    assistant_content: str = Field(..., description="Final assistant message text")
    64→    tool_calls: Optional[List[Dict[str, Any]]] = Field(default=None, description="Tool calls made during stream")
    65→    a2ui_cards: Optional[List[Dict[str, Any]]] = Field(default=None, description="A2UI cards to store")
    66→    prompt_tokens: int = Field(default=0)
    67→    completion_tokens: int = Field(default=0)
    68→    model: str = Field(default="glm-4.7-flash")
    69→    error: Optional[str] = Field(default=None, description="Error message if stream failed")
    70→
    71→
    72→class RunFinalizeResponse(BaseModel):
    73→    """Response for /internal/chat/run/finalize"""
    74→    success: bool
    75→    assistant_message_id: Optional[int] = None
    76→    side_effects: List[str] = Field(default_factory=list)
    77→
    78→
    79→# =============================================================================
    80→# Endpoints
    81→# =============================================================================
    82→
    83→
    84→@router.get("/context", response_model=ContextResponse)
    85→async def get_context(
    86→    request: Request,
    87→    session_id: Optional[str] = None,
    88→    query: Optional[str] = None,
    89→):
    90→    """
    91→    Get aggregated user context for chat.
    92→
    93→    Includes:
    94→    - System prompt (based on persona style)
    95→    - User context (L0 profile + L1 data)
    96→    - Evidence (relevant knowledge)
    97→    - Anti-dependency check
    98→    - Recent chat history (if session_id provided)
    99→    """
   100→    auth = require_auth(request)
   101→    user_id = int(auth["user_id"])
   102→
   103→    # Get full context from Soul OS
   104→    ctx = get_full_context_for_chat(user_id, query or "")
   105→
   106→    # Get chat history if session provided
   107→    history: List[Dict[str, Any]] = []
   108→    if session_id:
   109→        history = chat_service.get_recent_messages_for_llm(user_id, session_id, limit=10)
   110→
   111→    return ContextResponse(
   112→        user_id=user_id,
   113→        system_prompt=ctx["system_prompt"],
   114→        persona_style=ctx["persona_style"],
   115→        user_context=ctx["user_context"],
   116→        evidence=ctx["evidence"],
   117→        anti_dependency=ctx["anti_dependency"],
   118→        history=history,
   119→    )
   120→
   121→
   122→@router.post("/chat/run/start", response_model=RunStartResponse)
   123→async def start_run(request: Request, body: RunStartRequest):
   124→    """
   125→    Start a new chat run.
   126→
   127→    Actions:
   128→    1. Create or validate session
   129→    2. Generate run_id
   130→    3. Record user message
   131→    4. Return run_id for finalization
   132→    """
   133→    auth = require_auth(request)
   134→    user_id = int(auth["user_id"])
   135→
   136→    # Session handling
   137→    session_id = body.session_id
   138→    if not session_id:
   139→        # Create new session
   140→        session = chat_service.create_session(user_id)
   141→        session_id = session["session_id"]
   142→    else:
   143→        # Validate existing session
   144→        existing = chat_service.get_session(user_id, session_id)
   145→        if not existing:
   146→            raise HTTPException(status_code=404, detail="session_not_found")
   147→
   148→    # Generate run_id
   149→    run_id = str(uuid.uuid4())
   150→
   151→    # Record user message
   152→    msg_result = chat_service.append_message(
   153→        session_id=session_id,
   154→        user_id=user_id,
   155→        role="user",
   156→        content=body.message,
   157→        model=body.model,
   158→    )
   159→
   160→    # Set session title from first message
   161→    chat_service.set_title_if_empty(session_id, body.message[:24])
   162→
   163→    return RunStartResponse(
   164→        run_id=run_id,
   165→        session_id=session_id,
   166→        user_message_id=msg_result["message_id"],
   167→    )
   168→
   169→
   170→@router.post("/chat/run/finalize", response_model=RunFinalizeResponse)
   171→async def finalize_run(request: Request, body: RunFinalizeRequest):
   172→    """
   173→    Finalize a chat run after streaming completes.
   174→
   175→    Actions:
   176→    1. Record assistant message with a2ui cards
   177→    2. Execute any pending side effects from tool calls
   178→    3. Update session timestamp
   179→
   180→    This ensures atomic commit of all changes.
   181→    """
   182→    auth = require_auth(request)
   183→    user_id = int(auth["user_id"])
   184→
   185→    # Validate session ownership
   186→    existing = chat_service.get_session(user_id, body.session_id)
   187→    if not existing:
   188→        raise HTTPException(status_code=404, detail="session_not_found")
   189→
   190→    # If there was an error, record it but don't store assistant message
   191→    if body.error:
   192→        # Log error but don't fail - we want the conversation to continue
   193→        # TODO: Add error logging table
   194→        return RunFinalizeResponse(
   195→            success=False,
   196→            assistant_message_id=None,
   197→            side_effects=[f"error_logged:{body.run_id}"],
   198→        )
   199→
   200→    # Build a2ui object from cards
   201→    a2ui = None
   202→    if body.a2ui_cards:
   203→        a2ui = {"cards": body.a2ui_cards}
   204→
   205→    # Record assistant message
   206→    msg_result = chat_service.append_message(
   207→        session_id=body.session_id,
   208→        user_id=user_id,
   209→        role="assistant",
   210→        content=body.assistant_content,
   211→        model=body.model,
   212→        a2ui=a2ui,
   213→        prompt_tokens=body.prompt_tokens,
   214→        completion_tokens=body.completion_tokens,
   215→    )
   216→
   217→    side_effects: List[str] = [f"message_stored:{msg_result['message_id']}"]
   218→
   219→    # Process tool calls for side effects (if any pending writes)
   220→    # Tool calls that create commitments, log mood, etc. are already executed
   221→    # during the stream via Skills. Here we just record what was done.
   222→    if body.tool_calls:
   223→        for tc in body.tool_calls:
   224→            tool_name = tc.get("toolName", tc.get("name", "unknown"))
   225→            side_effects.append(f"tool_executed:{tool_name}")
   226→
   227→    return RunFinalizeResponse(
   228→        success=True,
   229→        assistant_message_id=msg_result["message_id"],
   230→        side_effects=side_effects,
   231→    )
   232→
   233→
   234→# =============================================================================
   235→# Health check (useful for debugging internal connectivity)
   236→# =============================================================================
   237→
   238→
   239→@router.get("/health")
   240→async def internal_health():
   241→    """Health check for internal API."""
   242→    return {"status": "ok", "service": "internal_api"}
   243→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
