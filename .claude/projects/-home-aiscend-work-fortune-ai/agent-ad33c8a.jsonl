{"parentUuid":null,"isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":"Explore the services layer in /home/aiscend/work/fortune_ai/services/. I need to understand:\n\n1. glm_client.py - how LLM calls are currently made (this will be removed)\n2. soul_os.py - how context is assembled\n3. bazi_engine.py and bazi_facts.py - these will remain as Data Service\n4. twin_service.py, goal_service.py - state management services\n5. agent_service_client.py - current TypeScript agent integration (will be removed)\n\nFocus on:\n- Which services stay in Python (Data Service)\n- Which logic moves to Next.js (AI inference)\n- How context is currently built for LLM calls\n- Key data structures passed between services\n\nReturn a structured summary with file paths and key findings."},"uuid":"9c66faa5-7f49-4500-b2ec-5b976d58b2de","timestamp":"2026-01-01T15:00:59.079Z"}
{"parentUuid":"9c66faa5-7f49-4500-b2ec-5b976d58b2de","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01KtY3RFjqfAbCdoLieUooe1","type":"message","role":"assistant","content":[{"type":"text","text":"I'll conduct a thorough exploration of the services layer to understand the current architecture and identify what stays, what moves, and how data flows between services."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":506,"cache_read_input_tokens":20477,"cache_creation":{"ephemeral_5m_input_tokens":506,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrmF7YAR3KDFxNsgrx6","type":"assistant","uuid":"c83c9b1b-5e57-400a-8159-9eb1fca5298c","timestamp":"2026-01-01T15:01:03.079Z"}
{"parentUuid":"c83c9b1b-5e57-400a-8159-9eb1fca5298c","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01KtY3RFjqfAbCdoLieUooe1","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_015wo7BypqfRBBJPDJtKKemr","name":"Bash","input":{"command":"find /home/aiscend/work/fortune_ai/services -type f -name \"*.py\" | sort"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":506,"cache_read_input_tokens":20477,"cache_creation":{"ephemeral_5m_input_tokens":506,"ephemeral_1h_input_tokens":0},"output_tokens":109,"service_tier":"standard"}},"requestId":"req_011CWgrmF7YAR3KDFxNsgrx6","type":"assistant","uuid":"b55430f1-479f-4def-8e7c-1287037a6311","timestamp":"2026-01-01T15:01:03.934Z"}
{"parentUuid":"b55430f1-479f-4def-8e7c-1287037a6311","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_015wo7BypqfRBBJPDJtKKemr","type":"tool_result","content":"/home/aiscend/work/fortune_ai/services/agent_service_client.py\n/home/aiscend/work/fortune_ai/services/auth_service.py\n/home/aiscend/work/fortune_ai/services/bazi_engine.py\n/home/aiscend/work/fortune_ai/services/bazi_facts.py\n/home/aiscend/work/fortune_ai/services/bazi_report_service.py\n/home/aiscend/work/fortune_ai/services/bento_service.py\n/home/aiscend/work/fortune_ai/services/chat_backend_config.py\n/home/aiscend/work/fortune_ai/services/chat_service.py\n/home/aiscend/work/fortune_ai/services/conversation_store.py\n/home/aiscend/work/fortune_ai/services/currency_service.py\n/home/aiscend/work/fortune_ai/services/glm_client.py\n/home/aiscend/work/fortune_ai/services/goal_service.py\n/home/aiscend/work/fortune_ai/services/growth_service.py\n/home/aiscend/work/fortune_ai/services/__init__.py\n/home/aiscend/work/fortune_ai/services/jitai_service.py\n/home/aiscend/work/fortune_ai/services/kb_service.py\n/home/aiscend/work/fortune_ai/services/llm_client.py\n/home/aiscend/work/fortune_ai/services/plan_service.py\n/home/aiscend/work/fortune_ai/services/poster_service.py\n/home/aiscend/work/fortune_ai/services/product_service.py\n/home/aiscend/work/fortune_ai/services/prompt_store.py\n/home/aiscend/work/fortune_ai/services/push_service.py\n/home/aiscend/work/fortune_ai/services/rectification/engine.py\n/home/aiscend/work/fortune_ai/services/rectification/ephemeris.py\n/home/aiscend/work/fortune_ai/services/rectification/__init__.py\n/home/aiscend/work/fortune_ai/services/rectification/parsing.py\n/home/aiscend/work/fortune_ai/services/rectification/scoring.py\n/home/aiscend/work/fortune_ai/services/rectification_store.py\n/home/aiscend/work/fortune_ai/services/rectification/types.py\n/home/aiscend/work/fortune_ai/services/rectification_v3.py\n/home/aiscend/work/fortune_ai/services/reflection_service.py\n/home/aiscend/work/fortune_ai/services/security.py\n/home/aiscend/work/fortune_ai/services/social_service.py\n/home/aiscend/work/fortune_ai/services/soul_os.py\n/home/aiscend/work/fortune_ai/services/task_service.py\n/home/aiscend/work/fortune_ai/services/tieban/candidate_pool.py\n/home/aiscend/work/fortune_ai/services/tieban/case_library.py\n/home/aiscend/work/fortune_ai/services/tieban/cross_validator.py\n/home/aiscend/work/fortune_ai/services/tieban/dougong.py\n/home/aiscend/work/fortune_ai/services/tieban/engines.py\n/home/aiscend/work/fortune_ai/services/tieban/etl.py\n/home/aiscend/work/fortune_ai/services/tieban/fsm.py\n/home/aiscend/work/fortune_ai/services/tieban/__init__.py\n/home/aiscend/work/fortune_ai/services/tieban/kao_ke.py\n/home/aiscend/work/fortune_ai/services/tieban/liunian_engine.py\n/home/aiscend/work/fortune_ai/services/tieban/machuan_lookup.py\n/home/aiscend/work/fortune_ai/services/tieban/mapping.py\n/home/aiscend/work/fortune_ai/services/tieban/normalizer.py\n/home/aiscend/work/fortune_ai/services/tieban/parents_table.py\n/home/aiscend/work/fortune_ai/services/tieban/report_builder.py\n/home/aiscend/work/fortune_ai/services/tieban/reverse_validator.py\n/home/aiscend/work/fortune_ai/services/tieban/roll_engine.py\n/home/aiscend/work/fortune_ai/services/tieban/ruleset_loader.py\n/home/aiscend/work/fortune_ai/services/tieban/secret_keys.py\n/home/aiscend/work/fortune_ai/services/tieban/service.py\n/home/aiscend/work/fortune_ai/services/tieban/store.py\n/home/aiscend/work/fortune_ai/services/tieban/taihua_engine.py\n/home/aiscend/work/fortune_ai/services/tieban/verse_pool.py\n/home/aiscend/work/fortune_ai/services/twin_service.py\n/home/aiscend/work/fortune_ai/services/yunshi_service.py","is_error":false}]},"uuid":"ea8aa8e5-a01e-4c3c-b8c1-523ff20016cc","timestamp":"2026-01-01T15:01:04.269Z","toolUseResult":{"stdout":"/home/aiscend/work/fortune_ai/services/agent_service_client.py\n/home/aiscend/work/fortune_ai/services/auth_service.py\n/home/aiscend/work/fortune_ai/services/bazi_engine.py\n/home/aiscend/work/fortune_ai/services/bazi_facts.py\n/home/aiscend/work/fortune_ai/services/bazi_report_service.py\n/home/aiscend/work/fortune_ai/services/bento_service.py\n/home/aiscend/work/fortune_ai/services/chat_backend_config.py\n/home/aiscend/work/fortune_ai/services/chat_service.py\n/home/aiscend/work/fortune_ai/services/conversation_store.py\n/home/aiscend/work/fortune_ai/services/currency_service.py\n/home/aiscend/work/fortune_ai/services/glm_client.py\n/home/aiscend/work/fortune_ai/services/goal_service.py\n/home/aiscend/work/fortune_ai/services/growth_service.py\n/home/aiscend/work/fortune_ai/services/__init__.py\n/home/aiscend/work/fortune_ai/services/jitai_service.py\n/home/aiscend/work/fortune_ai/services/kb_service.py\n/home/aiscend/work/fortune_ai/services/llm_client.py\n/home/aiscend/work/fortune_ai/services/plan_service.py\n/home/aiscend/work/fortune_ai/services/poster_service.py\n/home/aiscend/work/fortune_ai/services/product_service.py\n/home/aiscend/work/fortune_ai/services/prompt_store.py\n/home/aiscend/work/fortune_ai/services/push_service.py\n/home/aiscend/work/fortune_ai/services/rectification/engine.py\n/home/aiscend/work/fortune_ai/services/rectification/ephemeris.py\n/home/aiscend/work/fortune_ai/services/rectification/__init__.py\n/home/aiscend/work/fortune_ai/services/rectification/parsing.py\n/home/aiscend/work/fortune_ai/services/rectification/scoring.py\n/home/aiscend/work/fortune_ai/services/rectification_store.py\n/home/aiscend/work/fortune_ai/services/rectification/types.py\n/home/aiscend/work/fortune_ai/services/rectification_v3.py\n/home/aiscend/work/fortune_ai/services/reflection_service.py\n/home/aiscend/work/fortune_ai/services/security.py\n/home/aiscend/work/fortune_ai/services/social_service.py\n/home/aiscend/work/fortune_ai/services/soul_os.py\n/home/aiscend/work/fortune_ai/services/task_service.py\n/home/aiscend/work/fortune_ai/services/tieban/candidate_pool.py\n/home/aiscend/work/fortune_ai/services/tieban/case_library.py\n/home/aiscend/work/fortune_ai/services/tieban/cross_validator.py\n/home/aiscend/work/fortune_ai/services/tieban/dougong.py\n/home/aiscend/work/fortune_ai/services/tieban/engines.py\n/home/aiscend/work/fortune_ai/services/tieban/etl.py\n/home/aiscend/work/fortune_ai/services/tieban/fsm.py\n/home/aiscend/work/fortune_ai/services/tieban/__init__.py\n/home/aiscend/work/fortune_ai/services/tieban/kao_ke.py\n/home/aiscend/work/fortune_ai/services/tieban/liunian_engine.py\n/home/aiscend/work/fortune_ai/services/tieban/machuan_lookup.py\n/home/aiscend/work/fortune_ai/services/tieban/mapping.py\n/home/aiscend/work/fortune_ai/services/tieban/normalizer.py\n/home/aiscend/work/fortune_ai/services/tieban/parents_table.py\n/home/aiscend/work/fortune_ai/services/tieban/report_builder.py\n/home/aiscend/work/fortune_ai/services/tieban/reverse_validator.py\n/home/aiscend/work/fortune_ai/services/tieban/roll_engine.py\n/home/aiscend/work/fortune_ai/services/tieban/ruleset_loader.py\n/home/aiscend/work/fortune_ai/services/tieban/secret_keys.py\n/home/aiscend/work/fortune_ai/services/tieban/service.py\n/home/aiscend/work/fortune_ai/services/tieban/store.py\n/home/aiscend/work/fortune_ai/services/tieban/taihua_engine.py\n/home/aiscend/work/fortune_ai/services/tieban/verse_pool.py\n/home/aiscend/work/fortune_ai/services/twin_service.py\n/home/aiscend/work/fortune_ai/services/yunshi_service.py","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"ea8aa8e5-a01e-4c3c-b8c1-523ff20016cc","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01AWM7U5JsJmGVyHd6DKUNHg","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me read the key files you've specified:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":1765,"cache_read_input_tokens":20983,"cache_creation":{"ephemeral_5m_input_tokens":1765,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrmfWEQwTiRnK3aTPCM","type":"assistant","uuid":"7fb7ab1d-b0d9-429e-aa9c-5a185bf33284","timestamp":"2026-01-01T15:01:08.568Z"}
{"parentUuid":"7fb7ab1d-b0d9-429e-aa9c-5a185bf33284","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01AWM7U5JsJmGVyHd6DKUNHg","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01K28z7M3LqPRysJuwvXuxM8","name":"Read","input":{"file_path":"/home/aiscend/work/fortune_ai/services/glm_client.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":1765,"cache_read_input_tokens":20983,"cache_creation":{"ephemeral_5m_input_tokens":1765,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrmfWEQwTiRnK3aTPCM","type":"assistant","uuid":"2de5176f-418e-43a8-a374-188a7a36970a","timestamp":"2026-01-01T15:01:09.082Z"}
{"parentUuid":"2de5176f-418e-43a8-a374-188a7a36970a","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01AWM7U5JsJmGVyHd6DKUNHg","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01GZwQ1LfW3gcGvuGtc5eKDn","name":"Read","input":{"file_path":"/home/aiscend/work/fortune_ai/services/soul_os.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":1765,"cache_read_input_tokens":20983,"cache_creation":{"ephemeral_5m_input_tokens":1765,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrmfWEQwTiRnK3aTPCM","type":"assistant","uuid":"d9cad52e-5f81-445b-951f-6e3059bbceec","timestamp":"2026-01-01T15:01:09.433Z"}
{"parentUuid":"d9cad52e-5f81-445b-951f-6e3059bbceec","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01AWM7U5JsJmGVyHd6DKUNHg","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01MAcYEyXp14Rh9jfBj4j2Rg","name":"Read","input":{"file_path":"/home/aiscend/work/fortune_ai/services/bazi_facts.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":1765,"cache_read_input_tokens":20983,"cache_creation":{"ephemeral_5m_input_tokens":1765,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrmfWEQwTiRnK3aTPCM","type":"assistant","uuid":"70c61785-08a5-407f-9cbb-90b87e312d2e","timestamp":"2026-01-01T15:01:09.624Z"}
{"parentUuid":"70c61785-08a5-407f-9cbb-90b87e312d2e","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01AWM7U5JsJmGVyHd6DKUNHg","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01DCe5XTJwT7tjhZUJQsSgMe","name":"Read","input":{"file_path":"/home/aiscend/work/fortune_ai/services/bazi_engine.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":1765,"cache_read_input_tokens":20983,"cache_creation":{"ephemeral_5m_input_tokens":1765,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrmfWEQwTiRnK3aTPCM","type":"assistant","uuid":"b1b6ecd2-fc24-404a-b7d8-20e72d733d80","timestamp":"2026-01-01T15:01:09.758Z"}
{"parentUuid":"b1b6ecd2-fc24-404a-b7d8-20e72d733d80","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01AWM7U5JsJmGVyHd6DKUNHg","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PQApcDcimwsc9tGHjkiNYW","name":"Read","input":{"file_path":"/home/aiscend/work/fortune_ai/services/twin_service.py"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":5,"cache_creation_input_tokens":1765,"cache_read_input_tokens":20983,"cache_creation":{"ephemeral_5m_input_tokens":1765,"ephemeral_1h_input_tokens":0},"output_tokens":307,"service_tier":"standard"}},"requestId":"req_011CWgrmfWEQwTiRnK3aTPCM","type":"assistant","uuid":"06c97f2e-9a73-43d2-86c0-f6e898efd51e","timestamp":"2026-01-01T15:01:09.782Z"}
{"parentUuid":"06c97f2e-9a73-43d2-86c0-f6e898efd51e","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01K28z7M3LqPRysJuwvXuxM8","type":"tool_result","content":"     1→from __future__ import annotations\n     2→\n     3→import json\n     4→import os\n     5→from typing import Any, Dict, Iterable, List, Optional, Tuple\n     6→\n     7→import httpx\n     8→\n     9→\n    10→class GlmError(RuntimeError):\n    11→    pass\n    12→\n    13→\n    14→def _env(name: str) -> str:\n    15→    v = (os.getenv(name) or \"\").strip()\n    16→    if not v:\n    17→        raise GlmError(f\"missing_env:{name}\")\n    18→    return v\n    19→\n    20→\n    21→def call_chat_completions(\n    22→    *,\n    23→    messages: List[Dict[str, Any]],\n    24→    model: Optional[str] = None,\n    25→    max_tokens: int = 1200,\n    26→    temperature: float = 0.6,\n    27→    timeout_s: float = 120.0,\n    28→) -> Tuple[str, Dict[str, Any]]:\n    29→    \"\"\"Call Z.AI GLM OpenAI-compatible Chat Completions endpoint.\n    30→\n    31→    Docs: https://docs.z.ai/guides/llm/glm-4.5\n    32→    \"\"\"\n    33→    base_url = (os.getenv(\"GLM_BASE_URL\") or \"https://api.z.ai/api/paas/v4\").rstrip(\"/\")\n    34→    api_key = (os.getenv(\"GLM_API_KEY\") or os.getenv(\"ZAI_GLM_KEY\") or os.getenv(\"ANTHROPIC_AUTH_TOKEN\") or \"\").strip()\n    35→    if not api_key:\n    36→        raise GlmError(\"missing_env:GLM_API_KEY_OR_ZAI_GLM_KEY\")\n    37→    model_name = (model or os.getenv(\"FORTUNE_AI_GLM_MODEL\") or \"\").strip() or \"glm-4.7\"\n    38→    thinking_type = (os.getenv(\"FORTUNE_AI_GLM_THINKING\") or \"disabled\").strip().lower()\n    39→    if thinking_type not in (\"enabled\", \"disabled\"):\n    40→        thinking_type = \"disabled\"\n    41→\n    42→    url = f\"{base_url}/chat/completions\"\n    43→    headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {api_key}\"}\n    44→\n    45→    def _post(payload: Dict[str, Any]) -> Dict[str, Any]:\n    46→        try:\n    47→            with httpx.Client(timeout=timeout_s) as client:\n    48→                resp = client.post(url, headers=headers, json=payload)\n    49→        except httpx.RequestError as e:\n    50→            raise GlmError(f\"glm_request_error:{type(e).__name__}:{str(e)[:200]}\")\n    51→\n    52→        if resp.status_code >= 400:\n    53→            try:\n    54→                j = resp.json()\n    55→            except Exception:\n    56→                j = None\n    57→            msg = \"\"\n    58→            if isinstance(j, dict):\n    59→                err = j.get(\"error\")\n    60→                if isinstance(err, dict) and err.get(\"message\"):\n    61→                    msg = str(err.get(\"message\") or \"\")\n    62→            msg = msg or (resp.text or \"\")[:200]\n    63→            raise GlmError(f\"glm_http_error:{resp.status_code}:{msg}\")\n    64→\n    65→        try:\n    66→            return resp.json()\n    67→        except Exception:\n    68→            raise GlmError(f\"glm_invalid_response:non_json:{(resp.text or '')[:200]}\")\n    69→\n    70→    def _extract_text(data: Dict[str, Any]) -> Tuple[str, str]:\n    71→        choices = data.get(\"choices\")\n    72→        if not isinstance(choices, list) or not choices:\n    73→            raise GlmError(\"glm_invalid_response:no_choices\")\n    74→        first = choices[0]\n    75→        if not isinstance(first, dict):\n    76→            raise GlmError(\"glm_invalid_response:invalid_choice\")\n    77→        msg = first.get(\"message\")\n    78→        if not isinstance(msg, dict):\n    79→            raise GlmError(\"glm_invalid_response:missing_message\")\n    80→        content = msg.get(\"content\")\n    81→        reasoning = msg.get(\"reasoning_content\")\n    82→        if isinstance(content, str) and content.strip():\n    83→            return content.strip(), str(reasoning or \"\")\n    84→        if isinstance(content, list):\n    85→            # Some OpenAI-compatible variants may return content as a list of parts.\n    86→            parts: list[str] = []\n    87→            for p in content:\n    88→                if isinstance(p, str):\n    89→                    parts.append(p)\n    90→                elif isinstance(p, dict) and isinstance(p.get(\"text\"), str):\n    91→                    parts.append(str(p.get(\"text\") or \"\"))\n    92→            text = \"\".join(parts).strip()\n    93→            if text:\n    94→                return text, str(reasoning or \"\")\n    95→        return \"\", str(reasoning or \"\")\n    96→\n    97→    payload = {\n    98→        \"model\": model_name,\n    99→        \"max_tokens\": int(max_tokens),\n   100→        \"temperature\": float(temperature),\n   101→        \"stream\": False,\n   102→        \"thinking\": {\"type\": thinking_type},\n   103→        \"messages\": messages,\n   104→    }\n   105→    data = _post(payload)\n   106→    text, reasoning = _extract_text(data)\n   107→    if text:\n   108→        return text, data\n   109→    if reasoning and thinking_type == \"enabled\":\n   110→        # Z.AI returns reasoning_content without final content when thinking is enabled.\n   111→        payload_fallback = dict(payload)\n   112→        payload_fallback[\"thinking\"] = {\"type\": \"disabled\"}\n   113→        data_fallback = _post(payload_fallback)\n   114→        text_fallback, _ = _extract_text(data_fallback)\n   115→        if text_fallback:\n   116→            return text_fallback, data_fallback\n   117→    raise GlmError(\"glm_invalid_response:empty_content\")\n   118→\n   119→\n   120→def call_messages_api(\n   121→    *,\n   122→    system: str,\n   123→    messages: List[Dict[str, Any]],\n   124→    model: Optional[str] = None,\n   125→    max_tokens: int = 1200,\n   126→    temperature: float = 0.6,\n   127→    timeout_s: float = 120.0,\n   128→) -> Tuple[str, Dict[str, Any]]:\n   129→    \"\"\"Backward-compatible shim for older Anthropic-style callers.\n   130→\n   131→    It converts `system` + anthropic-style `messages` into OpenAI-style messages\n   132→    and calls Z.AI GLM Chat Completions.\n   133→    \"\"\"\n   134→    out: List[Dict[str, Any]] = [{\"role\": \"system\", \"content\": (system or \"\").strip()}]\n   135→    for m in messages or []:\n   136→        if not isinstance(m, dict):\n   137→            continue\n   138→        role = str(m.get(\"role\") or \"user\")\n   139→        content = m.get(\"content\")\n   140→        if isinstance(content, list):\n   141→            parts: list[str] = []\n   142→            for blk in content:\n   143→                if isinstance(blk, dict) and blk.get(\"type\") == \"text\" and isinstance(blk.get(\"text\"), str):\n   144→                    parts.append(str(blk.get(\"text\") or \"\"))\n   145→            content_s = \"\".join(parts).strip()\n   146→        else:\n   147→            content_s = str(content or \"\").strip()\n   148→        out.append({\"role\": role, \"content\": content_s})\n   149→    return call_chat_completions(\n   150→        messages=out,\n   151→        model=model,\n   152→        max_tokens=max_tokens,\n   153→        temperature=temperature,\n   154→        timeout_s=timeout_s,\n   155→    )\n   156→\n   157→\n   158→def extract_json_object(text: str) -> Optional[Dict[str, Any]]:\n   159→    s = (text or \"\").strip()\n   160→    if not s:\n   161→        return None\n   162→    # Fast path: whole response is JSON\n   163→    if s.startswith(\"{\") and s.endswith(\"}\"):\n   164→        try:\n   165→            obj = json.loads(s)\n   166→            return obj if isinstance(obj, dict) else None\n   167→        except Exception:\n   168→            pass\n   169→    # Best-effort: find first {...} JSON object\n   170→    start = s.find(\"{\")\n   171→    if start < 0:\n   172→        return None\n   173→    depth = 0\n   174→    in_str = False\n   175→    esc = False\n   176→    for i in range(start, len(s)):\n   177→        ch = s[i]\n   178→        if in_str:\n   179→            if esc:\n   180→                esc = False\n   181→            elif ch == \"\\\\\":\n   182→                esc = True\n   183→            elif ch == \"\\\"\":\n   184→                in_str = False\n   185→            continue\n   186→        if ch == \"\\\"\":\n   187→            in_str = True\n   188→            continue\n   189→        if ch == \"{\":\n   190→            depth += 1\n   191→        elif ch == \"}\":\n   192→            depth -= 1\n   193→            if depth == 0:\n   194→                frag = s[start : i + 1]\n   195→                try:\n   196→                    obj = json.loads(frag)\n   197→                    return obj if isinstance(obj, dict) else None\n   198→                except Exception:\n   199→                    return None\n   200→    return None\n   201→\n   202→\n   203→def stream_chat_completions(\n   204→    *,\n   205→    messages: List[Dict[str, Any]],\n   206→    model: Optional[str] = None,\n   207→    max_tokens: int = 1200,\n   208→    temperature: float = 0.6,\n   209→    timeout_s: float = 300.0,\n   210→) -> Iterable[str]:\n   211→    \"\"\"\n   212→    Stream text deltas from Z.AI GLM OpenAI-compatible Chat Completions endpoint.\n   213→\n   214→    Yields incremental `content` strings as they arrive.\n   215→    \"\"\"\n   216→    base_url = (os.getenv(\"GLM_BASE_URL\") or \"https://api.z.ai/api/paas/v4\").rstrip(\"/\")\n   217→    api_key = (os.getenv(\"GLM_API_KEY\") or os.getenv(\"ZAI_GLM_KEY\") or os.getenv(\"ANTHROPIC_AUTH_TOKEN\") or \"\").strip()\n   218→    if not api_key:\n   219→        raise GlmError(\"missing_env:GLM_API_KEY_OR_ZAI_GLM_KEY\")\n   220→\n   221→    model_name = (model or os.getenv(\"FORTUNE_AI_GLM_MODEL\") or \"\").strip() or \"glm-4.7\"\n   222→    thinking_type = (os.getenv(\"FORTUNE_AI_GLM_THINKING\") or \"disabled\").strip().lower()\n   223→    if thinking_type not in (\"enabled\", \"disabled\"):\n   224→        thinking_type = \"disabled\"\n   225→\n   226→    url = f\"{base_url}/chat/completions\"\n   227→    headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {api_key}\"}\n   228→\n   229→    payload = {\n   230→        \"model\": model_name,\n   231→        \"max_tokens\": int(max_tokens),\n   232→        \"temperature\": float(temperature),\n   233→        \"stream\": True,\n   234→        \"thinking\": {\"type\": thinking_type},\n   235→        \"messages\": messages,\n   236→    }\n   237→\n   238→    timeout = httpx.Timeout(timeout_s, connect=10.0)\n   239→    try:\n   240→        with httpx.Client(timeout=timeout) as client:\n   241→            with client.stream(\"POST\", url, headers=headers, json=payload) as resp:\n   242→                if resp.status_code >= 400:\n   243→                    try:\n   244→                        j = resp.json()\n   245→                    except Exception:\n   246→                        j = None\n   247→                    msg = \"\"\n   248→                    if isinstance(j, dict):\n   249→                        err = j.get(\"error\")\n   250→                        if isinstance(err, dict) and err.get(\"message\"):\n   251→                            msg = str(err.get(\"message\") or \"\")\n   252→                    msg = msg or (resp.text or \"\")[:200]\n   253→                    raise GlmError(f\"glm_http_error:{resp.status_code}:{msg}\")\n   254→\n   255→                for raw_line in resp.iter_lines():\n   256→                    line = (raw_line or \"\").strip()\n   257→                    if not line:\n   258→                        continue\n   259→                    if not line.startswith(\"data:\"):\n   260→                        continue\n   261→                    data = line[5:].strip()\n   262→                    if not data:\n   263→                        continue\n   264→                    if data == \"[DONE]\":\n   265→                        break\n   266→                    try:\n   267→                        obj = json.loads(data)\n   268→                    except Exception:\n   269→                        continue\n   270→\n   271→                    choices = obj.get(\"choices\")\n   272→                    if not isinstance(choices, list) or not choices:\n   273→                        continue\n   274→                    first = choices[0] if isinstance(choices[0], dict) else None\n   275→                    if not first:\n   276→                        continue\n   277→\n   278→                    delta = first.get(\"delta\") if isinstance(first.get(\"delta\"), dict) else {}\n   279→                    content = delta.get(\"content\")\n   280→                    if isinstance(content, str) and content:\n   281→                        yield content\n   282→                        continue\n   283→\n   284→                    # Tolerate alternative formats (some providers use message/content)\n   285→                    msg = first.get(\"message\") if isinstance(first.get(\"message\"), dict) else {}\n   286→                    content2 = msg.get(\"content\")\n   287→                    if isinstance(content2, str) and content2:\n   288→                        yield content2\n   289→\n   290→    except httpx.RequestError as e:\n   291→        raise GlmError(f\"glm_request_error:{type(e).__name__}:{str(e)[:200]}\")\n   292→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"702c513d-63ee-4f75-8cb8-362edf6bc7e4","timestamp":"2026-01-01T15:01:09.988Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aiscend/work/fortune_ai/services/glm_client.py","content":"from __future__ import annotations\n\nimport json\nimport os\nfrom typing import Any, Dict, Iterable, List, Optional, Tuple\n\nimport httpx\n\n\nclass GlmError(RuntimeError):\n    pass\n\n\ndef _env(name: str) -> str:\n    v = (os.getenv(name) or \"\").strip()\n    if not v:\n        raise GlmError(f\"missing_env:{name}\")\n    return v\n\n\ndef call_chat_completions(\n    *,\n    messages: List[Dict[str, Any]],\n    model: Optional[str] = None,\n    max_tokens: int = 1200,\n    temperature: float = 0.6,\n    timeout_s: float = 120.0,\n) -> Tuple[str, Dict[str, Any]]:\n    \"\"\"Call Z.AI GLM OpenAI-compatible Chat Completions endpoint.\n\n    Docs: https://docs.z.ai/guides/llm/glm-4.5\n    \"\"\"\n    base_url = (os.getenv(\"GLM_BASE_URL\") or \"https://api.z.ai/api/paas/v4\").rstrip(\"/\")\n    api_key = (os.getenv(\"GLM_API_KEY\") or os.getenv(\"ZAI_GLM_KEY\") or os.getenv(\"ANTHROPIC_AUTH_TOKEN\") or \"\").strip()\n    if not api_key:\n        raise GlmError(\"missing_env:GLM_API_KEY_OR_ZAI_GLM_KEY\")\n    model_name = (model or os.getenv(\"FORTUNE_AI_GLM_MODEL\") or \"\").strip() or \"glm-4.7\"\n    thinking_type = (os.getenv(\"FORTUNE_AI_GLM_THINKING\") or \"disabled\").strip().lower()\n    if thinking_type not in (\"enabled\", \"disabled\"):\n        thinking_type = \"disabled\"\n\n    url = f\"{base_url}/chat/completions\"\n    headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {api_key}\"}\n\n    def _post(payload: Dict[str, Any]) -> Dict[str, Any]:\n        try:\n            with httpx.Client(timeout=timeout_s) as client:\n                resp = client.post(url, headers=headers, json=payload)\n        except httpx.RequestError as e:\n            raise GlmError(f\"glm_request_error:{type(e).__name__}:{str(e)[:200]}\")\n\n        if resp.status_code >= 400:\n            try:\n                j = resp.json()\n            except Exception:\n                j = None\n            msg = \"\"\n            if isinstance(j, dict):\n                err = j.get(\"error\")\n                if isinstance(err, dict) and err.get(\"message\"):\n                    msg = str(err.get(\"message\") or \"\")\n            msg = msg or (resp.text or \"\")[:200]\n            raise GlmError(f\"glm_http_error:{resp.status_code}:{msg}\")\n\n        try:\n            return resp.json()\n        except Exception:\n            raise GlmError(f\"glm_invalid_response:non_json:{(resp.text or '')[:200]}\")\n\n    def _extract_text(data: Dict[str, Any]) -> Tuple[str, str]:\n        choices = data.get(\"choices\")\n        if not isinstance(choices, list) or not choices:\n            raise GlmError(\"glm_invalid_response:no_choices\")\n        first = choices[0]\n        if not isinstance(first, dict):\n            raise GlmError(\"glm_invalid_response:invalid_choice\")\n        msg = first.get(\"message\")\n        if not isinstance(msg, dict):\n            raise GlmError(\"glm_invalid_response:missing_message\")\n        content = msg.get(\"content\")\n        reasoning = msg.get(\"reasoning_content\")\n        if isinstance(content, str) and content.strip():\n            return content.strip(), str(reasoning or \"\")\n        if isinstance(content, list):\n            # Some OpenAI-compatible variants may return content as a list of parts.\n            parts: list[str] = []\n            for p in content:\n                if isinstance(p, str):\n                    parts.append(p)\n                elif isinstance(p, dict) and isinstance(p.get(\"text\"), str):\n                    parts.append(str(p.get(\"text\") or \"\"))\n            text = \"\".join(parts).strip()\n            if text:\n                return text, str(reasoning or \"\")\n        return \"\", str(reasoning or \"\")\n\n    payload = {\n        \"model\": model_name,\n        \"max_tokens\": int(max_tokens),\n        \"temperature\": float(temperature),\n        \"stream\": False,\n        \"thinking\": {\"type\": thinking_type},\n        \"messages\": messages,\n    }\n    data = _post(payload)\n    text, reasoning = _extract_text(data)\n    if text:\n        return text, data\n    if reasoning and thinking_type == \"enabled\":\n        # Z.AI returns reasoning_content without final content when thinking is enabled.\n        payload_fallback = dict(payload)\n        payload_fallback[\"thinking\"] = {\"type\": \"disabled\"}\n        data_fallback = _post(payload_fallback)\n        text_fallback, _ = _extract_text(data_fallback)\n        if text_fallback:\n            return text_fallback, data_fallback\n    raise GlmError(\"glm_invalid_response:empty_content\")\n\n\ndef call_messages_api(\n    *,\n    system: str,\n    messages: List[Dict[str, Any]],\n    model: Optional[str] = None,\n    max_tokens: int = 1200,\n    temperature: float = 0.6,\n    timeout_s: float = 120.0,\n) -> Tuple[str, Dict[str, Any]]:\n    \"\"\"Backward-compatible shim for older Anthropic-style callers.\n\n    It converts `system` + anthropic-style `messages` into OpenAI-style messages\n    and calls Z.AI GLM Chat Completions.\n    \"\"\"\n    out: List[Dict[str, Any]] = [{\"role\": \"system\", \"content\": (system or \"\").strip()}]\n    for m in messages or []:\n        if not isinstance(m, dict):\n            continue\n        role = str(m.get(\"role\") or \"user\")\n        content = m.get(\"content\")\n        if isinstance(content, list):\n            parts: list[str] = []\n            for blk in content:\n                if isinstance(blk, dict) and blk.get(\"type\") == \"text\" and isinstance(blk.get(\"text\"), str):\n                    parts.append(str(blk.get(\"text\") or \"\"))\n            content_s = \"\".join(parts).strip()\n        else:\n            content_s = str(content or \"\").strip()\n        out.append({\"role\": role, \"content\": content_s})\n    return call_chat_completions(\n        messages=out,\n        model=model,\n        max_tokens=max_tokens,\n        temperature=temperature,\n        timeout_s=timeout_s,\n    )\n\n\ndef extract_json_object(text: str) -> Optional[Dict[str, Any]]:\n    s = (text or \"\").strip()\n    if not s:\n        return None\n    # Fast path: whole response is JSON\n    if s.startswith(\"{\") and s.endswith(\"}\"):\n        try:\n            obj = json.loads(s)\n            return obj if isinstance(obj, dict) else None\n        except Exception:\n            pass\n    # Best-effort: find first {...} JSON object\n    start = s.find(\"{\")\n    if start < 0:\n        return None\n    depth = 0\n    in_str = False\n    esc = False\n    for i in range(start, len(s)):\n        ch = s[i]\n        if in_str:\n            if esc:\n                esc = False\n            elif ch == \"\\\\\":\n                esc = True\n            elif ch == \"\\\"\":\n                in_str = False\n            continue\n        if ch == \"\\\"\":\n            in_str = True\n            continue\n        if ch == \"{\":\n            depth += 1\n        elif ch == \"}\":\n            depth -= 1\n            if depth == 0:\n                frag = s[start : i + 1]\n                try:\n                    obj = json.loads(frag)\n                    return obj if isinstance(obj, dict) else None\n                except Exception:\n                    return None\n    return None\n\n\ndef stream_chat_completions(\n    *,\n    messages: List[Dict[str, Any]],\n    model: Optional[str] = None,\n    max_tokens: int = 1200,\n    temperature: float = 0.6,\n    timeout_s: float = 300.0,\n) -> Iterable[str]:\n    \"\"\"\n    Stream text deltas from Z.AI GLM OpenAI-compatible Chat Completions endpoint.\n\n    Yields incremental `content` strings as they arrive.\n    \"\"\"\n    base_url = (os.getenv(\"GLM_BASE_URL\") or \"https://api.z.ai/api/paas/v4\").rstrip(\"/\")\n    api_key = (os.getenv(\"GLM_API_KEY\") or os.getenv(\"ZAI_GLM_KEY\") or os.getenv(\"ANTHROPIC_AUTH_TOKEN\") or \"\").strip()\n    if not api_key:\n        raise GlmError(\"missing_env:GLM_API_KEY_OR_ZAI_GLM_KEY\")\n\n    model_name = (model or os.getenv(\"FORTUNE_AI_GLM_MODEL\") or \"\").strip() or \"glm-4.7\"\n    thinking_type = (os.getenv(\"FORTUNE_AI_GLM_THINKING\") or \"disabled\").strip().lower()\n    if thinking_type not in (\"enabled\", \"disabled\"):\n        thinking_type = \"disabled\"\n\n    url = f\"{base_url}/chat/completions\"\n    headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {api_key}\"}\n\n    payload = {\n        \"model\": model_name,\n        \"max_tokens\": int(max_tokens),\n        \"temperature\": float(temperature),\n        \"stream\": True,\n        \"thinking\": {\"type\": thinking_type},\n        \"messages\": messages,\n    }\n\n    timeout = httpx.Timeout(timeout_s, connect=10.0)\n    try:\n        with httpx.Client(timeout=timeout) as client:\n            with client.stream(\"POST\", url, headers=headers, json=payload) as resp:\n                if resp.status_code >= 400:\n                    try:\n                        j = resp.json()\n                    except Exception:\n                        j = None\n                    msg = \"\"\n                    if isinstance(j, dict):\n                        err = j.get(\"error\")\n                        if isinstance(err, dict) and err.get(\"message\"):\n                            msg = str(err.get(\"message\") or \"\")\n                    msg = msg or (resp.text or \"\")[:200]\n                    raise GlmError(f\"glm_http_error:{resp.status_code}:{msg}\")\n\n                for raw_line in resp.iter_lines():\n                    line = (raw_line or \"\").strip()\n                    if not line:\n                        continue\n                    if not line.startswith(\"data:\"):\n                        continue\n                    data = line[5:].strip()\n                    if not data:\n                        continue\n                    if data == \"[DONE]\":\n                        break\n                    try:\n                        obj = json.loads(data)\n                    except Exception:\n                        continue\n\n                    choices = obj.get(\"choices\")\n                    if not isinstance(choices, list) or not choices:\n                        continue\n                    first = choices[0] if isinstance(choices[0], dict) else None\n                    if not first:\n                        continue\n\n                    delta = first.get(\"delta\") if isinstance(first.get(\"delta\"), dict) else {}\n                    content = delta.get(\"content\")\n                    if isinstance(content, str) and content:\n                        yield content\n                        continue\n\n                    # Tolerate alternative formats (some providers use message/content)\n                    msg = first.get(\"message\") if isinstance(first.get(\"message\"), dict) else {}\n                    content2 = msg.get(\"content\")\n                    if isinstance(content2, str) and content2:\n                        yield content2\n\n    except httpx.RequestError as e:\n        raise GlmError(f\"glm_request_error:{type(e).__name__}:{str(e)[:200]}\")\n","numLines":292,"startLine":1,"totalLines":292}}}
{"parentUuid":"702c513d-63ee-4f75-8cb8-362edf6bc7e4","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01MAcYEyXp14Rh9jfBj4j2Rg","type":"tool_result","content":"     1→from __future__ import annotations\n     2→\n     3→import hashlib\n     4→import json\n     5→from dataclasses import dataclass\n     6→from datetime import date, datetime, timedelta, timezone\n     7→from typing import Any, Dict, List, Optional, Tuple\n     8→\n     9→import swisseph as swe\n    10→from lunar_python import LunarYear, Solar\n    11→\n    12→from common.logging import get_logger\n    13→from stores import fortune_db\n    14→\n    15→\n    16→logger = get_logger(__name__)\n    17→\n    18→\n    19→BAZI_FACTS_VERSION = \"bazi-tts-v1\"\n    20→\n    21→_DAY_GAN_ELEMENT = {\n    22→    \"甲\": \"木\",\n    23→    \"乙\": \"木\",\n    24→    \"丙\": \"火\",\n    25→    \"丁\": \"火\",\n    26→    \"戊\": \"土\",\n    27→    \"己\": \"土\",\n    28→    \"庚\": \"金\",\n    29→    \"辛\": \"金\",\n    30→    \"壬\": \"水\",\n    31→    \"癸\": \"水\",\n    32→}\n    33→\n    34→_MONTH_BRANCH_SEASON_ELEMENT = {\n    35→    \"寅\": \"木\",\n    36→    \"卯\": \"木\",\n    37→    \"辰\": \"木\",\n    38→    \"巳\": \"火\",\n    39→    \"午\": \"火\",\n    40→    \"未\": \"火\",\n    41→    \"申\": \"金\",\n    42→    \"酉\": \"金\",\n    43→    \"戌\": \"金\",\n    44→    \"亥\": \"水\",\n    45→    \"子\": \"水\",\n    46→    \"丑\": \"水\",\n    47→}\n    48→\n    49→_ELEMENT_REL = {\n    50→    \"木\": {\"generator\": \"水\", \"produces\": \"火\", \"controls\": \"土\", \"controlled_by\": \"金\"},\n    51→    \"火\": {\"generator\": \"木\", \"produces\": \"土\", \"controls\": \"金\", \"controlled_by\": \"水\"},\n    52→    \"土\": {\"generator\": \"火\", \"produces\": \"金\", \"controls\": \"水\", \"controlled_by\": \"木\"},\n    53→    \"金\": {\"generator\": \"土\", \"produces\": \"水\", \"controls\": \"木\", \"controlled_by\": \"火\"},\n    54→    \"水\": {\"generator\": \"金\", \"produces\": \"木\", \"controls\": \"火\", \"controlled_by\": \"土\"},\n    55→}\n    56→\n    57→_SHENSHA_SANHE_GROUPS = [\n    58→    (\"申子辰\", {\"taohua\": \"酉\", \"yima\": \"寅\", \"huagai\": \"辰\"}),\n    59→    (\"亥卯未\", {\"taohua\": \"子\", \"yima\": \"巳\", \"huagai\": \"未\"}),\n    60→    (\"寅午戌\", {\"taohua\": \"卯\", \"yima\": \"申\", \"huagai\": \"戌\"}),\n    61→    (\"巳酉丑\", {\"taohua\": \"午\", \"yima\": \"亥\", \"huagai\": \"丑\"}),\n    62→]\n    63→\n    64→_TIANYI_BY_DAY_GAN = {\n    65→    \"甲\": [\"丑\", \"未\"],\n    66→    \"戊\": [\"丑\", \"未\"],\n    67→    \"庚\": [\"丑\", \"未\"],\n    68→    \"乙\": [\"子\", \"申\"],\n    69→    \"己\": [\"子\", \"申\"],\n    70→    \"丙\": [\"亥\", \"酉\"],\n    71→    \"丁\": [\"亥\", \"酉\"],\n    72→    \"辛\": [\"寅\", \"午\"],\n    73→    \"壬\": [\"卯\", \"巳\"],\n    74→    \"癸\": [\"卯\", \"巳\"],\n    75→}\n    76→\n    77→_WENCHANG_BY_DAY_GAN = {\n    78→    \"甲\": [\"巳\", \"午\"],\n    79→    \"乙\": [\"巳\", \"午\"],\n    80→    \"丙\": [\"申\", \"酉\"],\n    81→    \"丁\": [\"申\", \"酉\"],\n    82→    \"戊\": [\"申\", \"酉\"],\n    83→    \"己\": [\"申\", \"酉\"],\n    84→    \"庚\": [\"亥\", \"子\"],\n    85→    \"辛\": [\"亥\", \"子\"],\n    86→    \"壬\": [\"寅\", \"卯\"],\n    87→    \"癸\": [\"寅\", \"卯\"],\n    88→}\n    89→\n    90→\n    91→def _dt_str(dt: datetime) -> str:\n    92→    return dt.replace(tzinfo=None).strftime(\"%Y-%m-%d %H:%M:%S\")\n    93→\n    94→\n    95→def _canonical_json(obj: Any) -> str:\n    96→    return json.dumps(obj, ensure_ascii=False, sort_keys=True, separators=(\",\", \":\"))\n    97→\n    98→\n    99→def _sha256_text(s: str) -> str:\n   100→    return \"sha256:\" + hashlib.sha256(s.encode(\"utf-8\")).hexdigest()\n   101→\n   102→\n   103→@dataclass(frozen=True)\n   104→class TrueSolarTime:\n   105→    tz_meridian_deg: float\n   106→    lon_corr_min: float\n   107→    eot_min: float\n   108→    true_solar_time_local: datetime\n   109→\n   110→\n   111→def compute_true_solar_time(\n   112→    *,\n   113→    birthday_local: datetime,\n   114→    tz_offset_hours: float,\n   115→    longitude: float,\n   116→) -> TrueSolarTime:\n   117→    tz_meridian_deg = float(tz_offset_hours) * 15.0\n   118→    lon_corr_min = (float(longitude) - tz_meridian_deg) * 4.0\n   119→\n   120→    birthday_utc = (birthday_local - timedelta(hours=float(tz_offset_hours))).replace(tzinfo=timezone.utc)\n   121→    hour_decimal_utc = (\n   122→        birthday_utc.hour\n   123→        + birthday_utc.minute / 60.0\n   124→        + birthday_utc.second / 3600.0\n   125→        + birthday_utc.microsecond / 3600.0 / 1_000_000.0\n   126→    )\n   127→    jd_ut = swe.julday(birthday_utc.year, birthday_utc.month, birthday_utc.day, hour_decimal_utc)\n   128→    eot_min = swe.time_equ(jd_ut) * 1440.0\n   129→\n   130→    corr_seconds = (lon_corr_min + eot_min) * 60.0\n   131→    t = birthday_local + timedelta(seconds=corr_seconds)\n   132→    true_solar_time_local = (t + timedelta(seconds=0.5)).replace(microsecond=0)  # round to nearest second\n   133→    return TrueSolarTime(\n   134→        tz_meridian_deg=tz_meridian_deg,\n   135→        lon_corr_min=lon_corr_min,\n   136→        eot_min=eot_min,\n   137→        true_solar_time_local=true_solar_time_local,\n   138→    )\n   139→\n   140→\n   141→def _wuxing_counts(wuxing: str) -> Dict[str, int]:\n   142→    out = {\"金\": 0, \"木\": 0, \"水\": 0, \"火\": 0, \"土\": 0}\n   143→    for k in out:\n   144→        out[k] = (wuxing or \"\").count(k)\n   145→    return out\n   146→\n   147→\n   148→def _season_bonus(\n   149→    *,\n   150→    month_branch: str,\n   151→    day_master_element: str,\n   152→) -> Tuple[str, int]:\n   153→    season_element = _MONTH_BRANCH_SEASON_ELEMENT.get(month_branch, \"\")\n   154→    if not season_element:\n   155→        return \"\", 0\n   156→    if season_element == day_master_element:\n   157→        return season_element, 2\n   158→    rel = _ELEMENT_REL[day_master_element]\n   159→    if season_element == rel[\"generator\"]:\n   160→        return season_element, 1\n   161→    if season_element == rel[\"controlled_by\"]:\n   162→        return season_element, -1\n   163→    if season_element == rel[\"controls\"]:\n   164→        return season_element, -1\n   165→    return season_element, 0\n   166→\n   167→\n   168→def _compute_strength(\n   169→    *,\n   170→    wuxing_count: Dict[str, int],\n   171→    month_branch: str,\n   172→    day_master_element: str,\n   173→) -> Dict[str, Any]:\n   174→    rel = _ELEMENT_REL[day_master_element]\n   175→    generator = rel[\"generator\"]\n   176→    produced = rel[\"produces\"]\n   177→    controlled_by = rel[\"controlled_by\"]\n   178→    controls = rel[\"controls\"]\n   179→\n   180→    support = int(wuxing_count.get(day_master_element, 0)) + int(wuxing_count.get(generator, 0))\n   181→    drain = int(wuxing_count.get(produced, 0)) + int(wuxing_count.get(controlled_by, 0))\n   182→    season_element, season_bonus = _season_bonus(month_branch=month_branch, day_master_element=day_master_element)\n   183→    score = int(support - drain + season_bonus)\n   184→\n   185→    if score >= 2:\n   186→        status = \"strong\"\n   187→        favorable = [produced, controls, controlled_by]\n   188→    elif score <= -2:\n   189→        status = \"weak\"\n   190→        favorable = [day_master_element, generator]\n   191→    else:\n   192→        status = \"neutral\"\n   193→        min_count = min(wuxing_count.values()) if wuxing_count else 0\n   194→        favorable = [k for k, v in wuxing_count.items() if v == min_count]\n   195→\n   196→    return {\n   197→        \"rule_id\": \"RULE-STRENGTH-SCORE-V1\",\n   198→        \"day_master_element\": day_master_element,\n   199→        \"generator_element\": generator,\n   200→        \"produced_element\": produced,\n   201→        \"controls_element\": controls,\n   202→        \"controlled_by_element\": controlled_by,\n   203→        \"season_element\": season_element,\n   204→        \"season_bonus\": season_bonus,\n   205→        \"support\": support,\n   206→        \"drain\": drain,\n   207→        \"score\": score,\n   208→        \"status\": status,\n   209→        \"favorable_elements\": favorable,\n   210→    }\n   211→\n   212→\n   213→def _branch_group_targets(branch: str) -> Dict[str, str]:\n   214→    for group, targets in _SHENSHA_SANHE_GROUPS:\n   215→        if branch in group:\n   216→            return targets\n   217→    return {}\n   218→\n   219→\n   220→def _compute_shensha(\n   221→    *,\n   222→    pillars: Dict[str, str],\n   223→    day_gan: str,\n   224→) -> List[Dict[str, Any]]:\n   225→    year_branch = pillars.get(\"year\", \"\")[1:2]\n   226→    day_branch = pillars.get(\"day\", \"\")[1:2]\n   227→    branches = [p[1:2] for p in pillars.values() if isinstance(p, str) and len(p) >= 2]\n   228→    branch_set = set(branches)\n   229→\n   230→    targets: Dict[str, str] = {}\n   231→    targets.update(_branch_group_targets(year_branch))\n   232→    targets.update(_branch_group_targets(day_branch))\n   233→\n   234→    taohua = targets.get(\"taohua\")\n   235→    yima = targets.get(\"yima\")\n   236→    huagai = targets.get(\"huagai\")\n   237→\n   238→    out: List[Dict[str, Any]] = [\n   239→        {\n   240→            \"name\": \"桃花\",\n   241→            \"rule_id\": \"RULE-SHENSHA-TAOHUA-V1\",\n   242→            \"hit\": bool(taohua and taohua in branch_set),\n   243→            \"note\": \"以日支/年支推咸池\",\n   244→        },\n   245→        {\n   246→            \"name\": \"驿马\",\n   247→            \"rule_id\": \"RULE-SHENSHA-YIMA-V1\",\n   248→            \"hit\": bool(yima and yima in branch_set),\n   249→            \"note\": \"以日支/年支推驿马\",\n   250→        },\n   251→        {\n   252→            \"name\": \"华盖\",\n   253→            \"rule_id\": \"RULE-SHENSHA-HUAGAI-V1\",\n   254→            \"hit\": bool(huagai and huagai in branch_set),\n   255→            \"note\": \"以日支/年支推华盖\",\n   256→        },\n   257→    ]\n   258→\n   259→    tianyi_targets = _TIANYI_BY_DAY_GAN.get(day_gan, [])\n   260→    out.append(\n   261→        {\n   262→            \"name\": \"天乙贵人\",\n   263→            \"rule_id\": \"RULE-SHENSHA-TIANYI-V1\",\n   264→            \"hit\": any(b in branch_set for b in tianyi_targets),\n   265→            \"note\": \"以日干推贵人\",\n   266→        }\n   267→    )\n   268→    wenchang_targets = _WENCHANG_BY_DAY_GAN.get(day_gan, [])\n   269→    out.append(\n   270→        {\n   271→            \"name\": \"文昌\",\n   272→            \"rule_id\": \"RULE-SHENSHA-WENCHANG-V1\",\n   273→            \"hit\": any(b in branch_set for b in wenchang_targets),\n   274→            \"note\": \"以日干推文昌\",\n   275→        }\n   276→    )\n   277→    return out\n   278→\n   279→\n   280→def _compute_luck(*, eight_char, gender: str) -> Dict[str, Any]:\n   281→    gender_code = 1 if gender == \"男\" else 0\n   282→    yun = eight_char.getYun(gender_code)\n   283→    forward = bool(yun.isForward())\n   284→    start_age_year = int(yun.getStartYear())\n   285→\n   286→    da_yun_items: List[Dict[str, Any]] = []\n   287→    for dy in yun.getDaYun(10) or []:\n   288→        gz = str(dy.getGanZhi() or \"\")\n   289→        if not gz:\n   290→            continue\n   291→        da_yun_items.append(\n   292→            {\n   293→                \"start_age\": int(dy.getStartAge()),\n   294→                \"end_age\": int(dy.getEndAge()),\n   295→                \"start_year\": int(dy.getStartYear()),\n   296→                \"end_year\": int(dy.getEndYear()),\n   297→                \"gan_zhi\": gz,\n   298→                \"xun\": str(dy.getXun() or \"\"),\n   299→                \"xun_kong\": str(dy.getXunKong() or \"\"),\n   300→            }\n   301→        )\n   302→\n   303→    for idx, item in enumerate(da_yun_items, start=1):\n   304→        item[\"index\"] = idx\n   305→\n   306→    this_year = datetime.now().year\n   307→    liu_nian_next5 = [{\"year\": y, \"gan_zhi\": LunarYear.fromYear(y).getGanZhi()} for y in range(this_year + 1, this_year + 6)]\n   308→\n   309→    return {\n   310→        \"forward\": forward,\n   311→        \"start_age_year\": start_age_year,\n   312→        \"da_yun\": da_yun_items,\n   313→        \"liu_nian_next5\": liu_nian_next5,\n   314→    }\n   315→\n   316→\n   317→def compute_facts(\n   318→    *,\n   319→    name: str,\n   320→    gender: str,\n   321→    birthday_local: datetime,\n   322→    tz_offset_hours: float,\n   323→    location: Dict[str, Any],\n   324→) -> Dict[str, Any]:\n   325→    if gender not in (\"男\", \"女\"):\n   326→        raise ValueError(\"invalid_gender\")\n   327→    longitude = float(location[\"longitude\"])\n   328→    latitude = float(location[\"latitude\"])\n   329→\n   330→    solar_time = compute_true_solar_time(birthday_local=birthday_local, tz_offset_hours=float(tz_offset_hours), longitude=longitude)\n   331→    ts = solar_time.true_solar_time_local\n   332→\n   333→    solar = Solar.fromYmdHms(ts.year, ts.month, ts.day, ts.hour, ts.minute, ts.second)\n   334→    lunar = solar.getLunar()\n   335→    eight = lunar.getEightChar()\n   336→\n   337→    pillars = {\"year\": eight.getYear(), \"month\": eight.getMonth(), \"day\": eight.getDay(), \"hour\": eight.getTime()}\n   338→    wuxing_concat = str(eight.getYearWuXing() or \"\") + str(eight.getMonthWuXing() or \"\") + str(eight.getDayWuXing() or \"\") + str(eight.getTimeWuXing() or \"\")\n   339→    wuxing_count = _wuxing_counts(wuxing_concat)\n   340→\n   341→    day_gan = pillars[\"day\"][0:1]\n   342→    day_master_element = _DAY_GAN_ELEMENT.get(day_gan, \"\")\n   343→    month_branch = pillars[\"month\"][1:2]\n   344→\n   345→    facts_base: Dict[str, Any] = {\n   346→        \"profile\": {\n   347→            \"name\": str(name),\n   348→            \"gender\": gender,\n   349→            \"birthday_local\": _dt_str(birthday_local),\n   350→            \"tz_offset_hours\": float(tz_offset_hours),\n   351→            \"location\": {\"name\": str(location.get(\"name\") or \"\"), \"longitude\": longitude, \"latitude\": latitude},\n   352→        },\n   353→        \"solar_time\": {\n   354→            \"tz_meridian_deg\": round(float(solar_time.tz_meridian_deg), 4),\n   355→            \"lon_corr_min\": round(float(solar_time.lon_corr_min), 4),\n   356→            \"eot_min\": round(float(solar_time.eot_min), 4),\n   357→            \"true_solar_time_local\": _dt_str(ts),\n   358→        },\n   359→        \"bazi\": {\n   360→            \"pillars\": pillars,\n   361→            \"day_master\": {\"gan\": day_gan, \"element\": day_master_element},\n   362→            \"wuxing_count\": wuxing_count,\n   363→            \"shi_shen_gan\": {\n   364→                \"year\": str(eight.getYearShiShenGan() or \"\"),\n   365→                \"month\": str(eight.getMonthShiShenGan() or \"\"),\n   366→                \"day\": str(eight.getDayShiShenGan() or \"\"),\n   367→                \"hour\": str(eight.getTimeShiShenGan() or \"\"),\n   368→            },\n   369→            \"shi_shen_zhi\": {\n   370→                \"year\": list(eight.getYearShiShenZhi() or []),\n   371→                \"month\": list(eight.getMonthShiShenZhi() or []),\n   372→                \"day\": list(eight.getDayShiShenZhi() or []),\n   373→                \"hour\": list(eight.getTimeShiShenZhi() or []),\n   374→            },\n   375→            \"na_yin\": {\n   376→                \"year\": str(eight.getYearNaYin() or \"\"),\n   377→                \"month\": str(eight.getMonthNaYin() or \"\"),\n   378→                \"day\": str(eight.getDayNaYin() or \"\"),\n   379→                \"hour\": str(eight.getTimeNaYin() or \"\"),\n   380→            },\n   381→            \"di_shi\": {\n   382→                \"year\": str(eight.getYearDiShi() or \"\"),\n   383→                \"month\": str(eight.getMonthDiShi() or \"\"),\n   384→                \"day\": str(eight.getDayDiShi() or \"\"),\n   385→                \"hour\": str(eight.getTimeDiShi() or \"\"),\n   386→            },\n   387→            \"luck\": _compute_luck(eight_char=eight, gender=gender),\n   388→            \"strength\": _compute_strength(wuxing_count=wuxing_count, month_branch=month_branch, day_master_element=day_master_element),\n   389→            \"shensha\": _compute_shensha(pillars=pillars, day_gan=day_gan),\n   390→        },\n   391→        \"version\": {\"compute_version\": BAZI_FACTS_VERSION},\n   392→    }\n   393→\n   394→    facts_hash = _sha256_text(_canonical_json(facts_base))\n   395→    facts_base[\"version\"][\"facts_hash\"] = facts_hash\n   396→    return facts_base\n   397→\n   398→\n   399→def make_bazi_digest(facts: Dict[str, Any]) -> str:\n   400→    try:\n   401→        pillars = facts.get(\"bazi\", {}).get(\"pillars\", {})\n   402→        y = str(pillars.get(\"year\") or \"\")\n   403→        m = str(pillars.get(\"month\") or \"\")\n   404→        d = str(pillars.get(\"day\") or \"\")\n   405→        h = str(pillars.get(\"hour\") or \"\")\n   406→        dm = facts.get(\"bazi\", {}).get(\"day_master\", {})\n   407→        dm_gan = str(dm.get(\"gan\") or \"\")\n   408→        dm_el = str(dm.get(\"element\") or \"\")\n   409→        strength = facts.get(\"bazi\", {}).get(\"strength\", {})\n   410→        status = str(strength.get(\"status\") or \"\")\n   411→        return f\"{y}{m}{d}{h} 日主{dm_gan}{dm_el} {status}\".strip()\n   412→    except Exception:\n   413→        return \"\"\n   414→\n   415→\n   416→def ensure_snapshot_for_user(user_id: int) -> Dict[str, Any]:\n   417→    user = fortune_db.fetch_one(\n   418→        \"SELECT name, gender, birthday_local, tz_offset_hours, location FROM fortune_user WHERE user_id=%s AND deleted_at IS NULL\",\n   419→        (int(user_id),),\n   420→    )\n   421→    if not user:\n   422→        raise ValueError(\"user_not_found\")\n   423→\n   424→    snap = fortune_db.fetch_one(\n   425→        \"SELECT facts, facts_hash, compute_version FROM fortune_bazi_snapshot WHERE user_id=%s ORDER BY created_at DESC LIMIT 1\",\n   426→        (int(user_id),),\n   427→    )\n   428→    if snap and snap.get(\"facts\") and snap.get(\"facts_hash\"):\n   429→        return {\"facts\": snap.get(\"facts\") or {}, \"facts_hash\": str(snap.get(\"facts_hash\") or \"\"), \"compute_version\": str(snap.get(\"compute_version\") or \"\")}\n   430→\n   431→    # Ensure birthday_local is a datetime object (not just date)\n   432→    birthday_local = user[\"birthday_local\"]\n   433→    if isinstance(birthday_local, date) and not isinstance(birthday_local, datetime):\n   434→        birthday_local = datetime.combine(birthday_local, datetime.min.time())\n   435→\n   436→    facts = compute_facts(\n   437→        name=str(user.get(\"name\") or \"\"),\n   438→        gender=str(user.get(\"gender\") or \"\"),\n   439→        birthday_local=birthday_local,\n   440→        tz_offset_hours=float(user.get(\"tz_offset_hours\") or 8.0),\n   441→        location=user.get(\"location\") or {},\n   442→    )\n   443→    digest = make_bazi_digest(facts)\n   444→    facts_json = json.dumps(facts, ensure_ascii=False)\n   445→    facts_hash = str(facts.get(\"version\", {}).get(\"facts_hash\") or \"\")\n   446→\n   447→    with fortune_db.db_cursor(dict_cursor=True) as cur:\n   448→        cur.execute(\n   449→            \"\"\"\n   450→            INSERT INTO fortune_bazi_snapshot (user_id, compute_version, facts, facts_hash)\n   451→            VALUES (%s, %s, %s::jsonb, %s)\n   452→            ON CONFLICT (user_id, compute_version, facts_hash) DO NOTHING\n   453→            \"\"\",\n   454→            (int(user_id), BAZI_FACTS_VERSION, facts_json, facts_hash),\n   455→        )\n   456→        if digest:\n   457→            cur.execute(\"UPDATE fortune_user SET bazi_digest=%s, updated_at=now() WHERE user_id=%s\", (digest, int(user_id)))\n   458→\n   459→    logger.info(\n   460→        \"bazi facts computed\",\n   461→        extra={\"operation\": \"bazi_facts_compute\", \"user_id\": int(user_id), \"compute_version\": BAZI_FACTS_VERSION, \"facts_hash\": facts_hash},\n   462→    )\n   463→    return {\"facts\": facts, \"facts_hash\": facts_hash, \"compute_version\": BAZI_FACTS_VERSION}\n   464→\n   465→\n   466→def upsert_snapshot_for_profile(\n   467→    *,\n   468→    user_id: int,\n   469→    name: str,\n   470→    gender: str,\n   471→    birthday_local: datetime,\n   472→    tz_offset_hours: float,\n   473→    location: Dict[str, Any],\n   474→) -> Dict[str, Any]:\n   475→    facts = compute_facts(\n   476→        name=name,\n   477→        gender=gender,\n   478→        birthday_local=birthday_local,\n   479→        tz_offset_hours=tz_offset_hours,\n   480→        location=location,\n   481→    )\n   482→    digest = make_bazi_digest(facts)\n   483→    facts_json = json.dumps(facts, ensure_ascii=False)\n   484→    facts_hash = str(facts.get(\"version\", {}).get(\"facts_hash\") or \"\")\n   485→\n   486→    with fortune_db.db_cursor(dict_cursor=True) as cur:\n   487→        cur.execute(\n   488→            \"\"\"\n   489→            INSERT INTO fortune_bazi_snapshot (user_id, compute_version, facts, facts_hash)\n   490→            VALUES (%s, %s, %s::jsonb, %s)\n   491→            ON CONFLICT (user_id, compute_version, facts_hash) DO NOTHING\n   492→            \"\"\",\n   493→            (int(user_id), BAZI_FACTS_VERSION, facts_json, facts_hash),\n   494→        )\n   495→        cur.execute(\"UPDATE fortune_user SET bazi_digest=%s, updated_at=now() WHERE user_id=%s\", (digest, int(user_id)))\n   496→\n   497→    logger.info(\n   498→        \"bazi facts computed\",\n   499→        extra={\"operation\": \"bazi_facts_compute\", \"user_id\": int(user_id), \"compute_version\": BAZI_FACTS_VERSION, \"facts_hash\": facts_hash},\n   500→    )\n   501→    return {\"facts\": facts, \"facts_hash\": facts_hash, \"compute_version\": BAZI_FACTS_VERSION}\n   502→\n   503→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"afb7b4c4-b1a7-43ec-b3f6-a0223791ed42","timestamp":"2026-01-01T15:01:09.988Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aiscend/work/fortune_ai/services/bazi_facts.py","content":"from __future__ import annotations\n\nimport hashlib\nimport json\nfrom dataclasses import dataclass\nfrom datetime import date, datetime, timedelta, timezone\nfrom typing import Any, Dict, List, Optional, Tuple\n\nimport swisseph as swe\nfrom lunar_python import LunarYear, Solar\n\nfrom common.logging import get_logger\nfrom stores import fortune_db\n\n\nlogger = get_logger(__name__)\n\n\nBAZI_FACTS_VERSION = \"bazi-tts-v1\"\n\n_DAY_GAN_ELEMENT = {\n    \"甲\": \"木\",\n    \"乙\": \"木\",\n    \"丙\": \"火\",\n    \"丁\": \"火\",\n    \"戊\": \"土\",\n    \"己\": \"土\",\n    \"庚\": \"金\",\n    \"辛\": \"金\",\n    \"壬\": \"水\",\n    \"癸\": \"水\",\n}\n\n_MONTH_BRANCH_SEASON_ELEMENT = {\n    \"寅\": \"木\",\n    \"卯\": \"木\",\n    \"辰\": \"木\",\n    \"巳\": \"火\",\n    \"午\": \"火\",\n    \"未\": \"火\",\n    \"申\": \"金\",\n    \"酉\": \"金\",\n    \"戌\": \"金\",\n    \"亥\": \"水\",\n    \"子\": \"水\",\n    \"丑\": \"水\",\n}\n\n_ELEMENT_REL = {\n    \"木\": {\"generator\": \"水\", \"produces\": \"火\", \"controls\": \"土\", \"controlled_by\": \"金\"},\n    \"火\": {\"generator\": \"木\", \"produces\": \"土\", \"controls\": \"金\", \"controlled_by\": \"水\"},\n    \"土\": {\"generator\": \"火\", \"produces\": \"金\", \"controls\": \"水\", \"controlled_by\": \"木\"},\n    \"金\": {\"generator\": \"土\", \"produces\": \"水\", \"controls\": \"木\", \"controlled_by\": \"火\"},\n    \"水\": {\"generator\": \"金\", \"produces\": \"木\", \"controls\": \"火\", \"controlled_by\": \"土\"},\n}\n\n_SHENSHA_SANHE_GROUPS = [\n    (\"申子辰\", {\"taohua\": \"酉\", \"yima\": \"寅\", \"huagai\": \"辰\"}),\n    (\"亥卯未\", {\"taohua\": \"子\", \"yima\": \"巳\", \"huagai\": \"未\"}),\n    (\"寅午戌\", {\"taohua\": \"卯\", \"yima\": \"申\", \"huagai\": \"戌\"}),\n    (\"巳酉丑\", {\"taohua\": \"午\", \"yima\": \"亥\", \"huagai\": \"丑\"}),\n]\n\n_TIANYI_BY_DAY_GAN = {\n    \"甲\": [\"丑\", \"未\"],\n    \"戊\": [\"丑\", \"未\"],\n    \"庚\": [\"丑\", \"未\"],\n    \"乙\": [\"子\", \"申\"],\n    \"己\": [\"子\", \"申\"],\n    \"丙\": [\"亥\", \"酉\"],\n    \"丁\": [\"亥\", \"酉\"],\n    \"辛\": [\"寅\", \"午\"],\n    \"壬\": [\"卯\", \"巳\"],\n    \"癸\": [\"卯\", \"巳\"],\n}\n\n_WENCHANG_BY_DAY_GAN = {\n    \"甲\": [\"巳\", \"午\"],\n    \"乙\": [\"巳\", \"午\"],\n    \"丙\": [\"申\", \"酉\"],\n    \"丁\": [\"申\", \"酉\"],\n    \"戊\": [\"申\", \"酉\"],\n    \"己\": [\"申\", \"酉\"],\n    \"庚\": [\"亥\", \"子\"],\n    \"辛\": [\"亥\", \"子\"],\n    \"壬\": [\"寅\", \"卯\"],\n    \"癸\": [\"寅\", \"卯\"],\n}\n\n\ndef _dt_str(dt: datetime) -> str:\n    return dt.replace(tzinfo=None).strftime(\"%Y-%m-%d %H:%M:%S\")\n\n\ndef _canonical_json(obj: Any) -> str:\n    return json.dumps(obj, ensure_ascii=False, sort_keys=True, separators=(\",\", \":\"))\n\n\ndef _sha256_text(s: str) -> str:\n    return \"sha256:\" + hashlib.sha256(s.encode(\"utf-8\")).hexdigest()\n\n\n@dataclass(frozen=True)\nclass TrueSolarTime:\n    tz_meridian_deg: float\n    lon_corr_min: float\n    eot_min: float\n    true_solar_time_local: datetime\n\n\ndef compute_true_solar_time(\n    *,\n    birthday_local: datetime,\n    tz_offset_hours: float,\n    longitude: float,\n) -> TrueSolarTime:\n    tz_meridian_deg = float(tz_offset_hours) * 15.0\n    lon_corr_min = (float(longitude) - tz_meridian_deg) * 4.0\n\n    birthday_utc = (birthday_local - timedelta(hours=float(tz_offset_hours))).replace(tzinfo=timezone.utc)\n    hour_decimal_utc = (\n        birthday_utc.hour\n        + birthday_utc.minute / 60.0\n        + birthday_utc.second / 3600.0\n        + birthday_utc.microsecond / 3600.0 / 1_000_000.0\n    )\n    jd_ut = swe.julday(birthday_utc.year, birthday_utc.month, birthday_utc.day, hour_decimal_utc)\n    eot_min = swe.time_equ(jd_ut) * 1440.0\n\n    corr_seconds = (lon_corr_min + eot_min) * 60.0\n    t = birthday_local + timedelta(seconds=corr_seconds)\n    true_solar_time_local = (t + timedelta(seconds=0.5)).replace(microsecond=0)  # round to nearest second\n    return TrueSolarTime(\n        tz_meridian_deg=tz_meridian_deg,\n        lon_corr_min=lon_corr_min,\n        eot_min=eot_min,\n        true_solar_time_local=true_solar_time_local,\n    )\n\n\ndef _wuxing_counts(wuxing: str) -> Dict[str, int]:\n    out = {\"金\": 0, \"木\": 0, \"水\": 0, \"火\": 0, \"土\": 0}\n    for k in out:\n        out[k] = (wuxing or \"\").count(k)\n    return out\n\n\ndef _season_bonus(\n    *,\n    month_branch: str,\n    day_master_element: str,\n) -> Tuple[str, int]:\n    season_element = _MONTH_BRANCH_SEASON_ELEMENT.get(month_branch, \"\")\n    if not season_element:\n        return \"\", 0\n    if season_element == day_master_element:\n        return season_element, 2\n    rel = _ELEMENT_REL[day_master_element]\n    if season_element == rel[\"generator\"]:\n        return season_element, 1\n    if season_element == rel[\"controlled_by\"]:\n        return season_element, -1\n    if season_element == rel[\"controls\"]:\n        return season_element, -1\n    return season_element, 0\n\n\ndef _compute_strength(\n    *,\n    wuxing_count: Dict[str, int],\n    month_branch: str,\n    day_master_element: str,\n) -> Dict[str, Any]:\n    rel = _ELEMENT_REL[day_master_element]\n    generator = rel[\"generator\"]\n    produced = rel[\"produces\"]\n    controlled_by = rel[\"controlled_by\"]\n    controls = rel[\"controls\"]\n\n    support = int(wuxing_count.get(day_master_element, 0)) + int(wuxing_count.get(generator, 0))\n    drain = int(wuxing_count.get(produced, 0)) + int(wuxing_count.get(controlled_by, 0))\n    season_element, season_bonus = _season_bonus(month_branch=month_branch, day_master_element=day_master_element)\n    score = int(support - drain + season_bonus)\n\n    if score >= 2:\n        status = \"strong\"\n        favorable = [produced, controls, controlled_by]\n    elif score <= -2:\n        status = \"weak\"\n        favorable = [day_master_element, generator]\n    else:\n        status = \"neutral\"\n        min_count = min(wuxing_count.values()) if wuxing_count else 0\n        favorable = [k for k, v in wuxing_count.items() if v == min_count]\n\n    return {\n        \"rule_id\": \"RULE-STRENGTH-SCORE-V1\",\n        \"day_master_element\": day_master_element,\n        \"generator_element\": generator,\n        \"produced_element\": produced,\n        \"controls_element\": controls,\n        \"controlled_by_element\": controlled_by,\n        \"season_element\": season_element,\n        \"season_bonus\": season_bonus,\n        \"support\": support,\n        \"drain\": drain,\n        \"score\": score,\n        \"status\": status,\n        \"favorable_elements\": favorable,\n    }\n\n\ndef _branch_group_targets(branch: str) -> Dict[str, str]:\n    for group, targets in _SHENSHA_SANHE_GROUPS:\n        if branch in group:\n            return targets\n    return {}\n\n\ndef _compute_shensha(\n    *,\n    pillars: Dict[str, str],\n    day_gan: str,\n) -> List[Dict[str, Any]]:\n    year_branch = pillars.get(\"year\", \"\")[1:2]\n    day_branch = pillars.get(\"day\", \"\")[1:2]\n    branches = [p[1:2] for p in pillars.values() if isinstance(p, str) and len(p) >= 2]\n    branch_set = set(branches)\n\n    targets: Dict[str, str] = {}\n    targets.update(_branch_group_targets(year_branch))\n    targets.update(_branch_group_targets(day_branch))\n\n    taohua = targets.get(\"taohua\")\n    yima = targets.get(\"yima\")\n    huagai = targets.get(\"huagai\")\n\n    out: List[Dict[str, Any]] = [\n        {\n            \"name\": \"桃花\",\n            \"rule_id\": \"RULE-SHENSHA-TAOHUA-V1\",\n            \"hit\": bool(taohua and taohua in branch_set),\n            \"note\": \"以日支/年支推咸池\",\n        },\n        {\n            \"name\": \"驿马\",\n            \"rule_id\": \"RULE-SHENSHA-YIMA-V1\",\n            \"hit\": bool(yima and yima in branch_set),\n            \"note\": \"以日支/年支推驿马\",\n        },\n        {\n            \"name\": \"华盖\",\n            \"rule_id\": \"RULE-SHENSHA-HUAGAI-V1\",\n            \"hit\": bool(huagai and huagai in branch_set),\n            \"note\": \"以日支/年支推华盖\",\n        },\n    ]\n\n    tianyi_targets = _TIANYI_BY_DAY_GAN.get(day_gan, [])\n    out.append(\n        {\n            \"name\": \"天乙贵人\",\n            \"rule_id\": \"RULE-SHENSHA-TIANYI-V1\",\n            \"hit\": any(b in branch_set for b in tianyi_targets),\n            \"note\": \"以日干推贵人\",\n        }\n    )\n    wenchang_targets = _WENCHANG_BY_DAY_GAN.get(day_gan, [])\n    out.append(\n        {\n            \"name\": \"文昌\",\n            \"rule_id\": \"RULE-SHENSHA-WENCHANG-V1\",\n            \"hit\": any(b in branch_set for b in wenchang_targets),\n            \"note\": \"以日干推文昌\",\n        }\n    )\n    return out\n\n\ndef _compute_luck(*, eight_char, gender: str) -> Dict[str, Any]:\n    gender_code = 1 if gender == \"男\" else 0\n    yun = eight_char.getYun(gender_code)\n    forward = bool(yun.isForward())\n    start_age_year = int(yun.getStartYear())\n\n    da_yun_items: List[Dict[str, Any]] = []\n    for dy in yun.getDaYun(10) or []:\n        gz = str(dy.getGanZhi() or \"\")\n        if not gz:\n            continue\n        da_yun_items.append(\n            {\n                \"start_age\": int(dy.getStartAge()),\n                \"end_age\": int(dy.getEndAge()),\n                \"start_year\": int(dy.getStartYear()),\n                \"end_year\": int(dy.getEndYear()),\n                \"gan_zhi\": gz,\n                \"xun\": str(dy.getXun() or \"\"),\n                \"xun_kong\": str(dy.getXunKong() or \"\"),\n            }\n        )\n\n    for idx, item in enumerate(da_yun_items, start=1):\n        item[\"index\"] = idx\n\n    this_year = datetime.now().year\n    liu_nian_next5 = [{\"year\": y, \"gan_zhi\": LunarYear.fromYear(y).getGanZhi()} for y in range(this_year + 1, this_year + 6)]\n\n    return {\n        \"forward\": forward,\n        \"start_age_year\": start_age_year,\n        \"da_yun\": da_yun_items,\n        \"liu_nian_next5\": liu_nian_next5,\n    }\n\n\ndef compute_facts(\n    *,\n    name: str,\n    gender: str,\n    birthday_local: datetime,\n    tz_offset_hours: float,\n    location: Dict[str, Any],\n) -> Dict[str, Any]:\n    if gender not in (\"男\", \"女\"):\n        raise ValueError(\"invalid_gender\")\n    longitude = float(location[\"longitude\"])\n    latitude = float(location[\"latitude\"])\n\n    solar_time = compute_true_solar_time(birthday_local=birthday_local, tz_offset_hours=float(tz_offset_hours), longitude=longitude)\n    ts = solar_time.true_solar_time_local\n\n    solar = Solar.fromYmdHms(ts.year, ts.month, ts.day, ts.hour, ts.minute, ts.second)\n    lunar = solar.getLunar()\n    eight = lunar.getEightChar()\n\n    pillars = {\"year\": eight.getYear(), \"month\": eight.getMonth(), \"day\": eight.getDay(), \"hour\": eight.getTime()}\n    wuxing_concat = str(eight.getYearWuXing() or \"\") + str(eight.getMonthWuXing() or \"\") + str(eight.getDayWuXing() or \"\") + str(eight.getTimeWuXing() or \"\")\n    wuxing_count = _wuxing_counts(wuxing_concat)\n\n    day_gan = pillars[\"day\"][0:1]\n    day_master_element = _DAY_GAN_ELEMENT.get(day_gan, \"\")\n    month_branch = pillars[\"month\"][1:2]\n\n    facts_base: Dict[str, Any] = {\n        \"profile\": {\n            \"name\": str(name),\n            \"gender\": gender,\n            \"birthday_local\": _dt_str(birthday_local),\n            \"tz_offset_hours\": float(tz_offset_hours),\n            \"location\": {\"name\": str(location.get(\"name\") or \"\"), \"longitude\": longitude, \"latitude\": latitude},\n        },\n        \"solar_time\": {\n            \"tz_meridian_deg\": round(float(solar_time.tz_meridian_deg), 4),\n            \"lon_corr_min\": round(float(solar_time.lon_corr_min), 4),\n            \"eot_min\": round(float(solar_time.eot_min), 4),\n            \"true_solar_time_local\": _dt_str(ts),\n        },\n        \"bazi\": {\n            \"pillars\": pillars,\n            \"day_master\": {\"gan\": day_gan, \"element\": day_master_element},\n            \"wuxing_count\": wuxing_count,\n            \"shi_shen_gan\": {\n                \"year\": str(eight.getYearShiShenGan() or \"\"),\n                \"month\": str(eight.getMonthShiShenGan() or \"\"),\n                \"day\": str(eight.getDayShiShenGan() or \"\"),\n                \"hour\": str(eight.getTimeShiShenGan() or \"\"),\n            },\n            \"shi_shen_zhi\": {\n                \"year\": list(eight.getYearShiShenZhi() or []),\n                \"month\": list(eight.getMonthShiShenZhi() or []),\n                \"day\": list(eight.getDayShiShenZhi() or []),\n                \"hour\": list(eight.getTimeShiShenZhi() or []),\n            },\n            \"na_yin\": {\n                \"year\": str(eight.getYearNaYin() or \"\"),\n                \"month\": str(eight.getMonthNaYin() or \"\"),\n                \"day\": str(eight.getDayNaYin() or \"\"),\n                \"hour\": str(eight.getTimeNaYin() or \"\"),\n            },\n            \"di_shi\": {\n                \"year\": str(eight.getYearDiShi() or \"\"),\n                \"month\": str(eight.getMonthDiShi() or \"\"),\n                \"day\": str(eight.getDayDiShi() or \"\"),\n                \"hour\": str(eight.getTimeDiShi() or \"\"),\n            },\n            \"luck\": _compute_luck(eight_char=eight, gender=gender),\n            \"strength\": _compute_strength(wuxing_count=wuxing_count, month_branch=month_branch, day_master_element=day_master_element),\n            \"shensha\": _compute_shensha(pillars=pillars, day_gan=day_gan),\n        },\n        \"version\": {\"compute_version\": BAZI_FACTS_VERSION},\n    }\n\n    facts_hash = _sha256_text(_canonical_json(facts_base))\n    facts_base[\"version\"][\"facts_hash\"] = facts_hash\n    return facts_base\n\n\ndef make_bazi_digest(facts: Dict[str, Any]) -> str:\n    try:\n        pillars = facts.get(\"bazi\", {}).get(\"pillars\", {})\n        y = str(pillars.get(\"year\") or \"\")\n        m = str(pillars.get(\"month\") or \"\")\n        d = str(pillars.get(\"day\") or \"\")\n        h = str(pillars.get(\"hour\") or \"\")\n        dm = facts.get(\"bazi\", {}).get(\"day_master\", {})\n        dm_gan = str(dm.get(\"gan\") or \"\")\n        dm_el = str(dm.get(\"element\") or \"\")\n        strength = facts.get(\"bazi\", {}).get(\"strength\", {})\n        status = str(strength.get(\"status\") or \"\")\n        return f\"{y}{m}{d}{h} 日主{dm_gan}{dm_el} {status}\".strip()\n    except Exception:\n        return \"\"\n\n\ndef ensure_snapshot_for_user(user_id: int) -> Dict[str, Any]:\n    user = fortune_db.fetch_one(\n        \"SELECT name, gender, birthday_local, tz_offset_hours, location FROM fortune_user WHERE user_id=%s AND deleted_at IS NULL\",\n        (int(user_id),),\n    )\n    if not user:\n        raise ValueError(\"user_not_found\")\n\n    snap = fortune_db.fetch_one(\n        \"SELECT facts, facts_hash, compute_version FROM fortune_bazi_snapshot WHERE user_id=%s ORDER BY created_at DESC LIMIT 1\",\n        (int(user_id),),\n    )\n    if snap and snap.get(\"facts\") and snap.get(\"facts_hash\"):\n        return {\"facts\": snap.get(\"facts\") or {}, \"facts_hash\": str(snap.get(\"facts_hash\") or \"\"), \"compute_version\": str(snap.get(\"compute_version\") or \"\")}\n\n    # Ensure birthday_local is a datetime object (not just date)\n    birthday_local = user[\"birthday_local\"]\n    if isinstance(birthday_local, date) and not isinstance(birthday_local, datetime):\n        birthday_local = datetime.combine(birthday_local, datetime.min.time())\n\n    facts = compute_facts(\n        name=str(user.get(\"name\") or \"\"),\n        gender=str(user.get(\"gender\") or \"\"),\n        birthday_local=birthday_local,\n        tz_offset_hours=float(user.get(\"tz_offset_hours\") or 8.0),\n        location=user.get(\"location\") or {},\n    )\n    digest = make_bazi_digest(facts)\n    facts_json = json.dumps(facts, ensure_ascii=False)\n    facts_hash = str(facts.get(\"version\", {}).get(\"facts_hash\") or \"\")\n\n    with fortune_db.db_cursor(dict_cursor=True) as cur:\n        cur.execute(\n            \"\"\"\n            INSERT INTO fortune_bazi_snapshot (user_id, compute_version, facts, facts_hash)\n            VALUES (%s, %s, %s::jsonb, %s)\n            ON CONFLICT (user_id, compute_version, facts_hash) DO NOTHING\n            \"\"\",\n            (int(user_id), BAZI_FACTS_VERSION, facts_json, facts_hash),\n        )\n        if digest:\n            cur.execute(\"UPDATE fortune_user SET bazi_digest=%s, updated_at=now() WHERE user_id=%s\", (digest, int(user_id)))\n\n    logger.info(\n        \"bazi facts computed\",\n        extra={\"operation\": \"bazi_facts_compute\", \"user_id\": int(user_id), \"compute_version\": BAZI_FACTS_VERSION, \"facts_hash\": facts_hash},\n    )\n    return {\"facts\": facts, \"facts_hash\": facts_hash, \"compute_version\": BAZI_FACTS_VERSION}\n\n\ndef upsert_snapshot_for_profile(\n    *,\n    user_id: int,\n    name: str,\n    gender: str,\n    birthday_local: datetime,\n    tz_offset_hours: float,\n    location: Dict[str, Any],\n) -> Dict[str, Any]:\n    facts = compute_facts(\n        name=name,\n        gender=gender,\n        birthday_local=birthday_local,\n        tz_offset_hours=tz_offset_hours,\n        location=location,\n    )\n    digest = make_bazi_digest(facts)\n    facts_json = json.dumps(facts, ensure_ascii=False)\n    facts_hash = str(facts.get(\"version\", {}).get(\"facts_hash\") or \"\")\n\n    with fortune_db.db_cursor(dict_cursor=True) as cur:\n        cur.execute(\n            \"\"\"\n            INSERT INTO fortune_bazi_snapshot (user_id, compute_version, facts, facts_hash)\n            VALUES (%s, %s, %s::jsonb, %s)\n            ON CONFLICT (user_id, compute_version, facts_hash) DO NOTHING\n            \"\"\",\n            (int(user_id), BAZI_FACTS_VERSION, facts_json, facts_hash),\n        )\n        cur.execute(\"UPDATE fortune_user SET bazi_digest=%s, updated_at=now() WHERE user_id=%s\", (digest, int(user_id)))\n\n    logger.info(\n        \"bazi facts computed\",\n        extra={\"operation\": \"bazi_facts_compute\", \"user_id\": int(user_id), \"compute_version\": BAZI_FACTS_VERSION, \"facts_hash\": facts_hash},\n    )\n    return {\"facts\": facts, \"facts_hash\": facts_hash, \"compute_version\": BAZI_FACTS_VERSION}\n\n","numLines":503,"startLine":1,"totalLines":503}}}
{"parentUuid":"afb7b4c4-b1a7-43ec-b3f6-a0223791ed42","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DCe5XTJwT7tjhZUJQsSgMe","type":"tool_result","content":"     1→\"\"\"\n     2→真太阳时八字计算封装。\n     3→- 默认出生地：北京，经纬度 (116.4074, 39.9042)\n     4→- 若缺经度/纬度则回落到默认，并在返回结果中标记 used_default_location=True\n     5→\"\"\"\n     6→from dataclasses import dataclass\n     7→from datetime import datetime\n     8→from typing import Dict, Optional, Tuple\n     9→\n    10→from common.logging import get_logger\n    11→\n    12→logger = get_logger(__name__)\n    13→\n    14→DEFAULT_LOCATION = {\n    15→    \"name\": \"北京\",\n    16→    \"longitude\": 116.4074,\n    17→    \"latitude\": 39.9042,\n    18→}\n    19→\n    20→\n    21→@dataclass\n    22→class BaziResult:\n    23→    year_pillar: str\n    24→    month_pillar: str\n    25→    day_pillar: str\n    26→    hour_pillar: str\n    27→    wuxing: Optional[str]\n    28→    used_default_location: bool\n    29→    location: Dict[str, float]\n    30→    calculated_at: datetime\n    31→\n    32→\n    33→def ensure_location(location: Optional[Dict[str, float]]) -> Tuple[Dict[str, float], bool]:\n    34→    if not location:\n    35→        return DEFAULT_LOCATION, True\n    36→    if \"longitude\" not in location or location.get(\"longitude\") is None:\n    37→        merged = {**DEFAULT_LOCATION, **location}\n    38→        return merged, True\n    39→    return location, False\n    40→\n    41→\n    42→def calculate_bazi(\n    43→    year: int,\n    44→    month: int,\n    45→    day: int,\n    46→    hour: int,\n    47→    minute: int,\n    48→    location: Optional[Dict[str, float]] = None,\n    49→) -> BaziResult:\n    50→    \"\"\"\n    51→    计算真太阳时八字；需要经度。缺失时使用北京默认经纬度。\n    52→    \"\"\"\n    53→    loc, used_default = ensure_location(location)\n    54→    try:\n    55→        from lunar_python import Solar\n    56→    except ImportError as exc:\n    57→        logger.error(\n    58→            \"lunar_python not installed; please `pip install lunar_python`\",\n    59→            extra={\"operation\": \"bazi_calculate\", \"error\": str(exc)},\n    60→        )\n    61→        raise\n    62→\n    63→    solar = Solar.fromYmdHms(year, month, day, hour, minute, 0)\n    64→    lunar = solar.getLunar()\n    65→    ba_zi = lunar.getEightChar()\n    66→\n    67→    try:\n    68→        wuxing = (\n    69→            ba_zi.getYearWuXing()\n    70→            + ba_zi.getMonthWuXing()\n    71→            + ba_zi.getDayWuXing()\n    72→            + ba_zi.getTimeWuXing()\n    73→        )\n    74→    except Exception:\n    75→        wuxing = None\n    76→\n    77→    result = BaziResult(\n    78→        year_pillar=ba_zi.getYear(),\n    79→        month_pillar=ba_zi.getMonth(),\n    80→        day_pillar=ba_zi.getDay(),\n    81→        hour_pillar=ba_zi.getTime(),\n    82→        wuxing=wuxing,\n    83→        used_default_location=used_default,\n    84→        location={\"name\": loc.get(\"name\", \"\"), \"longitude\": loc[\"longitude\"], \"latitude\": loc.get(\"latitude\", 0.0)},\n    85→        calculated_at=datetime.utcnow(),\n    86→    )\n    87→    logger.info(\n    88→        \"calculated bazi\",\n    89→        extra={\n    90→            \"operation\": \"bazi_calculate\",\n    91→            \"used_default_location\": used_default,\n    92→            \"longitude\": loc[\"longitude\"],\n    93→            \"latitude\": loc.get(\"latitude\"),\n    94→        },\n    95→    )\n    96→    return result\n    97→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"b3aee3a3-7a43-47a9-802d-e0aeb0ed68cc","timestamp":"2026-01-01T15:01:09.989Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aiscend/work/fortune_ai/services/bazi_engine.py","content":"\"\"\"\n真太阳时八字计算封装。\n- 默认出生地：北京，经纬度 (116.4074, 39.9042)\n- 若缺经度/纬度则回落到默认，并在返回结果中标记 used_default_location=True\n\"\"\"\nfrom dataclasses import dataclass\nfrom datetime import datetime\nfrom typing import Dict, Optional, Tuple\n\nfrom common.logging import get_logger\n\nlogger = get_logger(__name__)\n\nDEFAULT_LOCATION = {\n    \"name\": \"北京\",\n    \"longitude\": 116.4074,\n    \"latitude\": 39.9042,\n}\n\n\n@dataclass\nclass BaziResult:\n    year_pillar: str\n    month_pillar: str\n    day_pillar: str\n    hour_pillar: str\n    wuxing: Optional[str]\n    used_default_location: bool\n    location: Dict[str, float]\n    calculated_at: datetime\n\n\ndef ensure_location(location: Optional[Dict[str, float]]) -> Tuple[Dict[str, float], bool]:\n    if not location:\n        return DEFAULT_LOCATION, True\n    if \"longitude\" not in location or location.get(\"longitude\") is None:\n        merged = {**DEFAULT_LOCATION, **location}\n        return merged, True\n    return location, False\n\n\ndef calculate_bazi(\n    year: int,\n    month: int,\n    day: int,\n    hour: int,\n    minute: int,\n    location: Optional[Dict[str, float]] = None,\n) -> BaziResult:\n    \"\"\"\n    计算真太阳时八字；需要经度。缺失时使用北京默认经纬度。\n    \"\"\"\n    loc, used_default = ensure_location(location)\n    try:\n        from lunar_python import Solar\n    except ImportError as exc:\n        logger.error(\n            \"lunar_python not installed; please `pip install lunar_python`\",\n            extra={\"operation\": \"bazi_calculate\", \"error\": str(exc)},\n        )\n        raise\n\n    solar = Solar.fromYmdHms(year, month, day, hour, minute, 0)\n    lunar = solar.getLunar()\n    ba_zi = lunar.getEightChar()\n\n    try:\n        wuxing = (\n            ba_zi.getYearWuXing()\n            + ba_zi.getMonthWuXing()\n            + ba_zi.getDayWuXing()\n            + ba_zi.getTimeWuXing()\n        )\n    except Exception:\n        wuxing = None\n\n    result = BaziResult(\n        year_pillar=ba_zi.getYear(),\n        month_pillar=ba_zi.getMonth(),\n        day_pillar=ba_zi.getDay(),\n        hour_pillar=ba_zi.getTime(),\n        wuxing=wuxing,\n        used_default_location=used_default,\n        location={\"name\": loc.get(\"name\", \"\"), \"longitude\": loc[\"longitude\"], \"latitude\": loc.get(\"latitude\", 0.0)},\n        calculated_at=datetime.utcnow(),\n    )\n    logger.info(\n        \"calculated bazi\",\n        extra={\n            \"operation\": \"bazi_calculate\",\n            \"used_default_location\": used_default,\n            \"longitude\": loc[\"longitude\"],\n            \"latitude\": loc.get(\"latitude\"),\n        },\n    )\n    return result\n","numLines":97,"startLine":1,"totalLines":97}}}
{"parentUuid":"b3aee3a3-7a43-47a9-802d-e0aeb0ed68cc","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PQApcDcimwsc9tGHjkiNYW","type":"tool_result","content":"     1→\"\"\"\n     2→Digital Twin Service.\n     3→\n     4→REQ: REQ-TWIN-001 ~ REQ-TWIN-005\n     5→Design: §3.1.1 ~ §3.1.3\n     6→HOS-REF: §1.2, §1.3, §10.5.2\n     7→\"\"\"\n     8→\n     9→from __future__ import annotations\n    10→\n    11→import json\n    12→from datetime import datetime, timezone\n    13→from typing import Any, Dict, List, Optional, Tuple\n    14→\n    15→from common.logging import get_logger\n    16→from models.twin import (\n    17→    DimensionScores,\n    18→    TwinData,\n    19→    TwinHistoryEntry,\n    20→    TwinHistoryResponse,\n    21→    TwinLayer,\n    22→    TwinUpdateEvent,\n    23→    TwinUpdateResult,\n    24→)\n    25→from stores import fortune_db\n    26→\n    27→logger = get_logger(__name__)\n    28→\n    29→\n    30→class TwinServiceError(Exception):\n    31→    \"\"\"Base exception for twin service errors.\"\"\"\n    32→    pass\n    33→\n    34→\n    35→class TwinNotFoundError(TwinServiceError):\n    36→    \"\"\"Twin not found for user.\"\"\"\n    37→    pass\n    38→\n    39→\n    40→def _now_utc() -> datetime:\n    41→    return datetime.now(timezone.utc)\n    42→\n    43→\n    44→def _row_to_twin(row: Dict[str, Any]) -> TwinData:\n    45→    \"\"\"Convert database row to TwinData model.\"\"\"\n    46→    dimension_scores_raw = row.get(\"dimension_scores\") or {}\n    47→    if isinstance(dimension_scores_raw, str):\n    48→        dimension_scores_raw = json.loads(dimension_scores_raw)\n    49→\n    50→    return TwinData(\n    51→        twin_id=row.get(\"twin_id\"),\n    52→        user_id=row[\"user_id\"],\n    53→        metadata_astrology=row.get(\"metadata_astrology\") or {},\n    54→        metadata_psychology=row.get(\"metadata_psychology\") or {},\n    55→        metadata_memory=row.get(\"metadata_memory\") or {},\n    56→        dynamic_astro=row.get(\"dynamic_astro\") or {},\n    57→        dynamic_bio=row.get(\"dynamic_bio\") or {},\n    58→        dynamic_social=row.get(\"dynamic_social\") or {},\n    59→        dynamic_emotional=row.get(\"dynamic_emotional\") or {},\n    60→        aura_points=row.get(\"aura_points\") or 0,\n    61→        overall_wellbeing=float(row.get(\"overall_wellbeing\") or 50.0),\n    62→        growth_streak=row.get(\"growth_streak\") or 0,\n    63→        dimension_scores=DimensionScores(**dimension_scores_raw),\n    64→        compute_version=row.get(\"compute_version\") or \"v1.0\",\n    65→        last_full_refresh=row.get(\"last_full_refresh\"),\n    66→        created_at=row.get(\"created_at\"),\n    67→        updated_at=row.get(\"updated_at\"),\n    68→    )\n    69→\n    70→\n    71→def _get_bazi_data_for_user(user_id: int) -> Dict[str, Any]:\n    72→    \"\"\"\n    73→    Fetch bazi snapshot data for user.\n    74→    Returns empty dict if no bazi data exists.\n    75→    \"\"\"\n    76→    row = fortune_db.fetch_one(\n    77→        \"\"\"\n    78→        SELECT facts, facts_hash, compute_version\n    79→        FROM fortune_bazi_snapshot\n    80→        WHERE user_id = %s\n    81→        ORDER BY created_at DESC\n    82→        LIMIT 1\n    83→        \"\"\",\n    84→        [user_id],\n    85→    )\n    86→    if not row:\n    87→        return {}\n    88→\n    89→    facts = row.get(\"facts\") or {}\n    90→    if isinstance(facts, str):\n    91→        facts = json.loads(facts)\n    92→\n    93→    return {\n    94→        \"bazi\": facts,\n    95→        \"facts_hash\": row.get(\"facts_hash\"),\n    96→        \"compute_version\": row.get(\"compute_version\"),\n    97→    }\n    98→\n    99→\n   100→# =============================================================================\n   101→# TASK-1.2.1: create_twin\n   102→# =============================================================================\n   103→\n   104→def create_twin(user_id: int) -> TwinData:\n   105→    \"\"\"\n   106→    Create a new digital twin for user.\n   107→\n   108→    REQ: REQ-TWIN-001\n   109→    Design: §3.1.1 步骤 1-3\n   110→\n   111→    - Idempotent: returns existing twin if already exists\n   112→    - Syncs bazi data from fortune_bazi_snapshot to L1\n   113→    - Initializes all default values\n   114→    \"\"\"\n   115→    # Check if twin already exists (idempotent)\n   116→    existing = fortune_db.fetch_one(\n   117→        \"SELECT * FROM fortune_digital_twin WHERE user_id = %s\",\n   118→        [user_id],\n   119→    )\n   120→    if existing:\n   121→        logger.debug(\"twin_exists user_id=%s twin_id=%s\", user_id, existing[\"twin_id\"])\n   122→        return _row_to_twin(existing)\n   123→\n   124→    # Fetch bazi data for L1 metadata\n   125→    bazi_data = _get_bazi_data_for_user(user_id)\n   126→\n   127→    # Initialize default dimension scores\n   128→    default_dimensions = {\n   129→        \"energy\": 50,\n   130→        \"clarity\": 50,\n   131→        \"connection\": 50,\n   132→        \"growth\": 50,\n   133→        \"balance\": 50,\n   134→    }\n   135→\n   136→    # Insert new twin\n   137→    row = fortune_db.execute_returning_one(\n   138→        \"\"\"\n   139→        INSERT INTO fortune_digital_twin (\n   140→            user_id,\n   141→            metadata_astrology,\n   142→            metadata_psychology,\n   143→            metadata_memory,\n   144→            dynamic_astro,\n   145→            dynamic_bio,\n   146→            dynamic_social,\n   147→            dynamic_emotional,\n   148→            aura_points,\n   149→            overall_wellbeing,\n   150→            growth_streak,\n   151→            dimension_scores,\n   152→            compute_version,\n   153→            created_at,\n   154→            updated_at\n   155→        ) VALUES (\n   156→            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s\n   157→        )\n   158→        RETURNING *\n   159→        \"\"\",\n   160→        [\n   161→            user_id,\n   162→            json.dumps(bazi_data),  # metadata_astrology\n   163→            json.dumps({}),  # metadata_psychology\n   164→            json.dumps({}),  # metadata_memory\n   165→            json.dumps({}),  # dynamic_astro\n   166→            json.dumps({}),  # dynamic_bio\n   167→            json.dumps({}),  # dynamic_social\n   168→            json.dumps({}),  # dynamic_emotional\n   169→            0,  # aura_points\n   170→            50.0,  # overall_wellbeing\n   171→            0,  # growth_streak\n   172→            json.dumps(default_dimensions),  # dimension_scores\n   173→            \"v1.0\",  # compute_version\n   174→            _now_utc(),  # created_at\n   175→            _now_utc(),  # updated_at\n   176→        ],\n   177→    )\n   178→\n   179→    if not row:\n   180→        raise TwinServiceError(f\"Failed to create twin for user {user_id}\")\n   181→\n   182→    logger.info(\"twin_created user_id=%s twin_id=%s\", user_id, row[\"twin_id\"])\n   183→    return _row_to_twin(row)\n   184→\n   185→\n   186→# =============================================================================\n   187→# TASK-1.2.2: get_twin\n   188→# =============================================================================\n   189→\n   190→def get_twin(\n   191→    user_id: int,\n   192→    layers: Optional[List[TwinLayer]] = None,\n   193→    auto_create: bool = True,\n   194→) -> TwinData:\n   195→    \"\"\"\n   196→    Get digital twin for user.\n   197→\n   198→    REQ: REQ-TWIN-002\n   199→    Design: §3.1.2 步骤 1-3\n   200→\n   201→    Args:\n   202→        user_id: User ID\n   203→        layers: Optional list of layers to include (default: all)\n   204→        auto_create: If True, create twin if not exists\n   205→\n   206→    Returns:\n   207→        TwinData with requested layers\n   208→    \"\"\"\n   209→    row = fortune_db.fetch_one(\n   210→        \"SELECT * FROM fortune_digital_twin WHERE user_id = %s\",\n   211→        [user_id],\n   212→    )\n   213→\n   214→    if not row:\n   215→        if auto_create:\n   216→            logger.debug(\"twin_auto_create user_id=%s\", user_id)\n   217→            return create_twin(user_id)\n   218→        raise TwinNotFoundError(f\"Twin not found for user {user_id}\")\n   219→\n   220→    twin = _row_to_twin(row)\n   221→    logger.debug(\"twin_query user_id=%s twin_id=%s\", user_id, twin.twin_id)\n   222→    return twin\n   223→\n   224→\n   225→def get_twin_by_layer(\n   226→    user_id: int,\n   227→    layer: str,\n   228→    auto_create: bool = True,\n   229→) -> Dict[str, Any]:\n   230→    \"\"\"\n   231→    Get specific layer data for user's twin.\n   232→\n   233→    Args:\n   234→        user_id: User ID\n   235→        layer: Layer name ('L1', 'L2', 'L3', or 'all')\n   236→        auto_create: If True, create twin if not exists\n   237→\n   238→    Returns:\n   239→        Dict with layer data\n   240→    \"\"\"\n   241→    twin = get_twin(user_id, auto_create=auto_create)\n   242→\n   243→    if layer == \"all\":\n   244→        return twin.model_dump()\n   245→    elif layer == \"L1\":\n   246→        return twin.get_layer(TwinLayer.L1)\n   247→    elif layer == \"L2\":\n   248→        return twin.get_layer(TwinLayer.L2)\n   249→    elif layer == \"L3\":\n   250→        return twin.get_layer(TwinLayer.L3)\n   251→    else:\n   252→        raise ValueError(f\"Invalid layer: {layer}\")\n   253→\n   254→\n   255→# =============================================================================\n   256→# TASK-1.2.3: update_twin\n   257→# =============================================================================\n   258→\n   259→def _parse_json_path(path: str) -> Tuple[str, List[str]]:\n   260→    \"\"\"\n   261→    Parse JSON path to column name and path parts.\n   262→\n   263→    Example:\n   264→        'dynamic_emotional.current_mood' -> ('dynamic_emotional', ['current_mood'])\n   265→        'metadata_astrology.bazi.day_master' -> ('metadata_astrology', ['bazi', 'day_master'])\n   266→    \"\"\"\n   267→    parts = path.split(\".\")\n   268→    if not parts:\n   269→        raise ValueError(f\"Invalid path: {path}\")\n   270→\n   271→    column = parts[0]\n   272→    path_parts = parts[1:] if len(parts) > 1 else []\n   273→\n   274→    # Validate column name\n   275→    valid_columns = {\n   276→        \"metadata_astrology\", \"metadata_psychology\", \"metadata_memory\",\n   277→        \"dynamic_astro\", \"dynamic_bio\", \"dynamic_social\", \"dynamic_emotional\",\n   278→        \"dimension_scores\",\n   279→    }\n   280→    if column not in valid_columns:\n   281→        raise ValueError(f\"Invalid column in path: {column}\")\n   282→\n   283→    return column, path_parts\n   284→\n   285→\n   286→def _get_nested_value(data: Dict[str, Any], path_parts: List[str]) -> Any:\n   287→    \"\"\"Get nested value from dict using path parts.\"\"\"\n   288→    current = data\n   289→    for part in path_parts:\n   290→        if isinstance(current, dict):\n   291→            current = current.get(part)\n   292→        else:\n   293→            return None\n   294→    return current\n   295→\n   296→\n   297→def _set_nested_value(data: Dict[str, Any], path_parts: List[str], value: Any) -> Dict[str, Any]:\n   298→    \"\"\"Set nested value in dict using path parts. Returns new dict.\"\"\"\n   299→    if not path_parts:\n   300→        return value if isinstance(value, dict) else data\n   301→\n   302→    result = dict(data)\n   303→    current = result\n   304→\n   305→    for i, part in enumerate(path_parts[:-1]):\n   306→        if part not in current or not isinstance(current[part], dict):\n   307→            current[part] = {}\n   308→        current[part] = dict(current[part])\n   309→        current = current[part]\n   310→\n   311→    current[path_parts[-1]] = value\n   312→    return result\n   313→\n   314→\n   315→def update_twin(event: TwinUpdateEvent) -> TwinUpdateResult:\n   316→    \"\"\"\n   317→    Update digital twin data.\n   318→\n   319→    REQ: REQ-TWIN-003\n   320→    Design: §3.1.3 步骤 1-5\n   321→\n   322→    - Uses transaction for atomicity (FOR UPDATE lock held until commit)\n   323→    - Supports nested path updates via jsonb_set\n   324→    - Records old_value and new_value in log\n   325→    - Triggers L3 recalculation if L2 is updated\n   326→    \"\"\"\n   327→    user_id = event.user_id\n   328→    column, path_parts = _parse_json_path(event.path)\n   329→\n   330→    # Use transaction to ensure atomicity: FOR UPDATE lock is held until commit\n   331→    with fortune_db.transaction() as tx:\n   332→        # Get current twin with row lock\n   333→        row = tx.fetch_one(\n   334→            \"SELECT * FROM fortune_digital_twin WHERE user_id = %s FOR UPDATE\",\n   335→            [user_id],\n   336→        )\n   337→        if not row:\n   338→            # Auto-create twin if not exists (outside transaction, then re-lock)\n   339→            twin = create_twin(user_id)\n   340→            row = tx.fetch_one(\n   341→                \"SELECT * FROM fortune_digital_twin WHERE user_id = %s FOR UPDATE\",\n   342→                [user_id],\n   343→            )\n   344→\n   345→        twin_id = row[\"twin_id\"]\n   346→\n   347→        # Get current column value\n   348→        current_data = row.get(column) or {}\n   349→        if isinstance(current_data, str):\n   350→            current_data = json.loads(current_data)\n   351→\n   352→        # Get old value\n   353→        old_value = _get_nested_value(current_data, path_parts) if path_parts else current_data\n   354→\n   355→        # Set new value\n   356→        if path_parts:\n   357→            new_data = _set_nested_value(current_data, path_parts, event.new_value)\n   358→        else:\n   359→            new_data = event.new_value if isinstance(event.new_value, dict) else current_data\n   360→\n   361→        # Update database (within same transaction)\n   362→        tx.execute(\n   363→            f\"\"\"\n   364→            UPDATE fortune_digital_twin\n   365→            SET {column} = %s, updated_at = %s\n   366→            WHERE twin_id = %s\n   367→            \"\"\",\n   368→            [json.dumps(new_data), _now_utc(), twin_id],\n   369→        )\n   370→\n   371→        # Write update log (within same transaction)\n   372→        log_row = tx.execute_returning_one(\n   373→            \"\"\"\n   374→            INSERT INTO fortune_twin_update_log (\n   375→                twin_id, trigger_type, layer, path, old_value, new_value,\n   376→                confidence, source, created_at\n   377→            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n   378→            RETURNING log_id\n   379→            \"\"\",\n   380→            [\n   381→                twin_id,\n   382→                event.trigger,\n   383→                event.layer.value,\n   384→                event.path,\n   385→                json.dumps(old_value) if old_value is not None else None,\n   386→                json.dumps(event.new_value),\n   387→                event.confidence,\n   388→                event.source,\n   389→                _now_utc(),\n   390→            ],\n   391→        )\n   392→\n   393→        log_id = log_row[\"log_id\"] if log_row else None\n   394→    # Transaction commits here, lock released\n   395→\n   396→    # Trigger L3 recalculation if L2 was updated (outside transaction)\n   397→    dimensions_recalculated = False\n   398→    if event.layer == TwinLayer.L2:\n   399→        recalculate_dimensions(user_id)\n   400→        dimensions_recalculated = True\n   401→\n   402→    logger.info(\n   403→        \"twin_update user_id=%s twin_id=%s path=%s layer=%s trigger=%s\",\n   404→        user_id, twin_id, event.path, event.layer.value, event.trigger\n   405→    )\n   406→\n   407→    return TwinUpdateResult(\n   408→        updated=True,\n   409→        log_id=log_id,\n   410→        old_value=old_value,\n   411→        new_value=event.new_value,\n   412→        dimensions_recalculated=dimensions_recalculated,\n   413→    )\n   414→\n   415→\n   416→# =============================================================================\n   417→# TASK-1.2.4: recalculate_dimensions\n   418→# =============================================================================\n   419→\n   420→def recalculate_dimensions(user_id: int) -> DimensionScores:\n   421→    \"\"\"\n   422→    Recalculate L3 dimension scores from L2 data.\n   423→\n   424→    REQ: REQ-TWIN-004\n   425→    Design: §3.1.3 步骤 4\n   426→\n   427→    Dimension formulas:\n   428→    - energy: f(mood_intensity, sleep_score, activity_level)\n   429→    - clarity: f(focus_score, stress_level, meditation_minutes)\n   430→    - connection: f(social_interactions, buffs_received, relationship_quality)\n   431→    - growth: f(commitments_completed, streak, learning_activities)\n   432→    - balance: f(work_life_ratio, emotional_stability, routine_adherence)\n   433→    \"\"\"\n   434→    row = fortune_db.fetch_one(\n   435→        \"\"\"\n   436→        SELECT dynamic_bio, dynamic_social, dynamic_emotional,\n   437→               aura_points, growth_streak\n   438→        FROM fortune_digital_twin\n   439→        WHERE user_id = %s\n   440→        \"\"\",\n   441→        [user_id],\n   442→    )\n   443→\n   444→    if not row:\n   445→        raise TwinNotFoundError(f\"Twin not found for user {user_id}\")\n   446→\n   447→    # Parse L2 data\n   448→    bio = row.get(\"dynamic_bio\") or {}\n   449→    social = row.get(\"dynamic_social\") or {}\n   450→    emotional = row.get(\"dynamic_emotional\") or {}\n   451→    aura = row.get(\"aura_points\") or 0\n   452→    streak = row.get(\"growth_streak\") or 0\n   453→\n   454→    if isinstance(bio, str):\n   455→        bio = json.loads(bio)\n   456→    if isinstance(social, str):\n   457→        social = json.loads(social)\n   458→    if isinstance(emotional, str):\n   459→        emotional = json.loads(emotional)\n   460→\n   461→    # Calculate energy dimension\n   462→    mood_intensity = emotional.get(\"mood_intensity\", 5)\n   463→    sleep_score = bio.get(\"sleep_score\", 50)\n   464→    activity_level = bio.get(\"activity_level\", 50)\n   465→    energy = (mood_intensity * 5 + sleep_score * 0.3 + activity_level * 0.2)\n   466→    energy = max(0, min(100, energy))\n   467→\n   468→    # Calculate clarity dimension\n   469→    focus_score = emotional.get(\"focus_score\", 50)\n   470→    stress_level = emotional.get(\"stress_level\", 50)\n   471→    meditation_minutes = bio.get(\"meditation_minutes\", 0)\n   472→    clarity = focus_score * 0.4 + (100 - stress_level) * 0.4 + min(meditation_minutes, 30) * 0.67\n   473→    clarity = max(0, min(100, clarity))\n   474→\n   475→    # Calculate connection dimension\n   476→    social_interactions = social.get(\"interactions_today\", 0)\n   477→    buffs_received = social.get(\"recent_buffs_received\", 0)\n   478→    relationship_quality = social.get(\"relationship_quality\", 50)\n   479→    connection = min(social_interactions * 5, 30) + min(buffs_received * 10, 30) + relationship_quality * 0.4\n   480→    connection = max(0, min(100, connection))\n   481→\n   482→    # Calculate growth dimension\n   483→    commitments_completed = social.get(\"commitments_completed_week\", 0)\n   484→    learning_activities = bio.get(\"learning_activities\", 0)\n   485→    growth = min(commitments_completed * 10, 40) + min(streak * 2, 30) + min(learning_activities * 5, 30)\n   486→    growth = max(0, min(100, growth))\n   487→\n   488→    # Calculate balance dimension\n   489→    work_life_ratio = bio.get(\"work_life_ratio\", 50)\n   490→    emotional_stability = 100 - abs(emotional.get(\"mood_volatility\", 0))\n   491→    routine_adherence = bio.get(\"routine_adherence\", 50)\n   492→    balance = work_life_ratio * 0.3 + emotional_stability * 0.4 + routine_adherence * 0.3\n   493→    balance = max(0, min(100, balance))\n   494→\n   495→    # Create dimension scores\n   496→    scores = DimensionScores(\n   497→        energy=energy,\n   498→        clarity=clarity,\n   499→        connection=connection,\n   500→        growth=growth,\n   501→        balance=balance,\n   502→    )\n   503→\n   504→    # Calculate overall wellbeing\n   505→    overall = (energy + clarity + connection + growth + balance) / 5\n   506→\n   507→    # Update database\n   508→    fortune_db.execute(\n   509→        \"\"\"\n   510→        UPDATE fortune_digital_twin\n   511→        SET dimension_scores = %s,\n   512→            overall_wellbeing = %s,\n   513→            updated_at = %s\n   514→        WHERE user_id = %s\n   515→        \"\"\",\n   516→        [json.dumps(scores.model_dump()), overall, _now_utc(), user_id],\n   517→    )\n   518→\n   519→    logger.debug(\"dimension_recalc user_id=%s scores=%s\", user_id, scores.model_dump())\n   520→    return scores\n   521→\n   522→\n   523→# =============================================================================\n   524→# Additional helpers\n   525→# =============================================================================\n   526→\n   527→def get_twin_history(\n   528→    user_id: int,\n   529→    limit: int = 20,\n   530→    offset: int = 0,\n   531→    trigger_type: Optional[str] = None,\n   532→    layer: Optional[TwinLayer] = None,\n   533→) -> TwinHistoryResponse:\n   534→    \"\"\"\n   535→    Get twin update history.\n   536→\n   537→    REQ: REQ-TWIN-005\n   538→    Design: §3.1 (扩展)\n   539→    \"\"\"\n   540→    # Get twin_id\n   541→    twin_row = fortune_db.fetch_one(\n   542→        \"SELECT twin_id FROM fortune_digital_twin WHERE user_id = %s\",\n   543→        [user_id],\n   544→    )\n   545→    if not twin_row:\n   546→        return TwinHistoryResponse(entries=[], total_count=0, limit=limit, offset=offset)\n   547→\n   548→    twin_id = twin_row[\"twin_id\"]\n   549→\n   550→    # Build query\n   551→    conditions = [\"twin_id = %s\"]\n   552→    params: List[Any] = [twin_id]\n   553→\n   554→    if trigger_type:\n   555→        conditions.append(\"trigger_type = %s\")\n   556→        params.append(trigger_type)\n   557→\n   558→    if layer:\n   559→        conditions.append(\"layer = %s\")\n   560→        params.append(layer.value)\n   561→\n   562→    where_clause = \" AND \".join(conditions)\n   563→\n   564→    # Get total count\n   565→    count_row = fortune_db.fetch_one(\n   566→        f\"SELECT COUNT(*) as cnt FROM fortune_twin_update_log WHERE {where_clause}\",\n   567→        params,\n   568→    )\n   569→    total_count = count_row[\"cnt\"] if count_row else 0\n   570→\n   571→    # Get entries\n   572→    params.extend([limit, offset])\n   573→    rows = fortune_db.fetch_all(\n   574→        f\"\"\"\n   575→        SELECT * FROM fortune_twin_update_log\n   576→        WHERE {where_clause}\n   577→        ORDER BY created_at DESC\n   578→        LIMIT %s OFFSET %s\n   579→        \"\"\",\n   580→        params,\n   581→    )\n   582→\n   583→    entries = []\n   584→    for row in rows:\n   585→        old_val = row.get(\"old_value\")\n   586→        new_val = row.get(\"new_value\")\n   587→        if isinstance(old_val, str):\n   588→            old_val = json.loads(old_val)\n   589→        if isinstance(new_val, str):\n   590→            new_val = json.loads(new_val)\n   591→\n   592→        entries.append(TwinHistoryEntry(\n   593→            log_id=row[\"log_id\"],\n   594→            trigger_type=row[\"trigger_type\"],\n   595→            layer=TwinLayer(row[\"layer\"]),\n   596→            path=row[\"path\"],\n   597→            old_value=old_val,\n   598→            new_value=new_val,\n   599→            confidence=float(row[\"confidence\"]),\n   600→            source=row[\"source\"],\n   601→            created_at=row[\"created_at\"],\n   602→        ))\n   603→\n   604→    return TwinHistoryResponse(\n   605→        entries=entries,\n   606→        total_count=total_count,\n   607→        limit=limit,\n   608→        offset=offset,\n   609→    )\n   610→\n   611→\n   612→def sync_bazi_to_twin(user_id: int) -> bool:\n   613→    \"\"\"\n   614→    Sync latest bazi snapshot to twin's L1 metadata.\n   615→\n   616→    Called when bazi data is updated.\n   617→    \"\"\"\n   618→    bazi_data = _get_bazi_data_for_user(user_id)\n   619→    if not bazi_data:\n   620→        return False\n   621→\n   622→    # Check if twin exists\n   623→    row = fortune_db.fetch_one(\n   624→        \"SELECT twin_id FROM fortune_digital_twin WHERE user_id = %s\",\n   625→        [user_id],\n   626→    )\n   627→\n   628→    if not row:\n   629→        # Create twin with bazi data\n   630→        create_twin(user_id)\n   631→        return True\n   632→\n   633→    # Update existing twin\n   634→    fortune_db.execute(\n   635→        \"\"\"\n   636→        UPDATE fortune_digital_twin\n   637→        SET metadata_astrology = %s, updated_at = %s\n   638→        WHERE user_id = %s\n   639→        \"\"\",\n   640→        [json.dumps(bazi_data), _now_utc(), user_id],\n   641→    )\n   642→\n   643→    logger.info(\"bazi_synced_to_twin user_id=%s\", user_id)\n   644→    return True\n   645→\n   646→\n   647→def increment_aura(user_id: int, amount: int, reason: str = \"action\") -> int:\n   648→    \"\"\"\n   649→    Increment user's aura points.\n   650→\n   651→    Returns new aura total.\n   652→    \"\"\"\n   653→    row = fortune_db.execute_returning_one(\n   654→        \"\"\"\n   655→        UPDATE fortune_digital_twin\n   656→        SET aura_points = aura_points + %s, updated_at = %s\n   657→        WHERE user_id = %s\n   658→        RETURNING aura_points\n   659→        \"\"\",\n   660→        [amount, _now_utc(), user_id],\n   661→    )\n   662→\n   663→    if not row:\n   664→        # Create twin first\n   665→        twin = create_twin(user_id)\n   666→        row = fortune_db.execute_returning_one(\n   667→            \"\"\"\n   668→            UPDATE fortune_digital_twin\n   669→            SET aura_points = aura_points + %s, updated_at = %s\n   670→            WHERE user_id = %s\n   671→            RETURNING aura_points\n   672→            \"\"\",\n   673→            [amount, _now_utc(), user_id],\n   674→        )\n   675→\n   676→    new_aura = row[\"aura_points\"] if row else 0\n   677→    logger.debug(\"aura_increment user_id=%s amount=%s new_total=%s reason=%s\", user_id, amount, new_aura, reason)\n   678→    return new_aura\n   679→\n   680→\n   681→def increment_growth_streak(user_id: int) -> int:\n   682→    \"\"\"\n   683→    Increment user's growth streak.\n   684→\n   685→    Returns new streak count.\n   686→    \"\"\"\n   687→    row = fortune_db.execute_returning_one(\n   688→        \"\"\"\n   689→        UPDATE fortune_digital_twin\n   690→        SET growth_streak = growth_streak + 1, updated_at = %s\n   691→        WHERE user_id = %s\n   692→        RETURNING growth_streak\n   693→        \"\"\",\n   694→        [_now_utc(), user_id],\n   695→    )\n   696→\n   697→    if not row:\n   698→        twin = create_twin(user_id)\n   699→        return 1\n   700→\n   701→    return row[\"growth_streak\"]\n   702→\n   703→\n   704→def reset_growth_streak(user_id: int) -> None:\n   705→    \"\"\"Reset user's growth streak to 0.\"\"\"\n   706→    fortune_db.execute(\n   707→        \"\"\"\n   708→        UPDATE fortune_digital_twin\n   709→        SET growth_streak = 0, updated_at = %s\n   710→        WHERE user_id = %s\n   711→        \"\"\",\n   712→        [_now_utc(), user_id],\n   713→    )\n   714→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"b226cf64-9626-42ff-b587-0bd1d3b82083","timestamp":"2026-01-01T15:01:09.989Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aiscend/work/fortune_ai/services/twin_service.py","content":"\"\"\"\nDigital Twin Service.\n\nREQ: REQ-TWIN-001 ~ REQ-TWIN-005\nDesign: §3.1.1 ~ §3.1.3\nHOS-REF: §1.2, §1.3, §10.5.2\n\"\"\"\n\nfrom __future__ import annotations\n\nimport json\nfrom datetime import datetime, timezone\nfrom typing import Any, Dict, List, Optional, Tuple\n\nfrom common.logging import get_logger\nfrom models.twin import (\n    DimensionScores,\n    TwinData,\n    TwinHistoryEntry,\n    TwinHistoryResponse,\n    TwinLayer,\n    TwinUpdateEvent,\n    TwinUpdateResult,\n)\nfrom stores import fortune_db\n\nlogger = get_logger(__name__)\n\n\nclass TwinServiceError(Exception):\n    \"\"\"Base exception for twin service errors.\"\"\"\n    pass\n\n\nclass TwinNotFoundError(TwinServiceError):\n    \"\"\"Twin not found for user.\"\"\"\n    pass\n\n\ndef _now_utc() -> datetime:\n    return datetime.now(timezone.utc)\n\n\ndef _row_to_twin(row: Dict[str, Any]) -> TwinData:\n    \"\"\"Convert database row to TwinData model.\"\"\"\n    dimension_scores_raw = row.get(\"dimension_scores\") or {}\n    if isinstance(dimension_scores_raw, str):\n        dimension_scores_raw = json.loads(dimension_scores_raw)\n\n    return TwinData(\n        twin_id=row.get(\"twin_id\"),\n        user_id=row[\"user_id\"],\n        metadata_astrology=row.get(\"metadata_astrology\") or {},\n        metadata_psychology=row.get(\"metadata_psychology\") or {},\n        metadata_memory=row.get(\"metadata_memory\") or {},\n        dynamic_astro=row.get(\"dynamic_astro\") or {},\n        dynamic_bio=row.get(\"dynamic_bio\") or {},\n        dynamic_social=row.get(\"dynamic_social\") or {},\n        dynamic_emotional=row.get(\"dynamic_emotional\") or {},\n        aura_points=row.get(\"aura_points\") or 0,\n        overall_wellbeing=float(row.get(\"overall_wellbeing\") or 50.0),\n        growth_streak=row.get(\"growth_streak\") or 0,\n        dimension_scores=DimensionScores(**dimension_scores_raw),\n        compute_version=row.get(\"compute_version\") or \"v1.0\",\n        last_full_refresh=row.get(\"last_full_refresh\"),\n        created_at=row.get(\"created_at\"),\n        updated_at=row.get(\"updated_at\"),\n    )\n\n\ndef _get_bazi_data_for_user(user_id: int) -> Dict[str, Any]:\n    \"\"\"\n    Fetch bazi snapshot data for user.\n    Returns empty dict if no bazi data exists.\n    \"\"\"\n    row = fortune_db.fetch_one(\n        \"\"\"\n        SELECT facts, facts_hash, compute_version\n        FROM fortune_bazi_snapshot\n        WHERE user_id = %s\n        ORDER BY created_at DESC\n        LIMIT 1\n        \"\"\",\n        [user_id],\n    )\n    if not row:\n        return {}\n\n    facts = row.get(\"facts\") or {}\n    if isinstance(facts, str):\n        facts = json.loads(facts)\n\n    return {\n        \"bazi\": facts,\n        \"facts_hash\": row.get(\"facts_hash\"),\n        \"compute_version\": row.get(\"compute_version\"),\n    }\n\n\n# =============================================================================\n# TASK-1.2.1: create_twin\n# =============================================================================\n\ndef create_twin(user_id: int) -> TwinData:\n    \"\"\"\n    Create a new digital twin for user.\n\n    REQ: REQ-TWIN-001\n    Design: §3.1.1 步骤 1-3\n\n    - Idempotent: returns existing twin if already exists\n    - Syncs bazi data from fortune_bazi_snapshot to L1\n    - Initializes all default values\n    \"\"\"\n    # Check if twin already exists (idempotent)\n    existing = fortune_db.fetch_one(\n        \"SELECT * FROM fortune_digital_twin WHERE user_id = %s\",\n        [user_id],\n    )\n    if existing:\n        logger.debug(\"twin_exists user_id=%s twin_id=%s\", user_id, existing[\"twin_id\"])\n        return _row_to_twin(existing)\n\n    # Fetch bazi data for L1 metadata\n    bazi_data = _get_bazi_data_for_user(user_id)\n\n    # Initialize default dimension scores\n    default_dimensions = {\n        \"energy\": 50,\n        \"clarity\": 50,\n        \"connection\": 50,\n        \"growth\": 50,\n        \"balance\": 50,\n    }\n\n    # Insert new twin\n    row = fortune_db.execute_returning_one(\n        \"\"\"\n        INSERT INTO fortune_digital_twin (\n            user_id,\n            metadata_astrology,\n            metadata_psychology,\n            metadata_memory,\n            dynamic_astro,\n            dynamic_bio,\n            dynamic_social,\n            dynamic_emotional,\n            aura_points,\n            overall_wellbeing,\n            growth_streak,\n            dimension_scores,\n            compute_version,\n            created_at,\n            updated_at\n        ) VALUES (\n            %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s\n        )\n        RETURNING *\n        \"\"\",\n        [\n            user_id,\n            json.dumps(bazi_data),  # metadata_astrology\n            json.dumps({}),  # metadata_psychology\n            json.dumps({}),  # metadata_memory\n            json.dumps({}),  # dynamic_astro\n            json.dumps({}),  # dynamic_bio\n            json.dumps({}),  # dynamic_social\n            json.dumps({}),  # dynamic_emotional\n            0,  # aura_points\n            50.0,  # overall_wellbeing\n            0,  # growth_streak\n            json.dumps(default_dimensions),  # dimension_scores\n            \"v1.0\",  # compute_version\n            _now_utc(),  # created_at\n            _now_utc(),  # updated_at\n        ],\n    )\n\n    if not row:\n        raise TwinServiceError(f\"Failed to create twin for user {user_id}\")\n\n    logger.info(\"twin_created user_id=%s twin_id=%s\", user_id, row[\"twin_id\"])\n    return _row_to_twin(row)\n\n\n# =============================================================================\n# TASK-1.2.2: get_twin\n# =============================================================================\n\ndef get_twin(\n    user_id: int,\n    layers: Optional[List[TwinLayer]] = None,\n    auto_create: bool = True,\n) -> TwinData:\n    \"\"\"\n    Get digital twin for user.\n\n    REQ: REQ-TWIN-002\n    Design: §3.1.2 步骤 1-3\n\n    Args:\n        user_id: User ID\n        layers: Optional list of layers to include (default: all)\n        auto_create: If True, create twin if not exists\n\n    Returns:\n        TwinData with requested layers\n    \"\"\"\n    row = fortune_db.fetch_one(\n        \"SELECT * FROM fortune_digital_twin WHERE user_id = %s\",\n        [user_id],\n    )\n\n    if not row:\n        if auto_create:\n            logger.debug(\"twin_auto_create user_id=%s\", user_id)\n            return create_twin(user_id)\n        raise TwinNotFoundError(f\"Twin not found for user {user_id}\")\n\n    twin = _row_to_twin(row)\n    logger.debug(\"twin_query user_id=%s twin_id=%s\", user_id, twin.twin_id)\n    return twin\n\n\ndef get_twin_by_layer(\n    user_id: int,\n    layer: str,\n    auto_create: bool = True,\n) -> Dict[str, Any]:\n    \"\"\"\n    Get specific layer data for user's twin.\n\n    Args:\n        user_id: User ID\n        layer: Layer name ('L1', 'L2', 'L3', or 'all')\n        auto_create: If True, create twin if not exists\n\n    Returns:\n        Dict with layer data\n    \"\"\"\n    twin = get_twin(user_id, auto_create=auto_create)\n\n    if layer == \"all\":\n        return twin.model_dump()\n    elif layer == \"L1\":\n        return twin.get_layer(TwinLayer.L1)\n    elif layer == \"L2\":\n        return twin.get_layer(TwinLayer.L2)\n    elif layer == \"L3\":\n        return twin.get_layer(TwinLayer.L3)\n    else:\n        raise ValueError(f\"Invalid layer: {layer}\")\n\n\n# =============================================================================\n# TASK-1.2.3: update_twin\n# =============================================================================\n\ndef _parse_json_path(path: str) -> Tuple[str, List[str]]:\n    \"\"\"\n    Parse JSON path to column name and path parts.\n\n    Example:\n        'dynamic_emotional.current_mood' -> ('dynamic_emotional', ['current_mood'])\n        'metadata_astrology.bazi.day_master' -> ('metadata_astrology', ['bazi', 'day_master'])\n    \"\"\"\n    parts = path.split(\".\")\n    if not parts:\n        raise ValueError(f\"Invalid path: {path}\")\n\n    column = parts[0]\n    path_parts = parts[1:] if len(parts) > 1 else []\n\n    # Validate column name\n    valid_columns = {\n        \"metadata_astrology\", \"metadata_psychology\", \"metadata_memory\",\n        \"dynamic_astro\", \"dynamic_bio\", \"dynamic_social\", \"dynamic_emotional\",\n        \"dimension_scores\",\n    }\n    if column not in valid_columns:\n        raise ValueError(f\"Invalid column in path: {column}\")\n\n    return column, path_parts\n\n\ndef _get_nested_value(data: Dict[str, Any], path_parts: List[str]) -> Any:\n    \"\"\"Get nested value from dict using path parts.\"\"\"\n    current = data\n    for part in path_parts:\n        if isinstance(current, dict):\n            current = current.get(part)\n        else:\n            return None\n    return current\n\n\ndef _set_nested_value(data: Dict[str, Any], path_parts: List[str], value: Any) -> Dict[str, Any]:\n    \"\"\"Set nested value in dict using path parts. Returns new dict.\"\"\"\n    if not path_parts:\n        return value if isinstance(value, dict) else data\n\n    result = dict(data)\n    current = result\n\n    for i, part in enumerate(path_parts[:-1]):\n        if part not in current or not isinstance(current[part], dict):\n            current[part] = {}\n        current[part] = dict(current[part])\n        current = current[part]\n\n    current[path_parts[-1]] = value\n    return result\n\n\ndef update_twin(event: TwinUpdateEvent) -> TwinUpdateResult:\n    \"\"\"\n    Update digital twin data.\n\n    REQ: REQ-TWIN-003\n    Design: §3.1.3 步骤 1-5\n\n    - Uses transaction for atomicity (FOR UPDATE lock held until commit)\n    - Supports nested path updates via jsonb_set\n    - Records old_value and new_value in log\n    - Triggers L3 recalculation if L2 is updated\n    \"\"\"\n    user_id = event.user_id\n    column, path_parts = _parse_json_path(event.path)\n\n    # Use transaction to ensure atomicity: FOR UPDATE lock is held until commit\n    with fortune_db.transaction() as tx:\n        # Get current twin with row lock\n        row = tx.fetch_one(\n            \"SELECT * FROM fortune_digital_twin WHERE user_id = %s FOR UPDATE\",\n            [user_id],\n        )\n        if not row:\n            # Auto-create twin if not exists (outside transaction, then re-lock)\n            twin = create_twin(user_id)\n            row = tx.fetch_one(\n                \"SELECT * FROM fortune_digital_twin WHERE user_id = %s FOR UPDATE\",\n                [user_id],\n            )\n\n        twin_id = row[\"twin_id\"]\n\n        # Get current column value\n        current_data = row.get(column) or {}\n        if isinstance(current_data, str):\n            current_data = json.loads(current_data)\n\n        # Get old value\n        old_value = _get_nested_value(current_data, path_parts) if path_parts else current_data\n\n        # Set new value\n        if path_parts:\n            new_data = _set_nested_value(current_data, path_parts, event.new_value)\n        else:\n            new_data = event.new_value if isinstance(event.new_value, dict) else current_data\n\n        # Update database (within same transaction)\n        tx.execute(\n            f\"\"\"\n            UPDATE fortune_digital_twin\n            SET {column} = %s, updated_at = %s\n            WHERE twin_id = %s\n            \"\"\",\n            [json.dumps(new_data), _now_utc(), twin_id],\n        )\n\n        # Write update log (within same transaction)\n        log_row = tx.execute_returning_one(\n            \"\"\"\n            INSERT INTO fortune_twin_update_log (\n                twin_id, trigger_type, layer, path, old_value, new_value,\n                confidence, source, created_at\n            ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n            RETURNING log_id\n            \"\"\",\n            [\n                twin_id,\n                event.trigger,\n                event.layer.value,\n                event.path,\n                json.dumps(old_value) if old_value is not None else None,\n                json.dumps(event.new_value),\n                event.confidence,\n                event.source,\n                _now_utc(),\n            ],\n        )\n\n        log_id = log_row[\"log_id\"] if log_row else None\n    # Transaction commits here, lock released\n\n    # Trigger L3 recalculation if L2 was updated (outside transaction)\n    dimensions_recalculated = False\n    if event.layer == TwinLayer.L2:\n        recalculate_dimensions(user_id)\n        dimensions_recalculated = True\n\n    logger.info(\n        \"twin_update user_id=%s twin_id=%s path=%s layer=%s trigger=%s\",\n        user_id, twin_id, event.path, event.layer.value, event.trigger\n    )\n\n    return TwinUpdateResult(\n        updated=True,\n        log_id=log_id,\n        old_value=old_value,\n        new_value=event.new_value,\n        dimensions_recalculated=dimensions_recalculated,\n    )\n\n\n# =============================================================================\n# TASK-1.2.4: recalculate_dimensions\n# =============================================================================\n\ndef recalculate_dimensions(user_id: int) -> DimensionScores:\n    \"\"\"\n    Recalculate L3 dimension scores from L2 data.\n\n    REQ: REQ-TWIN-004\n    Design: §3.1.3 步骤 4\n\n    Dimension formulas:\n    - energy: f(mood_intensity, sleep_score, activity_level)\n    - clarity: f(focus_score, stress_level, meditation_minutes)\n    - connection: f(social_interactions, buffs_received, relationship_quality)\n    - growth: f(commitments_completed, streak, learning_activities)\n    - balance: f(work_life_ratio, emotional_stability, routine_adherence)\n    \"\"\"\n    row = fortune_db.fetch_one(\n        \"\"\"\n        SELECT dynamic_bio, dynamic_social, dynamic_emotional,\n               aura_points, growth_streak\n        FROM fortune_digital_twin\n        WHERE user_id = %s\n        \"\"\",\n        [user_id],\n    )\n\n    if not row:\n        raise TwinNotFoundError(f\"Twin not found for user {user_id}\")\n\n    # Parse L2 data\n    bio = row.get(\"dynamic_bio\") or {}\n    social = row.get(\"dynamic_social\") or {}\n    emotional = row.get(\"dynamic_emotional\") or {}\n    aura = row.get(\"aura_points\") or 0\n    streak = row.get(\"growth_streak\") or 0\n\n    if isinstance(bio, str):\n        bio = json.loads(bio)\n    if isinstance(social, str):\n        social = json.loads(social)\n    if isinstance(emotional, str):\n        emotional = json.loads(emotional)\n\n    # Calculate energy dimension\n    mood_intensity = emotional.get(\"mood_intensity\", 5)\n    sleep_score = bio.get(\"sleep_score\", 50)\n    activity_level = bio.get(\"activity_level\", 50)\n    energy = (mood_intensity * 5 + sleep_score * 0.3 + activity_level * 0.2)\n    energy = max(0, min(100, energy))\n\n    # Calculate clarity dimension\n    focus_score = emotional.get(\"focus_score\", 50)\n    stress_level = emotional.get(\"stress_level\", 50)\n    meditation_minutes = bio.get(\"meditation_minutes\", 0)\n    clarity = focus_score * 0.4 + (100 - stress_level) * 0.4 + min(meditation_minutes, 30) * 0.67\n    clarity = max(0, min(100, clarity))\n\n    # Calculate connection dimension\n    social_interactions = social.get(\"interactions_today\", 0)\n    buffs_received = social.get(\"recent_buffs_received\", 0)\n    relationship_quality = social.get(\"relationship_quality\", 50)\n    connection = min(social_interactions * 5, 30) + min(buffs_received * 10, 30) + relationship_quality * 0.4\n    connection = max(0, min(100, connection))\n\n    # Calculate growth dimension\n    commitments_completed = social.get(\"commitments_completed_week\", 0)\n    learning_activities = bio.get(\"learning_activities\", 0)\n    growth = min(commitments_completed * 10, 40) + min(streak * 2, 30) + min(learning_activities * 5, 30)\n    growth = max(0, min(100, growth))\n\n    # Calculate balance dimension\n    work_life_ratio = bio.get(\"work_life_ratio\", 50)\n    emotional_stability = 100 - abs(emotional.get(\"mood_volatility\", 0))\n    routine_adherence = bio.get(\"routine_adherence\", 50)\n    balance = work_life_ratio * 0.3 + emotional_stability * 0.4 + routine_adherence * 0.3\n    balance = max(0, min(100, balance))\n\n    # Create dimension scores\n    scores = DimensionScores(\n        energy=energy,\n        clarity=clarity,\n        connection=connection,\n        growth=growth,\n        balance=balance,\n    )\n\n    # Calculate overall wellbeing\n    overall = (energy + clarity + connection + growth + balance) / 5\n\n    # Update database\n    fortune_db.execute(\n        \"\"\"\n        UPDATE fortune_digital_twin\n        SET dimension_scores = %s,\n            overall_wellbeing = %s,\n            updated_at = %s\n        WHERE user_id = %s\n        \"\"\",\n        [json.dumps(scores.model_dump()), overall, _now_utc(), user_id],\n    )\n\n    logger.debug(\"dimension_recalc user_id=%s scores=%s\", user_id, scores.model_dump())\n    return scores\n\n\n# =============================================================================\n# Additional helpers\n# =============================================================================\n\ndef get_twin_history(\n    user_id: int,\n    limit: int = 20,\n    offset: int = 0,\n    trigger_type: Optional[str] = None,\n    layer: Optional[TwinLayer] = None,\n) -> TwinHistoryResponse:\n    \"\"\"\n    Get twin update history.\n\n    REQ: REQ-TWIN-005\n    Design: §3.1 (扩展)\n    \"\"\"\n    # Get twin_id\n    twin_row = fortune_db.fetch_one(\n        \"SELECT twin_id FROM fortune_digital_twin WHERE user_id = %s\",\n        [user_id],\n    )\n    if not twin_row:\n        return TwinHistoryResponse(entries=[], total_count=0, limit=limit, offset=offset)\n\n    twin_id = twin_row[\"twin_id\"]\n\n    # Build query\n    conditions = [\"twin_id = %s\"]\n    params: List[Any] = [twin_id]\n\n    if trigger_type:\n        conditions.append(\"trigger_type = %s\")\n        params.append(trigger_type)\n\n    if layer:\n        conditions.append(\"layer = %s\")\n        params.append(layer.value)\n\n    where_clause = \" AND \".join(conditions)\n\n    # Get total count\n    count_row = fortune_db.fetch_one(\n        f\"SELECT COUNT(*) as cnt FROM fortune_twin_update_log WHERE {where_clause}\",\n        params,\n    )\n    total_count = count_row[\"cnt\"] if count_row else 0\n\n    # Get entries\n    params.extend([limit, offset])\n    rows = fortune_db.fetch_all(\n        f\"\"\"\n        SELECT * FROM fortune_twin_update_log\n        WHERE {where_clause}\n        ORDER BY created_at DESC\n        LIMIT %s OFFSET %s\n        \"\"\",\n        params,\n    )\n\n    entries = []\n    for row in rows:\n        old_val = row.get(\"old_value\")\n        new_val = row.get(\"new_value\")\n        if isinstance(old_val, str):\n            old_val = json.loads(old_val)\n        if isinstance(new_val, str):\n            new_val = json.loads(new_val)\n\n        entries.append(TwinHistoryEntry(\n            log_id=row[\"log_id\"],\n            trigger_type=row[\"trigger_type\"],\n            layer=TwinLayer(row[\"layer\"]),\n            path=row[\"path\"],\n            old_value=old_val,\n            new_value=new_val,\n            confidence=float(row[\"confidence\"]),\n            source=row[\"source\"],\n            created_at=row[\"created_at\"],\n        ))\n\n    return TwinHistoryResponse(\n        entries=entries,\n        total_count=total_count,\n        limit=limit,\n        offset=offset,\n    )\n\n\ndef sync_bazi_to_twin(user_id: int) -> bool:\n    \"\"\"\n    Sync latest bazi snapshot to twin's L1 metadata.\n\n    Called when bazi data is updated.\n    \"\"\"\n    bazi_data = _get_bazi_data_for_user(user_id)\n    if not bazi_data:\n        return False\n\n    # Check if twin exists\n    row = fortune_db.fetch_one(\n        \"SELECT twin_id FROM fortune_digital_twin WHERE user_id = %s\",\n        [user_id],\n    )\n\n    if not row:\n        # Create twin with bazi data\n        create_twin(user_id)\n        return True\n\n    # Update existing twin\n    fortune_db.execute(\n        \"\"\"\n        UPDATE fortune_digital_twin\n        SET metadata_astrology = %s, updated_at = %s\n        WHERE user_id = %s\n        \"\"\",\n        [json.dumps(bazi_data), _now_utc(), user_id],\n    )\n\n    logger.info(\"bazi_synced_to_twin user_id=%s\", user_id)\n    return True\n\n\ndef increment_aura(user_id: int, amount: int, reason: str = \"action\") -> int:\n    \"\"\"\n    Increment user's aura points.\n\n    Returns new aura total.\n    \"\"\"\n    row = fortune_db.execute_returning_one(\n        \"\"\"\n        UPDATE fortune_digital_twin\n        SET aura_points = aura_points + %s, updated_at = %s\n        WHERE user_id = %s\n        RETURNING aura_points\n        \"\"\",\n        [amount, _now_utc(), user_id],\n    )\n\n    if not row:\n        # Create twin first\n        twin = create_twin(user_id)\n        row = fortune_db.execute_returning_one(\n            \"\"\"\n            UPDATE fortune_digital_twin\n            SET aura_points = aura_points + %s, updated_at = %s\n            WHERE user_id = %s\n            RETURNING aura_points\n            \"\"\",\n            [amount, _now_utc(), user_id],\n        )\n\n    new_aura = row[\"aura_points\"] if row else 0\n    logger.debug(\"aura_increment user_id=%s amount=%s new_total=%s reason=%s\", user_id, amount, new_aura, reason)\n    return new_aura\n\n\ndef increment_growth_streak(user_id: int) -> int:\n    \"\"\"\n    Increment user's growth streak.\n\n    Returns new streak count.\n    \"\"\"\n    row = fortune_db.execute_returning_one(\n        \"\"\"\n        UPDATE fortune_digital_twin\n        SET growth_streak = growth_streak + 1, updated_at = %s\n        WHERE user_id = %s\n        RETURNING growth_streak\n        \"\"\",\n        [_now_utc(), user_id],\n    )\n\n    if not row:\n        twin = create_twin(user_id)\n        return 1\n\n    return row[\"growth_streak\"]\n\n\ndef reset_growth_streak(user_id: int) -> None:\n    \"\"\"Reset user's growth streak to 0.\"\"\"\n    fortune_db.execute(\n        \"\"\"\n        UPDATE fortune_digital_twin\n        SET growth_streak = 0, updated_at = %s\n        WHERE user_id = %s\n        \"\"\",\n        [_now_utc(), user_id],\n    )\n","numLines":714,"startLine":1,"totalLines":714}}}
{"parentUuid":"b226cf64-9626-42ff-b587-0bd1d3b82083","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01GZwQ1LfW3gcGvuGtc5eKDn","type":"tool_result","content":"     1→\"\"\"\n     2→Soul OS 核心服务层\n     3→\n     4→基于 os_design_claude_mvp.md 的四层架构实现：\n     5→- L0 Firmware: 八字事实快照管理\n     6→- L1 Schema: PERMA + 行为证据汇总\n     7→- L2 Agents: 知识库检索 + Prompt 模板\n     8→- L3 Synthesis: GLM 整合 + A2UI 输出\n     9→\n    10→包含：\n    11→- State Score 计算\n    12→- 反依赖机制\n    13→- JITAI 调节动作库\n    14→- Guidance Card 生成\n    15→\"\"\"\n    16→\n    17→from __future__ import annotations\n    18→\n    19→import hashlib\n    20→import json\n    21→from dataclasses import dataclass, field\n    22→from datetime import date, datetime, timedelta, timezone\n    23→from enum import Enum\n    24→from typing import Any, Dict, List, Optional, Tuple\n    25→from uuid import uuid4\n    26→\n    27→from common.logging import get_logger\n    28→from stores import fortune_db\n    29→\n    30→logger = get_logger(__name__)\n    31→\n    32→\n    33→# =============================================================================\n    34→# Enums & Constants\n    35→# =============================================================================\n    36→\n    37→class PersonaStyle(str, Enum):\n    38→    STANDARD = \"standard\"  # 清晰、中性、专业\n    39→    WARM = \"warm\"          # 共情、支持性（默认）\n    40→    ROAST = \"roast\"        # 轻毒舌但不羞辱\n    41→\n    42→\n    43→class CommitmentType(str, Enum):\n    44→    START_TASK = \"start_task\"        # 立刻开始\n    45→    SCHEDULE_TASK = \"schedule_task\"  # 加入计划\n    46→    ASK_FOLLOWUP = \"ask_followup\"    # 澄清问题\n    47→    OPT_OUT = \"opt_out\"              # 暂停/关闭\n    48→\n    49→\n    50→class CommitmentStatus(str, Enum):\n    51→    SUGGESTED = \"suggested\"\n    52→    ACTIVE = \"active\"\n    53→    DONE = \"done\"\n    54→    SKIPPED = \"skipped\"\n    55→    CANCELED = \"canceled\"\n    56→\n    57→\n    58→# JITAI 调节动作库\n    59→JITAI_ACTIONS: Dict[str, Dict[str, str]] = {\n    60→    \"焦虑\": {\n    61→        \"high\": \"3分钟呼吸降噪：吸气4秒→屏息7秒→呼气8秒，重复3次。\",\n    62→        \"medium\": \"写下3个最坏情况，并评估每个发生的概率（0-100%）。\",\n    63→        \"low\": \"列出你现在能控制的3件事。\",\n    64→    },\n    65→    \"低落\": {\n    66→        \"high\": \"做一个最小行动：站起来倒杯水，或走到窗边看30秒。\",\n    67→        \"medium\": \"回忆一个小成就并写下来：我做到了____。\",\n    68→        \"low\": \"给自己一句鼓励：这很正常，我正在经历困难。\",\n    69→    },\n    70→    \"愤怒\": {\n    71→        \"high\": \"用力握拳10秒再松开，重复3次。然后深呼吸5次。\",\n    72→        \"medium\": \"写下：我需要的是____。我的底线是____。\",\n    73→        \"low\": \"离开当前场景2分钟，做5次深呼吸。\",\n    74→    },\n    75→    \"困惑\": {\n    76→        \"high\": \"写下3个选项和1个最重要的约束条件。\",\n    77→        \"medium\": \"列出2个选项，问自己：如果只能选一个，我会选哪个？为什么？\",\n    78→        \"low\": \"画一个简单的决策树：选项A→结果；选项B→结果。\",\n    79→    },\n    80→    \"兴奋\": {\n    81→        \"high\": \"写下这个感觉的来源，并把能量转化为一个2分钟行动。\",\n    82→        \"medium\": \"记录下这一刻，稍后复盘时用。\",\n    83→        \"low\": \"享受这个感觉，同时提醒自己不做冲动决策。\",\n    84→    },\n    85→    \"平静\": {\n    86→        \"high\": \"写下今天最想保留的一个做法。\",\n    87→        \"medium\": \"保持当前状态，安排一个5分钟的延续动作。\",\n    88→        \"low\": \"保持这个状态，继续当前的事。\",\n    89→    },\n    90→}\n    91→\n    92→# 心理学翻译规则：八字概念 → 可操作心理语言\n    93→BAZI_PSYCHOLOGY_TRANSLATIONS: Dict[str, Dict[str, str]] = {\n    94→    \"weak\": {\n    95→        \"translation\": \"你的能量更适合借力/合作，而非单打独斗\",\n    96→        \"action\": \"本周找一个支持者或合作伙伴\",\n    97→    },\n    98→    \"strong\": {\n    99→        \"translation\": \"你有充沛的内在能量，适合独立行动\",\n   100→        \"action\": \"设定一个独立完成的小目标\",\n   101→    },\n   102→    \"neutral\": {\n   103→        \"translation\": \"你的能量相对平衡，灵活度高\",\n   104→        \"action\": \"根据具体情况选择独立或合作\",\n   105→    },\n   106→    \"食伤重\": {\n   107→        \"translation\": \"你有强烈的表达欲和创造力\",\n   108→        \"action\": \"每天留15分钟自由书写或创作\",\n   109→    },\n   110→    \"官杀混杂\": {\n   111→        \"translation\": \"你可能感受到多重压力或权威冲突\",\n   112→        \"action\": \"写清哪些压力是你能控制的，哪些不能\",\n   113→    },\n   114→    \"桃花星\": {\n   115→        \"translation\": \"你在关系中有天然的吸引力和敏感度\",\n   116→        \"action\": \"觉察关系中的边界需求\",\n   117→    },\n   118→    \"驿马星\": {\n   119→        \"translation\": \"你有变动/探索的内在驱力\",\n   120→        \"action\": \"小范围实验胜过大规模改变\",\n   121→    },\n   122→    \"华盖\": {\n   123→        \"translation\": \"你有独立思考和精神探索的倾向\",\n   124→        \"action\": \"每周留1小时独处反思时间\",\n   125→    },\n   126→    \"天乙贵人\": {\n   127→        \"translation\": \"你容易获得贵人相助\",\n   128→        \"action\": \"主动寻求帮助，不要独自扛\",\n   129→    },\n   130→    \"文昌\": {\n   131→        \"translation\": \"你在学习和文字方面有天赋\",\n   132→        \"action\": \"保持学习习惯，用写作整理思路\",\n   133→    },\n   134→}\n   135→\n   136→\n   137→# =============================================================================\n   138→# Data Classes\n   139→# =============================================================================\n   140→\n   141→@dataclass\n   142→class StateScore:\n   143→    \"\"\"状态分数 - 把\"感觉\"变成可训练变量\"\"\"\n   144→    score: int  # 0-100\n   145→    emotion_signal: int  # 40% 权重\n   146→    action_signal: int   # 40% 权重\n   147→    streak_signal: int   # 20% 权重\n   148→    recovery_action: str  # 分数低时的补救动作\n   149→\n   150→    def to_dict(self) -> Dict[str, Any]:\n   151→        return {\n   152→            \"score\": self.score,\n   153→            \"breakdown\": {\n   154→                \"emotion\": self.emotion_signal,\n   155→                \"action\": self.action_signal,\n   156→                \"streak\": self.streak_signal,\n   157→            },\n   158→            \"recovery_action\": self.recovery_action,\n   159→        }\n   160→\n   161→\n   162→@dataclass\n   163→class PermaSnapshot:\n   164→    \"\"\"PERMA 积极心理学快照\"\"\"\n   165→    positive_emotion: Dict[str, Any] = field(default_factory=dict)\n   166→    engagement: Dict[str, Any] = field(default_factory=dict)\n   167→    relationships: Dict[str, Any] = field(default_factory=dict)\n   168→    meaning: Dict[str, Any] = field(default_factory=dict)\n   169→    accomplishment: Dict[str, Any] = field(default_factory=dict)\n   170→\n   171→    def to_dict(self) -> Dict[str, Any]:\n   172→        return {\n   173→            \"positive_emotion\": self.positive_emotion,\n   174→            \"engagement\": self.engagement,\n   175→            \"relationships\": self.relationships,\n   176→            \"meaning\": self.meaning,\n   177→            \"accomplishment\": self.accomplishment,\n   178→        }\n   179→\n   180→\n   181→@dataclass\n   182→class L1Schema:\n   183→    \"\"\"L1 特质层数据\"\"\"\n   184→    perma: PermaSnapshot\n   185→    cognitive_patterns: Dict[str, Any]\n   186→    strengths_in_use: List[str]\n   187→    preferences: Dict[str, Any]\n   188→\n   189→    def to_dict(self) -> Dict[str, Any]:\n   190→        return {\n   191→            \"perma_snapshot\": self.perma.to_dict(),\n   192→            \"cognitive_patterns\": self.cognitive_patterns,\n   193→            \"strengths_in_use\": self.strengths_in_use,\n   194→            \"preferences\": self.preferences,\n   195→        }\n   196→\n   197→\n   198→@dataclass\n   199→class AntiDependencyState:\n   200→    \"\"\"反依赖状态追踪\"\"\"\n   201→    same_question_count: int = 0\n   202→    daily_consult_count: int = 0\n   203→    last_action_days: int = 0\n   204→    should_intervene: bool = False\n   205→    intervention_type: str = \"\"\n   206→    intervention_message: str = \"\"\n   207→    suggested_task: Optional[Dict[str, Any]] = None  # 干预时必须返回的任务\n   208→    is_new_user: bool = False  # 是否为新用户（7天内）\n   209→\n   210→\n   211→@dataclass\n   212→class GuidanceCard:\n   213→    \"\"\"指导卡片\"\"\"\n   214→    card_id: str\n   215→    card_type: str\n   216→    conclusion: str\n   217→    why: str\n   218→    prescriptions: List[Dict[str, Any]]\n   219→    time_window: Dict[str, Any]\n   220→    risk_boundary: str\n   221→    commitment_ask: str\n   222→    actions: List[Dict[str, Any]]\n   223→    evidence: Dict[str, Any]\n   224→    created_at: str\n   225→\n   226→    def to_dict(self) -> Dict[str, Any]:\n   227→        return {\n   228→            \"card_id\": self.card_id,\n   229→            \"type\": self.card_type,\n   230→            \"conclusion\": self.conclusion,\n   231→            \"why\": self.why,\n   232→            \"prescriptions\": self.prescriptions,\n   233→            \"time_window\": self.time_window,\n   234→            \"risk_boundary\": self.risk_boundary,\n   235→            \"commitment_ask\": self.commitment_ask,\n   236→            \"actions\": self.actions,\n   237→            \"evidence\": self.evidence,\n   238→            \"created_at\": self.created_at,\n   239→        }\n   240→\n   241→\n   242→# =============================================================================\n   243→# L0 Firmware Layer - 八字事实快照管理\n   244→# =============================================================================\n   245→\n   246→def get_l0_facts(user_id: int) -> Dict[str, Any]:\n   247→    \"\"\"获取 L0 层八字事实快照\"\"\"\n   248→    snap = fortune_db.fetch_one(\n   249→        \"\"\"\n   250→        SELECT facts, facts_hash, compute_version\n   251→        FROM fortune_bazi_snapshot\n   252→        WHERE user_id = %s\n   253→        ORDER BY created_at DESC\n   254→        LIMIT 1\n   255→        \"\"\",\n   256→        (int(user_id),),\n   257→    )\n   258→    if not snap:\n   259→        return {\"facts\": {}, \"facts_hash\": \"\", \"compute_version\": \"\"}\n   260→    return {\n   261→        \"facts\": snap.get(\"facts\") or {},\n   262→        \"facts_hash\": str(snap.get(\"facts_hash\") or \"\"),\n   263→        \"compute_version\": str(snap.get(\"compute_version\") or \"\"),\n   264→    }\n   265→\n   266→\n   267→def translate_bazi_to_psychology(facts: Dict[str, Any]) -> List[Dict[str, str]]:\n   268→    \"\"\"将八字概念翻译为可操作的心理学语言\"\"\"\n   269→    translations = []\n   270→    bazi = facts.get(\"bazi\", {})\n   271→\n   272→    # 旺衰翻译\n   273→    strength = bazi.get(\"strength\", {})\n   274→    status = strength.get(\"level\", \"neutral\")\n   275→    if status in BAZI_PSYCHOLOGY_TRANSLATIONS:\n   276→        trans = BAZI_PSYCHOLOGY_TRANSLATIONS[status]\n   277→        translations.append({\n   278→            \"concept\": f\"日主{status}\",\n   279→            \"translation\": trans[\"translation\"],\n   280→            \"action\": trans[\"action\"],\n   281→        })\n   282→\n   283→    # 神煞翻译\n   284→    for shensha in bazi.get(\"shensha\", []):\n   285→        if shensha.get(\"hit\"):\n   286→            name = shensha.get(\"name\", \"\")\n   287→            if name in BAZI_PSYCHOLOGY_TRANSLATIONS:\n   288→                trans = BAZI_PSYCHOLOGY_TRANSLATIONS[name]\n   289→                translations.append({\n   290→                    \"concept\": name,\n   291→                    \"translation\": trans[\"translation\"],\n   292→                    \"action\": trans[\"action\"],\n   293→                })\n   294→\n   295→    return translations\n   296→\n   297→\n   298→# =============================================================================\n   299→# L1 Schema Layer - PERMA + 行为证据汇总\n   300→# =============================================================================\n   301→\n   302→def get_l1_schema(user_id: int, window_days: int = 7) -> L1Schema:\n   303→    \"\"\"获取 L1 层特质图式\"\"\"\n   304→    uid = int(user_id)\n   305→    window_start = datetime.now(timezone.utc) - timedelta(days=window_days)\n   306→\n   307→    # 获取用户偏好\n   308→    prefs = fortune_db.fetch_one(\n   309→        \"SELECT * FROM fortune_user_preferences WHERE user_id = %s\",\n   310→        (uid,),\n   311→    ) or {}\n   312→\n   313→    # P: Positive Emotion - 从 checkin 获取\n   314→    checkins = fortune_db.fetch_all(\n   315→        \"\"\"\n   316→        SELECT mood, intensity, created_at\n   317→        FROM fortune_checkin\n   318→        WHERE user_id = %s AND created_at >= %s\n   319→        ORDER BY created_at DESC\n   320→        LIMIT 20\n   321→        \"\"\",\n   322→        (uid, window_start),\n   323→    )\n   324→\n   325→    positive_moods = [\"平静\", \"兴奋\", \"开心\", \"满足\", \"感恩\"]\n   326→    negative_moods = [\"焦虑\", \"愤怒\", \"沮丧\", \"悲伤\", \"恐惧\"]\n   327→\n   328→    # 分别计算正负面情绪的平均强度\n   329→    positive_checkins = [c for c in checkins if c.get(\"mood\") in positive_moods]\n   330→    negative_checkins = [c for c in checkins if c.get(\"mood\") in negative_moods]\n   331→\n   332→    pos_avg = sum(c.get(\"intensity\", 5) for c in positive_checkins) / len(positive_checkins) if positive_checkins else 0\n   333→    neg_avg = sum(c.get(\"intensity\", 5) for c in negative_checkins) / len(negative_checkins) if negative_checkins else 0\n   334→\n   335→    # 正向情绪高强度=加分，负向情绪高强度=扣分，基线5分\n   336→    raw_score = pos_avg - neg_avg + 5 if checkins else 5.0\n   337→    positive_count = len(positive_checkins)\n   338→\n   339→    positive_emotion = {\n   340→        \"score\": round(max(0, min(10, raw_score)), 1),\n   341→        \"trend\": \"up\" if positive_count > len(checkins) / 2 else \"stable\",\n   342→        \"recent_count\": len(checkins),\n   343→    }\n   344→\n   345→    # E: Engagement - 从 plan enrollment 获取\n   346→    enrollments = fortune_db.fetch_all(\n   347→        \"\"\"\n   348→        SELECT plan_id, status, current_day\n   349→        FROM fortune_plan_enrollment\n   350→        WHERE user_id = %s AND status = 'active'\n   351→        \"\"\",\n   352→        (uid,),\n   353→    )\n   354→\n   355→    # 计算完成率\n   356→    done_count = fortune_db.fetch_one(\n   357→        \"\"\"\n   358→        SELECT COUNT(*) as cnt\n   359→        FROM fortune_commitment\n   360→        WHERE user_id = %s AND status = 'done' AND created_at >= %s\n   361→        \"\"\",\n   362→        (uid, window_start),\n   363→    ) or {}\n   364→\n   365→    suggested_count = fortune_db.fetch_one(\n   366→        \"\"\"\n   367→        SELECT COUNT(*) as cnt\n   368→        FROM fortune_commitment\n   369→        WHERE user_id = %s AND created_at >= %s\n   370→        \"\"\",\n   371→        (uid, window_start),\n   372→    ) or {}\n   373→\n   374→    total = suggested_count.get(\"cnt\", 0) or 1\n   375→    completion_rate = round(done_count.get(\"cnt\", 0) / total, 2) if total else 0\n   376→\n   377→    engagement = {\n   378→        \"score\": round(completion_rate * 10, 1),  # 0-10 scale\n   379→        \"active_plans\": len(enrollments),\n   380→        \"completion_rate\": completion_rate,\n   381→    }\n   382→\n   383→    # R: Relationships - 从对话中提取（简化版）\n   384→    recent_msgs = fortune_db.fetch_all(\n   385→        \"\"\"\n   386→        SELECT content\n   387→        FROM fortune_conversation_message\n   388→        WHERE user_id = %s AND role = 'user' AND created_at >= %s\n   389→        ORDER BY created_at DESC\n   390→        LIMIT 10\n   391→        \"\"\",\n   392→        (uid, window_start),\n   393→    )\n   394→\n   395→    relationship_keywords = [\"同事\", \"朋友\", \"家人\", \"伴侣\", \"关系\"]\n   396→    relationship_mentions = sum(\n   397→        1 for m in recent_msgs\n   398→        if any(kw in (m.get(\"content\") or \"\") for kw in relationship_keywords)\n   399→    )\n   400→\n   401→    relationships = {\n   402→        \"score\": min(10, relationship_mentions * 2.5),  # 0-10 scale, 4 mentions = 10\n   403→        \"recent_mentions\": relationship_mentions,\n   404→        \"recent_note\": \"\",\n   405→    }\n   406→\n   407→    # M: Meaning - 从计划参与推断\n   408→    aligned_cnt = done_count.get(\"cnt\", 0)\n   409→    meaning = {\n   410→        \"score\": min(10, aligned_cnt),  # 0-10 scale\n   411→        \"core_value\": \"成长\" if enrollments else \"探索\",\n   412→        \"aligned_actions\": aligned_cnt,\n   413→    }\n   414→\n   415→    # A: Accomplishment\n   416→    streak = _calculate_streak(uid)\n   417→    weekly_done = done_count.get(\"cnt\", 0)\n   418→    accomplishment = {\n   419→        \"score\": min(10, weekly_done + streak * 0.5),  # 0-10 scale\n   420→        \"weekly_done\": weekly_done,\n   421→        \"streak\": streak,\n   422→    }\n   423→\n   424→    perma = PermaSnapshot(\n   425→        positive_emotion=positive_emotion,\n   426→        engagement=engagement,\n   427→        relationships=relationships,\n   428→        meaning=meaning,\n   429→        accomplishment=accomplishment,\n   430→    )\n   431→\n   432→    return L1Schema(\n   433→        perma=perma,\n   434→        cognitive_patterns={\"identified_schemas\": [], \"reframe_count\": 0},\n   435→        strengths_in_use=[],\n   436→        preferences={\n   437→            \"persona_style\": prefs.get(\"persona_style\", \"warm\"),\n   438→            \"push_enabled\": prefs.get(\"push_enabled\", True),\n   439→        },\n   440→    )\n   441→\n   442→\n   443→def _calculate_streak(user_id: int) -> int:\n   444→    \"\"\"计算连续行动天数\"\"\"\n   445→    rows = fortune_db.fetch_all(\n   446→        \"\"\"\n   447→        SELECT DATE(done_at) as done_date\n   448→        FROM fortune_commitment\n   449→        WHERE user_id = %s AND status = 'done' AND done_at IS NOT NULL\n   450→        ORDER BY done_at DESC\n   451→        LIMIT 30\n   452→        \"\"\",\n   453→        (int(user_id),),\n   454→    )\n   455→\n   456→    if not rows:\n   457→        return 0\n   458→\n   459→    dates = sorted(set(r[\"done_date\"] for r in rows if r.get(\"done_date\")), reverse=True)\n   460→    if not dates:\n   461→        return 0\n   462→\n   463→    today = date.today()\n   464→    streak = 0\n   465→    expected = today\n   466→\n   467→    for d in dates:\n   468→        if d == expected or d == expected - timedelta(days=1):\n   469→            streak += 1\n   470→            expected = d - timedelta(days=1)\n   471→        else:\n   472→            break\n   473→\n   474→    return streak\n   475→\n   476→\n   477→# =============================================================================\n   478→# State Score 计算\n   479→# =============================================================================\n   480→\n   481→def calculate_state_score(user_id: int, window: str = \"24h\") -> StateScore:\n   482→    \"\"\"\n   483→    计算状态分数（0-100）\n   484→\n   485→    三信号计算：\n   486→    - emotion_signal (40%): 情绪基线\n   487→    - action_signal (40%): 行动完成\n   488→    - streak_signal (20%): 连续记录\n   489→    \"\"\"\n   490→    uid = int(user_id)\n   491→\n   492→    # 确定时间窗口\n   493→    if window == \"24h\":\n   494→        window_start = datetime.now(timezone.utc) - timedelta(hours=24)\n   495→    elif window == \"7d\":\n   496→        window_start = datetime.now(timezone.utc) - timedelta(days=7)\n   497→    else:\n   498→        window_start = datetime.now(timezone.utc) - timedelta(hours=24)\n   499→\n   500→    # 信号1: 情绪基线（40%权重）\n   501→    checkin = fortune_db.fetch_one(\n   502→        \"\"\"\n   503→        SELECT mood, intensity\n   504→        FROM fortune_checkin\n   505→        WHERE user_id = %s AND created_at >= %s\n   506→        ORDER BY created_at DESC\n   507→        LIMIT 1\n   508→        \"\"\",\n   509→        (uid, window_start),\n   510→    )\n   511→\n   512→    if checkin:\n   513→        mood = checkin.get(\"mood\", \"\")\n   514→        intensity = int(checkin.get(\"intensity\", 5))\n   515→        positive_moods = [\"平静\", \"兴奋\", \"开心\", \"满足\", \"感恩\"]\n   516→\n   517→        if mood in positive_moods:\n   518→            # 正向情绪：强度越高越好\n   519→            emotion_signal = intensity * 4\n   520→        else:\n   521→            # 负向情绪：强度越高越差\n   522→            emotion_signal = max(0, (10 - intensity)) * 4\n   523→    else:\n   524→        emotion_signal = 20  # 无打卡给中性分\n   525→\n   526→    # 信号2: 行动完成（40%权重）\n   527→    done_result = fortune_db.fetch_one(\n   528→        \"\"\"\n   529→        SELECT COUNT(*) as cnt\n   530→        FROM fortune_commitment\n   531→        WHERE user_id = %s AND status = 'done' AND done_at >= %s\n   532→        \"\"\",\n   533→        (uid, window_start),\n   534→    ) or {}\n   535→    done_count = done_result.get(\"cnt\", 0)\n   536→    action_signal = min(done_count * 10, 40)\n   537→\n   538→    # 信号3: 连续记录（20%权重）\n   539→    streak = _calculate_streak(uid)\n   540→    streak_signal = min(streak * 4, 20)\n   541→\n   542→    # 总分\n   543→    score = emotion_signal + action_signal + streak_signal\n   544→\n   545→    # 补救动作\n   546→    recovery_action = _get_recovery_action(score, checkin)\n   547→\n   548→    return StateScore(\n   549→        score=score,\n   550→        emotion_signal=emotion_signal,\n   551→        action_signal=action_signal,\n   552→        streak_signal=streak_signal,\n   553→        recovery_action=recovery_action,\n   554→    )\n   555→\n   556→\n   557→def _get_recovery_action(score: int, last_checkin: Optional[Dict[str, Any]]) -> str:\n   558→    \"\"\"根据分数和最近打卡生成补救动作\"\"\"\n   559→    if score >= 70:\n   560→        return \"保持这个状态！今天再完成一个小任务来巩固。\"\n   561→    elif score >= 50:\n   562→        return \"做一个2分钟的最小行动，把分数拉上来。\"\n   563→    elif score >= 30:\n   564→        if last_checkin:\n   565→            mood = last_checkin.get(\"mood\", \"\")\n   566→            intensity = last_checkin.get(\"intensity\", 5)\n   567→            return get_jitai_action(mood, intensity)\n   568→        return \"先做3分钟呼吸降噪，然后完成一个最小任务。\"\n   569→    else:\n   570→        return \"先照顾好自己：喝杯水，做几次深呼吸，然后选一个最小的事情开始。\"\n   571→\n   572→\n   573→# =============================================================================\n   574→# JITAI 调节动作库\n   575→# =============================================================================\n   576→\n   577→def get_jitai_action(mood: str, intensity: int) -> str:\n   578→    \"\"\"获取 JITAI 即时适应性干预动作\"\"\"\n   579→    mood = (mood or \"\").strip()\n   580→    intensity = max(0, min(10, int(intensity)))\n   581→\n   582→    # 确定强度级别\n   583→    if intensity >= 7:\n   584→        level = \"high\"\n   585→    elif intensity >= 4:\n   586→        level = \"medium\"\n   587→    else:\n   588→        level = \"low\"\n   589→\n   590→    # 查找匹配的动作\n   591→    for keyword, actions in JITAI_ACTIONS.items():\n   592→        if keyword in mood:\n   593→            return actions.get(level, actions.get(\"medium\", \"\"))\n   594→\n   595→    # 默认动作\n   596→    if intensity >= 7:\n   597→        return \"先做3分钟呼吸锚点：1分钟呼吸→1分钟身体感受→1分钟选择下一步。\"\n   598→    return \"写下：我现在最需要被满足的一个需求是什么？然后做一个2分钟版本。\"\n   599→\n   600→\n   601→def create_checkin_with_jitai(\n   602→    user_id: int,\n   603→    *,\n   604→    mood: str,\n   605→    intensity: int,\n   606→    note: str = \"\",\n   607→) -> Dict[str, Any]:\n   608→    \"\"\"创建情绪打卡并返回 JITAI 推荐动作\"\"\"\n   609→    uid = int(user_id)\n   610→    mood = (mood or \"\")[:50]\n   611→    intensity = max(0, min(10, int(intensity)))\n   612→    note = (note or \"\")[:1000]\n   613→\n   614→    # 获取推荐动作\n   615→    action = get_jitai_action(mood, intensity)\n   616→\n   617→    # 写入打卡记录\n   618→    fortune_db.execute(\n   619→        \"\"\"\n   620→        INSERT INTO fortune_checkin (user_id, mood, intensity, note, recommended_action)\n   621→        VALUES (%s, %s, %s, %s, %s)\n   622→        \"\"\",\n   623→        (uid, mood, intensity, note, action),\n   624→    )\n   625→\n   626→    # 创建建议任务\n   627→    task_id = str(uuid4())\n   628→    fortune_db.execute(\n   629→        \"\"\"\n   630→        INSERT INTO fortune_commitment (task_id, user_id, source, commitment_type, title, details, status)\n   631→        VALUES (%s::uuid, %s, 'bento', 'start_task', %s, %s::jsonb, 'suggested')\n   632→        \"\"\",\n   633→        (\n   634→            task_id,\n   635→            uid,\n   636→            (action[:200] if action else \"情绪调节动作\"),\n   637→            json.dumps({\"from\": \"checkin\", \"mood\": mood, \"intensity\": intensity}, ensure_ascii=False),\n   638→        ),\n   639→    )\n   640→\n   641→    logger.info(\n   642→        \"checkin created with jitai\",\n   643→        extra={\"operation\": \"checkin_jitai\", \"user_id\": uid, \"mood\": mood, \"intensity\": intensity},\n   644→    )\n   645→\n   646→    return {\n   647→        \"mood\": mood,\n   648→        \"intensity\": intensity,\n   649→        \"recommended_action\": action,\n   650→        \"task_id\": task_id,\n   651→    }\n   652→\n   653→\n   654→# =============================================================================\n   655→# 反依赖机制\n   656→# =============================================================================\n   657→\n   658→def check_anti_dependency(user_id: int, current_message: str = \"\") -> AntiDependencyState:\n   659→    \"\"\"\n   660→    检查反依赖触发条件（优化版）\n   661→\n   662→    优化策略（基于 os_design_claude_mvp v1.md §5）：\n   663→    1. 新用户豁免期：注册7天内不触发 anti-dependency\n   664→    2. 提升日消息阈值：从5提升到8（有活跃任务时降为5）\n   665→    3. 干预时必须返回至少1个可执行任务\n   666→    \"\"\"\n   667→    uid = int(user_id)\n   668→    today_start = datetime.now(timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0)\n   669→\n   670→    state = AntiDependencyState()\n   671→\n   672→    # 检查用户注册时间，判断是否为新用户\n   673→    user_info = fortune_db.fetch_one(\n   674→        \"\"\"\n   675→        SELECT created_at, onboarding_completed\n   676→        FROM fortune_user\n   677→        WHERE user_id = %s\n   678→        \"\"\",\n   679→        (uid,),\n   680→    )\n   681→    if user_info and user_info.get(\"created_at\"):\n   682→        created_at = user_info[\"created_at\"]\n   683→        if hasattr(created_at, \"tzinfo\") and created_at.tzinfo is None:\n   684→            created_at = created_at.replace(tzinfo=timezone.utc)\n   685→        days_since_register = (datetime.now(timezone.utc) - created_at).days\n   686→        onboarding_completed = user_info.get(\"onboarding_completed\", False)\n   687→\n   688→        # 新用户豁免期：注册7天内且未完成引导\n   689→        if days_since_register < 7 and not onboarding_completed:\n   690→            state.is_new_user = True\n   691→            return state  # 新用户直接返回，不触发 anti-dependency\n   692→    else:\n   693→        days_since_register = 999\n   694→\n   695→    # 检查是否有活跃任务\n   696→    active_task = fortune_db.fetch_one(\n   697→        \"\"\"\n   698→        SELECT task_id, title\n   699→        FROM fortune_commitment\n   700→        WHERE user_id = %s AND status = 'active'\n   701→        ORDER BY created_at DESC\n   702→        LIMIT 1\n   703→        \"\"\",\n   704→        (uid,),\n   705→    )\n   706→    has_active_commitment = active_task is not None\n   707→\n   708→    # 动态阈值：有活跃任务时降低阈值\n   709→    daily_message_limit = 5 if has_active_commitment else 8\n   710→\n   711→    # 检查当日咨询次数\n   712→    daily_count = fortune_db.fetch_one(\n   713→        \"\"\"\n   714→        SELECT COUNT(*) as cnt\n   715→        FROM fortune_conversation_message\n   716→        WHERE user_id = %s AND role = 'user' AND created_at >= %s\n   717→        \"\"\",\n   718→        (uid, today_start),\n   719→    ) or {}\n   720→    state.daily_consult_count = daily_count.get(\"cnt\", 0)\n   721→\n   722→    # 检查最近行动天数\n   723→    last_action = fortune_db.fetch_one(\n   724→        \"\"\"\n   725→        SELECT done_at\n   726→        FROM fortune_commitment\n   727→        WHERE user_id = %s AND status = 'done'\n   728→        ORDER BY done_at DESC\n   729→        LIMIT 1\n   730→        \"\"\",\n   731→        (uid,),\n   732→    )\n   733→    if last_action and last_action.get(\"done_at\"):\n   734→        done_at = last_action[\"done_at\"]\n   735→        if hasattr(done_at, \"tzinfo\") and done_at.tzinfo is None:\n   736→            done_at = done_at.replace(tzinfo=timezone.utc)\n   737→        days_since = (datetime.now(timezone.utc) - done_at).days\n   738→        state.last_action_days = days_since\n   739→    else:\n   740→        state.last_action_days = 999\n   741→\n   742→    # 检查是否连续问同一问题（简化：检查最近3条消息相似度）\n   743→    if current_message:\n   744→        recent_msgs = fortune_db.fetch_all(\n   745→            \"\"\"\n   746→            SELECT content\n   747→            FROM fortune_conversation_message\n   748→            WHERE user_id = %s AND role = 'user'\n   749→            ORDER BY created_at DESC\n   750→            LIMIT 3\n   751→            \"\"\",\n   752→            (uid,),\n   753→        )\n   754→        similar_count = sum(\n   755→            1 for m in recent_msgs\n   756→            if _message_similarity(current_message, m.get(\"content\", \"\")) > 0.7\n   757→        )\n   758→        state.same_question_count = similar_count\n   759→\n   760→    # 获取或创建最小可执行任务（干预时必须返回）\n   761→    def get_or_create_minimal_task() -> Dict[str, Any]:\n   762→        # 优先返回已有的活跃任务\n   763→        if active_task:\n   764→            return {\n   765→                \"task_id\": str(active_task.get(\"task_id\", \"\")),\n   766→                \"title\": active_task.get(\"title\", \"完成当前任务\"),\n   767→                \"minutes\": 5,\n   768→                \"source\": \"existing_active\",\n   769→            }\n   770→        # 否则返回一个默认的最小任务\n   771→        return {\n   772→            \"task_id\": None,\n   773→            \"title\": \"做3分钟呼吸锚点：专注呼吸进出，走神时温和拉回\",\n   774→            \"minutes\": 3,\n   775→            \"source\": \"default_minimal\",\n   776→        }\n   777→\n   778→    # 判断是否需要干预\n   779→    if state.same_question_count >= 3:\n   780→        state.should_intervene = True\n   781→        state.intervention_type = \"repeated_question\"\n   782→        state.suggested_task = get_or_create_minimal_task()\n   783→        state.intervention_message = (\n   784→            \"我注意到你多次问了类似的问题。信息足够了，现在最重要的是做一个小实验。\\n\\n\"\n   785→            f\"请先完成这个任务：\\n> **{state.suggested_task['title']}**（约{state.suggested_task['minutes']}分钟）\\n\\n\"\n   786→            \"完成后我们再继续。\"\n   787→        )\n   788→    elif state.daily_consult_count >= daily_message_limit:\n   789→        state.should_intervene = True\n   790→        state.intervention_type = \"daily_limit\"\n   791→        state.suggested_task = get_or_create_minimal_task()\n   792→        state.intervention_message = (\n   793→            \"今天我们聊了很多，信息已经足够了。\\n\\n\"\n   794→            f\"现在最重要的是**先行动**：\\n> **{state.suggested_task['title']}**（约{state.suggested_task['minutes']}分钟）\\n\\n\"\n   795→            \"完成后我们再继续。\"\n   796→        )\n   797→    elif state.last_action_days >= 7 and not state.is_new_user:\n   798→        # 对新用户不触发 no_action 干预\n   799→        state.should_intervene = True\n   800→        state.intervention_type = \"no_action\"\n   801→        state.suggested_task = get_or_create_minimal_task()\n   802→        state.intervention_message = (\n   803→            \"看起来你已经有一段时间没有完成行动了。\\n\\n\"\n   804→            \"没关系，我们可以从一个更小的任务开始：\\n\"\n   805→            f\"> **{state.suggested_task['title']}**（约{state.suggested_task['minutes']}分钟）\\n\\n\"\n   806→            \"完成后告诉我。\"\n   807→        )\n   808→\n   809→    return state\n   810→\n   811→\n   812→def _message_similarity(msg1: str, msg2: str) -> float:\n   813→    \"\"\"简单的消息相似度计算（基于词重叠）\"\"\"\n   814→    if not msg1 or not msg2:\n   815→        return 0.0\n   816→\n   817→    words1 = set(msg1.replace(\"？\", \" \").replace(\"。\", \" \").split())\n   818→    words2 = set(msg2.replace(\"？\", \" \").replace(\"。\", \" \").split())\n   819→\n   820→    if not words1 or not words2:\n   821→        return 0.0\n   822→\n   823→    intersection = len(words1 & words2)\n   824→    union = len(words1 | words2)\n   825→\n   826→    return intersection / union if union > 0 else 0.0\n   827→\n   828→\n   829→# =============================================================================\n   830→# L2 Agents Layer - 知识库检索 + Prompt 模板\n   831→# =============================================================================\n   832→\n   833→def search_knowledge_base(query: str, top_k: int = 12) -> List[Dict[str, Any]]:\n   834→    \"\"\"从知识库检索相关内容\"\"\"\n   835→    if not query:\n   836→        return []\n   837→\n   838→    # PostgreSQL FTS 检索\n   839→    results = fortune_db.fetch_all(\n   840→        \"\"\"\n   841→        SELECT c.chunk_id, c.doc_id, c.page_no, c.chunk_no,\n   842→               ts_rank(c.content_tsv, plainto_tsquery('simple', %s)) AS rank,\n   843→               c.content,\n   844→               d.file_name, d.title\n   845→        FROM bazi_kb_chunk c\n   846→        JOIN bazi_kb_document d ON c.doc_id = d.doc_id\n   847→        WHERE c.content_tsv @@ plainto_tsquery('simple', %s)\n   848→        ORDER BY rank DESC\n   849→        LIMIT %s\n   850→        \"\"\",\n   851→        (query, query, top_k),\n   852→    )\n   853→\n   854→    kb_refs = []\n   855→    for r in results or []:\n   856→        kb_refs.append({\n   857→            \"kb_ref\": f\"kb:doc:{r['doc_id']}:page:{r['page_no']}:chunk:{r['chunk_no']}\",\n   858→            \"content\": (r.get(\"content\") or \"\")[:500],\n   859→            \"source\": r.get(\"title\") or r.get(\"file_name\") or \"\",\n   860→            \"rank\": r.get(\"rank\", 0),\n   861→        })\n   862→\n   863→    return kb_refs\n   864→\n   865→\n   866→def get_advisor_perspectives(question: str, facts: Dict[str, Any]) -> List[Dict[str, Any]]:\n   867→    \"\"\"获取四个原型顾问的视角（Prompt 模板参数化）\"\"\"\n   868→    perspectives = [\n   869→        {\n   870→            \"advisor\": \"关系视角\",\n   871→            \"optimization\": \"和谐 + 秩序\",\n   872→            \"prompt_hint\": \"考虑对方感受，先稳定关系，再解决问题\",\n   873→            \"applicable_for\": [\"人际冲突\", \"沟通问题\", \"家庭关系\"],\n   874→        },\n   875→        {\n   876→            \"advisor\": \"第一性原理视角\",\n   877→            \"optimization\": \"真相 + 效率\",\n   878→            \"prompt_hint\": \"问题的本质是什么？最小验证是什么？\",\n   879→            \"applicable_for\": [\"决策困境\", \"职业选择\", \"重大决定\"],\n   880→        },\n   881→        {\n   882→            \"advisor\": \"系统思维视角\",\n   883→            \"optimization\": \"风险 + 概率\",\n   884→            \"prompt_hint\": \"有哪些变量？因果链是什么？最坏情况概率多少？\",\n   885→            \"applicable_for\": [\"复杂问题\", \"风险评估\", \"长期规划\"],\n   886→        },\n   887→        {\n   888→            \"advisor\": \"效能整合视角\",\n   889→            \"optimization\": \"平衡 + 可持续\",\n   890→            \"prompt_hint\": \"重要且不紧急的事优先，建立可持续节奏\",\n   891→            \"applicable_for\": [\"时间管理\", \"精力分配\", \"习惯养成\"],\n   892→        },\n   893→    ]\n   894→\n   895→    return perspectives\n   896→\n   897→\n   898→# =============================================================================\n   899→# L3 Synthesis Layer - GLM 整合 + A2UI 输出\n   900→# =============================================================================\n   901→\n   902→def build_system_prompt(\n   903→    user_id: int,\n   904→    persona_style: str = \"warm\",\n   905→) -> str:\n   906→    \"\"\"构建 GLM System Prompt（对齐 OS 设计文档附录 A）\"\"\"\n   907→\n   908→    return f\"\"\"你是 Fortune AI 的对话 Agent，角色是积极心理学教练（Performance Coach）。\n   909→\n   910→【产品定位】\n   911→人生导航 / 陪伴 / 提升。系统和交互保持\"有效而极简\"。\n   912→\n   913→【四层架构理解】\n   914→- L0（定数）：用户的八字事实，作为先验约束，不做宿命论解读\n   915→- L1（特质）：用户的心理图式和当前状态，作为个性化调节\n   916→- L2（策略）：知识库和规则，作为专业依据\n   917→- L3（意识）：你的输出，作为整合与行动引导\n   918→\n   919→【你的优先级（不可逆）】\n   920→Coach > Teaching Assistant > Customer Support > Sales\n   921→\n   922→【硬性规则（必须遵守）】\n   923→1) 禁止恐吓、羞辱、宿命论断言；负面信息必须紧接\"你可以做什么\"的行动处方。\n   924→2) 禁止自行计算八字事实；只能基于提供的 facts + evidence 输出。\n   925→3) 每次输出必须包含：结论(conclusion) + 依据(why) + ≤3条处方(prescriptions) + 承诺邀请(commitment_ask)。\n   926→4) 处方必须包含 if_then（如果____→那么____）。\n   927→5) 时间窗口默认只给干预窗口（intervention）；forecast 只能条件句+低置信度。\n   928→6) 输出必须是 A2UI JSON，且第一组件必须是 markdown_text。\n   929→7) 必须给出可点击 actions（start_task / schedule_task / open_panel / opt_out）。\n   930→\n   931→【语言风格 persona_style = {persona_style}】\n   932→standard：清晰、中性、专业\n   933→warm：共情、支持性（默认）\n   934→roast：轻毒舌但不羞辱、不对人格做负面定性\n   935→\n   936→【输出格式（A2UI JSON）】\n   937→{{\n   938→  \"meta\": {{\"summary\": \"一句话摘要\"}},\n   939→  \"ui_components\": [\n   940→    {{\"type\": \"markdown_text\", \"title\": \"输出\", \"data\": \"### 结论要点\\\\n...\\\\n### 行动处方\\\\n...\\\\n### 承诺\\\\n...\"}},\n   941→    {{\"type\": \"action_buttons\", \"title\": \"下一步\", \"data\": [{{\"label\": \"开始行动\", \"action\": {{\"type\": \"start_task\"}}}}]}}\n   942→  ]\n   943→}}\n   944→\"\"\"\n   945→\n   946→\n   947→def build_user_context(user_id: int) -> Dict[str, Any]:\n   948→    \"\"\"构建用户上下文（L0 + L1 + State Score）\"\"\"\n   949→    uid = int(user_id)\n   950→\n   951→    # L0: 八字事实\n   952→    l0 = get_l0_facts(uid)\n   953→    facts = l0.get(\"facts\", {})\n   954→\n   955→    # 心理学翻译\n   956→    translations = translate_bazi_to_psychology(facts)\n   957→\n   958→    # L1: 特质图式\n   959→    l1 = get_l1_schema(uid)\n   960→\n   961→    # State Score\n   962→    state_score = calculate_state_score(uid)\n   963→\n   964→    return {\n   965→        \"l0_facts\": facts,\n   966→        \"l0_facts_hash\": l0.get(\"facts_hash\", \"\"),\n   967→        \"l0_translations\": translations,\n   968→        \"l1_schema\": l1.to_dict(),\n   969→        \"state_score\": state_score.to_dict(),\n   970→    }\n   971→\n   972→\n   973→def build_evidence(user_id: int, query: str = \"\") -> Dict[str, Any]:\n   974→    \"\"\"构建证据（kb_refs + rule_ids + facts_hash）\"\"\"\n   975→    l0 = get_l0_facts(user_id)\n   976→\n   977→    # 知识库检索\n   978→    kb_refs = []\n   979→    if query:\n   980→        kb_results = search_knowledge_base(query)\n   981→        kb_refs = [r[\"kb_ref\"] for r in kb_results]\n   982→\n   983→    # 规则 ID\n   984→    rule_ids = []\n   985→    facts = l0.get(\"facts\", {})\n   986→    bazi = facts.get(\"bazi\", {})\n   987→\n   988→    if bazi.get(\"strength\", {}).get(\"rule_id\"):\n   989→        rule_ids.append(bazi[\"strength\"][\"rule_id\"])\n   990→\n   991→    for shensha in bazi.get(\"shensha\", []):\n   992→        if shensha.get(\"hit\") and shensha.get(\"rule_id\"):\n   993→            rule_ids.append(shensha[\"rule_id\"])\n   994→\n   995→    return {\n   996→        \"facts_hash\": l0.get(\"facts_hash\", \"\"),\n   997→        \"kb_refs\": kb_refs,\n   998→        \"rule_ids\": rule_ids,\n   999→    }\n  1000→\n  1001→\n  1002→def guidance_card_to_a2ui(card: Dict[str, Any]) -> Dict[str, Any]:\n  1003→    \"\"\"将 Guidance Card 转换为 A2UI 格式\"\"\"\n  1004→    title = \"今日指引\"\n  1005→    conclusion = str(card.get(\"conclusion\") or \"\")\n  1006→    why = str(card.get(\"why\") or \"\")\n  1007→    prescriptions = card.get(\"prescriptions\") or []\n  1008→    tw = card.get(\"time_window\") or {}\n  1009→    commitment_ask = str(card.get(\"commitment_ask\") or \"你愿意先做哪一个？\")\n  1010→    risk = str(card.get(\"risk_boundary\") or \"不替代医疗/法律/投资建议\")\n  1011→\n  1012→    lines: List[str] = []\n  1013→    lines.append(\"### 结论要点\")\n  1014→    if conclusion:\n  1015→        lines.append(f\"- {conclusion}\")\n  1016→    lines.append(\"\")\n  1017→\n  1018→    if why:\n  1019→        lines.append(\"### 为什么（教练视角）\")\n  1020→        lines.append(why)\n  1021→        lines.append(\"\")\n  1022→\n  1023→    if prescriptions:\n  1024→        lines.append(\"### 行动处方（≤3条）\")\n  1025→        for i, p in enumerate(prescriptions[:3], start=1):\n  1026→            content = p.get(\"content\", \"\")\n  1027→            if_then = p.get(\"if_then\", \"\")\n  1028→            lines.append(f\"{i}) {content}\")\n  1029→            if if_then:\n  1030→                lines.append(f\"   - 如果犹豫：{if_then}\")\n  1031→        lines.append(\"\")\n  1032→\n  1033→    if tw:\n  1034→        lines.append(\"### 时间窗口\")\n  1035→        lines.append(f\"- {tw.get('value') or ''}（置信度：{tw.get('confidence') or ''}）\")\n  1036→        lines.append(\"\")\n  1037→\n  1038→    lines.append(\"### 风险边界\")\n  1039→    lines.append(risk)\n  1040→    lines.append(\"\")\n  1041→    lines.append(\"### 承诺\")\n  1042→    lines.append(commitment_ask)\n  1043→\n  1044→    actions = []\n  1045→    for a in card.get(\"actions\") or []:\n  1046→        if not isinstance(a, dict):\n  1047→            continue\n  1048→        label = str(a.get(\"label\") or \"\")\n  1049→        payload = {\"type\": str(a.get(\"type\") or \"\")}\n  1050→        if a.get(\"task_id\"):\n  1051→            payload[\"task_id\"] = str(a[\"task_id\"])\n  1052→        actions.append({\"label\": label, \"action\": payload})\n  1053→\n  1054→    return {\n  1055→        \"meta\": {\"summary\": conclusion[:80] or title},\n  1056→        \"ui_components\": [\n  1057→            {\"type\": \"markdown_text\", \"title\": title, \"data\": \"\\n\".join(lines).strip()},\n  1058→            {\"type\": \"action_buttons\", \"title\": \"下一步\", \"data\": actions},\n  1059→        ],\n  1060→    }\n  1061→\n  1062→\n  1063→# =============================================================================\n  1064→# Commitment 管理\n  1065→# =============================================================================\n  1066→\n  1067→def create_commitment(\n  1068→    user_id: int,\n  1069→    *,\n  1070→    session_id: Optional[str] = None,\n  1071→    card_id: str,\n  1072→    source: str,\n  1073→    commitment_type: str,\n  1074→    title: str,\n  1075→    details: Dict[str, Any],\n  1076→    due_at: Optional[datetime] = None,\n  1077→) -> str:\n  1078→    \"\"\"创建承诺任务\"\"\"\n  1079→    task_id = str(uuid4())\n  1080→    fortune_db.execute(\n  1081→        \"\"\"\n  1082→        INSERT INTO fortune_commitment (task_id, user_id, session_id, card_id, source, commitment_type, title, details, status, due_at)\n  1083→        VALUES (%s::uuid, %s, %s::uuid, %s::uuid, %s, %s, %s, %s::jsonb, 'suggested', %s)\n  1084→        \"\"\",\n  1085→        (\n  1086→            task_id,\n  1087→            int(user_id),\n  1088→            session_id,\n  1089→            card_id,\n  1090→            source,\n  1091→            commitment_type,\n  1092→            (title or \"\")[:200],\n  1093→            json.dumps(details or {}, ensure_ascii=False),\n  1094→            due_at,\n  1095→        ),\n  1096→    )\n  1097→\n  1098→    logger.info(\n  1099→        \"commitment created\",\n  1100→        extra={\"operation\": \"commitment_create\", \"user_id\": int(user_id), \"task_id\": task_id, \"source\": source},\n  1101→    )\n  1102→\n  1103→    return task_id\n  1104→\n  1105→\n  1106→def accept_commitment(user_id: int, task_id: str) -> bool:\n  1107→    \"\"\"接受承诺\"\"\"\n  1108→    result = fortune_db.execute(\n  1109→        \"\"\"\n  1110→        UPDATE fortune_commitment\n  1111→        SET status = 'active', accepted_at = NOW()\n  1112→        WHERE task_id = %s::uuid AND user_id = %s AND status = 'suggested'\n  1113→        \"\"\",\n  1114→        (task_id, int(user_id)),\n  1115→    )\n  1116→\n  1117→    if result > 0:\n  1118→        logger.info(\n  1119→            \"commitment accepted\",\n  1120→            extra={\"operation\": \"commitment_accept\", \"user_id\": int(user_id), \"task_id\": task_id},\n  1121→        )\n  1122→\n  1123→    return result > 0\n  1124→\n  1125→\n  1126→def complete_commitment(user_id: int, task_id: str, note: str = \"\") -> Dict[str, Any]:\n  1127→    \"\"\"完成承诺\"\"\"\n  1128→    result = fortune_db.execute(\n  1129→        \"\"\"\n  1130→        UPDATE fortune_commitment\n  1131→        SET status = 'done', done_at = NOW()\n  1132→        WHERE task_id = %s::uuid AND user_id = %s AND status IN ('suggested', 'active')\n  1133→        \"\"\",\n  1134→        (task_id, int(user_id)),\n  1135→    )\n  1136→\n  1137→    if result > 0:\n  1138→        # 计算新的 State Score\n  1139→        new_score = calculate_state_score(user_id)\n  1140→\n  1141→        logger.info(\n  1142→            \"commitment completed\",\n  1143→            extra={\n  1144→                \"operation\": \"commitment_complete\",\n  1145→                \"user_id\": int(user_id),\n  1146→                \"task_id\": task_id,\n  1147→                \"new_score\": new_score.score,\n  1148→            },\n  1149→        )\n  1150→\n  1151→        return {\n  1152→            \"success\": True,\n  1153→            \"state_score\": new_score.to_dict(),\n  1154→            \"message\": \"做得好！你的状态分数已更新。\",\n  1155→        }\n  1156→\n  1157→    return {\"success\": False, \"message\": \"任务不存在或已完成\"}\n  1158→\n  1159→\n  1160→def list_commitments(\n  1161→    user_id: int,\n  1162→    *,\n  1163→    status: Optional[List[str]] = None,\n  1164→    limit: int = 10,\n  1165→) -> List[Dict[str, Any]]:\n  1166→    \"\"\"列出承诺任务\"\"\"\n  1167→    lim = max(1, min(50, int(limit)))\n  1168→    sts = status or [\"suggested\", \"active\"]\n  1169→\n  1170→    rows = fortune_db.fetch_all(\n  1171→        \"\"\"\n  1172→        SELECT task_id, status, commitment_type, title, details, source, accepted_at, due_at, done_at, created_at\n  1173→        FROM fortune_commitment\n  1174→        WHERE user_id = %s AND status = ANY(%s)\n  1175→        ORDER BY created_at DESC\n  1176→        LIMIT %s\n  1177→        \"\"\",\n  1178→        (int(user_id), sts, lim),\n  1179→    )\n  1180→\n  1181→    items = []\n  1182→    for r in rows or []:\n  1183→        items.append({\n  1184→            \"task_id\": str(r[\"task_id\"]),\n  1185→            \"status\": str(r.get(\"status\") or \"\"),\n  1186→            \"commitment_type\": str(r.get(\"commitment_type\") or \"\"),\n  1187→            \"title\": str(r.get(\"title\") or \"\"),\n  1188→            \"details\": r.get(\"details\") or {},\n  1189→            \"source\": str(r.get(\"source\") or \"\"),\n  1190→            \"accepted_at\": (str(r[\"accepted_at\"]) if r.get(\"accepted_at\") else None),\n  1191→            \"due_at\": (str(r[\"due_at\"]) if r.get(\"due_at\") else None),\n  1192→            \"done_at\": (str(r[\"done_at\"]) if r.get(\"done_at\") else None),\n  1193→            \"created_at\": str(r.get(\"created_at\") or \"\"),\n  1194→        })\n  1195→\n  1196→    return items\n  1197→\n  1198→\n  1199→# =============================================================================\n  1200→# 综合接口\n  1201→# =============================================================================\n  1202→\n  1203→def get_full_context_for_chat(user_id: int, query: str = \"\") -> Dict[str, Any]:\n  1204→    \"\"\"获取完整的对话上下文（用于 Chat API）\"\"\"\n  1205→    uid = int(user_id)\n  1206→\n  1207→    # 用户偏好\n  1208→    prefs = fortune_db.fetch_one(\n  1209→        \"SELECT persona_style FROM fortune_user_preferences WHERE user_id = %s\",\n  1210→        (uid,),\n  1211→    ) or {}\n  1212→    persona_style = prefs.get(\"persona_style\", \"warm\")\n  1213→\n  1214→    # 用户上下文\n  1215→    user_context = build_user_context(uid)\n  1216→\n  1217→    # 证据\n  1218→    evidence = build_evidence(uid, query)\n  1219→\n  1220→    # 反依赖检查\n  1221→    anti_dep = check_anti_dependency(uid, query)\n  1222→\n  1223→    # System Prompt\n  1224→    system_prompt = build_system_prompt(uid, persona_style)\n  1225→\n  1226→    return {\n  1227→        \"system_prompt\": system_prompt,\n  1228→        \"persona_style\": persona_style,\n  1229→        \"user_context\": user_context,\n  1230→        \"evidence\": evidence,\n  1231→        \"anti_dependency\": {\n  1232→            \"should_intervene\": anti_dep.should_intervene,\n  1233→            \"intervention_type\": anti_dep.intervention_type,\n  1234→            \"intervention_message\": anti_dep.intervention_message,\n  1235→        },\n  1236→    }\n  1237→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"0a1d27a2-c41e-46c2-b600-dec05ae37992","timestamp":"2026-01-01T15:01:13.394Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aiscend/work/fortune_ai/services/soul_os.py","content":"\"\"\"\nSoul OS 核心服务层\n\n基于 os_design_claude_mvp.md 的四层架构实现：\n- L0 Firmware: 八字事实快照管理\n- L1 Schema: PERMA + 行为证据汇总\n- L2 Agents: 知识库检索 + Prompt 模板\n- L3 Synthesis: GLM 整合 + A2UI 输出\n\n包含：\n- State Score 计算\n- 反依赖机制\n- JITAI 调节动作库\n- Guidance Card 生成\n\"\"\"\n\nfrom __future__ import annotations\n\nimport hashlib\nimport json\nfrom dataclasses import dataclass, field\nfrom datetime import date, datetime, timedelta, timezone\nfrom enum import Enum\nfrom typing import Any, Dict, List, Optional, Tuple\nfrom uuid import uuid4\n\nfrom common.logging import get_logger\nfrom stores import fortune_db\n\nlogger = get_logger(__name__)\n\n\n# =============================================================================\n# Enums & Constants\n# =============================================================================\n\nclass PersonaStyle(str, Enum):\n    STANDARD = \"standard\"  # 清晰、中性、专业\n    WARM = \"warm\"          # 共情、支持性（默认）\n    ROAST = \"roast\"        # 轻毒舌但不羞辱\n\n\nclass CommitmentType(str, Enum):\n    START_TASK = \"start_task\"        # 立刻开始\n    SCHEDULE_TASK = \"schedule_task\"  # 加入计划\n    ASK_FOLLOWUP = \"ask_followup\"    # 澄清问题\n    OPT_OUT = \"opt_out\"              # 暂停/关闭\n\n\nclass CommitmentStatus(str, Enum):\n    SUGGESTED = \"suggested\"\n    ACTIVE = \"active\"\n    DONE = \"done\"\n    SKIPPED = \"skipped\"\n    CANCELED = \"canceled\"\n\n\n# JITAI 调节动作库\nJITAI_ACTIONS: Dict[str, Dict[str, str]] = {\n    \"焦虑\": {\n        \"high\": \"3分钟呼吸降噪：吸气4秒→屏息7秒→呼气8秒，重复3次。\",\n        \"medium\": \"写下3个最坏情况，并评估每个发生的概率（0-100%）。\",\n        \"low\": \"列出你现在能控制的3件事。\",\n    },\n    \"低落\": {\n        \"high\": \"做一个最小行动：站起来倒杯水，或走到窗边看30秒。\",\n        \"medium\": \"回忆一个小成就并写下来：我做到了____。\",\n        \"low\": \"给自己一句鼓励：这很正常，我正在经历困难。\",\n    },\n    \"愤怒\": {\n        \"high\": \"用力握拳10秒再松开，重复3次。然后深呼吸5次。\",\n        \"medium\": \"写下：我需要的是____。我的底线是____。\",\n        \"low\": \"离开当前场景2分钟，做5次深呼吸。\",\n    },\n    \"困惑\": {\n        \"high\": \"写下3个选项和1个最重要的约束条件。\",\n        \"medium\": \"列出2个选项，问自己：如果只能选一个，我会选哪个？为什么？\",\n        \"low\": \"画一个简单的决策树：选项A→结果；选项B→结果。\",\n    },\n    \"兴奋\": {\n        \"high\": \"写下这个感觉的来源，并把能量转化为一个2分钟行动。\",\n        \"medium\": \"记录下这一刻，稍后复盘时用。\",\n        \"low\": \"享受这个感觉，同时提醒自己不做冲动决策。\",\n    },\n    \"平静\": {\n        \"high\": \"写下今天最想保留的一个做法。\",\n        \"medium\": \"保持当前状态，安排一个5分钟的延续动作。\",\n        \"low\": \"保持这个状态，继续当前的事。\",\n    },\n}\n\n# 心理学翻译规则：八字概念 → 可操作心理语言\nBAZI_PSYCHOLOGY_TRANSLATIONS: Dict[str, Dict[str, str]] = {\n    \"weak\": {\n        \"translation\": \"你的能量更适合借力/合作，而非单打独斗\",\n        \"action\": \"本周找一个支持者或合作伙伴\",\n    },\n    \"strong\": {\n        \"translation\": \"你有充沛的内在能量，适合独立行动\",\n        \"action\": \"设定一个独立完成的小目标\",\n    },\n    \"neutral\": {\n        \"translation\": \"你的能量相对平衡，灵活度高\",\n        \"action\": \"根据具体情况选择独立或合作\",\n    },\n    \"食伤重\": {\n        \"translation\": \"你有强烈的表达欲和创造力\",\n        \"action\": \"每天留15分钟自由书写或创作\",\n    },\n    \"官杀混杂\": {\n        \"translation\": \"你可能感受到多重压力或权威冲突\",\n        \"action\": \"写清哪些压力是你能控制的，哪些不能\",\n    },\n    \"桃花星\": {\n        \"translation\": \"你在关系中有天然的吸引力和敏感度\",\n        \"action\": \"觉察关系中的边界需求\",\n    },\n    \"驿马星\": {\n        \"translation\": \"你有变动/探索的内在驱力\",\n        \"action\": \"小范围实验胜过大规模改变\",\n    },\n    \"华盖\": {\n        \"translation\": \"你有独立思考和精神探索的倾向\",\n        \"action\": \"每周留1小时独处反思时间\",\n    },\n    \"天乙贵人\": {\n        \"translation\": \"你容易获得贵人相助\",\n        \"action\": \"主动寻求帮助，不要独自扛\",\n    },\n    \"文昌\": {\n        \"translation\": \"你在学习和文字方面有天赋\",\n        \"action\": \"保持学习习惯，用写作整理思路\",\n    },\n}\n\n\n# =============================================================================\n# Data Classes\n# =============================================================================\n\n@dataclass\nclass StateScore:\n    \"\"\"状态分数 - 把\"感觉\"变成可训练变量\"\"\"\n    score: int  # 0-100\n    emotion_signal: int  # 40% 权重\n    action_signal: int   # 40% 权重\n    streak_signal: int   # 20% 权重\n    recovery_action: str  # 分数低时的补救动作\n\n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"score\": self.score,\n            \"breakdown\": {\n                \"emotion\": self.emotion_signal,\n                \"action\": self.action_signal,\n                \"streak\": self.streak_signal,\n            },\n            \"recovery_action\": self.recovery_action,\n        }\n\n\n@dataclass\nclass PermaSnapshot:\n    \"\"\"PERMA 积极心理学快照\"\"\"\n    positive_emotion: Dict[str, Any] = field(default_factory=dict)\n    engagement: Dict[str, Any] = field(default_factory=dict)\n    relationships: Dict[str, Any] = field(default_factory=dict)\n    meaning: Dict[str, Any] = field(default_factory=dict)\n    accomplishment: Dict[str, Any] = field(default_factory=dict)\n\n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"positive_emotion\": self.positive_emotion,\n            \"engagement\": self.engagement,\n            \"relationships\": self.relationships,\n            \"meaning\": self.meaning,\n            \"accomplishment\": self.accomplishment,\n        }\n\n\n@dataclass\nclass L1Schema:\n    \"\"\"L1 特质层数据\"\"\"\n    perma: PermaSnapshot\n    cognitive_patterns: Dict[str, Any]\n    strengths_in_use: List[str]\n    preferences: Dict[str, Any]\n\n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"perma_snapshot\": self.perma.to_dict(),\n            \"cognitive_patterns\": self.cognitive_patterns,\n            \"strengths_in_use\": self.strengths_in_use,\n            \"preferences\": self.preferences,\n        }\n\n\n@dataclass\nclass AntiDependencyState:\n    \"\"\"反依赖状态追踪\"\"\"\n    same_question_count: int = 0\n    daily_consult_count: int = 0\n    last_action_days: int = 0\n    should_intervene: bool = False\n    intervention_type: str = \"\"\n    intervention_message: str = \"\"\n    suggested_task: Optional[Dict[str, Any]] = None  # 干预时必须返回的任务\n    is_new_user: bool = False  # 是否为新用户（7天内）\n\n\n@dataclass\nclass GuidanceCard:\n    \"\"\"指导卡片\"\"\"\n    card_id: str\n    card_type: str\n    conclusion: str\n    why: str\n    prescriptions: List[Dict[str, Any]]\n    time_window: Dict[str, Any]\n    risk_boundary: str\n    commitment_ask: str\n    actions: List[Dict[str, Any]]\n    evidence: Dict[str, Any]\n    created_at: str\n\n    def to_dict(self) -> Dict[str, Any]:\n        return {\n            \"card_id\": self.card_id,\n            \"type\": self.card_type,\n            \"conclusion\": self.conclusion,\n            \"why\": self.why,\n            \"prescriptions\": self.prescriptions,\n            \"time_window\": self.time_window,\n            \"risk_boundary\": self.risk_boundary,\n            \"commitment_ask\": self.commitment_ask,\n            \"actions\": self.actions,\n            \"evidence\": self.evidence,\n            \"created_at\": self.created_at,\n        }\n\n\n# =============================================================================\n# L0 Firmware Layer - 八字事实快照管理\n# =============================================================================\n\ndef get_l0_facts(user_id: int) -> Dict[str, Any]:\n    \"\"\"获取 L0 层八字事实快照\"\"\"\n    snap = fortune_db.fetch_one(\n        \"\"\"\n        SELECT facts, facts_hash, compute_version\n        FROM fortune_bazi_snapshot\n        WHERE user_id = %s\n        ORDER BY created_at DESC\n        LIMIT 1\n        \"\"\",\n        (int(user_id),),\n    )\n    if not snap:\n        return {\"facts\": {}, \"facts_hash\": \"\", \"compute_version\": \"\"}\n    return {\n        \"facts\": snap.get(\"facts\") or {},\n        \"facts_hash\": str(snap.get(\"facts_hash\") or \"\"),\n        \"compute_version\": str(snap.get(\"compute_version\") or \"\"),\n    }\n\n\ndef translate_bazi_to_psychology(facts: Dict[str, Any]) -> List[Dict[str, str]]:\n    \"\"\"将八字概念翻译为可操作的心理学语言\"\"\"\n    translations = []\n    bazi = facts.get(\"bazi\", {})\n\n    # 旺衰翻译\n    strength = bazi.get(\"strength\", {})\n    status = strength.get(\"level\", \"neutral\")\n    if status in BAZI_PSYCHOLOGY_TRANSLATIONS:\n        trans = BAZI_PSYCHOLOGY_TRANSLATIONS[status]\n        translations.append({\n            \"concept\": f\"日主{status}\",\n            \"translation\": trans[\"translation\"],\n            \"action\": trans[\"action\"],\n        })\n\n    # 神煞翻译\n    for shensha in bazi.get(\"shensha\", []):\n        if shensha.get(\"hit\"):\n            name = shensha.get(\"name\", \"\")\n            if name in BAZI_PSYCHOLOGY_TRANSLATIONS:\n                trans = BAZI_PSYCHOLOGY_TRANSLATIONS[name]\n                translations.append({\n                    \"concept\": name,\n                    \"translation\": trans[\"translation\"],\n                    \"action\": trans[\"action\"],\n                })\n\n    return translations\n\n\n# =============================================================================\n# L1 Schema Layer - PERMA + 行为证据汇总\n# =============================================================================\n\ndef get_l1_schema(user_id: int, window_days: int = 7) -> L1Schema:\n    \"\"\"获取 L1 层特质图式\"\"\"\n    uid = int(user_id)\n    window_start = datetime.now(timezone.utc) - timedelta(days=window_days)\n\n    # 获取用户偏好\n    prefs = fortune_db.fetch_one(\n        \"SELECT * FROM fortune_user_preferences WHERE user_id = %s\",\n        (uid,),\n    ) or {}\n\n    # P: Positive Emotion - 从 checkin 获取\n    checkins = fortune_db.fetch_all(\n        \"\"\"\n        SELECT mood, intensity, created_at\n        FROM fortune_checkin\n        WHERE user_id = %s AND created_at >= %s\n        ORDER BY created_at DESC\n        LIMIT 20\n        \"\"\",\n        (uid, window_start),\n    )\n\n    positive_moods = [\"平静\", \"兴奋\", \"开心\", \"满足\", \"感恩\"]\n    negative_moods = [\"焦虑\", \"愤怒\", \"沮丧\", \"悲伤\", \"恐惧\"]\n\n    # 分别计算正负面情绪的平均强度\n    positive_checkins = [c for c in checkins if c.get(\"mood\") in positive_moods]\n    negative_checkins = [c for c in checkins if c.get(\"mood\") in negative_moods]\n\n    pos_avg = sum(c.get(\"intensity\", 5) for c in positive_checkins) / len(positive_checkins) if positive_checkins else 0\n    neg_avg = sum(c.get(\"intensity\", 5) for c in negative_checkins) / len(negative_checkins) if negative_checkins else 0\n\n    # 正向情绪高强度=加分，负向情绪高强度=扣分，基线5分\n    raw_score = pos_avg - neg_avg + 5 if checkins else 5.0\n    positive_count = len(positive_checkins)\n\n    positive_emotion = {\n        \"score\": round(max(0, min(10, raw_score)), 1),\n        \"trend\": \"up\" if positive_count > len(checkins) / 2 else \"stable\",\n        \"recent_count\": len(checkins),\n    }\n\n    # E: Engagement - 从 plan enrollment 获取\n    enrollments = fortune_db.fetch_all(\n        \"\"\"\n        SELECT plan_id, status, current_day\n        FROM fortune_plan_enrollment\n        WHERE user_id = %s AND status = 'active'\n        \"\"\",\n        (uid,),\n    )\n\n    # 计算完成率\n    done_count = fortune_db.fetch_one(\n        \"\"\"\n        SELECT COUNT(*) as cnt\n        FROM fortune_commitment\n        WHERE user_id = %s AND status = 'done' AND created_at >= %s\n        \"\"\",\n        (uid, window_start),\n    ) or {}\n\n    suggested_count = fortune_db.fetch_one(\n        \"\"\"\n        SELECT COUNT(*) as cnt\n        FROM fortune_commitment\n        WHERE user_id = %s AND created_at >= %s\n        \"\"\",\n        (uid, window_start),\n    ) or {}\n\n    total = suggested_count.get(\"cnt\", 0) or 1\n    completion_rate = round(done_count.get(\"cnt\", 0) / total, 2) if total else 0\n\n    engagement = {\n        \"score\": round(completion_rate * 10, 1),  # 0-10 scale\n        \"active_plans\": len(enrollments),\n        \"completion_rate\": completion_rate,\n    }\n\n    # R: Relationships - 从对话中提取（简化版）\n    recent_msgs = fortune_db.fetch_all(\n        \"\"\"\n        SELECT content\n        FROM fortune_conversation_message\n        WHERE user_id = %s AND role = 'user' AND created_at >= %s\n        ORDER BY created_at DESC\n        LIMIT 10\n        \"\"\",\n        (uid, window_start),\n    )\n\n    relationship_keywords = [\"同事\", \"朋友\", \"家人\", \"伴侣\", \"关系\"]\n    relationship_mentions = sum(\n        1 for m in recent_msgs\n        if any(kw in (m.get(\"content\") or \"\") for kw in relationship_keywords)\n    )\n\n    relationships = {\n        \"score\": min(10, relationship_mentions * 2.5),  # 0-10 scale, 4 mentions = 10\n        \"recent_mentions\": relationship_mentions,\n        \"recent_note\": \"\",\n    }\n\n    # M: Meaning - 从计划参与推断\n    aligned_cnt = done_count.get(\"cnt\", 0)\n    meaning = {\n        \"score\": min(10, aligned_cnt),  # 0-10 scale\n        \"core_value\": \"成长\" if enrollments else \"探索\",\n        \"aligned_actions\": aligned_cnt,\n    }\n\n    # A: Accomplishment\n    streak = _calculate_streak(uid)\n    weekly_done = done_count.get(\"cnt\", 0)\n    accomplishment = {\n        \"score\": min(10, weekly_done + streak * 0.5),  # 0-10 scale\n        \"weekly_done\": weekly_done,\n        \"streak\": streak,\n    }\n\n    perma = PermaSnapshot(\n        positive_emotion=positive_emotion,\n        engagement=engagement,\n        relationships=relationships,\n        meaning=meaning,\n        accomplishment=accomplishment,\n    )\n\n    return L1Schema(\n        perma=perma,\n        cognitive_patterns={\"identified_schemas\": [], \"reframe_count\": 0},\n        strengths_in_use=[],\n        preferences={\n            \"persona_style\": prefs.get(\"persona_style\", \"warm\"),\n            \"push_enabled\": prefs.get(\"push_enabled\", True),\n        },\n    )\n\n\ndef _calculate_streak(user_id: int) -> int:\n    \"\"\"计算连续行动天数\"\"\"\n    rows = fortune_db.fetch_all(\n        \"\"\"\n        SELECT DATE(done_at) as done_date\n        FROM fortune_commitment\n        WHERE user_id = %s AND status = 'done' AND done_at IS NOT NULL\n        ORDER BY done_at DESC\n        LIMIT 30\n        \"\"\",\n        (int(user_id),),\n    )\n\n    if not rows:\n        return 0\n\n    dates = sorted(set(r[\"done_date\"] for r in rows if r.get(\"done_date\")), reverse=True)\n    if not dates:\n        return 0\n\n    today = date.today()\n    streak = 0\n    expected = today\n\n    for d in dates:\n        if d == expected or d == expected - timedelta(days=1):\n            streak += 1\n            expected = d - timedelta(days=1)\n        else:\n            break\n\n    return streak\n\n\n# =============================================================================\n# State Score 计算\n# =============================================================================\n\ndef calculate_state_score(user_id: int, window: str = \"24h\") -> StateScore:\n    \"\"\"\n    计算状态分数（0-100）\n\n    三信号计算：\n    - emotion_signal (40%): 情绪基线\n    - action_signal (40%): 行动完成\n    - streak_signal (20%): 连续记录\n    \"\"\"\n    uid = int(user_id)\n\n    # 确定时间窗口\n    if window == \"24h\":\n        window_start = datetime.now(timezone.utc) - timedelta(hours=24)\n    elif window == \"7d\":\n        window_start = datetime.now(timezone.utc) - timedelta(days=7)\n    else:\n        window_start = datetime.now(timezone.utc) - timedelta(hours=24)\n\n    # 信号1: 情绪基线（40%权重）\n    checkin = fortune_db.fetch_one(\n        \"\"\"\n        SELECT mood, intensity\n        FROM fortune_checkin\n        WHERE user_id = %s AND created_at >= %s\n        ORDER BY created_at DESC\n        LIMIT 1\n        \"\"\",\n        (uid, window_start),\n    )\n\n    if checkin:\n        mood = checkin.get(\"mood\", \"\")\n        intensity = int(checkin.get(\"intensity\", 5))\n        positive_moods = [\"平静\", \"兴奋\", \"开心\", \"满足\", \"感恩\"]\n\n        if mood in positive_moods:\n            # 正向情绪：强度越高越好\n            emotion_signal = intensity * 4\n        else:\n            # 负向情绪：强度越高越差\n            emotion_signal = max(0, (10 - intensity)) * 4\n    else:\n        emotion_signal = 20  # 无打卡给中性分\n\n    # 信号2: 行动完成（40%权重）\n    done_result = fortune_db.fetch_one(\n        \"\"\"\n        SELECT COUNT(*) as cnt\n        FROM fortune_commitment\n        WHERE user_id = %s AND status = 'done' AND done_at >= %s\n        \"\"\",\n        (uid, window_start),\n    ) or {}\n    done_count = done_result.get(\"cnt\", 0)\n    action_signal = min(done_count * 10, 40)\n\n    # 信号3: 连续记录（20%权重）\n    streak = _calculate_streak(uid)\n    streak_signal = min(streak * 4, 20)\n\n    # 总分\n    score = emotion_signal + action_signal + streak_signal\n\n    # 补救动作\n    recovery_action = _get_recovery_action(score, checkin)\n\n    return StateScore(\n        score=score,\n        emotion_signal=emotion_signal,\n        action_signal=action_signal,\n        streak_signal=streak_signal,\n        recovery_action=recovery_action,\n    )\n\n\ndef _get_recovery_action(score: int, last_checkin: Optional[Dict[str, Any]]) -> str:\n    \"\"\"根据分数和最近打卡生成补救动作\"\"\"\n    if score >= 70:\n        return \"保持这个状态！今天再完成一个小任务来巩固。\"\n    elif score >= 50:\n        return \"做一个2分钟的最小行动，把分数拉上来。\"\n    elif score >= 30:\n        if last_checkin:\n            mood = last_checkin.get(\"mood\", \"\")\n            intensity = last_checkin.get(\"intensity\", 5)\n            return get_jitai_action(mood, intensity)\n        return \"先做3分钟呼吸降噪，然后完成一个最小任务。\"\n    else:\n        return \"先照顾好自己：喝杯水，做几次深呼吸，然后选一个最小的事情开始。\"\n\n\n# =============================================================================\n# JITAI 调节动作库\n# =============================================================================\n\ndef get_jitai_action(mood: str, intensity: int) -> str:\n    \"\"\"获取 JITAI 即时适应性干预动作\"\"\"\n    mood = (mood or \"\").strip()\n    intensity = max(0, min(10, int(intensity)))\n\n    # 确定强度级别\n    if intensity >= 7:\n        level = \"high\"\n    elif intensity >= 4:\n        level = \"medium\"\n    else:\n        level = \"low\"\n\n    # 查找匹配的动作\n    for keyword, actions in JITAI_ACTIONS.items():\n        if keyword in mood:\n            return actions.get(level, actions.get(\"medium\", \"\"))\n\n    # 默认动作\n    if intensity >= 7:\n        return \"先做3分钟呼吸锚点：1分钟呼吸→1分钟身体感受→1分钟选择下一步。\"\n    return \"写下：我现在最需要被满足的一个需求是什么？然后做一个2分钟版本。\"\n\n\ndef create_checkin_with_jitai(\n    user_id: int,\n    *,\n    mood: str,\n    intensity: int,\n    note: str = \"\",\n) -> Dict[str, Any]:\n    \"\"\"创建情绪打卡并返回 JITAI 推荐动作\"\"\"\n    uid = int(user_id)\n    mood = (mood or \"\")[:50]\n    intensity = max(0, min(10, int(intensity)))\n    note = (note or \"\")[:1000]\n\n    # 获取推荐动作\n    action = get_jitai_action(mood, intensity)\n\n    # 写入打卡记录\n    fortune_db.execute(\n        \"\"\"\n        INSERT INTO fortune_checkin (user_id, mood, intensity, note, recommended_action)\n        VALUES (%s, %s, %s, %s, %s)\n        \"\"\",\n        (uid, mood, intensity, note, action),\n    )\n\n    # 创建建议任务\n    task_id = str(uuid4())\n    fortune_db.execute(\n        \"\"\"\n        INSERT INTO fortune_commitment (task_id, user_id, source, commitment_type, title, details, status)\n        VALUES (%s::uuid, %s, 'bento', 'start_task', %s, %s::jsonb, 'suggested')\n        \"\"\",\n        (\n            task_id,\n            uid,\n            (action[:200] if action else \"情绪调节动作\"),\n            json.dumps({\"from\": \"checkin\", \"mood\": mood, \"intensity\": intensity}, ensure_ascii=False),\n        ),\n    )\n\n    logger.info(\n        \"checkin created with jitai\",\n        extra={\"operation\": \"checkin_jitai\", \"user_id\": uid, \"mood\": mood, \"intensity\": intensity},\n    )\n\n    return {\n        \"mood\": mood,\n        \"intensity\": intensity,\n        \"recommended_action\": action,\n        \"task_id\": task_id,\n    }\n\n\n# =============================================================================\n# 反依赖机制\n# =============================================================================\n\ndef check_anti_dependency(user_id: int, current_message: str = \"\") -> AntiDependencyState:\n    \"\"\"\n    检查反依赖触发条件（优化版）\n\n    优化策略（基于 os_design_claude_mvp v1.md §5）：\n    1. 新用户豁免期：注册7天内不触发 anti-dependency\n    2. 提升日消息阈值：从5提升到8（有活跃任务时降为5）\n    3. 干预时必须返回至少1个可执行任务\n    \"\"\"\n    uid = int(user_id)\n    today_start = datetime.now(timezone.utc).replace(hour=0, minute=0, second=0, microsecond=0)\n\n    state = AntiDependencyState()\n\n    # 检查用户注册时间，判断是否为新用户\n    user_info = fortune_db.fetch_one(\n        \"\"\"\n        SELECT created_at, onboarding_completed\n        FROM fortune_user\n        WHERE user_id = %s\n        \"\"\",\n        (uid,),\n    )\n    if user_info and user_info.get(\"created_at\"):\n        created_at = user_info[\"created_at\"]\n        if hasattr(created_at, \"tzinfo\") and created_at.tzinfo is None:\n            created_at = created_at.replace(tzinfo=timezone.utc)\n        days_since_register = (datetime.now(timezone.utc) - created_at).days\n        onboarding_completed = user_info.get(\"onboarding_completed\", False)\n\n        # 新用户豁免期：注册7天内且未完成引导\n        if days_since_register < 7 and not onboarding_completed:\n            state.is_new_user = True\n            return state  # 新用户直接返回，不触发 anti-dependency\n    else:\n        days_since_register = 999\n\n    # 检查是否有活跃任务\n    active_task = fortune_db.fetch_one(\n        \"\"\"\n        SELECT task_id, title\n        FROM fortune_commitment\n        WHERE user_id = %s AND status = 'active'\n        ORDER BY created_at DESC\n        LIMIT 1\n        \"\"\",\n        (uid,),\n    )\n    has_active_commitment = active_task is not None\n\n    # 动态阈值：有活跃任务时降低阈值\n    daily_message_limit = 5 if has_active_commitment else 8\n\n    # 检查当日咨询次数\n    daily_count = fortune_db.fetch_one(\n        \"\"\"\n        SELECT COUNT(*) as cnt\n        FROM fortune_conversation_message\n        WHERE user_id = %s AND role = 'user' AND created_at >= %s\n        \"\"\",\n        (uid, today_start),\n    ) or {}\n    state.daily_consult_count = daily_count.get(\"cnt\", 0)\n\n    # 检查最近行动天数\n    last_action = fortune_db.fetch_one(\n        \"\"\"\n        SELECT done_at\n        FROM fortune_commitment\n        WHERE user_id = %s AND status = 'done'\n        ORDER BY done_at DESC\n        LIMIT 1\n        \"\"\",\n        (uid,),\n    )\n    if last_action and last_action.get(\"done_at\"):\n        done_at = last_action[\"done_at\"]\n        if hasattr(done_at, \"tzinfo\") and done_at.tzinfo is None:\n            done_at = done_at.replace(tzinfo=timezone.utc)\n        days_since = (datetime.now(timezone.utc) - done_at).days\n        state.last_action_days = days_since\n    else:\n        state.last_action_days = 999\n\n    # 检查是否连续问同一问题（简化：检查最近3条消息相似度）\n    if current_message:\n        recent_msgs = fortune_db.fetch_all(\n            \"\"\"\n            SELECT content\n            FROM fortune_conversation_message\n            WHERE user_id = %s AND role = 'user'\n            ORDER BY created_at DESC\n            LIMIT 3\n            \"\"\",\n            (uid,),\n        )\n        similar_count = sum(\n            1 for m in recent_msgs\n            if _message_similarity(current_message, m.get(\"content\", \"\")) > 0.7\n        )\n        state.same_question_count = similar_count\n\n    # 获取或创建最小可执行任务（干预时必须返回）\n    def get_or_create_minimal_task() -> Dict[str, Any]:\n        # 优先返回已有的活跃任务\n        if active_task:\n            return {\n                \"task_id\": str(active_task.get(\"task_id\", \"\")),\n                \"title\": active_task.get(\"title\", \"完成当前任务\"),\n                \"minutes\": 5,\n                \"source\": \"existing_active\",\n            }\n        # 否则返回一个默认的最小任务\n        return {\n            \"task_id\": None,\n            \"title\": \"做3分钟呼吸锚点：专注呼吸进出，走神时温和拉回\",\n            \"minutes\": 3,\n            \"source\": \"default_minimal\",\n        }\n\n    # 判断是否需要干预\n    if state.same_question_count >= 3:\n        state.should_intervene = True\n        state.intervention_type = \"repeated_question\"\n        state.suggested_task = get_or_create_minimal_task()\n        state.intervention_message = (\n            \"我注意到你多次问了类似的问题。信息足够了，现在最重要的是做一个小实验。\\n\\n\"\n            f\"请先完成这个任务：\\n> **{state.suggested_task['title']}**（约{state.suggested_task['minutes']}分钟）\\n\\n\"\n            \"完成后我们再继续。\"\n        )\n    elif state.daily_consult_count >= daily_message_limit:\n        state.should_intervene = True\n        state.intervention_type = \"daily_limit\"\n        state.suggested_task = get_or_create_minimal_task()\n        state.intervention_message = (\n            \"今天我们聊了很多，信息已经足够了。\\n\\n\"\n            f\"现在最重要的是**先行动**：\\n> **{state.suggested_task['title']}**（约{state.suggested_task['minutes']}分钟）\\n\\n\"\n            \"完成后我们再继续。\"\n        )\n    elif state.last_action_days >= 7 and not state.is_new_user:\n        # 对新用户不触发 no_action 干预\n        state.should_intervene = True\n        state.intervention_type = \"no_action\"\n        state.suggested_task = get_or_create_minimal_task()\n        state.intervention_message = (\n            \"看起来你已经有一段时间没有完成行动了。\\n\\n\"\n            \"没关系，我们可以从一个更小的任务开始：\\n\"\n            f\"> **{state.suggested_task['title']}**（约{state.suggested_task['minutes']}分钟）\\n\\n\"\n            \"完成后告诉我。\"\n        )\n\n    return state\n\n\ndef _message_similarity(msg1: str, msg2: str) -> float:\n    \"\"\"简单的消息相似度计算（基于词重叠）\"\"\"\n    if not msg1 or not msg2:\n        return 0.0\n\n    words1 = set(msg1.replace(\"？\", \" \").replace(\"。\", \" \").split())\n    words2 = set(msg2.replace(\"？\", \" \").replace(\"。\", \" \").split())\n\n    if not words1 or not words2:\n        return 0.0\n\n    intersection = len(words1 & words2)\n    union = len(words1 | words2)\n\n    return intersection / union if union > 0 else 0.0\n\n\n# =============================================================================\n# L2 Agents Layer - 知识库检索 + Prompt 模板\n# =============================================================================\n\ndef search_knowledge_base(query: str, top_k: int = 12) -> List[Dict[str, Any]]:\n    \"\"\"从知识库检索相关内容\"\"\"\n    if not query:\n        return []\n\n    # PostgreSQL FTS 检索\n    results = fortune_db.fetch_all(\n        \"\"\"\n        SELECT c.chunk_id, c.doc_id, c.page_no, c.chunk_no,\n               ts_rank(c.content_tsv, plainto_tsquery('simple', %s)) AS rank,\n               c.content,\n               d.file_name, d.title\n        FROM bazi_kb_chunk c\n        JOIN bazi_kb_document d ON c.doc_id = d.doc_id\n        WHERE c.content_tsv @@ plainto_tsquery('simple', %s)\n        ORDER BY rank DESC\n        LIMIT %s\n        \"\"\",\n        (query, query, top_k),\n    )\n\n    kb_refs = []\n    for r in results or []:\n        kb_refs.append({\n            \"kb_ref\": f\"kb:doc:{r['doc_id']}:page:{r['page_no']}:chunk:{r['chunk_no']}\",\n            \"content\": (r.get(\"content\") or \"\")[:500],\n            \"source\": r.get(\"title\") or r.get(\"file_name\") or \"\",\n            \"rank\": r.get(\"rank\", 0),\n        })\n\n    return kb_refs\n\n\ndef get_advisor_perspectives(question: str, facts: Dict[str, Any]) -> List[Dict[str, Any]]:\n    \"\"\"获取四个原型顾问的视角（Prompt 模板参数化）\"\"\"\n    perspectives = [\n        {\n            \"advisor\": \"关系视角\",\n            \"optimization\": \"和谐 + 秩序\",\n            \"prompt_hint\": \"考虑对方感受，先稳定关系，再解决问题\",\n            \"applicable_for\": [\"人际冲突\", \"沟通问题\", \"家庭关系\"],\n        },\n        {\n            \"advisor\": \"第一性原理视角\",\n            \"optimization\": \"真相 + 效率\",\n            \"prompt_hint\": \"问题的本质是什么？最小验证是什么？\",\n            \"applicable_for\": [\"决策困境\", \"职业选择\", \"重大决定\"],\n        },\n        {\n            \"advisor\": \"系统思维视角\",\n            \"optimization\": \"风险 + 概率\",\n            \"prompt_hint\": \"有哪些变量？因果链是什么？最坏情况概率多少？\",\n            \"applicable_for\": [\"复杂问题\", \"风险评估\", \"长期规划\"],\n        },\n        {\n            \"advisor\": \"效能整合视角\",\n            \"optimization\": \"平衡 + 可持续\",\n            \"prompt_hint\": \"重要且不紧急的事优先，建立可持续节奏\",\n            \"applicable_for\": [\"时间管理\", \"精力分配\", \"习惯养成\"],\n        },\n    ]\n\n    return perspectives\n\n\n# =============================================================================\n# L3 Synthesis Layer - GLM 整合 + A2UI 输出\n# =============================================================================\n\ndef build_system_prompt(\n    user_id: int,\n    persona_style: str = \"warm\",\n) -> str:\n    \"\"\"构建 GLM System Prompt（对齐 OS 设计文档附录 A）\"\"\"\n\n    return f\"\"\"你是 Fortune AI 的对话 Agent，角色是积极心理学教练（Performance Coach）。\n\n【产品定位】\n人生导航 / 陪伴 / 提升。系统和交互保持\"有效而极简\"。\n\n【四层架构理解】\n- L0（定数）：用户的八字事实，作为先验约束，不做宿命论解读\n- L1（特质）：用户的心理图式和当前状态，作为个性化调节\n- L2（策略）：知识库和规则，作为专业依据\n- L3（意识）：你的输出，作为整合与行动引导\n\n【你的优先级（不可逆）】\nCoach > Teaching Assistant > Customer Support > Sales\n\n【硬性规则（必须遵守）】\n1) 禁止恐吓、羞辱、宿命论断言；负面信息必须紧接\"你可以做什么\"的行动处方。\n2) 禁止自行计算八字事实；只能基于提供的 facts + evidence 输出。\n3) 每次输出必须包含：结论(conclusion) + 依据(why) + ≤3条处方(prescriptions) + 承诺邀请(commitment_ask)。\n4) 处方必须包含 if_then（如果____→那么____）。\n5) 时间窗口默认只给干预窗口（intervention）；forecast 只能条件句+低置信度。\n6) 输出必须是 A2UI JSON，且第一组件必须是 markdown_text。\n7) 必须给出可点击 actions（start_task / schedule_task / open_panel / opt_out）。\n\n【语言风格 persona_style = {persona_style}】\nstandard：清晰、中性、专业\nwarm：共情、支持性（默认）\nroast：轻毒舌但不羞辱、不对人格做负面定性\n\n【输出格式（A2UI JSON）】\n{{\n  \"meta\": {{\"summary\": \"一句话摘要\"}},\n  \"ui_components\": [\n    {{\"type\": \"markdown_text\", \"title\": \"输出\", \"data\": \"### 结论要点\\\\n...\\\\n### 行动处方\\\\n...\\\\n### 承诺\\\\n...\"}},\n    {{\"type\": \"action_buttons\", \"title\": \"下一步\", \"data\": [{{\"label\": \"开始行动\", \"action\": {{\"type\": \"start_task\"}}}}]}}\n  ]\n}}\n\"\"\"\n\n\ndef build_user_context(user_id: int) -> Dict[str, Any]:\n    \"\"\"构建用户上下文（L0 + L1 + State Score）\"\"\"\n    uid = int(user_id)\n\n    # L0: 八字事实\n    l0 = get_l0_facts(uid)\n    facts = l0.get(\"facts\", {})\n\n    # 心理学翻译\n    translations = translate_bazi_to_psychology(facts)\n\n    # L1: 特质图式\n    l1 = get_l1_schema(uid)\n\n    # State Score\n    state_score = calculate_state_score(uid)\n\n    return {\n        \"l0_facts\": facts,\n        \"l0_facts_hash\": l0.get(\"facts_hash\", \"\"),\n        \"l0_translations\": translations,\n        \"l1_schema\": l1.to_dict(),\n        \"state_score\": state_score.to_dict(),\n    }\n\n\ndef build_evidence(user_id: int, query: str = \"\") -> Dict[str, Any]:\n    \"\"\"构建证据（kb_refs + rule_ids + facts_hash）\"\"\"\n    l0 = get_l0_facts(user_id)\n\n    # 知识库检索\n    kb_refs = []\n    if query:\n        kb_results = search_knowledge_base(query)\n        kb_refs = [r[\"kb_ref\"] for r in kb_results]\n\n    # 规则 ID\n    rule_ids = []\n    facts = l0.get(\"facts\", {})\n    bazi = facts.get(\"bazi\", {})\n\n    if bazi.get(\"strength\", {}).get(\"rule_id\"):\n        rule_ids.append(bazi[\"strength\"][\"rule_id\"])\n\n    for shensha in bazi.get(\"shensha\", []):\n        if shensha.get(\"hit\") and shensha.get(\"rule_id\"):\n            rule_ids.append(shensha[\"rule_id\"])\n\n    return {\n        \"facts_hash\": l0.get(\"facts_hash\", \"\"),\n        \"kb_refs\": kb_refs,\n        \"rule_ids\": rule_ids,\n    }\n\n\ndef guidance_card_to_a2ui(card: Dict[str, Any]) -> Dict[str, Any]:\n    \"\"\"将 Guidance Card 转换为 A2UI 格式\"\"\"\n    title = \"今日指引\"\n    conclusion = str(card.get(\"conclusion\") or \"\")\n    why = str(card.get(\"why\") or \"\")\n    prescriptions = card.get(\"prescriptions\") or []\n    tw = card.get(\"time_window\") or {}\n    commitment_ask = str(card.get(\"commitment_ask\") or \"你愿意先做哪一个？\")\n    risk = str(card.get(\"risk_boundary\") or \"不替代医疗/法律/投资建议\")\n\n    lines: List[str] = []\n    lines.append(\"### 结论要点\")\n    if conclusion:\n        lines.append(f\"- {conclusion}\")\n    lines.append(\"\")\n\n    if why:\n        lines.append(\"### 为什么（教练视角）\")\n        lines.append(why)\n        lines.append(\"\")\n\n    if prescriptions:\n        lines.append(\"### 行动处方（≤3条）\")\n        for i, p in enumerate(prescriptions[:3], start=1):\n            content = p.get(\"content\", \"\")\n            if_then = p.get(\"if_then\", \"\")\n            lines.append(f\"{i}) {content}\")\n            if if_then:\n                lines.append(f\"   - 如果犹豫：{if_then}\")\n        lines.append(\"\")\n\n    if tw:\n        lines.append(\"### 时间窗口\")\n        lines.append(f\"- {tw.get('value') or ''}（置信度：{tw.get('confidence') or ''}）\")\n        lines.append(\"\")\n\n    lines.append(\"### 风险边界\")\n    lines.append(risk)\n    lines.append(\"\")\n    lines.append(\"### 承诺\")\n    lines.append(commitment_ask)\n\n    actions = []\n    for a in card.get(\"actions\") or []:\n        if not isinstance(a, dict):\n            continue\n        label = str(a.get(\"label\") or \"\")\n        payload = {\"type\": str(a.get(\"type\") or \"\")}\n        if a.get(\"task_id\"):\n            payload[\"task_id\"] = str(a[\"task_id\"])\n        actions.append({\"label\": label, \"action\": payload})\n\n    return {\n        \"meta\": {\"summary\": conclusion[:80] or title},\n        \"ui_components\": [\n            {\"type\": \"markdown_text\", \"title\": title, \"data\": \"\\n\".join(lines).strip()},\n            {\"type\": \"action_buttons\", \"title\": \"下一步\", \"data\": actions},\n        ],\n    }\n\n\n# =============================================================================\n# Commitment 管理\n# =============================================================================\n\ndef create_commitment(\n    user_id: int,\n    *,\n    session_id: Optional[str] = None,\n    card_id: str,\n    source: str,\n    commitment_type: str,\n    title: str,\n    details: Dict[str, Any],\n    due_at: Optional[datetime] = None,\n) -> str:\n    \"\"\"创建承诺任务\"\"\"\n    task_id = str(uuid4())\n    fortune_db.execute(\n        \"\"\"\n        INSERT INTO fortune_commitment (task_id, user_id, session_id, card_id, source, commitment_type, title, details, status, due_at)\n        VALUES (%s::uuid, %s, %s::uuid, %s::uuid, %s, %s, %s, %s::jsonb, 'suggested', %s)\n        \"\"\",\n        (\n            task_id,\n            int(user_id),\n            session_id,\n            card_id,\n            source,\n            commitment_type,\n            (title or \"\")[:200],\n            json.dumps(details or {}, ensure_ascii=False),\n            due_at,\n        ),\n    )\n\n    logger.info(\n        \"commitment created\",\n        extra={\"operation\": \"commitment_create\", \"user_id\": int(user_id), \"task_id\": task_id, \"source\": source},\n    )\n\n    return task_id\n\n\ndef accept_commitment(user_id: int, task_id: str) -> bool:\n    \"\"\"接受承诺\"\"\"\n    result = fortune_db.execute(\n        \"\"\"\n        UPDATE fortune_commitment\n        SET status = 'active', accepted_at = NOW()\n        WHERE task_id = %s::uuid AND user_id = %s AND status = 'suggested'\n        \"\"\",\n        (task_id, int(user_id)),\n    )\n\n    if result > 0:\n        logger.info(\n            \"commitment accepted\",\n            extra={\"operation\": \"commitment_accept\", \"user_id\": int(user_id), \"task_id\": task_id},\n        )\n\n    return result > 0\n\n\ndef complete_commitment(user_id: int, task_id: str, note: str = \"\") -> Dict[str, Any]:\n    \"\"\"完成承诺\"\"\"\n    result = fortune_db.execute(\n        \"\"\"\n        UPDATE fortune_commitment\n        SET status = 'done', done_at = NOW()\n        WHERE task_id = %s::uuid AND user_id = %s AND status IN ('suggested', 'active')\n        \"\"\",\n        (task_id, int(user_id)),\n    )\n\n    if result > 0:\n        # 计算新的 State Score\n        new_score = calculate_state_score(user_id)\n\n        logger.info(\n            \"commitment completed\",\n            extra={\n                \"operation\": \"commitment_complete\",\n                \"user_id\": int(user_id),\n                \"task_id\": task_id,\n                \"new_score\": new_score.score,\n            },\n        )\n\n        return {\n            \"success\": True,\n            \"state_score\": new_score.to_dict(),\n            \"message\": \"做得好！你的状态分数已更新。\",\n        }\n\n    return {\"success\": False, \"message\": \"任务不存在或已完成\"}\n\n\ndef list_commitments(\n    user_id: int,\n    *,\n    status: Optional[List[str]] = None,\n    limit: int = 10,\n) -> List[Dict[str, Any]]:\n    \"\"\"列出承诺任务\"\"\"\n    lim = max(1, min(50, int(limit)))\n    sts = status or [\"suggested\", \"active\"]\n\n    rows = fortune_db.fetch_all(\n        \"\"\"\n        SELECT task_id, status, commitment_type, title, details, source, accepted_at, due_at, done_at, created_at\n        FROM fortune_commitment\n        WHERE user_id = %s AND status = ANY(%s)\n        ORDER BY created_at DESC\n        LIMIT %s\n        \"\"\",\n        (int(user_id), sts, lim),\n    )\n\n    items = []\n    for r in rows or []:\n        items.append({\n            \"task_id\": str(r[\"task_id\"]),\n            \"status\": str(r.get(\"status\") or \"\"),\n            \"commitment_type\": str(r.get(\"commitment_type\") or \"\"),\n            \"title\": str(r.get(\"title\") or \"\"),\n            \"details\": r.get(\"details\") or {},\n            \"source\": str(r.get(\"source\") or \"\"),\n            \"accepted_at\": (str(r[\"accepted_at\"]) if r.get(\"accepted_at\") else None),\n            \"due_at\": (str(r[\"due_at\"]) if r.get(\"due_at\") else None),\n            \"done_at\": (str(r[\"done_at\"]) if r.get(\"done_at\") else None),\n            \"created_at\": str(r.get(\"created_at\") or \"\"),\n        })\n\n    return items\n\n\n# =============================================================================\n# 综合接口\n# =============================================================================\n\ndef get_full_context_for_chat(user_id: int, query: str = \"\") -> Dict[str, Any]:\n    \"\"\"获取完整的对话上下文（用于 Chat API）\"\"\"\n    uid = int(user_id)\n\n    # 用户偏好\n    prefs = fortune_db.fetch_one(\n        \"SELECT persona_style FROM fortune_user_preferences WHERE user_id = %s\",\n        (uid,),\n    ) or {}\n    persona_style = prefs.get(\"persona_style\", \"warm\")\n\n    # 用户上下文\n    user_context = build_user_context(uid)\n\n    # 证据\n    evidence = build_evidence(uid, query)\n\n    # 反依赖检查\n    anti_dep = check_anti_dependency(uid, query)\n\n    # System Prompt\n    system_prompt = build_system_prompt(uid, persona_style)\n\n    return {\n        \"system_prompt\": system_prompt,\n        \"persona_style\": persona_style,\n        \"user_context\": user_context,\n        \"evidence\": evidence,\n        \"anti_dependency\": {\n            \"should_intervene\": anti_dep.should_intervene,\n            \"intervention_type\": anti_dep.intervention_type,\n            \"intervention_message\": anti_dep.intervention_message,\n        },\n    }\n","numLines":1237,"startLine":1,"totalLines":1237}}}
{"parentUuid":"0a1d27a2-c41e-46c2-b600-dec05ae37992","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01Q9XVvS1Y1AmMC6iXtLyy2N","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me read the remaining key files:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":17888,"cache_creation_input_tokens":22364,"cache_read_input_tokens":22748,"cache_creation":{"ephemeral_5m_input_tokens":22364,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrnMCgB6AS6GDzoe9Mk","type":"assistant","uuid":"85e2390e-7d11-4726-8e1c-01428af8a3f2","timestamp":"2026-01-01T15:01:18.999Z"}
{"parentUuid":"85e2390e-7d11-4726-8e1c-01428af8a3f2","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01Q9XVvS1Y1AmMC6iXtLyy2N","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_018GXydpcPTvWBRpuGu19XRm","name":"Read","input":{"file_path":"/home/aiscend/work/fortune_ai/services/goal_service.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":17888,"cache_creation_input_tokens":22364,"cache_read_input_tokens":22748,"cache_creation":{"ephemeral_5m_input_tokens":22364,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrnMCgB6AS6GDzoe9Mk","type":"assistant","uuid":"ce49905e-0387-4772-b51c-f48dcda65680","timestamp":"2026-01-01T15:01:19.227Z"}
{"parentUuid":"ce49905e-0387-4772-b51c-f48dcda65680","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01Q9XVvS1Y1AmMC6iXtLyy2N","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019gEJKyR5gTQLmy6pE9bVEK","name":"Read","input":{"file_path":"/home/aiscend/work/fortune_ai/services/agent_service_client.py"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":17888,"cache_creation_input_tokens":22364,"cache_read_input_tokens":22748,"cache_creation":{"ephemeral_5m_input_tokens":22364,"ephemeral_1h_input_tokens":0},"output_tokens":139,"service_tier":"standard"}},"requestId":"req_011CWgrnMCgB6AS6GDzoe9Mk","type":"assistant","uuid":"cb69be6f-0301-4d3e-82ab-b93f45a61de6","timestamp":"2026-01-01T15:01:19.462Z"}
{"parentUuid":"cb69be6f-0301-4d3e-82ab-b93f45a61de6","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_018GXydpcPTvWBRpuGu19XRm","type":"tool_result","content":"     1→\"\"\"\n     2→Goal Service - 目标设定模块\n     3→\n     4→基于 os_design_claude_mvp v1.md §3 设计：\n     5→- 支持年/季/月/周目标层级\n     6→- 包含 Outcome/Lead/Checkpoint 结构\n     7→- 与 Commitment 关联实现目标-任务闭环\n     8→\"\"\"\n     9→\n    10→from __future__ import annotations\n    11→\n    12→import json\n    13→from datetime import datetime, timezone\n    14→from typing import Any, Dict, List, Optional\n    15→from uuid import UUID\n    16→\n    17→from stores import fortune_db\n    18→\n    19→\n    20→def create_goal(\n    21→    user_id: int,\n    22→    title: str,\n    23→    goal_type: str,\n    24→    *,\n    25→    parent_goal_id: Optional[str] = None,\n    26→    outcome_measure: Optional[str] = None,\n    27→    lead_measures: Optional[List[str]] = None,\n    28→    assumptions: Optional[List[str]] = None,\n    29→    dimension: str = \"mixed\",\n    30→    checkpoints: Optional[List[Dict[str, Any]]] = None,\n    31→) -> Dict[str, Any]:\n    32→    \"\"\"\n    33→    创建目标\n    34→\n    35→    Args:\n    36→        user_id: 用户ID\n    37→        title: 目标标题\n    38→        goal_type: 目标类型 (annual/quarterly/monthly/weekly)\n    39→        parent_goal_id: 父目标ID（可选）\n    40→        outcome_measure: 结果指标\n    41→        lead_measures: 行为指标列表\n    42→        assumptions: 假设前提列表\n    43→        dimension: 维度 (cognition/time/capital/mixed)\n    44→        checkpoints: 检查点列表\n    45→\n    46→    Returns:\n    47→        创建的目标对象\n    48→    \"\"\"\n    49→    if goal_type not in (\"annual\", \"quarterly\", \"monthly\", \"weekly\"):\n    50→        raise ValueError(f\"Invalid goal type: {goal_type}\")\n    51→\n    52→    if dimension not in (\"cognition\", \"time\", \"capital\", \"mixed\"):\n    53→        dimension = \"mixed\"\n    54→\n    55→    with fortune_db.db_cursor(dict_cursor=True) as cur:\n    56→        cur.execute(\n    57→            \"\"\"\n    58→            INSERT INTO fortune_goal (\n    59→                user_id, parent_goal_id, type, title,\n    60→                outcome_measure, lead_measures, assumptions,\n    61→                dimension, checkpoints, status\n    62→            ) VALUES (\n    63→                %s, %s, %s, %s,\n    64→                %s, %s, %s,\n    65→                %s, %s, 'active'\n    66→            )\n    67→            RETURNING goal_id, user_id, parent_goal_id, type, title,\n    68→                      outcome_measure, lead_measures, assumptions,\n    69→                      dimension, checkpoints, status, created_at, updated_at\n    70→            \"\"\",\n    71→            (\n    72→                user_id,\n    73→                parent_goal_id,\n    74→                goal_type,\n    75→                title,\n    76→                outcome_measure,\n    77→                json.dumps(lead_measures or []),\n    78→                json.dumps(assumptions or []),\n    79→                dimension,\n    80→                json.dumps(checkpoints or []),\n    81→            ),\n    82→        )\n    83→        row = cur.fetchone()\n    84→        return dict(row) if row else {}\n    85→\n    86→\n    87→def get_goal(goal_id: str, user_id: Optional[int] = None) -> Optional[Dict[str, Any]]:\n    88→    \"\"\"获取单个目标\"\"\"\n    89→    if user_id:\n    90→        row = fortune_db.fetch_one(\n    91→            \"\"\"\n    92→            SELECT goal_id, user_id, parent_goal_id, type, title,\n    93→                   outcome_measure, lead_measures, assumptions,\n    94→                   dimension, checkpoints, status, created_at, updated_at\n    95→            FROM fortune_goal\n    96→            WHERE goal_id = %s AND user_id = %s\n    97→            \"\"\",\n    98→            (goal_id, user_id),\n    99→        )\n   100→    else:\n   101→        row = fortune_db.fetch_one(\n   102→            \"\"\"\n   103→            SELECT goal_id, user_id, parent_goal_id, type, title,\n   104→                   outcome_measure, lead_measures, assumptions,\n   105→                   dimension, checkpoints, status, created_at, updated_at\n   106→            FROM fortune_goal\n   107→            WHERE goal_id = %s\n   108→            \"\"\",\n   109→            (goal_id,),\n   110→        )\n   111→    return dict(row) if row else None\n   112→\n   113→\n   114→def list_goals(\n   115→    user_id: int,\n   116→    *,\n   117→    goal_type: Optional[str] = None,\n   118→    status: Optional[str] = None,\n   119→    limit: int = 50,\n   120→    offset: int = 0,\n   121→) -> List[Dict[str, Any]]:\n   122→    \"\"\"\n   123→    获取用户目标列表\n   124→\n   125→    Args:\n   126→        user_id: 用户ID\n   127→        goal_type: 过滤目标类型 (可选)\n   128→        status: 过滤状态 (可选)\n   129→        limit: 返回数量限制\n   130→        offset: 偏移量\n   131→\n   132→    Returns:\n   133→        目标列表\n   134→    \"\"\"\n   135→    conditions = [\"user_id = %s\"]\n   136→    params: List[Any] = [user_id]\n   137→\n   138→    if goal_type:\n   139→        conditions.append(\"type = %s\")\n   140→        params.append(goal_type)\n   141→\n   142→    if status:\n   143→        conditions.append(\"status = %s\")\n   144→        params.append(status)\n   145→\n   146→    where_clause = \" AND \".join(conditions)\n   147→    params.extend([limit, offset])\n   148→\n   149→    rows = fortune_db.fetch_all(\n   150→        f\"\"\"\n   151→        SELECT goal_id, user_id, parent_goal_id, type, title,\n   152→               outcome_measure, lead_measures, assumptions,\n   153→               dimension, checkpoints, status, created_at, updated_at\n   154→        FROM fortune_goal\n   155→        WHERE {where_clause}\n   156→        ORDER BY created_at DESC\n   157→        LIMIT %s OFFSET %s\n   158→        \"\"\",\n   159→        tuple(params),\n   160→    )\n   161→    return [dict(r) for r in rows]\n   162→\n   163→\n   164→def get_active_goals(user_id: int) -> List[Dict[str, Any]]:\n   165→    \"\"\"获取用户当前活跃的目标\"\"\"\n   166→    return list_goals(user_id, status=\"active\")\n   167→\n   168→\n   169→def update_goal(\n   170→    goal_id: str,\n   171→    user_id: int,\n   172→    *,\n   173→    title: Optional[str] = None,\n   174→    outcome_measure: Optional[str] = None,\n   175→    lead_measures: Optional[List[str]] = None,\n   176→    assumptions: Optional[List[str]] = None,\n   177→    dimension: Optional[str] = None,\n   178→    checkpoints: Optional[List[Dict[str, Any]]] = None,\n   179→    status: Optional[str] = None,\n   180→) -> Optional[Dict[str, Any]]:\n   181→    \"\"\"\n   182→    更新目标\n   183→\n   184→    Args:\n   185→        goal_id: 目标ID\n   186→        user_id: 用户ID (验证所有权)\n   187→        其他参数: 要更新的字段\n   188→\n   189→    Returns:\n   190→        更新后的目标对象\n   191→    \"\"\"\n   192→    updates = []\n   193→    params: List[Any] = []\n   194→\n   195→    if title is not None:\n   196→        updates.append(\"title = %s\")\n   197→        params.append(title)\n   198→\n   199→    if outcome_measure is not None:\n   200→        updates.append(\"outcome_measure = %s\")\n   201→        params.append(outcome_measure)\n   202→\n   203→    if lead_measures is not None:\n   204→        updates.append(\"lead_measures = %s\")\n   205→        params.append(json.dumps(lead_measures))\n   206→\n   207→    if assumptions is not None:\n   208→        updates.append(\"assumptions = %s\")\n   209→        params.append(json.dumps(assumptions))\n   210→\n   211→    if dimension is not None:\n   212→        if dimension in (\"cognition\", \"time\", \"capital\", \"mixed\"):\n   213→            updates.append(\"dimension = %s\")\n   214→            params.append(dimension)\n   215→\n   216→    if checkpoints is not None:\n   217→        updates.append(\"checkpoints = %s\")\n   218→        params.append(json.dumps(checkpoints))\n   219→\n   220→    if status is not None:\n   221→        if status in (\"active\", \"achieved\", \"abandoned\", \"revised\"):\n   222→            updates.append(\"status = %s\")\n   223→            params.append(status)\n   224→\n   225→    if not updates:\n   226→        return get_goal(goal_id, user_id)\n   227→\n   228→    updates.append(\"updated_at = NOW()\")\n   229→    params.extend([goal_id, user_id])\n   230→\n   231→    with fortune_db.db_cursor(dict_cursor=True) as cur:\n   232→        cur.execute(\n   233→            f\"\"\"\n   234→            UPDATE fortune_goal\n   235→            SET {\", \".join(updates)}\n   236→            WHERE goal_id = %s AND user_id = %s\n   237→            RETURNING goal_id, user_id, parent_goal_id, type, title,\n   238→                      outcome_measure, lead_measures, assumptions,\n   239→                      dimension, checkpoints, status, created_at, updated_at\n   240→            \"\"\",\n   241→            tuple(params),\n   242→        )\n   243→        row = cur.fetchone()\n   244→        return dict(row) if row else None\n   245→\n   246→\n   247→def link_commitment_to_goal(\n   248→    goal_id: str,\n   249→    task_id: str,\n   250→    user_id: int,\n   251→) -> bool:\n   252→    \"\"\"\n   253→    将任务关联到目标\n   254→\n   255→    Args:\n   256→        goal_id: 目标ID\n   257→        task_id: 任务ID\n   258→        user_id: 用户ID (验证所有权)\n   259→\n   260→    Returns:\n   261→        是否成功\n   262→    \"\"\"\n   263→    goal = get_goal(goal_id, user_id)\n   264→    if not goal:\n   265→        return False\n   266→\n   267→    with fortune_db.db_cursor() as cur:\n   268→        cur.execute(\n   269→            \"\"\"\n   270→            UPDATE fortune_commitment\n   271→            SET goal_id = %s\n   272→            WHERE task_id = %s AND user_id = %s\n   273→            \"\"\",\n   274→            (goal_id, task_id, user_id),\n   275→        )\n   276→        return cur.rowcount > 0\n   277→\n   278→\n   279→def record_checkpoint(\n   280→    goal_id: str,\n   281→    user_id: int,\n   282→    checkpoint_date: str,\n   283→    description: str,\n   284→    progress: Optional[str] = None,\n   285→) -> Optional[Dict[str, Any]]:\n   286→    \"\"\"\n   287→    记录检查点进展\n   288→\n   289→    Args:\n   290→        goal_id: 目标ID\n   291→        user_id: 用户ID\n   292→        checkpoint_date: 检查点日期\n   293→        description: 进展描述\n   294→        progress: 进展状态\n   295→\n   296→    Returns:\n   297→        更新后的目标对象\n   298→    \"\"\"\n   299→    goal = get_goal(goal_id, user_id)\n   300→    if not goal:\n   301→        return None\n   302→\n   303→    checkpoints = goal.get(\"checkpoints\") or []\n   304→    if isinstance(checkpoints, str):\n   305→        checkpoints = json.loads(checkpoints)\n   306→\n   307→    new_checkpoint = {\n   308→        \"date\": checkpoint_date,\n   309→        \"description\": description,\n   310→        \"progress\": progress,\n   311→        \"recorded_at\": datetime.now(timezone.utc).isoformat(),\n   312→    }\n   313→\n   314→    found = False\n   315→    for i, cp in enumerate(checkpoints):\n   316→        if cp.get(\"date\") == checkpoint_date:\n   317→            checkpoints[i] = new_checkpoint\n   318→            found = True\n   319→            break\n   320→\n   321→    if not found:\n   322→        checkpoints.append(new_checkpoint)\n   323→\n   324→    return update_goal(goal_id, user_id, checkpoints=checkpoints)\n   325→\n   326→\n   327→def get_goal_progress(goal_id: str, user_id: int) -> Dict[str, Any]:\n   328→    \"\"\"\n   329→    获取目标进度\n   330→\n   331→    Args:\n   332→        goal_id: 目标ID\n   333→        user_id: 用户ID\n   334→\n   335→    Returns:\n   336→        目标进度信息\n   337→    \"\"\"\n   338→    goal = get_goal(goal_id, user_id)\n   339→    if not goal:\n   340→        return {\"error\": \"goal_not_found\"}\n   341→\n   342→    tasks = fortune_db.fetch_all(\n   343→        \"\"\"\n   344→        SELECT task_id, title, status, created_at, accepted_at, done_at\n   345→        FROM fortune_commitment\n   346→        WHERE goal_id = %s AND user_id = %s\n   347→        ORDER BY created_at DESC\n   348→        \"\"\",\n   349→        (goal_id, user_id),\n   350→    )\n   351→\n   352→    total_tasks = len(tasks)\n   353→    done_tasks = sum(1 for t in tasks if t.get(\"status\") == \"done\")\n   354→    active_tasks = sum(1 for t in tasks if t.get(\"status\") == \"active\")\n   355→\n   356→    checkpoints = goal.get(\"checkpoints\") or []\n   357→    if isinstance(checkpoints, str):\n   358→        checkpoints = json.loads(checkpoints)\n   359→    completed_checkpoints = sum(\n   360→        1 for cp in checkpoints if cp.get(\"progress\") == \"completed\"\n   361→    )\n   362→\n   363→    return {\n   364→        \"goal_id\": str(goal.get(\"goal_id\")),\n   365→        \"title\": goal.get(\"title\"),\n   366→        \"status\": goal.get(\"status\"),\n   367→        \"tasks\": {\n   368→            \"total\": total_tasks,\n   369→            \"done\": done_tasks,\n   370→            \"active\": active_tasks,\n   371→            \"completion_rate\": (done_tasks / total_tasks * 100) if total_tasks > 0 else 0,\n   372→        },\n   373→        \"checkpoints\": {\n   374→            \"total\": len(checkpoints),\n   375→            \"completed\": completed_checkpoints,\n   376→        },\n   377→        \"recent_tasks\": [dict(t) for t in tasks[:5]],\n   378→    }\n   379→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"3de817d1-08ef-4eef-9e18-d43f4a942131","timestamp":"2026-01-01T15:01:19.646Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aiscend/work/fortune_ai/services/goal_service.py","content":"\"\"\"\nGoal Service - 目标设定模块\n\n基于 os_design_claude_mvp v1.md §3 设计：\n- 支持年/季/月/周目标层级\n- 包含 Outcome/Lead/Checkpoint 结构\n- 与 Commitment 关联实现目标-任务闭环\n\"\"\"\n\nfrom __future__ import annotations\n\nimport json\nfrom datetime import datetime, timezone\nfrom typing import Any, Dict, List, Optional\nfrom uuid import UUID\n\nfrom stores import fortune_db\n\n\ndef create_goal(\n    user_id: int,\n    title: str,\n    goal_type: str,\n    *,\n    parent_goal_id: Optional[str] = None,\n    outcome_measure: Optional[str] = None,\n    lead_measures: Optional[List[str]] = None,\n    assumptions: Optional[List[str]] = None,\n    dimension: str = \"mixed\",\n    checkpoints: Optional[List[Dict[str, Any]]] = None,\n) -> Dict[str, Any]:\n    \"\"\"\n    创建目标\n\n    Args:\n        user_id: 用户ID\n        title: 目标标题\n        goal_type: 目标类型 (annual/quarterly/monthly/weekly)\n        parent_goal_id: 父目标ID（可选）\n        outcome_measure: 结果指标\n        lead_measures: 行为指标列表\n        assumptions: 假设前提列表\n        dimension: 维度 (cognition/time/capital/mixed)\n        checkpoints: 检查点列表\n\n    Returns:\n        创建的目标对象\n    \"\"\"\n    if goal_type not in (\"annual\", \"quarterly\", \"monthly\", \"weekly\"):\n        raise ValueError(f\"Invalid goal type: {goal_type}\")\n\n    if dimension not in (\"cognition\", \"time\", \"capital\", \"mixed\"):\n        dimension = \"mixed\"\n\n    with fortune_db.db_cursor(dict_cursor=True) as cur:\n        cur.execute(\n            \"\"\"\n            INSERT INTO fortune_goal (\n                user_id, parent_goal_id, type, title,\n                outcome_measure, lead_measures, assumptions,\n                dimension, checkpoints, status\n            ) VALUES (\n                %s, %s, %s, %s,\n                %s, %s, %s,\n                %s, %s, 'active'\n            )\n            RETURNING goal_id, user_id, parent_goal_id, type, title,\n                      outcome_measure, lead_measures, assumptions,\n                      dimension, checkpoints, status, created_at, updated_at\n            \"\"\",\n            (\n                user_id,\n                parent_goal_id,\n                goal_type,\n                title,\n                outcome_measure,\n                json.dumps(lead_measures or []),\n                json.dumps(assumptions or []),\n                dimension,\n                json.dumps(checkpoints or []),\n            ),\n        )\n        row = cur.fetchone()\n        return dict(row) if row else {}\n\n\ndef get_goal(goal_id: str, user_id: Optional[int] = None) -> Optional[Dict[str, Any]]:\n    \"\"\"获取单个目标\"\"\"\n    if user_id:\n        row = fortune_db.fetch_one(\n            \"\"\"\n            SELECT goal_id, user_id, parent_goal_id, type, title,\n                   outcome_measure, lead_measures, assumptions,\n                   dimension, checkpoints, status, created_at, updated_at\n            FROM fortune_goal\n            WHERE goal_id = %s AND user_id = %s\n            \"\"\",\n            (goal_id, user_id),\n        )\n    else:\n        row = fortune_db.fetch_one(\n            \"\"\"\n            SELECT goal_id, user_id, parent_goal_id, type, title,\n                   outcome_measure, lead_measures, assumptions,\n                   dimension, checkpoints, status, created_at, updated_at\n            FROM fortune_goal\n            WHERE goal_id = %s\n            \"\"\",\n            (goal_id,),\n        )\n    return dict(row) if row else None\n\n\ndef list_goals(\n    user_id: int,\n    *,\n    goal_type: Optional[str] = None,\n    status: Optional[str] = None,\n    limit: int = 50,\n    offset: int = 0,\n) -> List[Dict[str, Any]]:\n    \"\"\"\n    获取用户目标列表\n\n    Args:\n        user_id: 用户ID\n        goal_type: 过滤目标类型 (可选)\n        status: 过滤状态 (可选)\n        limit: 返回数量限制\n        offset: 偏移量\n\n    Returns:\n        目标列表\n    \"\"\"\n    conditions = [\"user_id = %s\"]\n    params: List[Any] = [user_id]\n\n    if goal_type:\n        conditions.append(\"type = %s\")\n        params.append(goal_type)\n\n    if status:\n        conditions.append(\"status = %s\")\n        params.append(status)\n\n    where_clause = \" AND \".join(conditions)\n    params.extend([limit, offset])\n\n    rows = fortune_db.fetch_all(\n        f\"\"\"\n        SELECT goal_id, user_id, parent_goal_id, type, title,\n               outcome_measure, lead_measures, assumptions,\n               dimension, checkpoints, status, created_at, updated_at\n        FROM fortune_goal\n        WHERE {where_clause}\n        ORDER BY created_at DESC\n        LIMIT %s OFFSET %s\n        \"\"\",\n        tuple(params),\n    )\n    return [dict(r) for r in rows]\n\n\ndef get_active_goals(user_id: int) -> List[Dict[str, Any]]:\n    \"\"\"获取用户当前活跃的目标\"\"\"\n    return list_goals(user_id, status=\"active\")\n\n\ndef update_goal(\n    goal_id: str,\n    user_id: int,\n    *,\n    title: Optional[str] = None,\n    outcome_measure: Optional[str] = None,\n    lead_measures: Optional[List[str]] = None,\n    assumptions: Optional[List[str]] = None,\n    dimension: Optional[str] = None,\n    checkpoints: Optional[List[Dict[str, Any]]] = None,\n    status: Optional[str] = None,\n) -> Optional[Dict[str, Any]]:\n    \"\"\"\n    更新目标\n\n    Args:\n        goal_id: 目标ID\n        user_id: 用户ID (验证所有权)\n        其他参数: 要更新的字段\n\n    Returns:\n        更新后的目标对象\n    \"\"\"\n    updates = []\n    params: List[Any] = []\n\n    if title is not None:\n        updates.append(\"title = %s\")\n        params.append(title)\n\n    if outcome_measure is not None:\n        updates.append(\"outcome_measure = %s\")\n        params.append(outcome_measure)\n\n    if lead_measures is not None:\n        updates.append(\"lead_measures = %s\")\n        params.append(json.dumps(lead_measures))\n\n    if assumptions is not None:\n        updates.append(\"assumptions = %s\")\n        params.append(json.dumps(assumptions))\n\n    if dimension is not None:\n        if dimension in (\"cognition\", \"time\", \"capital\", \"mixed\"):\n            updates.append(\"dimension = %s\")\n            params.append(dimension)\n\n    if checkpoints is not None:\n        updates.append(\"checkpoints = %s\")\n        params.append(json.dumps(checkpoints))\n\n    if status is not None:\n        if status in (\"active\", \"achieved\", \"abandoned\", \"revised\"):\n            updates.append(\"status = %s\")\n            params.append(status)\n\n    if not updates:\n        return get_goal(goal_id, user_id)\n\n    updates.append(\"updated_at = NOW()\")\n    params.extend([goal_id, user_id])\n\n    with fortune_db.db_cursor(dict_cursor=True) as cur:\n        cur.execute(\n            f\"\"\"\n            UPDATE fortune_goal\n            SET {\", \".join(updates)}\n            WHERE goal_id = %s AND user_id = %s\n            RETURNING goal_id, user_id, parent_goal_id, type, title,\n                      outcome_measure, lead_measures, assumptions,\n                      dimension, checkpoints, status, created_at, updated_at\n            \"\"\",\n            tuple(params),\n        )\n        row = cur.fetchone()\n        return dict(row) if row else None\n\n\ndef link_commitment_to_goal(\n    goal_id: str,\n    task_id: str,\n    user_id: int,\n) -> bool:\n    \"\"\"\n    将任务关联到目标\n\n    Args:\n        goal_id: 目标ID\n        task_id: 任务ID\n        user_id: 用户ID (验证所有权)\n\n    Returns:\n        是否成功\n    \"\"\"\n    goal = get_goal(goal_id, user_id)\n    if not goal:\n        return False\n\n    with fortune_db.db_cursor() as cur:\n        cur.execute(\n            \"\"\"\n            UPDATE fortune_commitment\n            SET goal_id = %s\n            WHERE task_id = %s AND user_id = %s\n            \"\"\",\n            (goal_id, task_id, user_id),\n        )\n        return cur.rowcount > 0\n\n\ndef record_checkpoint(\n    goal_id: str,\n    user_id: int,\n    checkpoint_date: str,\n    description: str,\n    progress: Optional[str] = None,\n) -> Optional[Dict[str, Any]]:\n    \"\"\"\n    记录检查点进展\n\n    Args:\n        goal_id: 目标ID\n        user_id: 用户ID\n        checkpoint_date: 检查点日期\n        description: 进展描述\n        progress: 进展状态\n\n    Returns:\n        更新后的目标对象\n    \"\"\"\n    goal = get_goal(goal_id, user_id)\n    if not goal:\n        return None\n\n    checkpoints = goal.get(\"checkpoints\") or []\n    if isinstance(checkpoints, str):\n        checkpoints = json.loads(checkpoints)\n\n    new_checkpoint = {\n        \"date\": checkpoint_date,\n        \"description\": description,\n        \"progress\": progress,\n        \"recorded_at\": datetime.now(timezone.utc).isoformat(),\n    }\n\n    found = False\n    for i, cp in enumerate(checkpoints):\n        if cp.get(\"date\") == checkpoint_date:\n            checkpoints[i] = new_checkpoint\n            found = True\n            break\n\n    if not found:\n        checkpoints.append(new_checkpoint)\n\n    return update_goal(goal_id, user_id, checkpoints=checkpoints)\n\n\ndef get_goal_progress(goal_id: str, user_id: int) -> Dict[str, Any]:\n    \"\"\"\n    获取目标进度\n\n    Args:\n        goal_id: 目标ID\n        user_id: 用户ID\n\n    Returns:\n        目标进度信息\n    \"\"\"\n    goal = get_goal(goal_id, user_id)\n    if not goal:\n        return {\"error\": \"goal_not_found\"}\n\n    tasks = fortune_db.fetch_all(\n        \"\"\"\n        SELECT task_id, title, status, created_at, accepted_at, done_at\n        FROM fortune_commitment\n        WHERE goal_id = %s AND user_id = %s\n        ORDER BY created_at DESC\n        \"\"\",\n        (goal_id, user_id),\n    )\n\n    total_tasks = len(tasks)\n    done_tasks = sum(1 for t in tasks if t.get(\"status\") == \"done\")\n    active_tasks = sum(1 for t in tasks if t.get(\"status\") == \"active\")\n\n    checkpoints = goal.get(\"checkpoints\") or []\n    if isinstance(checkpoints, str):\n        checkpoints = json.loads(checkpoints)\n    completed_checkpoints = sum(\n        1 for cp in checkpoints if cp.get(\"progress\") == \"completed\"\n    )\n\n    return {\n        \"goal_id\": str(goal.get(\"goal_id\")),\n        \"title\": goal.get(\"title\"),\n        \"status\": goal.get(\"status\"),\n        \"tasks\": {\n            \"total\": total_tasks,\n            \"done\": done_tasks,\n            \"active\": active_tasks,\n            \"completion_rate\": (done_tasks / total_tasks * 100) if total_tasks > 0 else 0,\n        },\n        \"checkpoints\": {\n            \"total\": len(checkpoints),\n            \"completed\": completed_checkpoints,\n        },\n        \"recent_tasks\": [dict(t) for t in tasks[:5]],\n    }\n","numLines":379,"startLine":1,"totalLines":379}}}
{"parentUuid":"3de817d1-08ef-4eef-9e18-d43f4a942131","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019gEJKyR5gTQLmy6pE9bVEK","type":"tool_result","content":"     1→\"\"\"\n     2→Agent Service Client.\n     3→\n     4→REQ: REQ-CHAT-001\n     5→Design: §10.5.3 Agent Service Integration\n     6→\n     7→Provides HTTP client for calling the Vercel AI SDK-based agent_service.\n     8→Falls back gracefully to FastAPI direct implementation if unavailable.\n     9→\"\"\"\n    10→\n    11→from __future__ import annotations\n    12→\n    13→import os\n    14→import json\n    15→from dataclasses import dataclass\n    16→from typing import Any, Dict, List, Optional\n    17→\n    18→import httpx\n    19→\n    20→from common.logging import get_logger\n    21→\n    22→logger = get_logger(__name__)\n    23→\n    24→\n    25→# Configuration\n    26→AGENT_SERVICE_URL = os.getenv(\"AGENT_SERVICE_URL\", \"http://localhost:3002\")\n    27→AGENT_SERVICE_TOKEN = os.getenv(\"AGENT_SERVICE_TOKEN\", \"\")\n    28→AGENT_SERVICE_TIMEOUT = float(os.getenv(\"AGENT_SERVICE_TIMEOUT\", \"30\"))\n    29→\n    30→\n    31→class AgentServiceError(Exception):\n    32→    \"\"\"Base exception for agent service errors.\"\"\"\n    33→    pass\n    34→\n    35→\n    36→class AgentServiceUnavailable(AgentServiceError):\n    37→    \"\"\"Agent service is not available.\"\"\"\n    38→    pass\n    39→\n    40→\n    41→@dataclass\n    42→class AgentResponse:\n    43→    \"\"\"Response from agent service.\"\"\"\n    44→    text: str\n    45→    a2ui: Optional[Dict[str, Any]] = None\n    46→    tool_calls: Optional[List[Dict[str, Any]]] = None\n    47→    metadata: Optional[Dict[str, Any]] = None\n    48→\n    49→\n    50→def is_agent_service_configured() -> bool:\n    51→    \"\"\"Check if agent service is configured.\"\"\"\n    52→    return bool(AGENT_SERVICE_URL and AGENT_SERVICE_TOKEN)\n    53→\n    54→\n    55→def _json_safe(data: Any) -> Any:\n    56→    \"\"\"Best-effort conversion to JSON-serializable payload (datetime -> str, etc.).\"\"\"\n    57→    try:\n    58→        return json.loads(json.dumps(data, ensure_ascii=False, default=str))\n    59→    except Exception:\n    60→        return data\n    61→\n    62→\n    63→async def call_agent_service(\n    64→    user_id: int,\n    65→    session_id: str,\n    66→    messages: List[Dict[str, str]],\n    67→    user_context: Dict[str, Any],\n    68→    facts: Dict[str, Any],\n    69→    persona_style: str = \"warm\",\n    70→) -> AgentResponse:\n    71→    \"\"\"\n    72→    Call the agent service for chat completion.\n    73→\n    74→    REQ: REQ-CHAT-001\n    75→    Design: §10.5.3\n    76→\n    77→    Args:\n    78→        user_id: User ID\n    79→        session_id: Chat session ID\n    80→        messages: Chat history messages\n    81→        user_context: User profile and preferences\n    82→        facts: Bazi facts snapshot\n    83→        persona_style: Persona style (warm, standard, roast)\n    84→\n    85→    Returns:\n    86→        AgentResponse with text and optional A2UI components\n    87→\n    88→    Raises:\n    89→        AgentServiceUnavailable: If service is not reachable\n    90→        AgentServiceError: For other errors\n    91→    \"\"\"\n    92→    if not is_agent_service_configured():\n    93→        raise AgentServiceUnavailable(\"Agent service not configured\")\n    94→\n    95→    payload = {\n    96→        \"user_id\": user_id,\n    97→        \"session_id\": session_id,\n    98→        \"messages\": messages,\n    99→        \"context\": {\n   100→            \"user\": user_context,\n   101→            \"facts\": facts,\n   102→            \"persona_style\": persona_style,\n   103→        },\n   104→    }\n   105→    payload = _json_safe(payload)\n   106→\n   107→    headers = {\n   108→        \"Content-Type\": \"application/json\",\n   109→        \"Authorization\": f\"Bearer {AGENT_SERVICE_TOKEN}\",\n   110→    }\n   111→\n   112→    try:\n   113→        async with httpx.AsyncClient(timeout=AGENT_SERVICE_TIMEOUT) as client:\n   114→            response = await client.post(\n   115→                f\"{AGENT_SERVICE_URL}/api/chat\",\n   116→                json=payload,\n   117→                headers=headers,\n   118→            )\n   119→\n   120→            if response.status_code == 503:\n   121→                raise AgentServiceUnavailable(\"Agent service temporarily unavailable\")\n   122→\n   123→            if response.status_code != 200:\n   124→                error_text = response.text\n   125→                logger.error(\n   126→                    \"agent_service_error status=%s body=%s\",\n   127→                    response.status_code, error_text[:500]\n   128→                )\n   129→                raise AgentServiceError(f\"Agent service error: {response.status_code}\")\n   130→\n   131→            data = response.json()\n   132→\n   133→            return AgentResponse(\n   134→                text=data.get(\"text\", \"\"),\n   135→                a2ui=data.get(\"a2ui\") or data.get(\"a2Ui\"),\n   136→                tool_calls=data.get(\"tool_calls\") or data.get(\"toolCalls\"),\n   137→                metadata=data.get(\"metadata\") or data.get(\"meta\"),\n   138→            )\n   139→\n   140→    except httpx.ConnectError:\n   141→        logger.warning(\"agent_service_unavailable url=%s\", AGENT_SERVICE_URL)\n   142→        raise AgentServiceUnavailable(\"Cannot connect to agent service\")\n   143→    except httpx.TimeoutException:\n   144→        logger.warning(\"agent_service_timeout url=%s\", AGENT_SERVICE_URL)\n   145→        raise AgentServiceUnavailable(\"Agent service timeout\")\n   146→    except json.JSONDecodeError as e:\n   147→        logger.error(\"agent_service_invalid_json error=%s\", str(e))\n   148→        raise AgentServiceError(\"Invalid response from agent service\")\n   149→\n   150→\n   151→def call_agent_service_sync(\n   152→    user_id: int,\n   153→    session_id: str,\n   154→    messages: List[Dict[str, str]],\n   155→    user_context: Dict[str, Any],\n   156→    facts: Dict[str, Any],\n   157→    persona_style: str = \"warm\",\n   158→) -> AgentResponse:\n   159→    \"\"\"\n   160→    Synchronous wrapper for call_agent_service.\n   161→\n   162→    For use in non-async contexts.\n   163→    \"\"\"\n   164→    if not is_agent_service_configured():\n   165→        raise AgentServiceUnavailable(\"Agent service not configured\")\n   166→\n   167→    payload = {\n   168→        \"user_id\": user_id,\n   169→        \"session_id\": session_id,\n   170→        \"messages\": messages,\n   171→        \"context\": {\n   172→            \"user\": user_context,\n   173→            \"facts\": facts,\n   174→            \"persona_style\": persona_style,\n   175→        },\n   176→    }\n   177→    payload = _json_safe(payload)\n   178→\n   179→    headers = {\n   180→        \"Content-Type\": \"application/json\",\n   181→        \"Authorization\": f\"Bearer {AGENT_SERVICE_TOKEN}\",\n   182→    }\n   183→\n   184→    try:\n   185→        with httpx.Client(timeout=AGENT_SERVICE_TIMEOUT) as client:\n   186→            response = client.post(\n   187→                f\"{AGENT_SERVICE_URL}/api/chat\",\n   188→                json=payload,\n   189→                headers=headers,\n   190→            )\n   191→\n   192→            if response.status_code == 503:\n   193→                raise AgentServiceUnavailable(\"Agent service temporarily unavailable\")\n   194→\n   195→            if response.status_code != 200:\n   196→                error_text = response.text\n   197→                logger.error(\n   198→                    \"agent_service_error status=%s body=%s\",\n   199→                    response.status_code, error_text[:500]\n   200→                )\n   201→                raise AgentServiceError(f\"Agent service error: {response.status_code}\")\n   202→\n   203→            data = response.json()\n   204→\n   205→            return AgentResponse(\n   206→                text=data.get(\"text\", \"\"),\n   207→                a2ui=data.get(\"a2ui\") or data.get(\"a2Ui\"),\n   208→                tool_calls=data.get(\"tool_calls\") or data.get(\"toolCalls\"),\n   209→                metadata=data.get(\"metadata\") or data.get(\"meta\"),\n   210→            )\n   211→\n   212→    except httpx.ConnectError:\n   213→        logger.warning(\"agent_service_unavailable url=%s\", AGENT_SERVICE_URL)\n   214→        raise AgentServiceUnavailable(\"Cannot connect to agent service\")\n   215→    except httpx.TimeoutException:\n   216→        logger.warning(\"agent_service_timeout url=%s\", AGENT_SERVICE_URL)\n   217→        raise AgentServiceUnavailable(\"Agent service timeout\")\n   218→    except json.JSONDecodeError as e:\n   219→        logger.error(\"agent_service_invalid_json error=%s\", str(e))\n   220→        raise AgentServiceError(\"Invalid response from agent service\")\n   221→\n   222→\n   223→def health_check() -> Dict[str, Any]:\n   224→    \"\"\"\n   225→    Check agent service health.\n   226→\n   227→    Returns status and latency information.\n   228→    \"\"\"\n   229→    if not is_agent_service_configured():\n   230→        return {\"status\": \"not_configured\", \"url\": None}\n   231→\n   232→    import time\n   233→    start = time.time()\n   234→\n   235→    try:\n   236→        with httpx.Client(timeout=5.0) as client:\n   237→            response = client.get(f\"{AGENT_SERVICE_URL}/health\")\n   238→            latency_ms = int((time.time() - start) * 1000)\n   239→\n   240→            if response.status_code == 200:\n   241→                return {\n   242→                    \"status\": \"healthy\",\n   243→                    \"url\": AGENT_SERVICE_URL,\n   244→                    \"latency_ms\": latency_ms,\n   245→                }\n   246→            else:\n   247→                return {\n   248→                    \"status\": \"unhealthy\",\n   249→                    \"url\": AGENT_SERVICE_URL,\n   250→                    \"status_code\": response.status_code,\n   251→                }\n   252→    except Exception as e:\n   253→        return {\n   254→            \"status\": \"unreachable\",\n   255→            \"url\": AGENT_SERVICE_URL,\n   256→            \"error\": str(e),\n   257→        }\n   258→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"e1b1252f-0157-40d1-9662-07dd9cbf9f9c","timestamp":"2026-01-01T15:01:19.646Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aiscend/work/fortune_ai/services/agent_service_client.py","content":"\"\"\"\nAgent Service Client.\n\nREQ: REQ-CHAT-001\nDesign: §10.5.3 Agent Service Integration\n\nProvides HTTP client for calling the Vercel AI SDK-based agent_service.\nFalls back gracefully to FastAPI direct implementation if unavailable.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport os\nimport json\nfrom dataclasses import dataclass\nfrom typing import Any, Dict, List, Optional\n\nimport httpx\n\nfrom common.logging import get_logger\n\nlogger = get_logger(__name__)\n\n\n# Configuration\nAGENT_SERVICE_URL = os.getenv(\"AGENT_SERVICE_URL\", \"http://localhost:3002\")\nAGENT_SERVICE_TOKEN = os.getenv(\"AGENT_SERVICE_TOKEN\", \"\")\nAGENT_SERVICE_TIMEOUT = float(os.getenv(\"AGENT_SERVICE_TIMEOUT\", \"30\"))\n\n\nclass AgentServiceError(Exception):\n    \"\"\"Base exception for agent service errors.\"\"\"\n    pass\n\n\nclass AgentServiceUnavailable(AgentServiceError):\n    \"\"\"Agent service is not available.\"\"\"\n    pass\n\n\n@dataclass\nclass AgentResponse:\n    \"\"\"Response from agent service.\"\"\"\n    text: str\n    a2ui: Optional[Dict[str, Any]] = None\n    tool_calls: Optional[List[Dict[str, Any]]] = None\n    metadata: Optional[Dict[str, Any]] = None\n\n\ndef is_agent_service_configured() -> bool:\n    \"\"\"Check if agent service is configured.\"\"\"\n    return bool(AGENT_SERVICE_URL and AGENT_SERVICE_TOKEN)\n\n\ndef _json_safe(data: Any) -> Any:\n    \"\"\"Best-effort conversion to JSON-serializable payload (datetime -> str, etc.).\"\"\"\n    try:\n        return json.loads(json.dumps(data, ensure_ascii=False, default=str))\n    except Exception:\n        return data\n\n\nasync def call_agent_service(\n    user_id: int,\n    session_id: str,\n    messages: List[Dict[str, str]],\n    user_context: Dict[str, Any],\n    facts: Dict[str, Any],\n    persona_style: str = \"warm\",\n) -> AgentResponse:\n    \"\"\"\n    Call the agent service for chat completion.\n\n    REQ: REQ-CHAT-001\n    Design: §10.5.3\n\n    Args:\n        user_id: User ID\n        session_id: Chat session ID\n        messages: Chat history messages\n        user_context: User profile and preferences\n        facts: Bazi facts snapshot\n        persona_style: Persona style (warm, standard, roast)\n\n    Returns:\n        AgentResponse with text and optional A2UI components\n\n    Raises:\n        AgentServiceUnavailable: If service is not reachable\n        AgentServiceError: For other errors\n    \"\"\"\n    if not is_agent_service_configured():\n        raise AgentServiceUnavailable(\"Agent service not configured\")\n\n    payload = {\n        \"user_id\": user_id,\n        \"session_id\": session_id,\n        \"messages\": messages,\n        \"context\": {\n            \"user\": user_context,\n            \"facts\": facts,\n            \"persona_style\": persona_style,\n        },\n    }\n    payload = _json_safe(payload)\n\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {AGENT_SERVICE_TOKEN}\",\n    }\n\n    try:\n        async with httpx.AsyncClient(timeout=AGENT_SERVICE_TIMEOUT) as client:\n            response = await client.post(\n                f\"{AGENT_SERVICE_URL}/api/chat\",\n                json=payload,\n                headers=headers,\n            )\n\n            if response.status_code == 503:\n                raise AgentServiceUnavailable(\"Agent service temporarily unavailable\")\n\n            if response.status_code != 200:\n                error_text = response.text\n                logger.error(\n                    \"agent_service_error status=%s body=%s\",\n                    response.status_code, error_text[:500]\n                )\n                raise AgentServiceError(f\"Agent service error: {response.status_code}\")\n\n            data = response.json()\n\n            return AgentResponse(\n                text=data.get(\"text\", \"\"),\n                a2ui=data.get(\"a2ui\") or data.get(\"a2Ui\"),\n                tool_calls=data.get(\"tool_calls\") or data.get(\"toolCalls\"),\n                metadata=data.get(\"metadata\") or data.get(\"meta\"),\n            )\n\n    except httpx.ConnectError:\n        logger.warning(\"agent_service_unavailable url=%s\", AGENT_SERVICE_URL)\n        raise AgentServiceUnavailable(\"Cannot connect to agent service\")\n    except httpx.TimeoutException:\n        logger.warning(\"agent_service_timeout url=%s\", AGENT_SERVICE_URL)\n        raise AgentServiceUnavailable(\"Agent service timeout\")\n    except json.JSONDecodeError as e:\n        logger.error(\"agent_service_invalid_json error=%s\", str(e))\n        raise AgentServiceError(\"Invalid response from agent service\")\n\n\ndef call_agent_service_sync(\n    user_id: int,\n    session_id: str,\n    messages: List[Dict[str, str]],\n    user_context: Dict[str, Any],\n    facts: Dict[str, Any],\n    persona_style: str = \"warm\",\n) -> AgentResponse:\n    \"\"\"\n    Synchronous wrapper for call_agent_service.\n\n    For use in non-async contexts.\n    \"\"\"\n    if not is_agent_service_configured():\n        raise AgentServiceUnavailable(\"Agent service not configured\")\n\n    payload = {\n        \"user_id\": user_id,\n        \"session_id\": session_id,\n        \"messages\": messages,\n        \"context\": {\n            \"user\": user_context,\n            \"facts\": facts,\n            \"persona_style\": persona_style,\n        },\n    }\n    payload = _json_safe(payload)\n\n    headers = {\n        \"Content-Type\": \"application/json\",\n        \"Authorization\": f\"Bearer {AGENT_SERVICE_TOKEN}\",\n    }\n\n    try:\n        with httpx.Client(timeout=AGENT_SERVICE_TIMEOUT) as client:\n            response = client.post(\n                f\"{AGENT_SERVICE_URL}/api/chat\",\n                json=payload,\n                headers=headers,\n            )\n\n            if response.status_code == 503:\n                raise AgentServiceUnavailable(\"Agent service temporarily unavailable\")\n\n            if response.status_code != 200:\n                error_text = response.text\n                logger.error(\n                    \"agent_service_error status=%s body=%s\",\n                    response.status_code, error_text[:500]\n                )\n                raise AgentServiceError(f\"Agent service error: {response.status_code}\")\n\n            data = response.json()\n\n            return AgentResponse(\n                text=data.get(\"text\", \"\"),\n                a2ui=data.get(\"a2ui\") or data.get(\"a2Ui\"),\n                tool_calls=data.get(\"tool_calls\") or data.get(\"toolCalls\"),\n                metadata=data.get(\"metadata\") or data.get(\"meta\"),\n            )\n\n    except httpx.ConnectError:\n        logger.warning(\"agent_service_unavailable url=%s\", AGENT_SERVICE_URL)\n        raise AgentServiceUnavailable(\"Cannot connect to agent service\")\n    except httpx.TimeoutException:\n        logger.warning(\"agent_service_timeout url=%s\", AGENT_SERVICE_URL)\n        raise AgentServiceUnavailable(\"Agent service timeout\")\n    except json.JSONDecodeError as e:\n        logger.error(\"agent_service_invalid_json error=%s\", str(e))\n        raise AgentServiceError(\"Invalid response from agent service\")\n\n\ndef health_check() -> Dict[str, Any]:\n    \"\"\"\n    Check agent service health.\n\n    Returns status and latency information.\n    \"\"\"\n    if not is_agent_service_configured():\n        return {\"status\": \"not_configured\", \"url\": None}\n\n    import time\n    start = time.time()\n\n    try:\n        with httpx.Client(timeout=5.0) as client:\n            response = client.get(f\"{AGENT_SERVICE_URL}/health\")\n            latency_ms = int((time.time() - start) * 1000)\n\n            if response.status_code == 200:\n                return {\n                    \"status\": \"healthy\",\n                    \"url\": AGENT_SERVICE_URL,\n                    \"latency_ms\": latency_ms,\n                }\n            else:\n                return {\n                    \"status\": \"unhealthy\",\n                    \"url\": AGENT_SERVICE_URL,\n                    \"status_code\": response.status_code,\n                }\n    except Exception as e:\n        return {\n            \"status\": \"unreachable\",\n            \"url\": AGENT_SERVICE_URL,\n            \"error\": str(e),\n        }\n","numLines":258,"startLine":1,"totalLines":258}}}
{"parentUuid":"e1b1252f-0157-40d1-9662-07dd9cbf9f9c","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_0145oHoCZnVbhGeR9t27uYXs","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me search for how these services are currently being used in the API layer to understand the data flow:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":25730,"cache_read_input_tokens":45112,"cache_creation":{"ephemeral_5m_input_tokens":25730,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrngQ65TUGxZWKp3UV5","type":"assistant","uuid":"523eb7fc-6b01-48f2-a13b-280f512691dd","timestamp":"2026-01-01T15:01:23.622Z"}
{"parentUuid":"523eb7fc-6b01-48f2-a13b-280f512691dd","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_0145oHoCZnVbhGeR9t27uYXs","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01PVdDegq3wVxxzm7xWXW9tH","name":"Grep","input":{"pattern":"from services import|import.*soul_os|import.*glm_client|import.*agent_service_client","type":"py","glob":"api/**/*.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":25730,"cache_read_input_tokens":45112,"cache_creation":{"ephemeral_5m_input_tokens":25730,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrngQ65TUGxZWKp3UV5","type":"assistant","uuid":"ac6783a1-3235-411c-b855-cc0e228bea36","timestamp":"2026-01-01T15:01:24.545Z"}
{"parentUuid":"ac6783a1-3235-411c-b855-cc0e228bea36","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_0145oHoCZnVbhGeR9t27uYXs","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01Y87on58p2NES9zM2ciAoaq","name":"Grep","input":{"pattern":"soul_os\\.|glm_client\\.|agent_service_client\\.","type":"py","path":"/home/aiscend/work/fortune_ai/api"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":25730,"cache_read_input_tokens":45112,"cache_creation":{"ephemeral_5m_input_tokens":25730,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrngQ65TUGxZWKp3UV5","type":"assistant","uuid":"79b74dfd-4cf0-4a68-8f74-31e5276c92fc","timestamp":"2026-01-01T15:01:25.044Z"}
{"parentUuid":"79b74dfd-4cf0-4a68-8f74-31e5276c92fc","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_0145oHoCZnVbhGeR9t27uYXs","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01SocVTstLkh6GuwFAAXHSvm","name":"Read","input":{"file_path":"/home/aiscend/work/fortune_ai/api/chat_routes.py","limit":150}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":25730,"cache_read_input_tokens":45112,"cache_creation":{"ephemeral_5m_input_tokens":25730,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrngQ65TUGxZWKp3UV5","type":"assistant","uuid":"d11440db-a2fe-4496-8d68-420b1801cedd","timestamp":"2026-01-01T15:01:25.282Z"}
{"parentUuid":"d11440db-a2fe-4496-8d68-420b1801cedd","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01SocVTstLkh6GuwFAAXHSvm","type":"tool_result","content":"     1→from __future__ import annotations\n     2→\n     3→import json\n     4→import os\n     5→import re\n     6→from string import Template\n     7→from typing import Any, Dict, List, Optional, Tuple\n     8→\n     9→from fastapi import APIRouter, Request, Query\n    10→from fastapi.responses import JSONResponse, StreamingResponse\n    11→from pydantic import BaseModel, Field\n    12→\n    13→from api.deps import require_auth, require_csrf\n    14→from common.a2ui import validate_a2ui\n    15→from services import chat_service\n    16→from services import glm_client\n    17→from services import bazi_facts\n    18→from services import kb_service\n    19→from services import agent_service_client\n    20→from services import soul_os\n    21→from services.chat_backend_config import default_chat_backend\n    22→from services.yunshi_service import yunshi_service, build_daily_yunshi_a2ui, build_annual_yunshi_a2ui\n    23→from stores import fortune_db\n    24→\n    25→\n    26→router = APIRouter(prefix=\"/api/chat\", tags=[\"chat\"])\n    27→\n    28→\n    29→def _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    30→    return JSONResponse({\"ok\": True, \"data\": data or {}})\n    31→\n    32→\n    33→def _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    34→    return JSONResponse(\n    35→        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n    36→        status_code=status,\n    37→    )\n    38→\n    39→\n    40→class ChatSendRequest(BaseModel):\n    41→    session_id: Optional[str] = Field(None)\n    42→    text: str = Field(..., min_length=1)\n    43→\n    44→\n    45→_UUID_RE = re.compile(r\"^[0-9a-fA-F-]{36}$\")\n    46→\n    47→\n    48→SYSTEM_PROMPT_TEMPLATE = Template(\"\"\"你是 Fortune AI 的对话 Agent，角色是积极心理学教练（Performance Coach）。\n    49→\n    50→【产品定位】\n    51→人生导航 / 陪伴 / 提升。系统和交互保持“有效而极简”。\n    52→\n    53→【你的优先级（不可逆）】\n    54→Coach > Teaching Assistant > Customer Support > Sales\n    55→\n    56→【硬性规则（必须遵守）】\n    57→1) 禁止恐吓、羞辱、宿命论断言；负面信息必须紧接“你可以做什么”的行动处方。\n    58→2) 禁止自行计算八字事实；只能基于提供的 facts + evidence 输出。\n    59→3) 每次输出必须包含：结论(conclusion) + 依据(why) + ≤3条处方(prescriptions) + 承诺邀请(commitment_ask)。\n    60→4) 时间窗口默认只给干预窗口（intervention）；forecast 只能条件句+低置信度。\n    61→5) 输出必须是 A2UI JSON，且第一组件必须是 markdown_text。\n    62→6) 必须给出可点击 actions（start_task / schedule_task / open_panel / opt_out）。\n    63→\n    64→【语言风格 persona_style】\n    65→standard：清晰、中性、专业\n    66→warm：共情、支持性（默认）\n    67→roast：轻毒舌但不羞辱、不对人格做负面定性\n    68→\n    69→【输入（系统已注入）】\n    70→persona_style: $persona_style\n    71→user_context: $user_context_json\n    72→facts: $facts_json\n    73→evidence: $evidence_json\n    74→\n    75→【输出（必须严格仅输出 JSON）】\n    76→返回 A2UI JSON，结构：\n    77→- meta.summary：一句话摘要\n    78→- ui_components[0]：markdown_text（必须，包含：结论要点/依据/处方/时间窗口/边界/承诺邀请）\n    79→- ui_components[1]：action_buttons（必须，按钮结构：{label, action:{type, ...}}）\n    80→\n    81→严格按以下字段名输出（不要用 content/actions/action_type/payload 等变体；不要代码块；不要额外文本）：\n    82→{\n    83→  \"meta\": {\"summary\": \"...\"},\n    84→  \"ui_components\": [\n    85→    {\"type\":\"markdown_text\",\"title\":\"教练回复\",\"data\":\"...markdown...\"},\n    86→    {\"type\":\"action_buttons\",\"title\":\"下一步\",\"data\":[\n    87→      {\"label\":\"开始（2-5分钟）\",\"action\":{\"type\":\"start_task\",\"task_id\":\"...\"}},\n    88→      {\"label\":\"加入今日计划\",\"action\":{\"type\":\"schedule_task\",\"task_id\":\"...\"}},\n    89→      {\"label\":\"打开功能区\",\"action\":{\"type\":\"open_panel\",\"panel\":\"bento\"}},\n    90→      {\"label\":\"先不需要\",\"action\":{\"type\":\"opt_out\"}}\n    91→    ]}\n    92→  ]\n    93→}\n    94→\"\"\")\n    95→\n    96→SYSTEM_PROMPT_STREAM_TEMPLATE = Template(\"\"\"你是 Fortune AI 的对话 Agent，角色是积极心理学教练（Performance Coach）。\n    97→\n    98→【产品定位】\n    99→人生导航 / 陪伴 / 提升。系统和交互保持“有效而极简”。\n   100→\n   101→【你的优先级（不可逆）】\n   102→Coach > Teaching Assistant > Customer Support > Sales\n   103→\n   104→【硬性规则（必须遵守）】\n   105→1) 禁止恐吓、羞辱、宿命论断言；负面信息必须紧接“你可以做什么”的行动处方。\n   106→2) 禁止自行计算八字事实；只能基于提供的 facts + evidence 输出。\n   107→3) 每次输出必须包含：结论(conclusion) + 依据(why) + ≤3条处方(prescriptions) + 承诺邀请(commitment_ask)。\n   108→4) 每条处方必须包含 if_then：如果____→那么____；并优先给 2–5 分钟可启动版本。\n   109→5) 只输出 Markdown 文本，不要 JSON/代码块/额外说明。\n   110→\n   111→【语言风格 persona_style】\n   112→standard：清晰、中性、专业\n   113→warm：共情、支持性（默认）\n   114→roast：轻毒舌但不羞辱、不对人格做负面定性\n   115→\n   116→【输入（系统已注入）】\n   117→persona_style: $persona_style\n   118→user_context: $user_context_json\n   119→facts: $facts_json\n   120→evidence: $evidence_json\n   121→\n   122→【输出（Markdown）】\n   123→用如下结构输出（标题可省略但必须包含“处方”一节）：\n   124→\n   125→结论：...\n   126→依据：...\n   127→处方：\n   128→1) ...（包含 if_then）\n   129→2) ...（包含 if_then）\n   130→3) ...（包含 if_then）\n   131→承诺邀请：...（一句话，邀请用户选择一个处方开始）\n   132→\"\"\")\n   133→\n   134→\n   135→def _load_user_context(user_id: int) -> Tuple[Dict[str, Any], Dict[str, Any], Dict[str, Any]]:\n   136→    profile = fortune_db.fetch_one(\n   137→        \"SELECT name, gender, birthday_local, tz_offset_hours, location FROM fortune_user WHERE user_id=%s AND deleted_at IS NULL\",\n   138→        (int(user_id),),\n   139→    ) or {}\n   140→    prefs = fortune_db.fetch_one(\n   141→        \"SELECT persona_style, push_enabled, push_time, quiet_hours_start, quiet_hours_end, chat_backend FROM fortune_user_preferences WHERE user_id=%s\",\n   142→        (int(user_id),),\n   143→    ) or {}\n   144→    snap = fortune_db.fetch_one(\n   145→        \"SELECT facts, facts_hash, compute_version FROM fortune_bazi_snapshot WHERE user_id=%s ORDER BY created_at DESC LIMIT 1\",\n   146→        (int(user_id),),\n   147→    ) or {}\n   148→    return profile, prefs, snap\n   149→\n   150→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"679bc30a-7b0a-4950-9ea8-f70518236c27","timestamp":"2026-01-01T15:01:25.486Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aiscend/work/fortune_ai/api/chat_routes.py","content":"from __future__ import annotations\n\nimport json\nimport os\nimport re\nfrom string import Template\nfrom typing import Any, Dict, List, Optional, Tuple\n\nfrom fastapi import APIRouter, Request, Query\nfrom fastapi.responses import JSONResponse, StreamingResponse\nfrom pydantic import BaseModel, Field\n\nfrom api.deps import require_auth, require_csrf\nfrom common.a2ui import validate_a2ui\nfrom services import chat_service\nfrom services import glm_client\nfrom services import bazi_facts\nfrom services import kb_service\nfrom services import agent_service_client\nfrom services import soul_os\nfrom services.chat_backend_config import default_chat_backend\nfrom services.yunshi_service import yunshi_service, build_daily_yunshi_a2ui, build_annual_yunshi_a2ui\nfrom stores import fortune_db\n\n\nrouter = APIRouter(prefix=\"/api/chat\", tags=[\"chat\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n\ndef _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    return JSONResponse(\n        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n        status_code=status,\n    )\n\n\nclass ChatSendRequest(BaseModel):\n    session_id: Optional[str] = Field(None)\n    text: str = Field(..., min_length=1)\n\n\n_UUID_RE = re.compile(r\"^[0-9a-fA-F-]{36}$\")\n\n\nSYSTEM_PROMPT_TEMPLATE = Template(\"\"\"你是 Fortune AI 的对话 Agent，角色是积极心理学教练（Performance Coach）。\n\n【产品定位】\n人生导航 / 陪伴 / 提升。系统和交互保持“有效而极简”。\n\n【你的优先级（不可逆）】\nCoach > Teaching Assistant > Customer Support > Sales\n\n【硬性规则（必须遵守）】\n1) 禁止恐吓、羞辱、宿命论断言；负面信息必须紧接“你可以做什么”的行动处方。\n2) 禁止自行计算八字事实；只能基于提供的 facts + evidence 输出。\n3) 每次输出必须包含：结论(conclusion) + 依据(why) + ≤3条处方(prescriptions) + 承诺邀请(commitment_ask)。\n4) 时间窗口默认只给干预窗口（intervention）；forecast 只能条件句+低置信度。\n5) 输出必须是 A2UI JSON，且第一组件必须是 markdown_text。\n6) 必须给出可点击 actions（start_task / schedule_task / open_panel / opt_out）。\n\n【语言风格 persona_style】\nstandard：清晰、中性、专业\nwarm：共情、支持性（默认）\nroast：轻毒舌但不羞辱、不对人格做负面定性\n\n【输入（系统已注入）】\npersona_style: $persona_style\nuser_context: $user_context_json\nfacts: $facts_json\nevidence: $evidence_json\n\n【输出（必须严格仅输出 JSON）】\n返回 A2UI JSON，结构：\n- meta.summary：一句话摘要\n- ui_components[0]：markdown_text（必须，包含：结论要点/依据/处方/时间窗口/边界/承诺邀请）\n- ui_components[1]：action_buttons（必须，按钮结构：{label, action:{type, ...}}）\n\n严格按以下字段名输出（不要用 content/actions/action_type/payload 等变体；不要代码块；不要额外文本）：\n{\n  \"meta\": {\"summary\": \"...\"},\n  \"ui_components\": [\n    {\"type\":\"markdown_text\",\"title\":\"教练回复\",\"data\":\"...markdown...\"},\n    {\"type\":\"action_buttons\",\"title\":\"下一步\",\"data\":[\n      {\"label\":\"开始（2-5分钟）\",\"action\":{\"type\":\"start_task\",\"task_id\":\"...\"}},\n      {\"label\":\"加入今日计划\",\"action\":{\"type\":\"schedule_task\",\"task_id\":\"...\"}},\n      {\"label\":\"打开功能区\",\"action\":{\"type\":\"open_panel\",\"panel\":\"bento\"}},\n      {\"label\":\"先不需要\",\"action\":{\"type\":\"opt_out\"}}\n    ]}\n  ]\n}\n\"\"\")\n\nSYSTEM_PROMPT_STREAM_TEMPLATE = Template(\"\"\"你是 Fortune AI 的对话 Agent，角色是积极心理学教练（Performance Coach）。\n\n【产品定位】\n人生导航 / 陪伴 / 提升。系统和交互保持“有效而极简”。\n\n【你的优先级（不可逆）】\nCoach > Teaching Assistant > Customer Support > Sales\n\n【硬性规则（必须遵守）】\n1) 禁止恐吓、羞辱、宿命论断言；负面信息必须紧接“你可以做什么”的行动处方。\n2) 禁止自行计算八字事实；只能基于提供的 facts + evidence 输出。\n3) 每次输出必须包含：结论(conclusion) + 依据(why) + ≤3条处方(prescriptions) + 承诺邀请(commitment_ask)。\n4) 每条处方必须包含 if_then：如果____→那么____；并优先给 2–5 分钟可启动版本。\n5) 只输出 Markdown 文本，不要 JSON/代码块/额外说明。\n\n【语言风格 persona_style】\nstandard：清晰、中性、专业\nwarm：共情、支持性（默认）\nroast：轻毒舌但不羞辱、不对人格做负面定性\n\n【输入（系统已注入）】\npersona_style: $persona_style\nuser_context: $user_context_json\nfacts: $facts_json\nevidence: $evidence_json\n\n【输出（Markdown）】\n用如下结构输出（标题可省略但必须包含“处方”一节）：\n\n结论：...\n依据：...\n处方：\n1) ...（包含 if_then）\n2) ...（包含 if_then）\n3) ...（包含 if_then）\n承诺邀请：...（一句话，邀请用户选择一个处方开始）\n\"\"\")\n\n\ndef _load_user_context(user_id: int) -> Tuple[Dict[str, Any], Dict[str, Any], Dict[str, Any]]:\n    profile = fortune_db.fetch_one(\n        \"SELECT name, gender, birthday_local, tz_offset_hours, location FROM fortune_user WHERE user_id=%s AND deleted_at IS NULL\",\n        (int(user_id),),\n    ) or {}\n    prefs = fortune_db.fetch_one(\n        \"SELECT persona_style, push_enabled, push_time, quiet_hours_start, quiet_hours_end, chat_backend FROM fortune_user_preferences WHERE user_id=%s\",\n        (int(user_id),),\n    ) or {}\n    snap = fortune_db.fetch_one(\n        \"SELECT facts, facts_hash, compute_version FROM fortune_bazi_snapshot WHERE user_id=%s ORDER BY created_at DESC LIMIT 1\",\n        (int(user_id),),\n    ) or {}\n    return profile, prefs, snap\n\n","numLines":150,"startLine":1,"totalLines":1106}}}
{"parentUuid":"679bc30a-7b0a-4950-9ea8-f70518236c27","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01PVdDegq3wVxxzm7xWXW9tH","type":"tool_result","content":"Found 19 files\napi/main.py\napi/dashboard_routes.py\napi/auth_routes.py\napi/chat_routes.py\napi/report_routes.py\napi/bento_routes.py\napi/user_routes.py\napi/reflection_routes.py\napi/goal_routes.py\napi/social_routes.py\napi/currency_routes.py\napi/jitai_routes.py\napi/agent_tool.py\napi/twin_routes.py\napi/plan_routes.py\napi/kb_routes.py\napi/bazi_routes.py\napi/session_routes.py\napi/deps.py"}]},"uuid":"8b709d36-ac89-4a9e-92b5-664c5681ca58","timestamp":"2026-01-01T15:01:26.274Z","toolUseResult":{"mode":"files_with_matches","filenames":["api/main.py","api/dashboard_routes.py","api/auth_routes.py","api/chat_routes.py","api/report_routes.py","api/bento_routes.py","api/user_routes.py","api/reflection_routes.py","api/goal_routes.py","api/social_routes.py","api/currency_routes.py","api/jitai_routes.py","api/agent_tool.py","api/twin_routes.py","api/plan_routes.py","api/kb_routes.py","api/bazi_routes.py","api/session_routes.py","api/deps.py"],"numFiles":19}}
{"parentUuid":"8b709d36-ac89-4a9e-92b5-664c5681ca58","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01Y87on58p2NES9zM2ciAoaq","type":"tool_result","content":"Found 2 files\napi/dashboard_routes.py\napi/chat_routes.py"}]},"uuid":"2242f3ed-469e-4047-907f-b721f1ec9a0e","timestamp":"2026-01-01T15:01:26.318Z","toolUseResult":{"mode":"files_with_matches","filenames":["api/dashboard_routes.py","api/chat_routes.py"],"numFiles":2}}
{"parentUuid":"2242f3ed-469e-4047-907f-b721f1ec9a0e","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_012NkLJfPfVqngpvsHLUr6CW","type":"message","role":"assistant","content":[{"type":"text","text":"Let me continue reading the chat_routes to see how these services are used:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2581,"cache_creation_input_tokens":929,"cache_read_input_tokens":70842,"cache_creation":{"ephemeral_5m_input_tokens":929,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgroAzYchkPo57zsY3LY","type":"assistant","uuid":"dbcb7df6-9511-4926-af90-633e93b6c146","timestamp":"2026-01-01T15:01:31.035Z"}
{"parentUuid":"dbcb7df6-9511-4926-af90-633e93b6c146","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_012NkLJfPfVqngpvsHLUr6CW","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01EsWJKUqqPP3Ffib5LTUrGB","name":"Read","input":{"file_path":"/home/aiscend/work/fortune_ai/api/chat_routes.py","offset":150,"limit":200}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2581,"cache_creation_input_tokens":929,"cache_read_input_tokens":70842,"cache_creation":{"ephemeral_5m_input_tokens":929,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgroAzYchkPo57zsY3LY","type":"assistant","uuid":"e970b904-856a-4d2f-90a2-bcf3db75a9ac","timestamp":"2026-01-01T15:01:31.143Z"}
{"parentUuid":"e970b904-856a-4d2f-90a2-bcf3db75a9ac","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_012NkLJfPfVqngpvsHLUr6CW","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01LrdaKsoiCRqYLaEtQEyyiW","name":"Grep","input":{"pattern":"def.*send|def.*stream|glm_client\\.|soul_os\\.|agent_service","type":"py","path":"/home/aiscend/work/fortune_ai/api/chat_routes.py","output_mode":"content","head_limit":60}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":2581,"cache_creation_input_tokens":929,"cache_read_input_tokens":70842,"cache_creation":{"ephemeral_5m_input_tokens":929,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgroAzYchkPo57zsY3LY","type":"assistant","uuid":"87fa7f6b-87b6-4933-abe6-95476630066a","timestamp":"2026-01-01T15:01:32.013Z"}
{"parentUuid":"87fa7f6b-87b6-4933-abe6-95476630066a","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01EsWJKUqqPP3Ffib5LTUrGB","type":"tool_result","content":"   150→\n   151→def _write_agent_run_log(\n   152→    user_id: int,\n   153→    session_id: Optional[str],\n   154→    agent_name: str,\n   155→    prompt_version: str,\n   156→    facts_hash: Optional[str],\n   157→    input_data: Dict[str, Any],\n   158→    output_data: Dict[str, Any],\n   159→    tool_calls: Optional[List[Dict[str, Any]]] = None,\n   160→    usage: Optional[Dict[str, Any]] = None,\n   161→    latency_ms: Optional[int] = None,\n   162→    error: Optional[str] = None,\n   163→) -> None:\n   164→    \"\"\"\n   165→    Write audit log to fortune_agent_run table.\n   166→\n   167→    REQ: REQ-AGENT-006 (Audit)\n   168→    \"\"\"\n   169→    try:\n   170→        fortune_db.execute(\n   171→            \"\"\"\n   172→            INSERT INTO fortune_agent_run (\n   173→                user_id, session_id, agent_name, prompt_version, facts_hash,\n   174→                input, output, tool_calls, usage, latency_ms, error, created_at\n   175→            ) VALUES (%s, %s::uuid, %s, %s, %s, %s::jsonb, %s::jsonb, %s::jsonb, %s::jsonb, %s, %s, now())\n   176→            \"\"\",\n   177→            [\n   178→                user_id,\n   179→                session_id if session_id else None,\n   180→                agent_name,\n   181→                prompt_version,\n   182→                facts_hash,\n   183→                json.dumps(input_data, ensure_ascii=False, default=str),\n   184→                json.dumps(output_data, ensure_ascii=False, default=str),\n   185→                json.dumps(tool_calls, ensure_ascii=False) if tool_calls else None,\n   186→                json.dumps(usage, ensure_ascii=False) if usage else None,\n   187→                latency_ms,\n   188→                error,\n   189→            ],\n   190→        )\n   191→    except Exception as e:\n   192→        # Log but don't fail the request\n   193→        import logging\n   194→        logging.getLogger(__name__).warning(\"Failed to write agent run log: %s\", str(e))\n   195→\n   196→\n   197→def _a2ui_from_text(text: str) -> Dict[str, Any]:\n   198→    raw = (text or \"\").strip()\n   199→    obj = glm_client.extract_json_object(raw)\n   200→    if isinstance(obj, dict):\n   201→        norm = _normalize_a2ui(obj)\n   202→        if isinstance(norm, dict):\n   203→            try:\n   204→                validate_a2ui(norm)\n   205→                return norm\n   206→            except Exception:\n   207→                pass\n   208→    # Fallback: wrap as markdown_text A2UI\n   209→    summary = raw.splitlines()[0].strip()[:120] if raw else \"输出\"\n   210→    return {\n   211→        \"meta\": {\"summary\": summary},\n   212→        \"ui_components\": [\n   213→            {\"type\": \"markdown_text\", \"title\": \"输出\", \"data\": raw or \"（空）\"},\n   214→            {\"type\": \"action_buttons\", \"title\": \"下一步\", \"data\": []},\n   215→        ],\n   216→    }\n   217→\n   218→\n   219→def _normalize_action(action: Dict[str, Any]) -> Dict[str, Any]:\n   220→    a = dict(action or {})\n   221→    # common variants\n   222→    if a.get(\"type\") == \"open_panel\" and \"panel\" not in a and \"panel_id\" in a:\n   223→        a[\"panel\"] = a.get(\"panel_id\")\n   224→    return a\n   225→\n   226→\n   227→def _normalize_action_button(btn: Any) -> Dict[str, Any]:\n   228→    if not isinstance(btn, dict):\n   229→        return {\"label\": str(btn), \"action\": {\"type\": \"opt_out\"}}\n   230→    label = str(btn.get(\"label\") or btn.get(\"text\") or \"下一步\")\n   231→    action = btn.get(\"action\")\n   232→    if isinstance(action, dict):\n   233→        a = _normalize_action(action)\n   234→        if not a.get(\"type\"):\n   235→            a[\"type\"] = \"opt_out\"\n   236→        return {\"label\": label, \"action\": a}\n   237→    action_type = btn.get(\"action_type\") or btn.get(\"type\") or \"opt_out\"\n   238→    payload = btn.get(\"payload\") if isinstance(btn.get(\"payload\"), dict) else {}\n   239→    a = {\"type\": str(action_type)}\n   240→    a.update(payload)\n   241→    return {\"label\": label, \"action\": _normalize_action(a)}\n   242→\n   243→\n   244→def _normalize_a2ui(obj: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n   245→    if not isinstance(obj, dict):\n   246→        return None\n   247→    meta = obj.get(\"meta\")\n   248→    if not isinstance(meta, dict):\n   249→        meta = {}\n   250→\n   251→    comps = obj.get(\"ui_components\")\n   252→    if not isinstance(comps, list):\n   253→        # tolerate alternative root key\n   254→        comps = obj.get(\"components\") if isinstance(obj.get(\"components\"), list) else []\n   255→\n   256→    out_comps: List[Dict[str, Any]] = []\n   257→    for c in comps:\n   258→        if not isinstance(c, dict):\n   259→            continue\n   260→        t = str(c.get(\"type\") or \"\").strip()\n   261→        if not t:\n   262→            continue\n   263→        title = str(c.get(\"title\") or (\"教练回复\" if t == \"markdown_text\" else \"下一步\" if t == \"action_buttons\" else \"组件\"))\n   264→        data = c.get(\"data\")\n   265→        if data is None and \"content\" in c:\n   266→            data = c.get(\"content\")\n   267→        if t == \"action_buttons\":\n   268→            if data is None and \"actions\" in c:\n   269→                data = c.get(\"actions\")\n   270→            if isinstance(data, list):\n   271→                data = [_normalize_action_button(b) for b in data]\n   272→            else:\n   273→                data = []\n   274→        if t == \"markdown_text\" and not isinstance(data, str):\n   275→            data = \"\" if data is None else str(data)\n   276→        out_comps.append({\"type\": t, \"title\": title, \"data\": data})\n   277→\n   278→    if not out_comps:\n   279→        return None\n   280→    # Ensure markdown_text is first component for renderer compatibility.\n   281→    for i, c in enumerate(out_comps):\n   282→        if c.get(\"type\") == \"markdown_text\":\n   283→            if i != 0:\n   284→                out_comps.insert(0, out_comps.pop(i))\n   285→            break\n   286→\n   287→    meta_out = dict(meta)\n   288→    if not isinstance(meta_out.get(\"summary\"), str):\n   289→        meta_out[\"summary\"] = str(meta_out.get(\"summary\") or \"\")\n   290→    return {\"meta\": meta_out, \"ui_components\": out_comps}\n   291→\n   292→\n   293→_PRES_LINE_RE = re.compile(r\"^\\s*\\d+[\\.\\)]\\s*(.+?)\\s*$\")\n   294→_BULLET_LINE_RE = re.compile(r\"^\\s*[-*]\\s*(.+?)\\s*$\")\n   295→_MD_INLINE_RE = re.compile(r\"[*_`]+\")\n   296→\n   297→# =============================================================================\n   298→# Intent Detection for Yunshi\n   299→# =============================================================================\n   300→\n   301→YUNSHI_DAILY_KEYWORDS = [\n   302→    \"今日运势\", \"今天运势\", \"今天的运势\", \"今日的运势\",\n   303→    \"今日运气\", \"今天运气\", \"今天如何\", \"今天怎么样\",\n   304→    \"今日吉凶\", \"今天吉凶\", \"运势如何\", \"运势怎么样\",\n   305→    \"每日运势\", \"日运\",\n   306→]\n   307→\n   308→YUNSHI_ANNUAL_KEYWORDS = [\n   309→    \"流年\", \"今年运势\", \"年运势\", \"今年运气\", \"明年运势\",\n   310→    \"年度运势\", \"今年如何\", \"今年怎么样\", \"年运\",\n   311→]\n   312→\n   313→def detect_yunshi_intent(text: str) -> Optional[str]:\n   314→    \"\"\"\n   315→    检测用户消息是否为运势查询意图\n   316→\n   317→    Returns:\n   318→        - \"daily\": 今日运势查询\n   319→        - \"annual\": 流年运势查询\n   320→        - None: 非运势查询\n   321→    \"\"\"\n   322→    t = (text or \"\").strip().lower()\n   323→    if not t:\n   324→        return None\n   325→\n   326→    for kw in YUNSHI_DAILY_KEYWORDS:\n   327→        if kw in t:\n   328→            return \"daily\"\n   329→\n   330→    for kw in YUNSHI_ANNUAL_KEYWORDS:\n   331→        if kw in t:\n   332→            return \"annual\"\n   333→\n   334→    return None\n   335→\n   336→\n   337→def handle_yunshi_intent(\n   338→    user_id: int,\n   339→    session_id: str,\n   340→    intent: str,\n   341→    user_text: str,\n   342→) -> Optional[Dict[str, Any]]:\n   343→    \"\"\"\n   344→    处理运势查询意图，返回 A2UI 格式响应\n   345→\n   346→    Returns:\n   347→        - Dict with a2ui, suggested_tasks, backend if handled\n   348→        - None if should fall through to LLM\n   349→    \"\"\"\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"26a6c7ad-59f2-4baa-bd19-03a20707cafb","timestamp":"2026-01-01T15:01:32.210Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aiscend/work/fortune_ai/api/chat_routes.py","content":"\ndef _write_agent_run_log(\n    user_id: int,\n    session_id: Optional[str],\n    agent_name: str,\n    prompt_version: str,\n    facts_hash: Optional[str],\n    input_data: Dict[str, Any],\n    output_data: Dict[str, Any],\n    tool_calls: Optional[List[Dict[str, Any]]] = None,\n    usage: Optional[Dict[str, Any]] = None,\n    latency_ms: Optional[int] = None,\n    error: Optional[str] = None,\n) -> None:\n    \"\"\"\n    Write audit log to fortune_agent_run table.\n\n    REQ: REQ-AGENT-006 (Audit)\n    \"\"\"\n    try:\n        fortune_db.execute(\n            \"\"\"\n            INSERT INTO fortune_agent_run (\n                user_id, session_id, agent_name, prompt_version, facts_hash,\n                input, output, tool_calls, usage, latency_ms, error, created_at\n            ) VALUES (%s, %s::uuid, %s, %s, %s, %s::jsonb, %s::jsonb, %s::jsonb, %s::jsonb, %s, %s, now())\n            \"\"\",\n            [\n                user_id,\n                session_id if session_id else None,\n                agent_name,\n                prompt_version,\n                facts_hash,\n                json.dumps(input_data, ensure_ascii=False, default=str),\n                json.dumps(output_data, ensure_ascii=False, default=str),\n                json.dumps(tool_calls, ensure_ascii=False) if tool_calls else None,\n                json.dumps(usage, ensure_ascii=False) if usage else None,\n                latency_ms,\n                error,\n            ],\n        )\n    except Exception as e:\n        # Log but don't fail the request\n        import logging\n        logging.getLogger(__name__).warning(\"Failed to write agent run log: %s\", str(e))\n\n\ndef _a2ui_from_text(text: str) -> Dict[str, Any]:\n    raw = (text or \"\").strip()\n    obj = glm_client.extract_json_object(raw)\n    if isinstance(obj, dict):\n        norm = _normalize_a2ui(obj)\n        if isinstance(norm, dict):\n            try:\n                validate_a2ui(norm)\n                return norm\n            except Exception:\n                pass\n    # Fallback: wrap as markdown_text A2UI\n    summary = raw.splitlines()[0].strip()[:120] if raw else \"输出\"\n    return {\n        \"meta\": {\"summary\": summary},\n        \"ui_components\": [\n            {\"type\": \"markdown_text\", \"title\": \"输出\", \"data\": raw or \"（空）\"},\n            {\"type\": \"action_buttons\", \"title\": \"下一步\", \"data\": []},\n        ],\n    }\n\n\ndef _normalize_action(action: Dict[str, Any]) -> Dict[str, Any]:\n    a = dict(action or {})\n    # common variants\n    if a.get(\"type\") == \"open_panel\" and \"panel\" not in a and \"panel_id\" in a:\n        a[\"panel\"] = a.get(\"panel_id\")\n    return a\n\n\ndef _normalize_action_button(btn: Any) -> Dict[str, Any]:\n    if not isinstance(btn, dict):\n        return {\"label\": str(btn), \"action\": {\"type\": \"opt_out\"}}\n    label = str(btn.get(\"label\") or btn.get(\"text\") or \"下一步\")\n    action = btn.get(\"action\")\n    if isinstance(action, dict):\n        a = _normalize_action(action)\n        if not a.get(\"type\"):\n            a[\"type\"] = \"opt_out\"\n        return {\"label\": label, \"action\": a}\n    action_type = btn.get(\"action_type\") or btn.get(\"type\") or \"opt_out\"\n    payload = btn.get(\"payload\") if isinstance(btn.get(\"payload\"), dict) else {}\n    a = {\"type\": str(action_type)}\n    a.update(payload)\n    return {\"label\": label, \"action\": _normalize_action(a)}\n\n\ndef _normalize_a2ui(obj: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n    if not isinstance(obj, dict):\n        return None\n    meta = obj.get(\"meta\")\n    if not isinstance(meta, dict):\n        meta = {}\n\n    comps = obj.get(\"ui_components\")\n    if not isinstance(comps, list):\n        # tolerate alternative root key\n        comps = obj.get(\"components\") if isinstance(obj.get(\"components\"), list) else []\n\n    out_comps: List[Dict[str, Any]] = []\n    for c in comps:\n        if not isinstance(c, dict):\n            continue\n        t = str(c.get(\"type\") or \"\").strip()\n        if not t:\n            continue\n        title = str(c.get(\"title\") or (\"教练回复\" if t == \"markdown_text\" else \"下一步\" if t == \"action_buttons\" else \"组件\"))\n        data = c.get(\"data\")\n        if data is None and \"content\" in c:\n            data = c.get(\"content\")\n        if t == \"action_buttons\":\n            if data is None and \"actions\" in c:\n                data = c.get(\"actions\")\n            if isinstance(data, list):\n                data = [_normalize_action_button(b) for b in data]\n            else:\n                data = []\n        if t == \"markdown_text\" and not isinstance(data, str):\n            data = \"\" if data is None else str(data)\n        out_comps.append({\"type\": t, \"title\": title, \"data\": data})\n\n    if not out_comps:\n        return None\n    # Ensure markdown_text is first component for renderer compatibility.\n    for i, c in enumerate(out_comps):\n        if c.get(\"type\") == \"markdown_text\":\n            if i != 0:\n                out_comps.insert(0, out_comps.pop(i))\n            break\n\n    meta_out = dict(meta)\n    if not isinstance(meta_out.get(\"summary\"), str):\n        meta_out[\"summary\"] = str(meta_out.get(\"summary\") or \"\")\n    return {\"meta\": meta_out, \"ui_components\": out_comps}\n\n\n_PRES_LINE_RE = re.compile(r\"^\\s*\\d+[\\.\\)]\\s*(.+?)\\s*$\")\n_BULLET_LINE_RE = re.compile(r\"^\\s*[-*]\\s*(.+?)\\s*$\")\n_MD_INLINE_RE = re.compile(r\"[*_`]+\")\n\n# =============================================================================\n# Intent Detection for Yunshi\n# =============================================================================\n\nYUNSHI_DAILY_KEYWORDS = [\n    \"今日运势\", \"今天运势\", \"今天的运势\", \"今日的运势\",\n    \"今日运气\", \"今天运气\", \"今天如何\", \"今天怎么样\",\n    \"今日吉凶\", \"今天吉凶\", \"运势如何\", \"运势怎么样\",\n    \"每日运势\", \"日运\",\n]\n\nYUNSHI_ANNUAL_KEYWORDS = [\n    \"流年\", \"今年运势\", \"年运势\", \"今年运气\", \"明年运势\",\n    \"年度运势\", \"今年如何\", \"今年怎么样\", \"年运\",\n]\n\ndef detect_yunshi_intent(text: str) -> Optional[str]:\n    \"\"\"\n    检测用户消息是否为运势查询意图\n\n    Returns:\n        - \"daily\": 今日运势查询\n        - \"annual\": 流年运势查询\n        - None: 非运势查询\n    \"\"\"\n    t = (text or \"\").strip().lower()\n    if not t:\n        return None\n\n    for kw in YUNSHI_DAILY_KEYWORDS:\n        if kw in t:\n            return \"daily\"\n\n    for kw in YUNSHI_ANNUAL_KEYWORDS:\n        if kw in t:\n            return \"annual\"\n\n    return None\n\n\ndef handle_yunshi_intent(\n    user_id: int,\n    session_id: str,\n    intent: str,\n    user_text: str,\n) -> Optional[Dict[str, Any]]:\n    \"\"\"\n    处理运势查询意图，返回 A2UI 格式响应\n\n    Returns:\n        - Dict with a2ui, suggested_tasks, backend if handled\n        - None if should fall through to LLM\n    \"\"\"","numLines":200,"startLine":150,"totalLines":1106}}}
{"parentUuid":"26a6c7ad-59f2-4baa-bd19-03a20707cafb","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01LrdaKsoiCRqYLaEtQEyyiW","type":"tool_result","content":"19:from services import agent_service_client\n199:    obj = glm_client.extract_json_object(raw)\n505:def chat_send(req: ChatSendRequest, request: Request):\n511:    - agent_service: Vercel AI SDK orchestration (future)\n547:    full_context = soul_os.get_full_context_for_chat(user_id, user_text)\n614:    if chat_backend == \"agent_service\":\n621:            agent_response = agent_service_client.call_agent_service_sync(\n643:                model=\"agent_service\",\n652:                prompt_version=\"agent_service\",\n654:                input_data={\"user_text\": user_text, \"backend\": \"agent_service\"},\n664:                    \"backend\": \"agent_service\",\n668:        except agent_service_client.AgentServiceUnavailable:\n671:        except agent_service_client.AgentServiceError as e:\n678:                prompt_version=\"agent_service\",\n680:                input_data={\"user_text\": user_text, \"backend\": \"agent_service\"},\n719:        raw_text, raw = glm_client.call_chat_completions(messages=llm_messages)\n720:    except glm_client.GlmError as e:\n787:def chat_stream(\n832:    full_context = soul_os.get_full_context_for_chat(user_id, user_text)\n933:        # Stream from agent_service when selected and available\n934:        if preferred_backend == \"agent_service\":\n937:                if not agent_service_client.is_agent_service_configured():\n938:                    raise agent_service_client.AgentServiceUnavailable(\"Agent service not configured\")\n950:                    \"Authorization\": f\"Bearer {agent_service_client.AGENT_SERVICE_TOKEN}\",\n953:                with httpx.Client(timeout=agent_service_client.AGENT_SERVICE_TIMEOUT) as client:\n954:                    with client.stream(\"POST\", f\"{agent_service_client.AGENT_SERVICE_URL}/api/chat\", json=payload, headers=headers) as resp:\n956:                            raise agent_service_client.AgentServiceUnavailable(\"Agent service temporarily unavailable\")\n958:                            raise agent_service_client.AgentServiceError(f\"Agent service error: {resp.status_code}\")\n988:        if backend_used != \"agent_service\":\n1011:                for delta in glm_client.stream_chat_completions(messages=llm_messages):\n1018:                    raw_text, _raw = glm_client.call_chat_completions(messages=llm_messages)\n1025:            except glm_client.GlmError as e:\n1028:                    raw_text, _raw = glm_client.call_chat_completions(messages=llm_messages)\n1035:                except glm_client.GlmError:\n1066:            model=(\"agent_service\" if backend_used == \"agent_service\" else model_name),\n1074:            prompt_version=(\"agent_service-stream\" if backend_used == \"agent_service\" else \"v1.0-stream\"),\n\n[Showing results with pagination = limit: 60, offset: 0]"}]},"uuid":"5ef5dbb1-7ba0-4c7a-afac-b7bdb2a9a051","timestamp":"2026-01-01T15:01:33.050Z","toolUseResult":{"mode":"content","numFiles":0,"filenames":[],"content":"19:from services import agent_service_client\n199:    obj = glm_client.extract_json_object(raw)\n505:def chat_send(req: ChatSendRequest, request: Request):\n511:    - agent_service: Vercel AI SDK orchestration (future)\n547:    full_context = soul_os.get_full_context_for_chat(user_id, user_text)\n614:    if chat_backend == \"agent_service\":\n621:            agent_response = agent_service_client.call_agent_service_sync(\n643:                model=\"agent_service\",\n652:                prompt_version=\"agent_service\",\n654:                input_data={\"user_text\": user_text, \"backend\": \"agent_service\"},\n664:                    \"backend\": \"agent_service\",\n668:        except agent_service_client.AgentServiceUnavailable:\n671:        except agent_service_client.AgentServiceError as e:\n678:                prompt_version=\"agent_service\",\n680:                input_data={\"user_text\": user_text, \"backend\": \"agent_service\"},\n719:        raw_text, raw = glm_client.call_chat_completions(messages=llm_messages)\n720:    except glm_client.GlmError as e:\n787:def chat_stream(\n832:    full_context = soul_os.get_full_context_for_chat(user_id, user_text)\n933:        # Stream from agent_service when selected and available\n934:        if preferred_backend == \"agent_service\":\n937:                if not agent_service_client.is_agent_service_configured():\n938:                    raise agent_service_client.AgentServiceUnavailable(\"Agent service not configured\")\n950:                    \"Authorization\": f\"Bearer {agent_service_client.AGENT_SERVICE_TOKEN}\",\n953:                with httpx.Client(timeout=agent_service_client.AGENT_SERVICE_TIMEOUT) as client:\n954:                    with client.stream(\"POST\", f\"{agent_service_client.AGENT_SERVICE_URL}/api/chat\", json=payload, headers=headers) as resp:\n956:                            raise agent_service_client.AgentServiceUnavailable(\"Agent service temporarily unavailable\")\n958:                            raise agent_service_client.AgentServiceError(f\"Agent service error: {resp.status_code}\")\n988:        if backend_used != \"agent_service\":\n1011:                for delta in glm_client.stream_chat_completions(messages=llm_messages):\n1018:                    raw_text, _raw = glm_client.call_chat_completions(messages=llm_messages)\n1025:            except glm_client.GlmError as e:\n1028:                    raw_text, _raw = glm_client.call_chat_completions(messages=llm_messages)\n1035:                except glm_client.GlmError:\n1066:            model=(\"agent_service\" if backend_used == \"agent_service\" else model_name),\n1074:            prompt_version=(\"agent_service-stream\" if backend_used == \"agent_service\" else \"v1.0-stream\"),","numLines":36,"appliedLimit":60}}
{"parentUuid":"5ef5dbb1-7ba0-4c7a-afac-b7bdb2a9a051","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01WGH5csB1EjyF2gaoRqS3ju","type":"message","role":"assistant","content":[{"type":"text","text":"Perfect! Now let me look at how the context is built and see the complete flow. Let me also check the llm_client to understand the bigger picture:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":6692,"cache_read_input_tokens":71771,"cache_creation":{"ephemeral_5m_input_tokens":6692,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgroj85EJWLo1umh425i","type":"assistant","uuid":"6f64d53d-4205-4efc-8ceb-e5a930f138bc","timestamp":"2026-01-01T15:01:38.270Z"}
{"parentUuid":"6f64d53d-4205-4efc-8ceb-e5a930f138bc","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01WGH5csB1EjyF2gaoRqS3ju","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_012xdtTbJ4aH2hy7HzNm3aEn","name":"Read","input":{"file_path":"/home/aiscend/work/fortune_ai/services/llm_client.py","limit":100}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":6692,"cache_read_input_tokens":71771,"cache_creation":{"ephemeral_5m_input_tokens":6692,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgroj85EJWLo1umh425i","type":"assistant","uuid":"ea46111c-aadf-444b-8479-f6e86a3636fd","timestamp":"2026-01-01T15:01:38.686Z"}
{"parentUuid":"ea46111c-aadf-444b-8479-f6e86a3636fd","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01WGH5csB1EjyF2gaoRqS3ju","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_017f5oKvnH2dSaK8vBYE9Pp2","name":"Read","input":{"file_path":"/home/aiscend/work/fortune_ai/api/chat_routes.py","offset":500,"limit":120}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":6692,"cache_read_input_tokens":71771,"cache_creation":{"ephemeral_5m_input_tokens":6692,"ephemeral_1h_input_tokens":0},"output_tokens":213,"service_tier":"standard"}},"requestId":"req_011CWgroj85EJWLo1umh425i","type":"assistant","uuid":"a451e343-27b6-42ea-8281-65816cee71e3","timestamp":"2026-01-01T15:01:39.055Z"}
{"parentUuid":"a451e343-27b6-42ea-8281-65816cee71e3","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_012xdtTbJ4aH2hy7HzNm3aEn","type":"tool_result","content":"     1→import os\n     2→from typing import Optional\n     3→\n     4→import httpx\n     5→\n     6→\n     7→class LLMError(Exception):\n     8→    pass\n     9→\n    10→\n    11→def call_standard(prompt: str, timeout_s: Optional[float] = None) -> str:\n    12→    \"\"\"Call external 'standard' LLM endpoint if configured, else return fallback markdown.\n    13→\n    14→    Env:\n    15→      - LLM_STANDARD_ENDPOINT: full URL to POST JSON {model:'standard', prompt:<str>}\n    16→      - LLM_STANDARD_API_KEY: optional bearer token\n    17→      - LLM_TIMEOUT: optional seconds\n    18→    \"\"\"\n    19→    endpoint = os.getenv(\"LLM_STANDARD_ENDPOINT\")\n    20→    api_key = os.getenv(\"LLM_STANDARD_API_KEY\")\n    21→    if timeout_s is None:\n    22→        try:\n    23→            timeout_s = float(os.getenv(\"LLM_TIMEOUT\", \"30\"))\n    24→        except Exception:\n    25→            timeout_s = 30.0\n    26→\n    27→    if not endpoint:\n    28→        raise LLMError(\"missing_env:LLM_STANDARD_ENDPOINT\")\n    29→\n    30→    headers = {\"Content-Type\": \"application/json\"}\n    31→    if api_key:\n    32→        headers[\"Authorization\"] = f\"Bearer {api_key}\"\n    33→    payload = {\"model\": \"standard\", \"prompt\": prompt}\n    34→    try:\n    35→        with httpx.Client(timeout=timeout_s) as client:\n    36→            resp = client.post(endpoint, json=payload, headers=headers)\n    37→            resp.raise_for_status()\n    38→            data = resp.json()\n    39→            # Accept common shapes\n    40→            if isinstance(data, dict):\n    41→                if \"text\" in data and isinstance(data[\"text\"], str):\n    42→                    return data[\"text\"]\n    43→                if \"content\" in data and isinstance(data[\"content\"], str):\n    44→                    return data[\"content\"]\n    45→                if \"choices\" in data and data[\"choices\"]:\n    46→                    first = data[\"choices\"][0]\n    47→                    if isinstance(first, dict):\n    48→                        for key in (\"text\", \"message\", \"content\"):\n    49→                            val = first.get(key)\n    50→                            if isinstance(val, str):\n    51→                                return val\n    52→            raise LLMError(\"unexpected LLM response shape\")\n    53→    except Exception as e:\n    54→        raise LLMError(str(e))\n    55→\n    56→\n    57→def markdown_to_a2ui(md_text: str) -> dict:\n    58→    summary = md_text.strip().splitlines()\n    59→    # take first non-empty line as summary, truncate\n    60→    first = next((ln for ln in summary if ln.strip()), \"\")[:120]\n    61→    return {\n    62→        \"meta\": {\"score\": 0, \"summary\": first},\n    63→        \"ui_components\": [\n    64→            {\"type\": \"markdown_text\", \"title\": \"八字解读（原典）\", \"data\": md_text}\n    65→        ],\n    66→    }\n    67→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"7f5ec847-d68b-49a0-bddb-2378a6312558","timestamp":"2026-01-01T15:01:39.224Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aiscend/work/fortune_ai/services/llm_client.py","content":"import os\nfrom typing import Optional\n\nimport httpx\n\n\nclass LLMError(Exception):\n    pass\n\n\ndef call_standard(prompt: str, timeout_s: Optional[float] = None) -> str:\n    \"\"\"Call external 'standard' LLM endpoint if configured, else return fallback markdown.\n\n    Env:\n      - LLM_STANDARD_ENDPOINT: full URL to POST JSON {model:'standard', prompt:<str>}\n      - LLM_STANDARD_API_KEY: optional bearer token\n      - LLM_TIMEOUT: optional seconds\n    \"\"\"\n    endpoint = os.getenv(\"LLM_STANDARD_ENDPOINT\")\n    api_key = os.getenv(\"LLM_STANDARD_API_KEY\")\n    if timeout_s is None:\n        try:\n            timeout_s = float(os.getenv(\"LLM_TIMEOUT\", \"30\"))\n        except Exception:\n            timeout_s = 30.0\n\n    if not endpoint:\n        raise LLMError(\"missing_env:LLM_STANDARD_ENDPOINT\")\n\n    headers = {\"Content-Type\": \"application/json\"}\n    if api_key:\n        headers[\"Authorization\"] = f\"Bearer {api_key}\"\n    payload = {\"model\": \"standard\", \"prompt\": prompt}\n    try:\n        with httpx.Client(timeout=timeout_s) as client:\n            resp = client.post(endpoint, json=payload, headers=headers)\n            resp.raise_for_status()\n            data = resp.json()\n            # Accept common shapes\n            if isinstance(data, dict):\n                if \"text\" in data and isinstance(data[\"text\"], str):\n                    return data[\"text\"]\n                if \"content\" in data and isinstance(data[\"content\"], str):\n                    return data[\"content\"]\n                if \"choices\" in data and data[\"choices\"]:\n                    first = data[\"choices\"][0]\n                    if isinstance(first, dict):\n                        for key in (\"text\", \"message\", \"content\"):\n                            val = first.get(key)\n                            if isinstance(val, str):\n                                return val\n            raise LLMError(\"unexpected LLM response shape\")\n    except Exception as e:\n        raise LLMError(str(e))\n\n\ndef markdown_to_a2ui(md_text: str) -> dict:\n    summary = md_text.strip().splitlines()\n    # take first non-empty line as summary, truncate\n    first = next((ln for ln in summary if ln.strip()), \"\")[:120]\n    return {\n        \"meta\": {\"score\": 0, \"summary\": first},\n        \"ui_components\": [\n            {\"type\": \"markdown_text\", \"title\": \"八字解读（原典）\", \"data\": md_text}\n        ],\n    }\n","numLines":67,"startLine":1,"totalLines":67}}}
{"parentUuid":"7f5ec847-d68b-49a0-bddb-2378a6312558","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_017f5oKvnH2dSaK8vBYE9Pp2","type":"tool_result","content":"   500→            return first[\"data\"]\n   501→    return json.dumps(a2ui, ensure_ascii=False)\n   502→\n   503→\n   504→@router.post(\"/send\")\n   505→def chat_send(req: ChatSendRequest, request: Request):\n   506→    \"\"\"\n   507→    Send a chat message and get AI response.\n   508→\n   509→    Supports two backends based on user preference:\n   510→    - fastapi: Direct LLM call (default, current implementation)\n   511→    - agent_service: Vercel AI SDK orchestration (future)\n   512→\n   513→    Also writes audit log to fortune_agent_run for compliance.\n   514→    \"\"\"\n   515→    import time as time_module\n   516→\n   517→    auth = require_auth(request)\n   518→    require_csrf(request, auth)\n   519→    user_id = int(auth[\"user_id\"])\n   520→\n   521→    session_id = (req.session_id or \"\").strip()\n   522→    if session_id and not _UUID_RE.match(session_id):\n   523→        return _err(400, \"invalid_request\", \"invalid_session_id\")\n   524→\n   525→    if not session_id:\n   526→        s = chat_service.create_session(user_id, title=\"\")\n   527→        session_id = s[\"session_id\"]\n   528→    else:\n   529→        if not chat_service.get_session(user_id, session_id):\n   530→            return _err(404, \"not_found\", \"session_not_found\")\n   531→\n   532→    user_text = req.text.strip()\n   533→    if not user_text:\n   534→        return _err(400, \"invalid_request\", \"empty_text\")\n   535→\n   536→    model_name = (os.getenv(\"FORTUNE_AI_GLM_MODEL\") or \"glm-4.7\").strip()\n   537→\n   538→    # Save user message\n   539→    chat_service.append_message(session_id=session_id, user_id=user_id, role=\"user\", content=user_text, model=model_name)\n   540→    chat_service.set_title_if_empty(session_id, user_text[:24])\n   541→\n   542→    profile, prefs, snap = _load_user_context(user_id)\n   543→    if not snap or not snap.get(\"facts\") or not snap.get(\"facts_hash\"):\n   544→        snap = bazi_facts.ensure_snapshot_for_user(user_id)\n   545→\n   546→    # 使用 soul_os 获取完整上下文\n   547→    full_context = soul_os.get_full_context_for_chat(user_id, user_text)\n   548→\n   549→    # 反依赖检查\n   550→    anti_dep = full_context.get(\"anti_dependency\", {})\n   551→    if anti_dep.get(\"should_intervene\"):\n   552→        # 返回反依赖干预消息\n   553→        intervention_msg = anti_dep.get(\"intervention_message\", \"\")\n   554→        a2ui = {\n   555→            \"meta\": {\"summary\": \"让我们先行动起来\"},\n   556→            \"ui_components\": [\n   557→                {\"type\": \"markdown_text\", \"title\": \"教练提醒\", \"data\": intervention_msg},\n   558→                {\"type\": \"action_buttons\", \"title\": \"下一步\", \"data\": [\n   559→                    {\"label\": \"好的，我去做\", \"action\": {\"type\": \"opt_out\"}},\n   560→                    {\"label\": \"打开任务\", \"action\": {\"type\": \"open_panel\", \"panel\": \"tasks\"}},\n   561→                ]},\n   562→            ],\n   563→        }\n   564→        chat_service.append_message(\n   565→            session_id=session_id,\n   566→            user_id=user_id,\n   567→            role=\"assistant\",\n   568→            content=intervention_msg,\n   569→            a2ui=a2ui,\n   570→            model=\"anti_dependency\",\n   571→        )\n   572→        return _ok({\n   573→            \"session_id\": session_id,\n   574→            \"assistant_message\": {\"role\": \"assistant\", \"a2ui\": a2ui},\n   575→            \"suggested_tasks\": [],\n   576→            \"backend\": \"anti_dependency\",\n   577→            \"intervention_type\": anti_dep.get(\"intervention_type\", \"\"),\n   578→        })\n   579→\n   580→    # ==========================================================================\n   581→    # 运势意图检测 - 优先于 LLM 调用\n   582→    # ==========================================================================\n   583→    yunshi_intent = detect_yunshi_intent(user_text)\n   584→    if yunshi_intent:\n   585→        yunshi_response = handle_yunshi_intent(user_id, session_id, yunshi_intent, user_text)\n   586→        if yunshi_response:\n   587→            a2ui = yunshi_response[\"a2ui\"]\n   588→            md = yunshi_response.get(\"content\", \"\")\n   589→            suggested_tasks = yunshi_response.get(\"suggested_tasks\", [])\n   590→\n   591→            chat_service.append_message(\n   592→                session_id=session_id,\n   593→                user_id=user_id,\n   594→                role=\"assistant\",\n   595→                content=md,\n   596→                a2ui=a2ui,\n   597→                model=\"yunshi\",\n   598→            )\n   599→\n   600→            return _ok({\n   601→                \"session_id\": session_id,\n   602→                \"assistant_message\": {\"role\": \"assistant\", \"a2ui\": a2ui},\n   603→                \"suggested_tasks\": suggested_tasks,\n   604→                \"backend\": \"yunshi\",\n   605→            })\n   606→\n   607→    # Check chat backend preference\n   608→    chat_backend = str(prefs.get(\"chat_backend\") or default_chat_backend())\n   609→    start_time = time_module.time()\n   610→    persona_style = full_context.get(\"persona_style\", \"warm\")\n   611→    facts_obj = snap.get(\"facts\") or {}\n   612→    facts_hash = str(snap.get(\"facts_hash\") or \"\")\n   613→\n   614→    if chat_backend == \"agent_service\":\n   615→        # Try Agent Service backend\n   616→        try:\n   617→            # Build messages for agent service\n   618→            hist = chat_service.get_recent_messages_for_llm(user_id, session_id, limit=10)\n   619→            agent_messages = [{\"role\": m.get(\"role\", \"user\"), \"content\": str(m.get(\"content\") or \"\")} for m in hist]\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"622a0295-2dbe-4fbc-b513-fdbca363afb8","timestamp":"2026-01-01T15:01:39.224Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aiscend/work/fortune_ai/api/chat_routes.py","content":"            return first[\"data\"]\n    return json.dumps(a2ui, ensure_ascii=False)\n\n\n@router.post(\"/send\")\ndef chat_send(req: ChatSendRequest, request: Request):\n    \"\"\"\n    Send a chat message and get AI response.\n\n    Supports two backends based on user preference:\n    - fastapi: Direct LLM call (default, current implementation)\n    - agent_service: Vercel AI SDK orchestration (future)\n\n    Also writes audit log to fortune_agent_run for compliance.\n    \"\"\"\n    import time as time_module\n\n    auth = require_auth(request)\n    require_csrf(request, auth)\n    user_id = int(auth[\"user_id\"])\n\n    session_id = (req.session_id or \"\").strip()\n    if session_id and not _UUID_RE.match(session_id):\n        return _err(400, \"invalid_request\", \"invalid_session_id\")\n\n    if not session_id:\n        s = chat_service.create_session(user_id, title=\"\")\n        session_id = s[\"session_id\"]\n    else:\n        if not chat_service.get_session(user_id, session_id):\n            return _err(404, \"not_found\", \"session_not_found\")\n\n    user_text = req.text.strip()\n    if not user_text:\n        return _err(400, \"invalid_request\", \"empty_text\")\n\n    model_name = (os.getenv(\"FORTUNE_AI_GLM_MODEL\") or \"glm-4.7\").strip()\n\n    # Save user message\n    chat_service.append_message(session_id=session_id, user_id=user_id, role=\"user\", content=user_text, model=model_name)\n    chat_service.set_title_if_empty(session_id, user_text[:24])\n\n    profile, prefs, snap = _load_user_context(user_id)\n    if not snap or not snap.get(\"facts\") or not snap.get(\"facts_hash\"):\n        snap = bazi_facts.ensure_snapshot_for_user(user_id)\n\n    # 使用 soul_os 获取完整上下文\n    full_context = soul_os.get_full_context_for_chat(user_id, user_text)\n\n    # 反依赖检查\n    anti_dep = full_context.get(\"anti_dependency\", {})\n    if anti_dep.get(\"should_intervene\"):\n        # 返回反依赖干预消息\n        intervention_msg = anti_dep.get(\"intervention_message\", \"\")\n        a2ui = {\n            \"meta\": {\"summary\": \"让我们先行动起来\"},\n            \"ui_components\": [\n                {\"type\": \"markdown_text\", \"title\": \"教练提醒\", \"data\": intervention_msg},\n                {\"type\": \"action_buttons\", \"title\": \"下一步\", \"data\": [\n                    {\"label\": \"好的，我去做\", \"action\": {\"type\": \"opt_out\"}},\n                    {\"label\": \"打开任务\", \"action\": {\"type\": \"open_panel\", \"panel\": \"tasks\"}},\n                ]},\n            ],\n        }\n        chat_service.append_message(\n            session_id=session_id,\n            user_id=user_id,\n            role=\"assistant\",\n            content=intervention_msg,\n            a2ui=a2ui,\n            model=\"anti_dependency\",\n        )\n        return _ok({\n            \"session_id\": session_id,\n            \"assistant_message\": {\"role\": \"assistant\", \"a2ui\": a2ui},\n            \"suggested_tasks\": [],\n            \"backend\": \"anti_dependency\",\n            \"intervention_type\": anti_dep.get(\"intervention_type\", \"\"),\n        })\n\n    # ==========================================================================\n    # 运势意图检测 - 优先于 LLM 调用\n    # ==========================================================================\n    yunshi_intent = detect_yunshi_intent(user_text)\n    if yunshi_intent:\n        yunshi_response = handle_yunshi_intent(user_id, session_id, yunshi_intent, user_text)\n        if yunshi_response:\n            a2ui = yunshi_response[\"a2ui\"]\n            md = yunshi_response.get(\"content\", \"\")\n            suggested_tasks = yunshi_response.get(\"suggested_tasks\", [])\n\n            chat_service.append_message(\n                session_id=session_id,\n                user_id=user_id,\n                role=\"assistant\",\n                content=md,\n                a2ui=a2ui,\n                model=\"yunshi\",\n            )\n\n            return _ok({\n                \"session_id\": session_id,\n                \"assistant_message\": {\"role\": \"assistant\", \"a2ui\": a2ui},\n                \"suggested_tasks\": suggested_tasks,\n                \"backend\": \"yunshi\",\n            })\n\n    # Check chat backend preference\n    chat_backend = str(prefs.get(\"chat_backend\") or default_chat_backend())\n    start_time = time_module.time()\n    persona_style = full_context.get(\"persona_style\", \"warm\")\n    facts_obj = snap.get(\"facts\") or {}\n    facts_hash = str(snap.get(\"facts_hash\") or \"\")\n\n    if chat_backend == \"agent_service\":\n        # Try Agent Service backend\n        try:\n            # Build messages for agent service\n            hist = chat_service.get_recent_messages_for_llm(user_id, session_id, limit=10)\n            agent_messages = [{\"role\": m.get(\"role\", \"user\"), \"content\": str(m.get(\"content\") or \"\")} for m in hist]","numLines":120,"startLine":500,"totalLines":1106}}}
{"parentUuid":"622a0295-2dbe-4fbc-b513-fdbca363afb8","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_012dEAc25tgvotT8gJmm7uXX","type":"message","role":"assistant","content":[{"type":"text","text":"Excellent! I have all the information I need. Let me now create a comprehensive analysis document by reading a few more key files to understand the complete architecture:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":3467,"cache_read_input_tokens":78463,"cache_creation":{"ephemeral_5m_input_tokens":3467,"ephemeral_1h_input_tokens":0},"output_tokens":5,"service_tier":"standard"}},"requestId":"req_011CWgrpETvtuUs6S97oenaY","type":"assistant","uuid":"e173bcc3-c42d-4dce-8e2b-9af3dc9b6666","timestamp":"2026-01-01T15:01:44.358Z"}
{"parentUuid":"e173bcc3-c42d-4dce-8e2b-9af3dc9b6666","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_012dEAc25tgvotT8gJmm7uXX","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01DLKT32t2mFfzxybahnhLjh","name":"Bash","input":{"command":"find /home/aiscend/work/fortune_ai -name \"models\" -type d | head -5"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":6,"cache_creation_input_tokens":3467,"cache_read_input_tokens":78463,"cache_creation":{"ephemeral_5m_input_tokens":3467,"ephemeral_1h_input_tokens":0},"output_tokens":109,"service_tier":"standard"}},"requestId":"req_011CWgrpETvtuUs6S97oenaY","type":"assistant","uuid":"007e7543-76cc-4f97-b615-3b31eb99b3d7","timestamp":"2026-01-01T15:01:44.748Z"}
{"parentUuid":"007e7543-76cc-4f97-b615-3b31eb99b3d7","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01DLKT32t2mFfzxybahnhLjh","type":"tool_result","content":"/home/aiscend/work/fortune_ai/models","is_error":false}]},"uuid":"c7bd718b-0e39-4f86-9b66-077f7ea8def6","timestamp":"2026-01-01T15:01:45.208Z","toolUseResult":{"stdout":"/home/aiscend/work/fortune_ai/models","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"c7bd718b-0e39-4f86-9b66-077f7ea8def6","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01VSRXJbjUBVg2p64cC2N8B4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_014NQwQAnX8mi7U5yEm1BZSx","name":"Glob","input":{"pattern":"models/twin.py","path":"/home/aiscend/work/fortune_ai"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":171,"cache_read_input_tokens":81930,"cache_creation":{"ephemeral_5m_input_tokens":171,"ephemeral_1h_input_tokens":0},"output_tokens":26,"service_tier":"standard"}},"requestId":"req_011CWgrpeYXHCNodKuaXFUoD","type":"assistant","uuid":"4addba73-c97b-4620-ae20-3ee0c02690a9","timestamp":"2026-01-01T15:01:49.493Z"}
{"parentUuid":"4addba73-c97b-4620-ae20-3ee0c02690a9","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01VSRXJbjUBVg2p64cC2N8B4","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013C4MWFtJLKUvZZXbEPSnh1","name":"Read","input":{"file_path":"/home/aiscend/work/fortune_ai/models/twin.py","limit":80}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":4,"cache_creation_input_tokens":171,"cache_read_input_tokens":81930,"cache_creation":{"ephemeral_5m_input_tokens":171,"ephemeral_1h_input_tokens":0},"output_tokens":26,"service_tier":"standard"}},"requestId":"req_011CWgrpeYXHCNodKuaXFUoD","type":"assistant","uuid":"2571d8c7-da07-4c3f-9d82-4308cb7a25b6","timestamp":"2026-01-01T15:01:49.765Z"}
{"parentUuid":"2571d8c7-da07-4c3f-9d82-4308cb7a25b6","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013C4MWFtJLKUvZZXbEPSnh1","type":"tool_result","content":"     1→\"\"\"\n     2→Digital Twin Pydantic Models.\n     3→\n     4→REQ: REQ-TWIN-001, REQ-TWIN-002\n     5→Design: §5.1.1, §4.3.1\n     6→HOS-REF: §1.2\n     7→\"\"\"\n     8→\n     9→from __future__ import annotations\n    10→\n    11→from datetime import datetime\n    12→from enum import Enum\n    13→from typing import Any, Dict, List, Literal, Optional\n    14→\n    15→from pydantic import BaseModel, Field, field_validator, model_validator\n    16→\n    17→\n    18→class TwinLayer(str, Enum):\n    19→    \"\"\"Twin data layers.\"\"\"\n    20→    L1 = \"L1\"  # Metadata layer (static)\n    21→    L2 = \"L2\"  # Dynamic state layer\n    22→    L3 = \"L3\"  # Aggregated metrics\n    23→\n    24→\n    25→class DimensionScores(BaseModel):\n    26→    \"\"\"\n    27→    L3 aggregated dimension scores.\n    28→    All scores are clamped to [0, 100].\n    29→    \"\"\"\n    30→    energy: float = Field(default=50.0, ge=0, le=100, description=\"能量维度\")\n    31→    clarity: float = Field(default=50.0, ge=0, le=100, description=\"清晰度维度\")\n    32→    connection: float = Field(default=50.0, ge=0, le=100, description=\"连接维度\")\n    33→    growth: float = Field(default=50.0, ge=0, le=100, description=\"成长维度\")\n    34→    balance: float = Field(default=50.0, ge=0, le=100, description=\"平衡维度\")\n    35→\n    36→    @field_validator(\"energy\", \"clarity\", \"connection\", \"growth\", \"balance\", mode=\"before\")\n    37→    @classmethod\n    38→    def clamp_score(cls, v: Any) -> float:\n    39→        \"\"\"Clamp score to [0, 100].\"\"\"\n    40→        if v is None:\n    41→            return 50.0\n    42→        try:\n    43→            val = float(v)\n    44→            return max(0.0, min(100.0, val))\n    45→        except (TypeError, ValueError):\n    46→            return 50.0\n    47→\n    48→\n    49→class TwinMetadata(BaseModel):\n    50→    \"\"\"L1 Metadata layer - static/semi-static data.\"\"\"\n    51→    astrology: Dict[str, Any] = Field(default_factory=dict, description=\"八字/命盘数据\")\n    52→    psychology: Dict[str, Any] = Field(default_factory=dict, description=\"心理测评结果\")\n    53→    memory: Dict[str, Any] = Field(default_factory=dict, description=\"长期记忆/偏好\")\n    54→\n    55→\n    56→class TwinDynamicState(BaseModel):\n    57→    \"\"\"L2 Dynamic state layer - frequently changing data.\"\"\"\n    58→    astro: Dict[str, Any] = Field(default_factory=dict, description=\"当前运势/流年\")\n    59→    bio: Dict[str, Any] = Field(default_factory=dict, description=\"生理状态\")\n    60→    social: Dict[str, Any] = Field(default_factory=dict, description=\"社交状态\")\n    61→    emotional: Dict[str, Any] = Field(default_factory=dict, description=\"情绪状态\")\n    62→\n    63→\n    64→class TwinAggregatedMetrics(BaseModel):\n    65→    \"\"\"L3 Aggregated metrics - computed from L1 and L2.\"\"\"\n    66→    aura_points: int = Field(default=0, ge=0, description=\"能量点数\")\n    67→    overall_wellbeing: float = Field(default=50.0, ge=0, le=100, description=\"整体幸福指数\")\n    68→    growth_streak: int = Field(default=0, ge=0, description=\"成长连续天数\")\n    69→    dimension_scores: DimensionScores = Field(default_factory=DimensionScores)\n    70→\n    71→\n    72→class TwinData(BaseModel):\n    73→    \"\"\"\n    74→    Complete Digital Twin data model.\n    75→\n    76→    Represents the user's spiritual digital twin with three layers:\n    77→    - L1: Metadata (astrology, psychology, memory)\n    78→    - L2: Dynamic state (astro, bio, social, emotional)\n    79→    - L3: Aggregated metrics (aura, wellbeing, dimensions)\n    80→    \"\"\"\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"cc0cd893-7f2c-4d93-8fd0-257608453fd1","timestamp":"2026-01-01T15:01:49.958Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aiscend/work/fortune_ai/models/twin.py","content":"\"\"\"\nDigital Twin Pydantic Models.\n\nREQ: REQ-TWIN-001, REQ-TWIN-002\nDesign: §5.1.1, §4.3.1\nHOS-REF: §1.2\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom datetime import datetime\nfrom enum import Enum\nfrom typing import Any, Dict, List, Literal, Optional\n\nfrom pydantic import BaseModel, Field, field_validator, model_validator\n\n\nclass TwinLayer(str, Enum):\n    \"\"\"Twin data layers.\"\"\"\n    L1 = \"L1\"  # Metadata layer (static)\n    L2 = \"L2\"  # Dynamic state layer\n    L3 = \"L3\"  # Aggregated metrics\n\n\nclass DimensionScores(BaseModel):\n    \"\"\"\n    L3 aggregated dimension scores.\n    All scores are clamped to [0, 100].\n    \"\"\"\n    energy: float = Field(default=50.0, ge=0, le=100, description=\"能量维度\")\n    clarity: float = Field(default=50.0, ge=0, le=100, description=\"清晰度维度\")\n    connection: float = Field(default=50.0, ge=0, le=100, description=\"连接维度\")\n    growth: float = Field(default=50.0, ge=0, le=100, description=\"成长维度\")\n    balance: float = Field(default=50.0, ge=0, le=100, description=\"平衡维度\")\n\n    @field_validator(\"energy\", \"clarity\", \"connection\", \"growth\", \"balance\", mode=\"before\")\n    @classmethod\n    def clamp_score(cls, v: Any) -> float:\n        \"\"\"Clamp score to [0, 100].\"\"\"\n        if v is None:\n            return 50.0\n        try:\n            val = float(v)\n            return max(0.0, min(100.0, val))\n        except (TypeError, ValueError):\n            return 50.0\n\n\nclass TwinMetadata(BaseModel):\n    \"\"\"L1 Metadata layer - static/semi-static data.\"\"\"\n    astrology: Dict[str, Any] = Field(default_factory=dict, description=\"八字/命盘数据\")\n    psychology: Dict[str, Any] = Field(default_factory=dict, description=\"心理测评结果\")\n    memory: Dict[str, Any] = Field(default_factory=dict, description=\"长期记忆/偏好\")\n\n\nclass TwinDynamicState(BaseModel):\n    \"\"\"L2 Dynamic state layer - frequently changing data.\"\"\"\n    astro: Dict[str, Any] = Field(default_factory=dict, description=\"当前运势/流年\")\n    bio: Dict[str, Any] = Field(default_factory=dict, description=\"生理状态\")\n    social: Dict[str, Any] = Field(default_factory=dict, description=\"社交状态\")\n    emotional: Dict[str, Any] = Field(default_factory=dict, description=\"情绪状态\")\n\n\nclass TwinAggregatedMetrics(BaseModel):\n    \"\"\"L3 Aggregated metrics - computed from L1 and L2.\"\"\"\n    aura_points: int = Field(default=0, ge=0, description=\"能量点数\")\n    overall_wellbeing: float = Field(default=50.0, ge=0, le=100, description=\"整体幸福指数\")\n    growth_streak: int = Field(default=0, ge=0, description=\"成长连续天数\")\n    dimension_scores: DimensionScores = Field(default_factory=DimensionScores)\n\n\nclass TwinData(BaseModel):\n    \"\"\"\n    Complete Digital Twin data model.\n\n    Represents the user's spiritual digital twin with three layers:\n    - L1: Metadata (astrology, psychology, memory)\n    - L2: Dynamic state (astro, bio, social, emotional)\n    - L3: Aggregated metrics (aura, wellbeing, dimensions)\n    \"\"\"","numLines":80,"startLine":1,"totalLines":221}}}
{"parentUuid":"cc0cd893-7f2c-4d93-8fd0-257608453fd1","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_014NQwQAnX8mi7U5yEm1BZSx","type":"tool_result","content":"/home/aiscend/work/fortune_ai/models/twin.py"}]},"uuid":"a5bbdfd0-606a-4f69-9e08-7634e4093763","timestamp":"2026-01-01T15:01:50.770Z","toolUseResult":{"filenames":["/home/aiscend/work/fortune_ai/models/twin.py"],"durationMs":842,"numFiles":1,"truncated":false}}
{"parentUuid":"a5bbdfd0-606a-4f69-9e08-7634e4093763","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"ad33c8a","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01RRveivJC8TMKyoTvtiK1W5","type":"message","role":"assistant","content":[{"type":"text","text":"Perfect! Now I have enough information to provide a comprehensive analysis. Let me create the structured summary:\n\n## SERVICES LAYER EXPLORATION - COMPREHENSIVE ANALYSIS\n\nBased on my thorough analysis of `/home/aiscend/work/fortune_ai/services/`, here is the structured breakdown:\n\n---\n\n## 1. ARCHITECTURE OVERVIEW\n\nThe services layer implements a **3+1 architecture** (from `soul_os.py`):\n\n- **L0 (Firmware)**: Bazi facts snapshots - immutable user destiny data\n- **L1 (Schema)**: User traits, PERMA psychology, behavioral patterns\n- **L2 (Agents)**: Knowledge base retrieval, prompt templates, rules\n- **L3 (Synthesis)**: AI integration (currently GLM), A2UI output\n- **State Service**: Twin (user state), Goal, Commitment management\n\n---\n\n## 2. SERVICES TO STAY (DATA SERVICE LAYER)\n\n### A. `bazi_facts.py`\n**File Path**: `/home/aiscend/work/fortune_ai/services/bazi_facts.py` (503 lines)\n\n**Purpose**: Ephemeris calculation & destiny data generation (L0 Firmware)\n\n**Key Functions**:\n- `compute_facts()` - Calculates true solar time + 8-pillar chart (uses swisseph, lunar_python)\n- `ensure_snapshot_for_user()` - Caches bazi data in DB\n- `upsert_snapshot_for_profile()` - Updates bazi when user profile changes\n- `make_bazi_digest()` - Creates digestible summary (e.g., \"甲木日主 strong\")\n\n**Data Structures**:\n```python\nFacts = {\n  \"profile\": {name, gender, birthday_local, location},\n  \"solar_time\": {tz_meridian_deg, lon_corr_min, eot_min, true_solar_time_local},\n  \"bazi\": {\n    \"pillars\": {year, month, day, hour},\n    \"day_master\": {gan, element},\n    \"wuxing_count\": {金, 木, 水, 火, 土},\n    \"shi_shen_gan/zhi\": strength mapping,\n    \"luck\": {forward, da_yun[], liu_nian_next5[]},\n    \"strength\": {status, score, favorable_elements[], rule_id},\n    \"shensha\": [{name, hit, rule_id}]  // 桃花, 驿马, 华盖, etc.\n  },\n  \"version\": {compute_version: \"bazi-tts-v1\", facts_hash}\n}\n```\n\n**Stays Because**: Pure computation, deterministic, no LLM dependency. Will become HTTP API endpoint in Data Service.\n\n---\n\n### B. `bazi_engine.py`\n**File Path**: `/home/aiscend/work/fortune_ai/services/bazi_engine.py` (97 lines)\n\n**Purpose**: True solar time wrapper for simplified bazi calculation\n\n**Key Class**: `BaziResult` - minimal output for quick calculations\n\n**Stays Because**: Lightweight calculation layer, zero AI dependency.\n\n---\n\n### C. `twin_service.py`\n**File Path**: `/home/aiscend/work/fortune_ai/services/twin_service.py` (714 lines)\n\n**Purpose**: Digital Twin state management (L1 + L2 + L3 layers)\n\n**Core Functions**:\n- `create_twin(user_id)` - Initializes L1 (astrology metadata)\n- `get_twin(user_id)` - Fetches complete twin state\n- `update_twin(event)` - Atomic updates with transaction lock + audit log\n- `recalculate_dimensions(user_id)` - L3 metrics from L2 data\n\n**Data Flow**:\n```\nL1 (Metadata) = bazi_snapshot + psychology profile\nL2 (Dynamic) = {dynamic_astro, dynamic_bio, dynamic_social, dynamic_emotional}\nL3 (Metrics) = DimensionScores {energy, clarity, connection, growth, balance}\n\nTwinUpdateEvent -> update_twin() -> {transaction lock, atomicity, audit log}\n```\n\n**Key Insights**:\n- Uses `fortune_db.transaction()` with `FOR UPDATE` lock for atomicity\n- Records all changes to `fortune_twin_update_log` (immutable audit trail)\n- Triggers `recalculate_dimensions` when L2 updates\n- Dimension formulas use bio, social, emotional state as inputs\n\n**Stays Because**: Pure state container, no LLM. Core data structure for user profile.\n\n---\n\n### D. `goal_service.py`\n**File Path**: `/home/aiscend/work/fortune_ai/services/goal_service.py` (379 lines)\n\n**Purpose**: Goal hierarchy & progress tracking (annual/quarterly/monthly/weekly)\n\n**Core Functions**:\n- `create_goal(user_id, title, goal_type)` - Create goal with outcome/lead measures\n- `list_goals(user_id, goal_type, status)` - Query goals\n- `link_commitment_to_goal(goal_id, task_id)` - Goal-Task relationship\n- `record_checkpoint(goal_id, checkpoint_date, description)` - Track progress\n- `get_goal_progress(goal_id)` - Compute metrics (tasks done, completion %)\n\n**Data Model**:\n```python\nGoal = {\n  goal_id, user_id, parent_goal_id,  # hierarchy\n  type: \"annual|quarterly|monthly|weekly\",\n  title, outcome_measure,\n  lead_measures: [],  # behavioral indicators\n  assumptions: [],\n  dimension: \"cognition|time|capital|mixed\",\n  checkpoints: [{date, description, progress, recorded_at}],\n  status: \"active|achieved|abandoned|revised\"\n}\n```\n\n**Stays Because**: Pure CRUD over relational schema, no AI.\n\n---\n\n## 3. SERVICES MOVING TO NEXT.JS (AI INFERENCE)\n\n### A. `glm_client.py`\n**File Path**: `/home/aiscend/work/fortune_ai/services/glm_client.py` (292 lines)\n\n**Current Role**: LLM inference with Z.AI GLM API (OpenAI-compatible)\n\n**Key Functions**:\n- `call_chat_completions()` - Sync HTTP POST to GLM endpoint\n- `call_messages_api()` - Anthropic-style compatibility shim\n- `stream_chat_completions()` - SSE streaming\n- `extract_json_object()` - Best-effort JSON parsing from LLM output\n\n**Env Vars Used**:\n```\nGLM_BASE_URL = \"https://api.z.ai/api/paas/v4\"\nGLM_API_KEY\nFORTUNE_AI_GLM_MODEL = \"glm-4.7\"\nFORTUNE_AI_GLM_THINKING = \"enabled|disabled\"\n```\n\n**Moves to Next.js Because**: \n- LLM calls should happen in AI Runtime (Vercel, etc.)\n- These are simple HTTP wrappers—can be replicated in TypeScript/Node\n- Frontend needs streaming capability for real-time UX\n\n---\n\n### B. `soul_os.py`\n**File Path**: `/home/aiscend/work/fortune_ai/services/soul_os.py` (1237 lines)\n\n**Current Role**: Context assembly + system prompt generation (L2 → L3)\n\n**Key Functions** (stays in Python as **Context Service**, migrates logic to Next.js):\n\n1. **Context Building** (← MOVES):\n   ```python\n   get_full_context_for_chat(user_id, query) -> {\n     system_prompt: str,\n     persona_style: str,\n     user_context: {l0_facts, l0_translations, l1_schema, state_score},\n     evidence: {facts_hash, kb_refs, rule_ids},\n     anti_dependency: {should_intervene, intervention_type, message}\n   }\n   ```\n   - **Migrates to**: Next.js can call Python API for context, or compute locally\n\n2. **State Score** (← STAYS):\n   ```python\n   calculate_state_score(user_id, window=\"24h|7d\") -> StateScore {\n     score: 0-100,\n     emotion_signal: 40%,  # from checkin mood/intensity\n     action_signal: 40%,   # from commitments done\n     streak_signal: 20%    # continuous days\n   }\n   ```\n   - **Why stays**: Requires DB queries; best in Python Data Service\n\n3. **Anti-Dependency Check** (← STAYS):\n   ```python\n   check_anti_dependency(user_id, message) -> AntiDependencyState {\n     same_question_count,\n     daily_consult_count,\n     should_intervene: bool,\n     intervention_type: \"repeated_question|daily_limit|no_action\",\n     suggested_task: {task_id, title, minutes}\n   }\n   ```\n   - **Why stays**: Needs DB; complex heuristics; triggers task creation\n\n4. **L2 Schema Retrieval** (← STAYS):\n   ```python\n   get_l1_schema(user_id, window_days=7) -> L1Schema {\n     perma: {positive_emotion, engagement, relationships, meaning, accomplishment},\n     cognitive_patterns, strengths_in_use, preferences\n   }\n   ```\n   - **Why stays**: Aggregates multi-source DB queries\n\n5. **JITAI Actions** (← STAYS):\n   ```python\n   get_jitai_action(mood, intensity) -> str\n   create_checkin_with_jitai(user_id, mood, intensity) -> {action, task_id}\n   ```\n   - **Why stays**: Creates side-effects (task insertion)\n\n6. **Knowledge Base Search** (← STAYS):\n   ```python\n   search_knowledge_base(query, top_k=12) -> [{kb_ref, content, source}]\n   ```\n   - **Why stays**: PostgreSQL FTS; retrieval logic\n\n7. **Commitment Management** (← STAYS):\n   ```python\n   create_commitment(...) -> task_id\n   accept_commitment(user_id, task_id) -> bool\n   complete_commitment(user_id, task_id) -> {success, state_score}\n   ```\n   - **Why stays**: Task lifecycle, state updates\n\n**System Prompt Building** (← MOVES):\n- `build_system_prompt(user_id, persona_style)` generates instruction text\n- Can move to Next.js once context is fetched from Python API\n\n**Key Data Structures**:\n```python\nStateScore = {score, emotion_signal, action_signal, streak_signal, recovery_action}\nPermaSnapshot = {positive_emotion, engagement, relationships, meaning, accomplishment}\nL1Schema = {perma, cognitive_patterns, strengths_in_use, preferences}\nGuidanceCard = {card_id, conclusion, why, prescriptions, actions, evidence}\nAntiDependencyState = {should_intervene, intervention_type, intervention_message, suggested_task}\n```\n\n---\n\n### C. `agent_service_client.py`\n**File Path**: `/home/aiscend/work/fortune_ai/services/agent_service_client.py` (258 lines)\n\n**Current Role**: HTTP client to TypeScript agent_service (Vercel AI SDK)\n\n**Functions**:\n- `call_agent_service(async)` - POST to `http://localhost:3002/api/chat`\n- `call_agent_service_sync()` - Blocking version\n- `health_check()` - Service readiness probe\n\n**Request Payload**:\n```json\n{\n  \"user_id\": int,\n  \"session_id\": str,\n  \"messages\": [{role, content}],\n  \"context\": {\n    \"user\": {user_context},\n    \"facts\": {bazi_facts},\n    \"persona_style\": \"warm|standard|roast\"\n  }\n}\n```\n\n**Response**:\n```python\nAgentResponse = {\n  text: str,\n  a2ui: Optional[Dict],  # A2UI JSON structure\n  tool_calls: Optional[List],\n  metadata: Optional[Dict]\n}\n```\n\n**Moves to Next.js Because**: This is literally a shim between Python FastAPI and the new Next.js agent service. It becomes redundant once Next.js is the backend.\n\n---\n\n## 4. CURRENT DATA FLOW (Chat Request)\n\n```\nRequest: /api/chat/send {user_text, session_id}\n         ↓\n   [auth check] → require_auth()\n         ↓\n   [fetch context] → soul_os.get_full_context_for_chat(user_id, user_text)\n         ↓\n         ├─→ get_l0_facts() → fetch bazi_snapshot from DB\n         ├─→ translate_bazi_to_psychology() → convert to actionable language\n         ├─→ get_l1_schema() → fetch PERMA + behavioral patterns\n         ├─→ calculate_state_score() → emotion/action/streak signals\n         ├─→ search_knowledge_base() → FTS query\n         └─→ check_anti_dependency() → intervention check + task creation\n         ↓\n   [anti-dependency intervention?]\n         ├─ YES → return intervention message + task\n         └─ NO → continue\n         ↓\n   [yunshi detection?] → detect_yunshi_intent()\n         ├─ YES → handle_yunshi_intent() → return specialized response\n         └─ NO → continue\n         ↓\n   [LLM Call] → chat_backend preference\n         ├─ \"agent_service\" → agent_service_client.call_agent_service_sync()\n         │                      ↓\n         │               call TypeScript agent_service on port 3002\n         │\n         └─ \"glm\" (default) → glm_client.call_chat_completions()\n                              ↓\n                      [build LLM messages] → soul_os.build_system_prompt()\n                      [history] → chat_service.get_recent_messages_for_llm()\n                      ↓\n                      glm_client.call_chat_completions(\n                        system_prompt, messages, model, max_tokens\n                      )\n         ↓\n   [parse response] → glm_client.extract_json_object() or _a2ui_from_text()\n         ↓\n   [save to DB] → chat_service.append_message()\n         ↓\n   [audit log] → _write_agent_run_log()\n         ↓\n   Response: {session_id, a2ui, backend, suggested_tasks}\n```\n\n---\n\n## 5. KEY DATA STRUCTURES PASSED BETWEEN SERVICES\n\n### Context Object (L0 + L1 + L2)\n```python\nuser_context = {\n  \"l0_facts\": {\n    \"profile\": {name, gender, birthday_local, tz_offset_hours, location},\n    \"solar_time\": {...},\n    \"bazi\": {pillars, day_master, wuxing_count, strength, shensha, luck}\n  },\n  \"l0_translations\": [\n    {\"concept\": \"日主弱\", \"translation\": \"...\", \"action\": \"...\"},\n    {\"concept\": \"桃花\", \"translation\": \"...\", \"action\": \"...\"}\n  ],\n  \"l1_schema\": {\n    \"perma_snapshot\": {\n      \"positive_emotion\": {score, trend, recent_count},\n      \"engagement\": {score, active_plans, completion_rate},\n      \"relationships\": {score, recent_mentions},\n      \"meaning\": {score, core_value, aligned_actions},\n      \"accomplishment\": {score, weekly_done, streak}\n    },\n    \"cognitive_patterns\": {...},\n    \"strengths_in_use\": [],\n    \"preferences\": {persona_style, push_enabled}\n  },\n  \"state_score\": {\n    \"score\": 0-100,\n    \"breakdown\": {emotion, action, streak},\n    \"recovery_action\": \"...\"\n  }\n}\n```\n\n### Evidence Object\n```python\nevidence = {\n  \"facts_hash\": \"sha256:...\",\n  \"kb_refs\": [\"kb:doc:1:page:2:chunk:3\", ...],\n  \"rule_ids\": [\"RULE-STRENGTH-SCORE-V1\", \"RULE-SHENSHA-TAOHUA-V1\", ...]\n}\n```\n\n### Twin Data (Digital Twin)\n```python\nTwinData = {\n  \"twin_id\": UUID,\n  \"user_id\": int,\n  \"metadata_astrology\": {bazi snapshot},\n  \"metadata_psychology\": {assessment results},\n  \"metadata_memory\": {long-term preferences},\n  \"dynamic_astro\": {current transit},\n  \"dynamic_bio\": {sleep_score, activity_level, meditation_minutes},\n  \"dynamic_social\": {interactions_today, commitments_completed, relationship_quality},\n  \"dynamic_emotional\": {mood_intensity, focus_score, stress_level, mood_volatility},\n  \"aura_points\": int,\n  \"overall_wellbeing\": float (0-100),\n  \"growth_streak\": int,\n  \"dimension_scores\": {energy, clarity, connection, growth, balance},\n  \"compute_version\": \"v1.0\",\n  \"last_full_refresh\": datetime,\n  \"created_at\": datetime,\n  \"updated_at\": datetime\n}\n```\n\n### Commitment (Task)\n```python\nCommitment = {\n  \"task_id\": UUID,\n  \"user_id\": int,\n  \"card_id\": Optional[UUID],\n  \"goal_id\": Optional[UUID],\n  \"session_id\": Optional[UUID],\n  \"source\": \"bento|soul_os|yunshi|user\",\n  \"commitment_type\": \"start_task|schedule_task|ask_followup|opt_out\",\n  \"title\": str,\n  \"details\": {from: \"checkin\", mood: \"...\", intensity: ...},\n  \"status\": \"suggested|active|done|skipped|canceled\",\n  \"accepted_at\": Optional[datetime],\n  \"done_at\": Optional[datetime],\n  \"due_at\": Optional[datetime],\n  \"created_at\": datetime\n}\n```\n\n---\n\n## 6. MIGRATION STRATEGY SUMMARY\n\n| Service | Current State | Destination | Reason |\n|---------|---------------|-------------|--------|\n| **bazi_facts.py** | Python Data Lib | Data Service (HTTP API) | Pure computation; stays in Python |\n| **bazi_engine.py** | Python Data Lib | Data Service (HTTP API) | Lightweight wrapper; stays in Python |\n| **twin_service.py** | Python State Mgmt | Data Service (HTTP API + ORM) | Core data structure; DB queries |\n| **goal_service.py** | Python State Mgmt | Data Service (HTTP API + ORM) | CRUD layer; DB queries |\n| **soul_os.py** | **Hybrid** | Split: Python API + Next.js Logic | Context stays in Python; LLM prep moves to JS |\n| **glm_client.py** | Python LLM Client | Remove / Move to Next.js | LLM calls should be in AI Runtime |\n| **agent_service_client.py** | Python HTTP Shim | Remove (redundant in Next.js era) | No longer needed once Next.js is backend |\n\n---\n\n## 7. NEXT.JS WILL NEED\n\nFrom the exploration, the Next.js backend should implement:\n\n1. **Context Fetcher** (calls Python Data Service):\n   - `GET /api/user/{user_id}/context?query=...` → returns full context object\n   \n2. **LLM Integration** (replaces glm_client.py):\n   - Support streaming from Z.AI GLM or other providers\n   - JSON parsing from LLM output\n   \n3. **System Prompt Builder** (replicates soul_os logic):\n   - Persona style injection\n   - Evidence formatting\n   - Structure validation\n   \n4. **A2UI Normalization** (replicates chat_routes logic):\n   - JSON extraction from markdown\n   - Component validation\n   - Fallback formatting\n\n---\n\n## 8. FILES AND ABSOLUTE PATHS\n\n### Stay in Python (Data Service):\n- `/home/aiscend/work/fortune_ai/services/bazi_facts.py` (503 L)\n- `/home/aiscend/work/fortune_ai/services/bazi_engine.py` (97 L)\n- `/home/aiscend/work/fortune_ai/services/twin_service.py` (714 L)\n- `/home/aiscend/work/fortune_ai/services/goal_service.py` (379 L)\n- `/home/aiscend/work/fortune_ai/services/soul_os.py` (L0-L2 context, minus LLM orchestration)\n\n### Move to Next.js (AI Runtime):\n- `/home/aiscend/work/fortune_ai/services/glm_client.py` (292 L) - Reimplement logic\n- `/home/aiscend/work/fortune_ai/services/agent_service_client.py` (258 L) - No longer needed\n\n### API Integration Points:\n- `/home/aiscend/work/fortune_ai/api/chat_routes.py` (1074+ L) - Core orchestration; will shift to Next.js\n\n---\n\nThis architecture allows:\n- **Data Service** (Python) handles state, persistence, computation\n- **AI Service** (Next.js) handles prompt engineering, streaming, real-time UX\n- **Clean separation**: Python does heavy lifting; JS handles user-facing AI interactions"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":1341,"cache_creation_input_tokens":346,"cache_read_input_tokens":82101,"cache_creation":{"ephemeral_5m_input_tokens":346,"ephemeral_1h_input_tokens":0},"output_tokens":5334,"service_tier":"standard"}},"requestId":"req_011CWgrpxG8TxbkgQWTUPnjx","type":"assistant","uuid":"f9854067-214b-4373-9803-616dc805ddb5","timestamp":"2026-01-01T15:02:42.885Z"}
