{"parentUuid":null,"isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":"Explore the current FastAPI backend structure in /home/aiscend/work/fortune_ai/api/. I need to understand:\n\n1. The main.py entry point and router registration\n2. All route files and their endpoints\n3. The deps.py dependency injection patterns\n4. How authentication/session is currently handled\n5. How chat_routes.py handles chat (this is the core refactoring target)\n\nFocus on identifying:\n- Current endpoint patterns\n- Authentication middleware\n- CSRF handling\n- Session management\n- Which routes need to stay in FastAPI vs migrate to Next.js\n\nReturn a structured summary with file paths and key findings."},"uuid":"74172b64-f830-4d9a-af79-66d5567b3df6","timestamp":"2026-01-01T15:00:59.076Z"}
{"parentUuid":"74172b64-f830-4d9a-af79-66d5567b3df6","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01RWft64wGHNWe5ZvACckmkC","type":"message","role":"assistant","content":[{"type":"text","text":"I'll conduct a thorough exploration of the FastAPI backend structure. Let me start by mapping out the directory and examining the key files."}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":463,"cache_read_input_tokens":20477,"cache_creation":{"ephemeral_5m_input_tokens":463,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrmFiVpbhcFWm7vV1C3","type":"assistant","uuid":"f95345e7-ffbd-46e5-af58-4542715b7247","timestamp":"2026-01-01T15:01:03.301Z"}
{"parentUuid":"f95345e7-ffbd-46e5-af58-4542715b7247","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01RWft64wGHNWe5ZvACckmkC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01YVH7oHoFEdU37DabJj12HB","name":"Bash","input":{"command":"find /home/aiscend/work/fortune_ai/api -type f -name \"*.py\" | head -20","description":"List Python files in API directory"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":463,"cache_read_input_tokens":20477,"cache_creation":{"ephemeral_5m_input_tokens":463,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrmFiVpbhcFWm7vV1C3","type":"assistant","uuid":"a267a5db-3390-4bc2-838f-72adf750b2f5","timestamp":"2026-01-01T15:01:03.601Z"}
{"parentUuid":"a267a5db-3390-4bc2-838f-72adf750b2f5","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01RWft64wGHNWe5ZvACckmkC","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011vLLVzto5QSJzdFKBUi22G","name":"Glob","input":{"pattern":"/home/aiscend/work/fortune_ai/api/**/*.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":3,"cache_creation_input_tokens":463,"cache_read_input_tokens":20477,"cache_creation":{"ephemeral_5m_input_tokens":463,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrmFiVpbhcFWm7vV1C3","type":"assistant","uuid":"dfe8b8d6-ed37-4d49-9f25-a0bfc9f8fed0","timestamp":"2026-01-01T15:01:03.783Z"}
{"parentUuid":"dfe8b8d6-ed37-4d49-9f25-a0bfc9f8fed0","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01YVH7oHoFEdU37DabJj12HB","type":"tool_result","content":"/home/aiscend/work/fortune_ai/api/main.py\n/home/aiscend/work/fortune_ai/api/agent_tool.py\n/home/aiscend/work/fortune_ai/api/push_routes.py\n/home/aiscend/work/fortune_ai/api/chat_routes.py\n/home/aiscend/work/fortune_ai/api/session_routes.py\n/home/aiscend/work/fortune_ai/api/social_routes.py\n/home/aiscend/work/fortune_ai/api/poster_routes.py\n/home/aiscend/work/fortune_ai/api/bazi_routes.py\n/home/aiscend/work/fortune_ai/api/jitai_routes.py\n/home/aiscend/work/fortune_ai/api/auth_routes.py\n/home/aiscend/work/fortune_ai/api/goal_routes.py\n/home/aiscend/work/fortune_ai/api/user_routes.py\n/home/aiscend/work/fortune_ai/api/dashboard_routes.py\n/home/aiscend/work/fortune_ai/api/reflection_routes.py\n/home/aiscend/work/fortune_ai/api/deps.py\n/home/aiscend/work/fortune_ai/api/currency_routes.py\n/home/aiscend/work/fortune_ai/api/report_routes.py\n/home/aiscend/work/fortune_ai/api/plan_routes.py\n/home/aiscend/work/fortune_ai/api/twin_routes.py\n/home/aiscend/work/fortune_ai/api/kb_routes.py","is_error":false}]},"uuid":"3a977dd1-b631-4395-8657-62731aaf01b5","timestamp":"2026-01-01T15:01:05.027Z","toolUseResult":{"stdout":"/home/aiscend/work/fortune_ai/api/main.py\n/home/aiscend/work/fortune_ai/api/agent_tool.py\n/home/aiscend/work/fortune_ai/api/push_routes.py\n/home/aiscend/work/fortune_ai/api/chat_routes.py\n/home/aiscend/work/fortune_ai/api/session_routes.py\n/home/aiscend/work/fortune_ai/api/social_routes.py\n/home/aiscend/work/fortune_ai/api/poster_routes.py\n/home/aiscend/work/fortune_ai/api/bazi_routes.py\n/home/aiscend/work/fortune_ai/api/jitai_routes.py\n/home/aiscend/work/fortune_ai/api/auth_routes.py\n/home/aiscend/work/fortune_ai/api/goal_routes.py\n/home/aiscend/work/fortune_ai/api/user_routes.py\n/home/aiscend/work/fortune_ai/api/dashboard_routes.py\n/home/aiscend/work/fortune_ai/api/reflection_routes.py\n/home/aiscend/work/fortune_ai/api/deps.py\n/home/aiscend/work/fortune_ai/api/currency_routes.py\n/home/aiscend/work/fortune_ai/api/report_routes.py\n/home/aiscend/work/fortune_ai/api/plan_routes.py\n/home/aiscend/work/fortune_ai/api/twin_routes.py\n/home/aiscend/work/fortune_ai/api/kb_routes.py","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"3a977dd1-b631-4395-8657-62731aaf01b5","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011vLLVzto5QSJzdFKBUi22G","type":"tool_result","content":"/home/aiscend/work/fortune_ai/api/deps.py\n/home/aiscend/work/fortune_ai/api/session_routes.py\n/home/aiscend/work/fortune_ai/api/bazi_routes.py\n/home/aiscend/work/fortune_ai/api/kb_routes.py\n/home/aiscend/work/fortune_ai/api/plan_routes.py\n/home/aiscend/work/fortune_ai/api/twin_routes.py\n/home/aiscend/work/fortune_ai/api/agent_tool.py\n/home/aiscend/work/fortune_ai/api/jitai_routes.py\n/home/aiscend/work/fortune_ai/api/currency_routes.py\n/home/aiscend/work/fortune_ai/api/push_routes.py\n/home/aiscend/work/fortune_ai/api/social_routes.py\n/home/aiscend/work/fortune_ai/api/goal_routes.py\n/home/aiscend/work/fortune_ai/api/reflection_routes.py\n/home/aiscend/work/fortune_ai/api/user_routes.py\n/home/aiscend/work/fortune_ai/api/bento_routes.py\n/home/aiscend/work/fortune_ai/api/yunshi_routes.py\n/home/aiscend/work/fortune_ai/api/report_routes.py\n/home/aiscend/work/fortune_ai/api/chat_routes.py\n/home/aiscend/work/fortune_ai/api/auth_routes.py\n/home/aiscend/work/fortune_ai/api/poster_routes.py\n/home/aiscend/work/fortune_ai/api/dashboard_routes.py\n/home/aiscend/work/fortune_ai/api/main.py"}]},"uuid":"8b4538ab-95e1-4e92-8888-30ba717216cf","timestamp":"2026-01-01T15:01:05.657Z","toolUseResult":{"filenames":["/home/aiscend/work/fortune_ai/api/deps.py","/home/aiscend/work/fortune_ai/api/session_routes.py","/home/aiscend/work/fortune_ai/api/bazi_routes.py","/home/aiscend/work/fortune_ai/api/kb_routes.py","/home/aiscend/work/fortune_ai/api/plan_routes.py","/home/aiscend/work/fortune_ai/api/twin_routes.py","/home/aiscend/work/fortune_ai/api/agent_tool.py","/home/aiscend/work/fortune_ai/api/jitai_routes.py","/home/aiscend/work/fortune_ai/api/currency_routes.py","/home/aiscend/work/fortune_ai/api/push_routes.py","/home/aiscend/work/fortune_ai/api/social_routes.py","/home/aiscend/work/fortune_ai/api/goal_routes.py","/home/aiscend/work/fortune_ai/api/reflection_routes.py","/home/aiscend/work/fortune_ai/api/user_routes.py","/home/aiscend/work/fortune_ai/api/bento_routes.py","/home/aiscend/work/fortune_ai/api/yunshi_routes.py","/home/aiscend/work/fortune_ai/api/report_routes.py","/home/aiscend/work/fortune_ai/api/chat_routes.py","/home/aiscend/work/fortune_ai/api/auth_routes.py","/home/aiscend/work/fortune_ai/api/poster_routes.py","/home/aiscend/work/fortune_ai/api/dashboard_routes.py","/home/aiscend/work/fortune_ai/api/main.py"],"durationMs":790,"numFiles":22,"truncated":false}}
{"parentUuid":"8b4538ab-95e1-4e92-8888-30ba717216cf","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01AAZWibhfmLWuTwiHNZyYsY","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me examine the core files - main.py, deps.py, and chat_routes.py:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":1397,"cache_read_input_tokens":20940,"cache_creation":{"ephemeral_5m_input_tokens":1397,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrmwuTvNWFTFRUJMrQ2","type":"assistant","uuid":"0a01f34b-e164-4db1-9e51-16558a83cb49","timestamp":"2026-01-01T15:01:13.398Z"}
{"parentUuid":"0a01f34b-e164-4db1-9e51-16558a83cb49","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01AAZWibhfmLWuTwiHNZyYsY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WGAGRtvWA9kuxTt21JsWf9","name":"Read","input":{"file_path":"/home/aiscend/work/fortune_ai/api/main.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":1397,"cache_read_input_tokens":20940,"cache_creation":{"ephemeral_5m_input_tokens":1397,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrmwuTvNWFTFRUJMrQ2","type":"assistant","uuid":"73541d4a-43db-4eb3-ae5b-2af86871f33e","timestamp":"2026-01-01T15:01:13.576Z"}
{"parentUuid":"73541d4a-43db-4eb3-ae5b-2af86871f33e","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01AAZWibhfmLWuTwiHNZyYsY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_013eUucvyaoWWMqJdNQAfCxf","name":"Read","input":{"file_path":"/home/aiscend/work/fortune_ai/api/deps.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":1397,"cache_read_input_tokens":20940,"cache_creation":{"ephemeral_5m_input_tokens":1397,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrmwuTvNWFTFRUJMrQ2","type":"assistant","uuid":"959b01ed-ccbf-446d-a34c-18b0fdfb1023","timestamp":"2026-01-01T15:01:13.592Z"}
{"parentUuid":"959b01ed-ccbf-446d-a34c-18b0fdfb1023","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01AAZWibhfmLWuTwiHNZyYsY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01L3tyDQsN56DggXuePh1QeB","name":"Read","input":{"file_path":"/home/aiscend/work/fortune_ai/api/chat_routes.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":1397,"cache_read_input_tokens":20940,"cache_creation":{"ephemeral_5m_input_tokens":1397,"ephemeral_1h_input_tokens":0},"output_tokens":202,"service_tier":"standard"}},"requestId":"req_011CWgrmwuTvNWFTFRUJMrQ2","type":"assistant","uuid":"563d38d6-3cd3-4bba-bd62-62747024d60c","timestamp":"2026-01-01T15:01:15.769Z"}
{"parentUuid":"563d38d6-3cd3-4bba-bd62-62747024d60c","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_013eUucvyaoWWMqJdNQAfCxf","type":"tool_result","content":"     1→from __future__ import annotations\n     2→\n     3→from typing import Any, Dict, Optional\n     4→\n     5→from fastapi import HTTPException, Request\n     6→\n     7→from services import auth_service\n     8→from services.security import sha256_hex\n     9→\n    10→\n    11→def get_client_ip(request: Request) -> str:\n    12→    try:\n    13→        return request.client.host if request.client else \"\"\n    14→    except Exception:\n    15→        return \"\"\n    16→\n    17→\n    18→def get_user_agent(request: Request) -> str:\n    19→    return (request.headers.get(\"user-agent\") or \"\")[:500]\n    20→\n    21→\n    22→def get_current_auth(request: Request) -> Optional[Dict[str, Any]]:\n    23→    session_token = request.cookies.get(\"fortune_session\") or \"\"\n    24→    return auth_service.get_user_by_session_token(session_token)\n    25→\n    26→\n    27→def require_auth(request: Request) -> Dict[str, Any]:\n    28→    auth = get_current_auth(request)\n    29→    if not auth:\n    30→        raise HTTPException(status_code=401, detail=\"unauthorized\")\n    31→    return auth\n    32→\n    33→\n    34→def require_csrf(request: Request, auth: Dict[str, Any]) -> None:\n    35→    token = (request.headers.get(\"X-CSRF-Token\") or \"\").strip()\n    36→    if not token:\n    37→        raise HTTPException(status_code=403, detail=\"missing_csrf\")\n    38→    got = sha256_hex(token)\n    39→    expected = str(auth.get(\"csrf_token_hash\") or \"\")\n    40→    if not expected or got != expected:\n    41→        raise HTTPException(status_code=403, detail=\"invalid_csrf\")\n    42→\n    43→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"1935aa34-4f2d-4669-982a-15e91e36127f","timestamp":"2026-01-01T15:01:15.954Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aiscend/work/fortune_ai/api/deps.py","content":"from __future__ import annotations\n\nfrom typing import Any, Dict, Optional\n\nfrom fastapi import HTTPException, Request\n\nfrom services import auth_service\nfrom services.security import sha256_hex\n\n\ndef get_client_ip(request: Request) -> str:\n    try:\n        return request.client.host if request.client else \"\"\n    except Exception:\n        return \"\"\n\n\ndef get_user_agent(request: Request) -> str:\n    return (request.headers.get(\"user-agent\") or \"\")[:500]\n\n\ndef get_current_auth(request: Request) -> Optional[Dict[str, Any]]:\n    session_token = request.cookies.get(\"fortune_session\") or \"\"\n    return auth_service.get_user_by_session_token(session_token)\n\n\ndef require_auth(request: Request) -> Dict[str, Any]:\n    auth = get_current_auth(request)\n    if not auth:\n        raise HTTPException(status_code=401, detail=\"unauthorized\")\n    return auth\n\n\ndef require_csrf(request: Request, auth: Dict[str, Any]) -> None:\n    token = (request.headers.get(\"X-CSRF-Token\") or \"\").strip()\n    if not token:\n        raise HTTPException(status_code=403, detail=\"missing_csrf\")\n    got = sha256_hex(token)\n    expected = str(auth.get(\"csrf_token_hash\") or \"\")\n    if not expected or got != expected:\n        raise HTTPException(status_code=403, detail=\"invalid_csrf\")\n\n","numLines":43,"startLine":1,"totalLines":43}}}
{"parentUuid":"1935aa34-4f2d-4669-982a-15e91e36127f","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01L3tyDQsN56DggXuePh1QeB","type":"tool_result","content":"     1→from __future__ import annotations\n     2→\n     3→import json\n     4→import os\n     5→import re\n     6→from string import Template\n     7→from typing import Any, Dict, List, Optional, Tuple\n     8→\n     9→from fastapi import APIRouter, Request, Query\n    10→from fastapi.responses import JSONResponse, StreamingResponse\n    11→from pydantic import BaseModel, Field\n    12→\n    13→from api.deps import require_auth, require_csrf\n    14→from common.a2ui import validate_a2ui\n    15→from services import chat_service\n    16→from services import glm_client\n    17→from services import bazi_facts\n    18→from services import kb_service\n    19→from services import agent_service_client\n    20→from services import soul_os\n    21→from services.chat_backend_config import default_chat_backend\n    22→from services.yunshi_service import yunshi_service, build_daily_yunshi_a2ui, build_annual_yunshi_a2ui\n    23→from stores import fortune_db\n    24→\n    25→\n    26→router = APIRouter(prefix=\"/api/chat\", tags=[\"chat\"])\n    27→\n    28→\n    29→def _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    30→    return JSONResponse({\"ok\": True, \"data\": data or {}})\n    31→\n    32→\n    33→def _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    34→    return JSONResponse(\n    35→        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n    36→        status_code=status,\n    37→    )\n    38→\n    39→\n    40→class ChatSendRequest(BaseModel):\n    41→    session_id: Optional[str] = Field(None)\n    42→    text: str = Field(..., min_length=1)\n    43→\n    44→\n    45→_UUID_RE = re.compile(r\"^[0-9a-fA-F-]{36}$\")\n    46→\n    47→\n    48→SYSTEM_PROMPT_TEMPLATE = Template(\"\"\"你是 Fortune AI 的对话 Agent，角色是积极心理学教练（Performance Coach）。\n    49→\n    50→【产品定位】\n    51→人生导航 / 陪伴 / 提升。系统和交互保持“有效而极简”。\n    52→\n    53→【你的优先级（不可逆）】\n    54→Coach > Teaching Assistant > Customer Support > Sales\n    55→\n    56→【硬性规则（必须遵守）】\n    57→1) 禁止恐吓、羞辱、宿命论断言；负面信息必须紧接“你可以做什么”的行动处方。\n    58→2) 禁止自行计算八字事实；只能基于提供的 facts + evidence 输出。\n    59→3) 每次输出必须包含：结论(conclusion) + 依据(why) + ≤3条处方(prescriptions) + 承诺邀请(commitment_ask)。\n    60→4) 时间窗口默认只给干预窗口（intervention）；forecast 只能条件句+低置信度。\n    61→5) 输出必须是 A2UI JSON，且第一组件必须是 markdown_text。\n    62→6) 必须给出可点击 actions（start_task / schedule_task / open_panel / opt_out）。\n    63→\n    64→【语言风格 persona_style】\n    65→standard：清晰、中性、专业\n    66→warm：共情、支持性（默认）\n    67→roast：轻毒舌但不羞辱、不对人格做负面定性\n    68→\n    69→【输入（系统已注入）】\n    70→persona_style: $persona_style\n    71→user_context: $user_context_json\n    72→facts: $facts_json\n    73→evidence: $evidence_json\n    74→\n    75→【输出（必须严格仅输出 JSON）】\n    76→返回 A2UI JSON，结构：\n    77→- meta.summary：一句话摘要\n    78→- ui_components[0]：markdown_text（必须，包含：结论要点/依据/处方/时间窗口/边界/承诺邀请）\n    79→- ui_components[1]：action_buttons（必须，按钮结构：{label, action:{type, ...}}）\n    80→\n    81→严格按以下字段名输出（不要用 content/actions/action_type/payload 等变体；不要代码块；不要额外文本）：\n    82→{\n    83→  \"meta\": {\"summary\": \"...\"},\n    84→  \"ui_components\": [\n    85→    {\"type\":\"markdown_text\",\"title\":\"教练回复\",\"data\":\"...markdown...\"},\n    86→    {\"type\":\"action_buttons\",\"title\":\"下一步\",\"data\":[\n    87→      {\"label\":\"开始（2-5分钟）\",\"action\":{\"type\":\"start_task\",\"task_id\":\"...\"}},\n    88→      {\"label\":\"加入今日计划\",\"action\":{\"type\":\"schedule_task\",\"task_id\":\"...\"}},\n    89→      {\"label\":\"打开功能区\",\"action\":{\"type\":\"open_panel\",\"panel\":\"bento\"}},\n    90→      {\"label\":\"先不需要\",\"action\":{\"type\":\"opt_out\"}}\n    91→    ]}\n    92→  ]\n    93→}\n    94→\"\"\")\n    95→\n    96→SYSTEM_PROMPT_STREAM_TEMPLATE = Template(\"\"\"你是 Fortune AI 的对话 Agent，角色是积极心理学教练（Performance Coach）。\n    97→\n    98→【产品定位】\n    99→人生导航 / 陪伴 / 提升。系统和交互保持“有效而极简”。\n   100→\n   101→【你的优先级（不可逆）】\n   102→Coach > Teaching Assistant > Customer Support > Sales\n   103→\n   104→【硬性规则（必须遵守）】\n   105→1) 禁止恐吓、羞辱、宿命论断言；负面信息必须紧接“你可以做什么”的行动处方。\n   106→2) 禁止自行计算八字事实；只能基于提供的 facts + evidence 输出。\n   107→3) 每次输出必须包含：结论(conclusion) + 依据(why) + ≤3条处方(prescriptions) + 承诺邀请(commitment_ask)。\n   108→4) 每条处方必须包含 if_then：如果____→那么____；并优先给 2–5 分钟可启动版本。\n   109→5) 只输出 Markdown 文本，不要 JSON/代码块/额外说明。\n   110→\n   111→【语言风格 persona_style】\n   112→standard：清晰、中性、专业\n   113→warm：共情、支持性（默认）\n   114→roast：轻毒舌但不羞辱、不对人格做负面定性\n   115→\n   116→【输入（系统已注入）】\n   117→persona_style: $persona_style\n   118→user_context: $user_context_json\n   119→facts: $facts_json\n   120→evidence: $evidence_json\n   121→\n   122→【输出（Markdown）】\n   123→用如下结构输出（标题可省略但必须包含“处方”一节）：\n   124→\n   125→结论：...\n   126→依据：...\n   127→处方：\n   128→1) ...（包含 if_then）\n   129→2) ...（包含 if_then）\n   130→3) ...（包含 if_then）\n   131→承诺邀请：...（一句话，邀请用户选择一个处方开始）\n   132→\"\"\")\n   133→\n   134→\n   135→def _load_user_context(user_id: int) -> Tuple[Dict[str, Any], Dict[str, Any], Dict[str, Any]]:\n   136→    profile = fortune_db.fetch_one(\n   137→        \"SELECT name, gender, birthday_local, tz_offset_hours, location FROM fortune_user WHERE user_id=%s AND deleted_at IS NULL\",\n   138→        (int(user_id),),\n   139→    ) or {}\n   140→    prefs = fortune_db.fetch_one(\n   141→        \"SELECT persona_style, push_enabled, push_time, quiet_hours_start, quiet_hours_end, chat_backend FROM fortune_user_preferences WHERE user_id=%s\",\n   142→        (int(user_id),),\n   143→    ) or {}\n   144→    snap = fortune_db.fetch_one(\n   145→        \"SELECT facts, facts_hash, compute_version FROM fortune_bazi_snapshot WHERE user_id=%s ORDER BY created_at DESC LIMIT 1\",\n   146→        (int(user_id),),\n   147→    ) or {}\n   148→    return profile, prefs, snap\n   149→\n   150→\n   151→def _write_agent_run_log(\n   152→    user_id: int,\n   153→    session_id: Optional[str],\n   154→    agent_name: str,\n   155→    prompt_version: str,\n   156→    facts_hash: Optional[str],\n   157→    input_data: Dict[str, Any],\n   158→    output_data: Dict[str, Any],\n   159→    tool_calls: Optional[List[Dict[str, Any]]] = None,\n   160→    usage: Optional[Dict[str, Any]] = None,\n   161→    latency_ms: Optional[int] = None,\n   162→    error: Optional[str] = None,\n   163→) -> None:\n   164→    \"\"\"\n   165→    Write audit log to fortune_agent_run table.\n   166→\n   167→    REQ: REQ-AGENT-006 (Audit)\n   168→    \"\"\"\n   169→    try:\n   170→        fortune_db.execute(\n   171→            \"\"\"\n   172→            INSERT INTO fortune_agent_run (\n   173→                user_id, session_id, agent_name, prompt_version, facts_hash,\n   174→                input, output, tool_calls, usage, latency_ms, error, created_at\n   175→            ) VALUES (%s, %s::uuid, %s, %s, %s, %s::jsonb, %s::jsonb, %s::jsonb, %s::jsonb, %s, %s, now())\n   176→            \"\"\",\n   177→            [\n   178→                user_id,\n   179→                session_id if session_id else None,\n   180→                agent_name,\n   181→                prompt_version,\n   182→                facts_hash,\n   183→                json.dumps(input_data, ensure_ascii=False, default=str),\n   184→                json.dumps(output_data, ensure_ascii=False, default=str),\n   185→                json.dumps(tool_calls, ensure_ascii=False) if tool_calls else None,\n   186→                json.dumps(usage, ensure_ascii=False) if usage else None,\n   187→                latency_ms,\n   188→                error,\n   189→            ],\n   190→        )\n   191→    except Exception as e:\n   192→        # Log but don't fail the request\n   193→        import logging\n   194→        logging.getLogger(__name__).warning(\"Failed to write agent run log: %s\", str(e))\n   195→\n   196→\n   197→def _a2ui_from_text(text: str) -> Dict[str, Any]:\n   198→    raw = (text or \"\").strip()\n   199→    obj = glm_client.extract_json_object(raw)\n   200→    if isinstance(obj, dict):\n   201→        norm = _normalize_a2ui(obj)\n   202→        if isinstance(norm, dict):\n   203→            try:\n   204→                validate_a2ui(norm)\n   205→                return norm\n   206→            except Exception:\n   207→                pass\n   208→    # Fallback: wrap as markdown_text A2UI\n   209→    summary = raw.splitlines()[0].strip()[:120] if raw else \"输出\"\n   210→    return {\n   211→        \"meta\": {\"summary\": summary},\n   212→        \"ui_components\": [\n   213→            {\"type\": \"markdown_text\", \"title\": \"输出\", \"data\": raw or \"（空）\"},\n   214→            {\"type\": \"action_buttons\", \"title\": \"下一步\", \"data\": []},\n   215→        ],\n   216→    }\n   217→\n   218→\n   219→def _normalize_action(action: Dict[str, Any]) -> Dict[str, Any]:\n   220→    a = dict(action or {})\n   221→    # common variants\n   222→    if a.get(\"type\") == \"open_panel\" and \"panel\" not in a and \"panel_id\" in a:\n   223→        a[\"panel\"] = a.get(\"panel_id\")\n   224→    return a\n   225→\n   226→\n   227→def _normalize_action_button(btn: Any) -> Dict[str, Any]:\n   228→    if not isinstance(btn, dict):\n   229→        return {\"label\": str(btn), \"action\": {\"type\": \"opt_out\"}}\n   230→    label = str(btn.get(\"label\") or btn.get(\"text\") or \"下一步\")\n   231→    action = btn.get(\"action\")\n   232→    if isinstance(action, dict):\n   233→        a = _normalize_action(action)\n   234→        if not a.get(\"type\"):\n   235→            a[\"type\"] = \"opt_out\"\n   236→        return {\"label\": label, \"action\": a}\n   237→    action_type = btn.get(\"action_type\") or btn.get(\"type\") or \"opt_out\"\n   238→    payload = btn.get(\"payload\") if isinstance(btn.get(\"payload\"), dict) else {}\n   239→    a = {\"type\": str(action_type)}\n   240→    a.update(payload)\n   241→    return {\"label\": label, \"action\": _normalize_action(a)}\n   242→\n   243→\n   244→def _normalize_a2ui(obj: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n   245→    if not isinstance(obj, dict):\n   246→        return None\n   247→    meta = obj.get(\"meta\")\n   248→    if not isinstance(meta, dict):\n   249→        meta = {}\n   250→\n   251→    comps = obj.get(\"ui_components\")\n   252→    if not isinstance(comps, list):\n   253→        # tolerate alternative root key\n   254→        comps = obj.get(\"components\") if isinstance(obj.get(\"components\"), list) else []\n   255→\n   256→    out_comps: List[Dict[str, Any]] = []\n   257→    for c in comps:\n   258→        if not isinstance(c, dict):\n   259→            continue\n   260→        t = str(c.get(\"type\") or \"\").strip()\n   261→        if not t:\n   262→            continue\n   263→        title = str(c.get(\"title\") or (\"教练回复\" if t == \"markdown_text\" else \"下一步\" if t == \"action_buttons\" else \"组件\"))\n   264→        data = c.get(\"data\")\n   265→        if data is None and \"content\" in c:\n   266→            data = c.get(\"content\")\n   267→        if t == \"action_buttons\":\n   268→            if data is None and \"actions\" in c:\n   269→                data = c.get(\"actions\")\n   270→            if isinstance(data, list):\n   271→                data = [_normalize_action_button(b) for b in data]\n   272→            else:\n   273→                data = []\n   274→        if t == \"markdown_text\" and not isinstance(data, str):\n   275→            data = \"\" if data is None else str(data)\n   276→        out_comps.append({\"type\": t, \"title\": title, \"data\": data})\n   277→\n   278→    if not out_comps:\n   279→        return None\n   280→    # Ensure markdown_text is first component for renderer compatibility.\n   281→    for i, c in enumerate(out_comps):\n   282→        if c.get(\"type\") == \"markdown_text\":\n   283→            if i != 0:\n   284→                out_comps.insert(0, out_comps.pop(i))\n   285→            break\n   286→\n   287→    meta_out = dict(meta)\n   288→    if not isinstance(meta_out.get(\"summary\"), str):\n   289→        meta_out[\"summary\"] = str(meta_out.get(\"summary\") or \"\")\n   290→    return {\"meta\": meta_out, \"ui_components\": out_comps}\n   291→\n   292→\n   293→_PRES_LINE_RE = re.compile(r\"^\\s*\\d+[\\.\\)]\\s*(.+?)\\s*$\")\n   294→_BULLET_LINE_RE = re.compile(r\"^\\s*[-*]\\s*(.+?)\\s*$\")\n   295→_MD_INLINE_RE = re.compile(r\"[*_`]+\")\n   296→\n   297→# =============================================================================\n   298→# Intent Detection for Yunshi\n   299→# =============================================================================\n   300→\n   301→YUNSHI_DAILY_KEYWORDS = [\n   302→    \"今日运势\", \"今天运势\", \"今天的运势\", \"今日的运势\",\n   303→    \"今日运气\", \"今天运气\", \"今天如何\", \"今天怎么样\",\n   304→    \"今日吉凶\", \"今天吉凶\", \"运势如何\", \"运势怎么样\",\n   305→    \"每日运势\", \"日运\",\n   306→]\n   307→\n   308→YUNSHI_ANNUAL_KEYWORDS = [\n   309→    \"流年\", \"今年运势\", \"年运势\", \"今年运气\", \"明年运势\",\n   310→    \"年度运势\", \"今年如何\", \"今年怎么样\", \"年运\",\n   311→]\n   312→\n   313→def detect_yunshi_intent(text: str) -> Optional[str]:\n   314→    \"\"\"\n   315→    检测用户消息是否为运势查询意图\n   316→\n   317→    Returns:\n   318→        - \"daily\": 今日运势查询\n   319→        - \"annual\": 流年运势查询\n   320→        - None: 非运势查询\n   321→    \"\"\"\n   322→    t = (text or \"\").strip().lower()\n   323→    if not t:\n   324→        return None\n   325→\n   326→    for kw in YUNSHI_DAILY_KEYWORDS:\n   327→        if kw in t:\n   328→            return \"daily\"\n   329→\n   330→    for kw in YUNSHI_ANNUAL_KEYWORDS:\n   331→        if kw in t:\n   332→            return \"annual\"\n   333→\n   334→    return None\n   335→\n   336→\n   337→def handle_yunshi_intent(\n   338→    user_id: int,\n   339→    session_id: str,\n   340→    intent: str,\n   341→    user_text: str,\n   342→) -> Optional[Dict[str, Any]]:\n   343→    \"\"\"\n   344→    处理运势查询意图，返回 A2UI 格式响应\n   345→\n   346→    Returns:\n   347→        - Dict with a2ui, suggested_tasks, backend if handled\n   348→        - None if should fall through to LLM\n   349→    \"\"\"\n   350→    try:\n   351→        from datetime import date, datetime\n   352→\n   353→        if intent == \"daily\":\n   354→            yunshi = yunshi_service.compute_daily_yunshi(user_id, target_date=date.today())\n   355→            a2ui = build_daily_yunshi_a2ui(yunshi)\n   356→\n   357→            # 提取处方作为任务\n   358→            suggested_tasks = []\n   359→            for p in yunshi.prescriptions[:2]:\n   360→                from stores import fortune_db\n   361→                row = fortune_db.execute_returning_one(\n   362→                    \"\"\"\n   363→                    INSERT INTO fortune_commitment (user_id, session_id, source, commitment_type, title, details, status, yunshi_snapshot_id)\n   364→                    VALUES (%s, %s, 'yunshi', 'start_task', %s, '{}'::jsonb, 'suggested', NULL)\n   365→                    RETURNING task_id\n   366→                    \"\"\",\n   367→                    (int(user_id), session_id, p.content[:200]),\n   368→                )\n   369→                if row and row.get(\"task_id\"):\n   370→                    suggested_tasks.append({\"task_id\": str(row[\"task_id\"]), \"title\": p.content})\n   371→\n   372→            # 确保 action_buttons 包含任务\n   373→            if a2ui.get(\"ui_components\"):\n   374→                for comp in a2ui[\"ui_components\"]:\n   375→                    if comp.get(\"type\") == \"action_buttons\":\n   376→                        buttons = []\n   377→                        for t in suggested_tasks[:2]:\n   378→                            buttons.append({\n   379→                                \"label\": f\"开始：{t['title'][:12]}...\",\n   380→                                \"action\": {\"type\": \"start_task\", \"task_id\": t[\"task_id\"]},\n   381→                            })\n   382→                        buttons.append({\"label\": \"查看详细运势\", \"action\": {\"type\": \"open_panel\", \"panel\": \"yunshi\"}})\n   383→                        buttons.append({\"label\": \"先不需要\", \"action\": {\"type\": \"opt_out\"}})\n   384→                        comp[\"data\"] = buttons\n   385→                        break\n   386→\n   387→            md = yunshi.summary\n   388→            return {\n   389→                \"a2ui\": a2ui,\n   390→                \"content\": md,\n   391→                \"suggested_tasks\": suggested_tasks,\n   392→                \"backend\": \"yunshi\",\n   393→            }\n   394→\n   395→        elif intent == \"annual\":\n   396→            target_year = datetime.now().year\n   397→            yunshi = yunshi_service.compute_annual_yunshi(user_id, target_year=target_year)\n   398→            a2ui = build_annual_yunshi_a2ui(yunshi)\n   399→\n   400→            # 流年不生成即时任务\n   401→            suggested_tasks = []\n   402→\n   403→            md = yunshi.summary\n   404→            return {\n   405→                \"a2ui\": a2ui,\n   406→                \"content\": md,\n   407→                \"suggested_tasks\": suggested_tasks,\n   408→                \"backend\": \"yunshi\",\n   409→            }\n   410→\n   411→    except Exception as e:\n   412→        import logging\n   413→        logging.getLogger(__name__).warning(f\"Yunshi intent handling failed: {e}\")\n   414→        return None\n   415→\n   416→    return None\n   417→\n   418→\n   419→def _strip_md(text: str) -> str:\n   420→    s = _MD_INLINE_RE.sub(\"\", text or \"\")\n   421→    s = re.sub(r\"\\s+\", \" \", s).strip()\n   422→    return s\n   423→\n   424→\n   425→def _short_label(text: str, max_len: int = 14) -> str:\n   426→    s = _strip_md(text)\n   427→    s = re.sub(r\"^\\d+[\\.\\)]\\s*\", \"\", s).strip()\n   428→    if len(s) > max_len:\n   429→        s = s[: max_len - 3].rstrip() + \"...\"\n   430→    return s or \"行动\"\n   431→\n   432→\n   433→def _extract_prescriptions(md: str) -> List[str]:\n   434→    lines = [ln.strip() for ln in (md or \"\").splitlines() if ln.strip()]\n   435→    start: Optional[int] = None\n   436→    for i, ln in enumerate(lines):\n   437→        if \"处方\" in ln and not _PRES_LINE_RE.match(ln):\n   438→            start = i + 1\n   439→            break\n   440→    if start is None:\n   441→        return []\n   442→    out: List[str] = []\n   443→    for ln in lines[start:]:\n   444→        if ln.startswith(\"#\"):\n   445→            break\n   446→        m = _PRES_LINE_RE.match(ln) or _BULLET_LINE_RE.match(ln)\n   447→        if m:\n   448→            item = _strip_md(m.group(1))\n   449→            if item:\n   450→                out.append(item)\n   451→        if len(out) >= 3:\n   452→            break\n   453→    return out\n   454→\n   455→\n   456→def _insert_suggested_tasks(user_id: int, session_id: str, prescriptions: List[str]) -> List[Dict[str, Any]]:\n   457→    tasks: List[Dict[str, Any]] = []\n   458→    for p in prescriptions[:3]:\n   459→        title = _strip_md(p) or \"行动\"\n   460→        row = fortune_db.execute_returning_one(\n   461→            \"\"\"\n   462→            INSERT INTO fortune_commitment (user_id, session_id, source, commitment_type, title, details, status)\n   463→            VALUES (%s, %s, 'chat', 'start_task', %s, '{}'::jsonb, 'suggested')\n   464→            RETURNING task_id\n   465→            \"\"\",\n   466→            (int(user_id), session_id, title[:200]),\n   467→        )\n   468→        if row and row.get(\"task_id\"):\n   469→            tasks.append({\"task_id\": str(row[\"task_id\"]), \"title\": title})\n   470→    return tasks\n   471→\n   472→\n   473→def _ensure_action_buttons(a2ui: Dict[str, Any], suggested_tasks: List[Dict[str, Any]]) -> None:\n   474→    buttons = []\n   475→    for t in suggested_tasks[:2]:\n   476→        title = _short_label(str(t.get(\"title\") or \"\"))\n   477→        buttons.append({\"label\": f\"开始：{title}\", \"action\": {\"type\": \"start_task\", \"task_id\": str(t[\"task_id\"])}})\n   478→    if suggested_tasks:\n   479→        buttons.append({\"label\": \"加入今日计划\", \"action\": {\"type\": \"schedule_task\", \"task_id\": str(suggested_tasks[0][\"task_id\"])}})\n   480→    buttons.append({\"label\": \"打开功能区\", \"action\": {\"type\": \"open_panel\", \"panel\": \"bento\"}})\n   481→    buttons.append({\"label\": \"先不需要\", \"action\": {\"type\": \"opt_out\"}})\n   482→\n   483→    comps = a2ui.get(\"ui_components\")\n   484→    if not isinstance(comps, list):\n   485→        a2ui[\"ui_components\"] = comps = []\n   486→\n   487→    for c in comps:\n   488→        if isinstance(c, dict) and c.get(\"type\") == \"action_buttons\":\n   489→            c[\"data\"] = buttons\n   490→            return\n   491→\n   492→    comps.append({\"type\": \"action_buttons\", \"title\": \"下一步\", \"data\": buttons})\n   493→\n   494→\n   495→def _assistant_markdown(a2ui: Dict[str, Any]) -> str:\n   496→    comps = a2ui.get(\"ui_components\") or []\n   497→    if isinstance(comps, list) and comps:\n   498→        first = comps[0] if isinstance(comps[0], dict) else None\n   499→        if first and isinstance(first.get(\"data\"), str):\n   500→            return first[\"data\"]\n   501→    return json.dumps(a2ui, ensure_ascii=False)\n   502→\n   503→\n   504→@router.post(\"/send\")\n   505→def chat_send(req: ChatSendRequest, request: Request):\n   506→    \"\"\"\n   507→    Send a chat message and get AI response.\n   508→\n   509→    Supports two backends based on user preference:\n   510→    - fastapi: Direct LLM call (default, current implementation)\n   511→    - agent_service: Vercel AI SDK orchestration (future)\n   512→\n   513→    Also writes audit log to fortune_agent_run for compliance.\n   514→    \"\"\"\n   515→    import time as time_module\n   516→\n   517→    auth = require_auth(request)\n   518→    require_csrf(request, auth)\n   519→    user_id = int(auth[\"user_id\"])\n   520→\n   521→    session_id = (req.session_id or \"\").strip()\n   522→    if session_id and not _UUID_RE.match(session_id):\n   523→        return _err(400, \"invalid_request\", \"invalid_session_id\")\n   524→\n   525→    if not session_id:\n   526→        s = chat_service.create_session(user_id, title=\"\")\n   527→        session_id = s[\"session_id\"]\n   528→    else:\n   529→        if not chat_service.get_session(user_id, session_id):\n   530→            return _err(404, \"not_found\", \"session_not_found\")\n   531→\n   532→    user_text = req.text.strip()\n   533→    if not user_text:\n   534→        return _err(400, \"invalid_request\", \"empty_text\")\n   535→\n   536→    model_name = (os.getenv(\"FORTUNE_AI_GLM_MODEL\") or \"glm-4.7\").strip()\n   537→\n   538→    # Save user message\n   539→    chat_service.append_message(session_id=session_id, user_id=user_id, role=\"user\", content=user_text, model=model_name)\n   540→    chat_service.set_title_if_empty(session_id, user_text[:24])\n   541→\n   542→    profile, prefs, snap = _load_user_context(user_id)\n   543→    if not snap or not snap.get(\"facts\") or not snap.get(\"facts_hash\"):\n   544→        snap = bazi_facts.ensure_snapshot_for_user(user_id)\n   545→\n   546→    # 使用 soul_os 获取完整上下文\n   547→    full_context = soul_os.get_full_context_for_chat(user_id, user_text)\n   548→\n   549→    # 反依赖检查\n   550→    anti_dep = full_context.get(\"anti_dependency\", {})\n   551→    if anti_dep.get(\"should_intervene\"):\n   552→        # 返回反依赖干预消息\n   553→        intervention_msg = anti_dep.get(\"intervention_message\", \"\")\n   554→        a2ui = {\n   555→            \"meta\": {\"summary\": \"让我们先行动起来\"},\n   556→            \"ui_components\": [\n   557→                {\"type\": \"markdown_text\", \"title\": \"教练提醒\", \"data\": intervention_msg},\n   558→                {\"type\": \"action_buttons\", \"title\": \"下一步\", \"data\": [\n   559→                    {\"label\": \"好的，我去做\", \"action\": {\"type\": \"opt_out\"}},\n   560→                    {\"label\": \"打开任务\", \"action\": {\"type\": \"open_panel\", \"panel\": \"tasks\"}},\n   561→                ]},\n   562→            ],\n   563→        }\n   564→        chat_service.append_message(\n   565→            session_id=session_id,\n   566→            user_id=user_id,\n   567→            role=\"assistant\",\n   568→            content=intervention_msg,\n   569→            a2ui=a2ui,\n   570→            model=\"anti_dependency\",\n   571→        )\n   572→        return _ok({\n   573→            \"session_id\": session_id,\n   574→            \"assistant_message\": {\"role\": \"assistant\", \"a2ui\": a2ui},\n   575→            \"suggested_tasks\": [],\n   576→            \"backend\": \"anti_dependency\",\n   577→            \"intervention_type\": anti_dep.get(\"intervention_type\", \"\"),\n   578→        })\n   579→\n   580→    # ==========================================================================\n   581→    # 运势意图检测 - 优先于 LLM 调用\n   582→    # ==========================================================================\n   583→    yunshi_intent = detect_yunshi_intent(user_text)\n   584→    if yunshi_intent:\n   585→        yunshi_response = handle_yunshi_intent(user_id, session_id, yunshi_intent, user_text)\n   586→        if yunshi_response:\n   587→            a2ui = yunshi_response[\"a2ui\"]\n   588→            md = yunshi_response.get(\"content\", \"\")\n   589→            suggested_tasks = yunshi_response.get(\"suggested_tasks\", [])\n   590→\n   591→            chat_service.append_message(\n   592→                session_id=session_id,\n   593→                user_id=user_id,\n   594→                role=\"assistant\",\n   595→                content=md,\n   596→                a2ui=a2ui,\n   597→                model=\"yunshi\",\n   598→            )\n   599→\n   600→            return _ok({\n   601→                \"session_id\": session_id,\n   602→                \"assistant_message\": {\"role\": \"assistant\", \"a2ui\": a2ui},\n   603→                \"suggested_tasks\": suggested_tasks,\n   604→                \"backend\": \"yunshi\",\n   605→            })\n   606→\n   607→    # Check chat backend preference\n   608→    chat_backend = str(prefs.get(\"chat_backend\") or default_chat_backend())\n   609→    start_time = time_module.time()\n   610→    persona_style = full_context.get(\"persona_style\", \"warm\")\n   611→    facts_obj = snap.get(\"facts\") or {}\n   612→    facts_hash = str(snap.get(\"facts_hash\") or \"\")\n   613→\n   614→    if chat_backend == \"agent_service\":\n   615→        # Try Agent Service backend\n   616→        try:\n   617→            # Build messages for agent service\n   618→            hist = chat_service.get_recent_messages_for_llm(user_id, session_id, limit=10)\n   619→            agent_messages = [{\"role\": m.get(\"role\", \"user\"), \"content\": str(m.get(\"content\") or \"\")} for m in hist]\n   620→\n   621→            agent_response = agent_service_client.call_agent_service_sync(\n   622→                user_id=user_id,\n   623→                session_id=session_id,\n   624→                messages=agent_messages,\n   625→                user_context={\"profile\": profile, \"preferences\": prefs},\n   626→                facts=facts_obj,\n   627→                persona_style=persona_style,\n   628→            )\n   629→\n   630→            # Process response\n   631→            a2ui = agent_response.a2ui or _a2ui_from_text(agent_response.text)\n   632→            md = _assistant_markdown(a2ui)\n   633→            prescriptions = _extract_prescriptions(md)\n   634→            suggested_tasks = _insert_suggested_tasks(user_id, session_id, prescriptions)\n   635→            _ensure_action_buttons(a2ui, suggested_tasks)\n   636→\n   637→            chat_service.append_message(\n   638→                session_id=session_id,\n   639→                user_id=user_id,\n   640→                role=\"assistant\",\n   641→                content=md,\n   642→                a2ui=a2ui,\n   643→                model=\"agent_service\",\n   644→            )\n   645→\n   646→            # Write audit log\n   647→            latency_ms = int((time_module.time() - start_time) * 1000)\n   648→            _write_agent_run_log(\n   649→                user_id=user_id,\n   650→                session_id=session_id,\n   651→                agent_name=\"coach\",\n   652→                prompt_version=\"agent_service\",\n   653→                facts_hash=facts_hash,\n   654→                input_data={\"user_text\": user_text, \"backend\": \"agent_service\"},\n   655→                output_data={\"a2ui_summary\": a2ui.get(\"meta\", {}).get(\"summary\", \"\"), \"suggested_tasks\": len(suggested_tasks)},\n   656→                latency_ms=latency_ms,\n   657→            )\n   658→\n   659→            return _ok(\n   660→                {\n   661→                    \"session_id\": session_id,\n   662→                    \"assistant_message\": {\"role\": \"assistant\", \"a2ui\": a2ui},\n   663→                    \"suggested_tasks\": suggested_tasks,\n   664→                    \"backend\": \"agent_service\",\n   665→                }\n   666→            )\n   667→\n   668→        except agent_service_client.AgentServiceUnavailable:\n   669→            # Fall back to FastAPI if agent service unavailable\n   670→            pass\n   671→        except agent_service_client.AgentServiceError as e:\n   672→            # Log error and fall back\n   673→            latency_ms = int((time_module.time() - start_time) * 1000)\n   674→            _write_agent_run_log(\n   675→                user_id=user_id,\n   676→                session_id=session_id,\n   677→                agent_name=\"coach\",\n   678→                prompt_version=\"agent_service\",\n   679→                facts_hash=facts_hash,\n   680→                input_data={\"user_text\": user_text, \"backend\": \"agent_service\"},\n   681→                output_data={},\n   682→                latency_ms=latency_ms,\n   683→                error=str(e),\n   684→            )\n   685→            # Fall back to FastAPI\n   686→            pass\n   687→\n   688→    # === FastAPI Direct LLM Implementation ===\n   689→    # 使用 soul_os 构建的 system prompt 和 evidence\n   690→    user_context = full_context.get(\"user_context\", {})\n   691→    evidence = full_context.get(\"evidence\", {})\n   692→\n   693→    user_context_json = json.dumps(user_context, ensure_ascii=False, default=str)\n   694→    facts_json = json.dumps(facts_obj, ensure_ascii=False)\n   695→    evidence_json = json.dumps(evidence, ensure_ascii=False)\n   696→\n   697→    # 使用 soul_os 生成的 system prompt\n   698→    system = full_context.get(\"system_prompt\", \"\")\n   699→    if not system:\n   700→        system = SYSTEM_PROMPT_TEMPLATE.safe_substitute(\n   701→            persona_style=persona_style,\n   702→            user_context_json=user_context_json,\n   703→            facts_json=facts_json,\n   704→            evidence_json=evidence_json,\n   705→        )\n   706→\n   707→    # 从 evidence 中提取 kb_refs 用于审计\n   708→    kb_refs = evidence.get(\"kb_refs\", [])\n   709→\n   710→    # Build LLM messages from DB (last 10 turns)\n   711→    hist = chat_service.get_recent_messages_for_llm(user_id, session_id, limit=10)\n   712→    llm_messages = [{\"role\": \"system\", \"content\": system}]\n   713→    for m in hist:\n   714→        role = \"assistant\" if m.get(\"role\") == \"assistant\" else \"user\"\n   715→        llm_messages.append({\"role\": role, \"content\": str(m.get(\"content\") or \"\")})\n   716→\n   717→    error_msg = None\n   718→    try:\n   719→        raw_text, raw = glm_client.call_chat_completions(messages=llm_messages)\n   720→    except glm_client.GlmError as e:\n   721→        error_msg = str(e)\n   722→        # Write audit log for failed request\n   723→        latency_ms = int((time_module.time() - start_time) * 1000)\n   724→        _write_agent_run_log(\n   725→            user_id=user_id,\n   726→            session_id=session_id,\n   727→            agent_name=\"coach\",\n   728→            prompt_version=\"v1.0\",\n   729→            facts_hash=facts_hash,\n   730→            input_data={\"user_text\": user_text, \"kb_refs\": kb_refs},\n   731→            output_data={},\n   732→            latency_ms=latency_ms,\n   733→            error=error_msg,\n   734→        )\n   735→        return _err(500, \"glm_error\", error_msg)\n   736→\n   737→    a2ui = _a2ui_from_text(raw_text)\n   738→    md = _assistant_markdown(a2ui)\n   739→    prescriptions = _extract_prescriptions(md)\n   740→    suggested_tasks = _insert_suggested_tasks(user_id, session_id, prescriptions)\n   741→    _ensure_action_buttons(a2ui, suggested_tasks)\n   742→\n   743→    usage = raw.get(\"usage\") if isinstance(raw, dict) else {}\n   744→    prompt_tokens = int(usage.get(\"prompt_tokens\") or usage.get(\"input_tokens\") or 0) if isinstance(usage, dict) else 0\n   745→    completion_tokens = int(usage.get(\"completion_tokens\") or usage.get(\"output_tokens\") or 0) if isinstance(usage, dict) else 0\n   746→\n   747→    chat_service.append_message(\n   748→        session_id=session_id,\n   749→        user_id=user_id,\n   750→        role=\"assistant\",\n   751→        content=md,\n   752→        a2ui=a2ui,\n   753→        model=str(raw.get(\"model\") or model_name),\n   754→        prompt_tokens=prompt_tokens,\n   755→        completion_tokens=completion_tokens,\n   756→    )\n   757→\n   758→    # Write audit log for successful request\n   759→    latency_ms = int((time_module.time() - start_time) * 1000)\n   760→    _write_agent_run_log(\n   761→        user_id=user_id,\n   762→        session_id=session_id,\n   763→        agent_name=\"coach\",\n   764→        prompt_version=\"v1.0\",\n   765→        facts_hash=facts_hash,\n   766→        input_data={\"user_text\": user_text, \"kb_refs\": kb_refs},\n   767→        output_data={\"a2ui_summary\": a2ui.get(\"meta\", {}).get(\"summary\", \"\"), \"suggested_tasks\": len(suggested_tasks)},\n   768→        usage={\"prompt_tokens\": prompt_tokens, \"completion_tokens\": completion_tokens, \"total_tokens\": prompt_tokens + completion_tokens},\n   769→        latency_ms=latency_ms,\n   770→    )\n   771→\n   772→    return _ok(\n   773→        {\n   774→            \"session_id\": session_id,\n   775→            \"assistant_message\": {\"role\": \"assistant\", \"a2ui\": a2ui},\n   776→            \"suggested_tasks\": suggested_tasks,\n   777→            \"backend\": \"fastapi\",\n   778→        }\n   779→    )\n   780→\n   781→\n   782→def _sse_json(obj: Any) -> str:\n   783→    return f\"data: {json.dumps(obj, ensure_ascii=False)}\\n\\n\"\n   784→\n   785→\n   786→@router.get(\"/stream\")\n   787→def chat_stream(\n   788→    request: Request,\n   789→    message: str = Query(..., min_length=1, description=\"User message\"),\n   790→    session_id: Optional[str] = Query(None, description=\"Existing session id\"),\n   791→):\n   792→    \"\"\"\n   793→    Stream chat response via Server-Sent Events (SSE).\n   794→\n   795→    Frontend protocol:\n   796→    - data: {\"type\":\"delta\",\"delta\":\"...\"}  (0..n)\n   797→    - data: {\"type\":\"final\",\"data\":{...}}   (1)\n   798→    - data: [DONE]\n   799→    \"\"\"\n   800→    import time as time_module\n   801→\n   802→    auth = require_auth(request)\n   803→    require_csrf(request, auth)\n   804→    user_id = int(auth[\"user_id\"])\n   805→\n   806→    sid = (session_id or \"\").strip()\n   807→    if sid and not _UUID_RE.match(sid):\n   808→        return _err(400, \"invalid_request\", \"invalid_session_id\")\n   809→\n   810→    if not sid:\n   811→        s = chat_service.create_session(user_id, title=\"\")\n   812→        sid = s[\"session_id\"]\n   813→    else:\n   814→        if not chat_service.get_session(user_id, sid):\n   815→            return _err(404, \"not_found\", \"session_not_found\")\n   816→\n   817→    user_text = (message or \"\").strip()\n   818→    if not user_text:\n   819→        return _err(400, \"invalid_request\", \"empty_text\")\n   820→\n   821→    model_name = (os.getenv(\"FORTUNE_AI_GLM_MODEL\") or \"glm-4.7\").strip()\n   822→\n   823→    # Save user message\n   824→    chat_service.append_message(session_id=sid, user_id=user_id, role=\"user\", content=user_text, model=model_name)\n   825→    chat_service.set_title_if_empty(sid, user_text[:24])\n   826→\n   827→    profile, prefs, snap = _load_user_context(user_id)\n   828→    if not snap or not snap.get(\"facts\") or not snap.get(\"facts_hash\"):\n   829→        snap = bazi_facts.ensure_snapshot_for_user(user_id)\n   830→\n   831→    # Use soul_os to get context + anti-dependency check\n   832→    full_context = soul_os.get_full_context_for_chat(user_id, user_text)\n   833→    anti_dep = full_context.get(\"anti_dependency\", {})\n   834→\n   835→    def gen():\n   836→        start_time = time_module.time()\n   837→        facts_obj = snap.get(\"facts\") or {}\n   838→        facts_hash = str(snap.get(\"facts_hash\") or \"\")\n   839→        persona_style = full_context.get(\"persona_style\", \"warm\")\n   840→\n   841→        # Anti-dependency intervention: return immediately\n   842→        if anti_dep.get(\"should_intervene\"):\n   843→            intervention_msg = str(anti_dep.get(\"intervention_message\", \"\") or \"\")\n   844→            a2ui = {\n   845→                \"meta\": {\"summary\": \"让我们先行动起来\"},\n   846→                \"ui_components\": [\n   847→                    {\"type\": \"markdown_text\", \"title\": \"教练提醒\", \"data\": intervention_msg},\n   848→                    {\"type\": \"action_buttons\", \"title\": \"下一步\", \"data\": [\n   849→                        {\"label\": \"好的，我去做\", \"action\": {\"type\": \"opt_out\"}},\n   850→                        {\"label\": \"打开任务\", \"action\": {\"type\": \"open_panel\", \"panel\": \"tasks\"}},\n   851→                    ]},\n   852→                ],\n   853→            }\n   854→            chat_service.append_message(\n   855→                session_id=sid,\n   856→                user_id=user_id,\n   857→                role=\"assistant\",\n   858→                content=intervention_msg,\n   859→                a2ui=a2ui,\n   860→                model=\"anti_dependency\",\n   861→            )\n   862→            yield _sse_json({\"type\": \"delta\", \"delta\": intervention_msg})\n   863→            yield _sse_json(\n   864→                {\n   865→                    \"type\": \"final\",\n   866→                    \"data\": {\n   867→                        \"session_id\": sid,\n   868→                        \"assistant_message\": {\"role\": \"assistant\", \"a2ui\": a2ui},\n   869→                        \"suggested_tasks\": [],\n   870→                        \"backend\": \"anti_dependency\",\n   871→                        \"intervention_type\": str(anti_dep.get(\"intervention_type\") or \"\"),\n   872→                    },\n   873→                }\n   874→            )\n   875→            yield \"data: [DONE]\\n\\n\"\n   876→            return\n   877→\n   878→        # ==========================================================================\n   879→        # 运势意图检测 - 优先于 LLM 调用\n   880→        # ==========================================================================\n   881→        yunshi_intent = detect_yunshi_intent(user_text)\n   882→        if yunshi_intent:\n   883→            yunshi_response = handle_yunshi_intent(user_id, sid, yunshi_intent, user_text)\n   884→            if yunshi_response:\n   885→                a2ui = yunshi_response[\"a2ui\"]\n   886→                md = yunshi_response.get(\"content\", \"\")\n   887→                suggested_tasks = yunshi_response.get(\"suggested_tasks\", [])\n   888→\n   889→                chat_service.append_message(\n   890→                    session_id=sid,\n   891→                    user_id=user_id,\n   892→                    role=\"assistant\",\n   893→                    content=md,\n   894→                    a2ui=a2ui,\n   895→                    model=\"yunshi\",\n   896→                )\n   897→\n   898→                yield _sse_json({\"type\": \"delta\", \"delta\": md})\n   899→                yield _sse_json(\n   900→                    {\n   901→                        \"type\": \"final\",\n   902→                        \"data\": {\n   903→                            \"session_id\": sid,\n   904→                            \"assistant_message\": {\"role\": \"assistant\", \"a2ui\": a2ui},\n   905→                            \"suggested_tasks\": suggested_tasks,\n   906→                            \"backend\": \"yunshi\",\n   907→                        },\n   908→                    }\n   909→                )\n   910→                yield \"data: [DONE]\\n\\n\"\n   911→                return\n   912→\n   913→        # Determine backend preference\n   914→        preferred_backend = str(prefs.get(\"chat_backend\") or default_chat_backend())\n   915→        yield _sse_json({\"type\": \"meta\", \"session_id\": sid, \"backend\": preferred_backend})\n   916→\n   917→        # Build history (last 10 turns)\n   918→        hist = chat_service.get_recent_messages_for_llm(user_id, sid, limit=10)\n   919→        base_messages = [{\"role\": m.get(\"role\", \"user\"), \"content\": str(m.get(\"content\") or \"\")} for m in hist]\n   920→\n   921→        # Context payload for agent service (if used)\n   922→        agent_context: Dict[str, Any] = {\n   923→            \"user\": {\"profile\": profile, \"preferences\": prefs},\n   924→            \"facts\": facts_obj,\n   925→            \"persona_style\": persona_style,\n   926→            \"output_format\": \"markdown\",\n   927→        }\n   928→\n   929→        full_text_parts: List[str] = []\n   930→        backend_used = preferred_backend\n   931→        tool_calls: Optional[List[Dict[str, Any]]] = None\n   932→\n   933→        # Stream from agent_service when selected and available\n   934→        if preferred_backend == \"agent_service\":\n   935→            try:\n   936→                import httpx\n   937→                if not agent_service_client.is_agent_service_configured():\n   938→                    raise agent_service_client.AgentServiceUnavailable(\"Agent service not configured\")\n   939→\n   940→                payload = {\n   941→                    \"user_id\": user_id,\n   942→                    \"session_id\": sid,\n   943→                    \"messages\": [{\"role\": m.get(\"role\", \"user\"), \"content\": str(m.get(\"content\") or \"\")} for m in hist],\n   944→                    \"stream\": True,\n   945→                    \"context\": agent_context,\n   946→                }\n   947→\n   948→                headers = {\n   949→                    \"Content-Type\": \"application/json\",\n   950→                    \"Authorization\": f\"Bearer {agent_service_client.AGENT_SERVICE_TOKEN}\",\n   951→                }\n   952→\n   953→                with httpx.Client(timeout=agent_service_client.AGENT_SERVICE_TIMEOUT) as client:\n   954→                    with client.stream(\"POST\", f\"{agent_service_client.AGENT_SERVICE_URL}/api/chat\", json=payload, headers=headers) as resp:\n   955→                        if resp.status_code == 503:\n   956→                            raise agent_service_client.AgentServiceUnavailable(\"Agent service temporarily unavailable\")\n   957→                        if resp.status_code != 200:\n   958→                            raise agent_service_client.AgentServiceError(f\"Agent service error: {resp.status_code}\")\n   959→\n   960→                        for raw_line in resp.iter_lines():\n   961→                            line = (raw_line or \"\").strip()\n   962→                            if not line or not line.startswith(\"data:\"):\n   963→                                continue\n   964→                            data = line[5:].strip()\n   965→                            if not data:\n   966→                                continue\n   967→                            try:\n   968→                                evt = json.loads(data)\n   969→                            except Exception:\n   970→                                continue\n   971→                            if not isinstance(evt, dict):\n   972→                                continue\n   973→                            if evt.get(\"type\") == \"text\" and isinstance(evt.get(\"content\"), str):\n   974→                                delta = str(evt.get(\"content\") or \"\")\n   975→                                if delta:\n   976→                                    full_text_parts.append(delta)\n   977→                                    yield _sse_json({\"type\": \"delta\", \"delta\": delta})\n   978→                            if evt.get(\"type\") == \"done\":\n   979→                                if isinstance(evt.get(\"text\"), str) and evt.get(\"text\"):\n   980→                                    full_text_parts = [str(evt.get(\"text\") or \"\")]\n   981→                                if isinstance(evt.get(\"tool_calls\"), list):\n   982→                                    tool_calls = evt.get(\"tool_calls\")\n   983→                                break\n   984→            except Exception:\n   985→                backend_used = \"fastapi\"\n   986→\n   987→        # Stream from direct LLM (fastapi)\n   988→        if backend_used != \"agent_service\":\n   989→            user_context = full_context.get(\"user_context\", {})\n   990→            evidence = full_context.get(\"evidence\", {})\n   991→            kb_refs = evidence.get(\"kb_refs\", [])\n   992→\n   993→            user_context_json = json.dumps(user_context, ensure_ascii=False, default=str)\n   994→            facts_json = json.dumps(facts_obj, ensure_ascii=False)\n   995→            evidence_json = json.dumps(evidence, ensure_ascii=False)\n   996→\n   997→            system_stream = SYSTEM_PROMPT_STREAM_TEMPLATE.safe_substitute(\n   998→                persona_style=persona_style,\n   999→                user_context_json=user_context_json,\n  1000→                facts_json=facts_json,\n  1001→                evidence_json=evidence_json,\n  1002→            )\n  1003→\n  1004→            llm_messages = [{\"role\": \"system\", \"content\": system_stream}]\n  1005→            for m in hist:\n  1006→                role = \"assistant\" if m.get(\"role\") == \"assistant\" else \"user\"\n  1007→                llm_messages.append({\"role\": role, \"content\": str(m.get(\"content\") or \"\")})\n  1008→\n  1009→            try:\n  1010→                got_any = False\n  1011→                for delta in glm_client.stream_chat_completions(messages=llm_messages):\n  1012→                    if delta:\n  1013→                        got_any = True\n  1014→                        full_text_parts.append(delta)\n  1015→                        yield _sse_json({\"type\": \"delta\", \"delta\": delta})\n  1016→                if not got_any:\n  1017→                    # Provider may not support streaming; fall back to non-streaming and simulate deltas.\n  1018→                    raw_text, _raw = glm_client.call_chat_completions(messages=llm_messages)\n  1019→                    raw_text = str(raw_text or \"\")\n  1020→                    for i in range(0, len(raw_text), 48):\n  1021→                        chunk = raw_text[i : i + 48]\n  1022→                        if chunk:\n  1023→                            full_text_parts.append(chunk)\n  1024→                            yield _sse_json({\"type\": \"delta\", \"delta\": chunk})\n  1025→            except glm_client.GlmError as e:\n  1026→                # Try a non-streaming fallback before failing.\n  1027→                try:\n  1028→                    raw_text, _raw = glm_client.call_chat_completions(messages=llm_messages)\n  1029→                    raw_text = str(raw_text or \"\")\n  1030→                    for i in range(0, len(raw_text), 48):\n  1031→                        chunk = raw_text[i : i + 48]\n  1032→                        if chunk:\n  1033→                            full_text_parts.append(chunk)\n  1034→                            yield _sse_json({\"type\": \"delta\", \"delta\": chunk})\n  1035→                except glm_client.GlmError:\n  1036→                    err = str(e)\n  1037→                    latency_ms = int((time_module.time() - start_time) * 1000)\n  1038→                    _write_agent_run_log(\n  1039→                        user_id=user_id,\n  1040→                        session_id=sid,\n  1041→                        agent_name=\"coach\",\n  1042→                        prompt_version=\"v1.0-stream\",\n  1043→                        facts_hash=facts_hash,\n  1044→                        input_data={\"user_text\": user_text, \"kb_refs\": kb_refs, \"backend\": \"fastapi\"},\n  1045→                        output_data={},\n  1046→                        latency_ms=latency_ms,\n  1047→                        error=err,\n  1048→                    )\n  1049→                    yield _sse_json({\"type\": \"error\", \"error\": err})\n  1050→                    yield \"data: [DONE]\\n\\n\"\n  1051→                    return\n  1052→\n  1053→        full_text = \"\".join(full_text_parts).strip()\n  1054→        a2ui = _a2ui_from_text(full_text)\n  1055→        md = _assistant_markdown(a2ui)\n  1056→        prescriptions = _extract_prescriptions(md)\n  1057→        suggested_tasks = _insert_suggested_tasks(user_id, sid, prescriptions)\n  1058→        _ensure_action_buttons(a2ui, suggested_tasks)\n  1059→\n  1060→        chat_service.append_message(\n  1061→            session_id=sid,\n  1062→            user_id=user_id,\n  1063→            role=\"assistant\",\n  1064→            content=md,\n  1065→            a2ui=a2ui,\n  1066→            model=(\"agent_service\" if backend_used == \"agent_service\" else model_name),\n  1067→        )\n  1068→\n  1069→        latency_ms = int((time_module.time() - start_time) * 1000)\n  1070→        _write_agent_run_log(\n  1071→            user_id=user_id,\n  1072→            session_id=sid,\n  1073→            agent_name=\"coach\",\n  1074→            prompt_version=(\"agent_service-stream\" if backend_used == \"agent_service\" else \"v1.0-stream\"),\n  1075→            facts_hash=facts_hash,\n  1076→            input_data={\"user_text\": user_text, \"backend\": backend_used},\n  1077→            output_data={\"a2ui_summary\": a2ui.get(\"meta\", {}).get(\"summary\", \"\"), \"suggested_tasks\": len(suggested_tasks)},\n  1078→            tool_calls=tool_calls,\n  1079→            latency_ms=latency_ms,\n  1080→        )\n  1081→\n  1082→        yield _sse_json(\n  1083→            {\n  1084→                \"type\": \"final\",\n  1085→                \"data\": {\n  1086→                    \"session_id\": sid,\n  1087→                    \"assistant_message\": {\"role\": \"assistant\", \"a2ui\": a2ui},\n  1088→                    \"suggested_tasks\": suggested_tasks,\n  1089→                    \"backend\": backend_used,\n  1090→                },\n  1091→            }\n  1092→        )\n  1093→        yield \"data: [DONE]\\n\\n\"\n  1094→\n  1095→    headers = {\n  1096→        \"Cache-Control\": \"no-cache\",\n  1097→        \"X-Accel-Buffering\": \"no\",\n  1098→    }\n  1099→    return StreamingResponse(gen(), media_type=\"text/event-stream\", headers=headers)\n  1100→\n  1101→\n  1102→@router.post(\"/ask\")\n  1103→def chat_ask_alias(req: ChatSendRequest, request: Request):\n  1104→    # Backward-compatible alias for /api/chat/send\n  1105→    return chat_send(req, request)\n  1106→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"3bcd7491-ca85-495f-a428-6b118a59431c","timestamp":"2026-01-01T15:01:16.882Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aiscend/work/fortune_ai/api/chat_routes.py","content":"from __future__ import annotations\n\nimport json\nimport os\nimport re\nfrom string import Template\nfrom typing import Any, Dict, List, Optional, Tuple\n\nfrom fastapi import APIRouter, Request, Query\nfrom fastapi.responses import JSONResponse, StreamingResponse\nfrom pydantic import BaseModel, Field\n\nfrom api.deps import require_auth, require_csrf\nfrom common.a2ui import validate_a2ui\nfrom services import chat_service\nfrom services import glm_client\nfrom services import bazi_facts\nfrom services import kb_service\nfrom services import agent_service_client\nfrom services import soul_os\nfrom services.chat_backend_config import default_chat_backend\nfrom services.yunshi_service import yunshi_service, build_daily_yunshi_a2ui, build_annual_yunshi_a2ui\nfrom stores import fortune_db\n\n\nrouter = APIRouter(prefix=\"/api/chat\", tags=[\"chat\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n\ndef _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    return JSONResponse(\n        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n        status_code=status,\n    )\n\n\nclass ChatSendRequest(BaseModel):\n    session_id: Optional[str] = Field(None)\n    text: str = Field(..., min_length=1)\n\n\n_UUID_RE = re.compile(r\"^[0-9a-fA-F-]{36}$\")\n\n\nSYSTEM_PROMPT_TEMPLATE = Template(\"\"\"你是 Fortune AI 的对话 Agent，角色是积极心理学教练（Performance Coach）。\n\n【产品定位】\n人生导航 / 陪伴 / 提升。系统和交互保持“有效而极简”。\n\n【你的优先级（不可逆）】\nCoach > Teaching Assistant > Customer Support > Sales\n\n【硬性规则（必须遵守）】\n1) 禁止恐吓、羞辱、宿命论断言；负面信息必须紧接“你可以做什么”的行动处方。\n2) 禁止自行计算八字事实；只能基于提供的 facts + evidence 输出。\n3) 每次输出必须包含：结论(conclusion) + 依据(why) + ≤3条处方(prescriptions) + 承诺邀请(commitment_ask)。\n4) 时间窗口默认只给干预窗口（intervention）；forecast 只能条件句+低置信度。\n5) 输出必须是 A2UI JSON，且第一组件必须是 markdown_text。\n6) 必须给出可点击 actions（start_task / schedule_task / open_panel / opt_out）。\n\n【语言风格 persona_style】\nstandard：清晰、中性、专业\nwarm：共情、支持性（默认）\nroast：轻毒舌但不羞辱、不对人格做负面定性\n\n【输入（系统已注入）】\npersona_style: $persona_style\nuser_context: $user_context_json\nfacts: $facts_json\nevidence: $evidence_json\n\n【输出（必须严格仅输出 JSON）】\n返回 A2UI JSON，结构：\n- meta.summary：一句话摘要\n- ui_components[0]：markdown_text（必须，包含：结论要点/依据/处方/时间窗口/边界/承诺邀请）\n- ui_components[1]：action_buttons（必须，按钮结构：{label, action:{type, ...}}）\n\n严格按以下字段名输出（不要用 content/actions/action_type/payload 等变体；不要代码块；不要额外文本）：\n{\n  \"meta\": {\"summary\": \"...\"},\n  \"ui_components\": [\n    {\"type\":\"markdown_text\",\"title\":\"教练回复\",\"data\":\"...markdown...\"},\n    {\"type\":\"action_buttons\",\"title\":\"下一步\",\"data\":[\n      {\"label\":\"开始（2-5分钟）\",\"action\":{\"type\":\"start_task\",\"task_id\":\"...\"}},\n      {\"label\":\"加入今日计划\",\"action\":{\"type\":\"schedule_task\",\"task_id\":\"...\"}},\n      {\"label\":\"打开功能区\",\"action\":{\"type\":\"open_panel\",\"panel\":\"bento\"}},\n      {\"label\":\"先不需要\",\"action\":{\"type\":\"opt_out\"}}\n    ]}\n  ]\n}\n\"\"\")\n\nSYSTEM_PROMPT_STREAM_TEMPLATE = Template(\"\"\"你是 Fortune AI 的对话 Agent，角色是积极心理学教练（Performance Coach）。\n\n【产品定位】\n人生导航 / 陪伴 / 提升。系统和交互保持“有效而极简”。\n\n【你的优先级（不可逆）】\nCoach > Teaching Assistant > Customer Support > Sales\n\n【硬性规则（必须遵守）】\n1) 禁止恐吓、羞辱、宿命论断言；负面信息必须紧接“你可以做什么”的行动处方。\n2) 禁止自行计算八字事实；只能基于提供的 facts + evidence 输出。\n3) 每次输出必须包含：结论(conclusion) + 依据(why) + ≤3条处方(prescriptions) + 承诺邀请(commitment_ask)。\n4) 每条处方必须包含 if_then：如果____→那么____；并优先给 2–5 分钟可启动版本。\n5) 只输出 Markdown 文本，不要 JSON/代码块/额外说明。\n\n【语言风格 persona_style】\nstandard：清晰、中性、专业\nwarm：共情、支持性（默认）\nroast：轻毒舌但不羞辱、不对人格做负面定性\n\n【输入（系统已注入）】\npersona_style: $persona_style\nuser_context: $user_context_json\nfacts: $facts_json\nevidence: $evidence_json\n\n【输出（Markdown）】\n用如下结构输出（标题可省略但必须包含“处方”一节）：\n\n结论：...\n依据：...\n处方：\n1) ...（包含 if_then）\n2) ...（包含 if_then）\n3) ...（包含 if_then）\n承诺邀请：...（一句话，邀请用户选择一个处方开始）\n\"\"\")\n\n\ndef _load_user_context(user_id: int) -> Tuple[Dict[str, Any], Dict[str, Any], Dict[str, Any]]:\n    profile = fortune_db.fetch_one(\n        \"SELECT name, gender, birthday_local, tz_offset_hours, location FROM fortune_user WHERE user_id=%s AND deleted_at IS NULL\",\n        (int(user_id),),\n    ) or {}\n    prefs = fortune_db.fetch_one(\n        \"SELECT persona_style, push_enabled, push_time, quiet_hours_start, quiet_hours_end, chat_backend FROM fortune_user_preferences WHERE user_id=%s\",\n        (int(user_id),),\n    ) or {}\n    snap = fortune_db.fetch_one(\n        \"SELECT facts, facts_hash, compute_version FROM fortune_bazi_snapshot WHERE user_id=%s ORDER BY created_at DESC LIMIT 1\",\n        (int(user_id),),\n    ) or {}\n    return profile, prefs, snap\n\n\ndef _write_agent_run_log(\n    user_id: int,\n    session_id: Optional[str],\n    agent_name: str,\n    prompt_version: str,\n    facts_hash: Optional[str],\n    input_data: Dict[str, Any],\n    output_data: Dict[str, Any],\n    tool_calls: Optional[List[Dict[str, Any]]] = None,\n    usage: Optional[Dict[str, Any]] = None,\n    latency_ms: Optional[int] = None,\n    error: Optional[str] = None,\n) -> None:\n    \"\"\"\n    Write audit log to fortune_agent_run table.\n\n    REQ: REQ-AGENT-006 (Audit)\n    \"\"\"\n    try:\n        fortune_db.execute(\n            \"\"\"\n            INSERT INTO fortune_agent_run (\n                user_id, session_id, agent_name, prompt_version, facts_hash,\n                input, output, tool_calls, usage, latency_ms, error, created_at\n            ) VALUES (%s, %s::uuid, %s, %s, %s, %s::jsonb, %s::jsonb, %s::jsonb, %s::jsonb, %s, %s, now())\n            \"\"\",\n            [\n                user_id,\n                session_id if session_id else None,\n                agent_name,\n                prompt_version,\n                facts_hash,\n                json.dumps(input_data, ensure_ascii=False, default=str),\n                json.dumps(output_data, ensure_ascii=False, default=str),\n                json.dumps(tool_calls, ensure_ascii=False) if tool_calls else None,\n                json.dumps(usage, ensure_ascii=False) if usage else None,\n                latency_ms,\n                error,\n            ],\n        )\n    except Exception as e:\n        # Log but don't fail the request\n        import logging\n        logging.getLogger(__name__).warning(\"Failed to write agent run log: %s\", str(e))\n\n\ndef _a2ui_from_text(text: str) -> Dict[str, Any]:\n    raw = (text or \"\").strip()\n    obj = glm_client.extract_json_object(raw)\n    if isinstance(obj, dict):\n        norm = _normalize_a2ui(obj)\n        if isinstance(norm, dict):\n            try:\n                validate_a2ui(norm)\n                return norm\n            except Exception:\n                pass\n    # Fallback: wrap as markdown_text A2UI\n    summary = raw.splitlines()[0].strip()[:120] if raw else \"输出\"\n    return {\n        \"meta\": {\"summary\": summary},\n        \"ui_components\": [\n            {\"type\": \"markdown_text\", \"title\": \"输出\", \"data\": raw or \"（空）\"},\n            {\"type\": \"action_buttons\", \"title\": \"下一步\", \"data\": []},\n        ],\n    }\n\n\ndef _normalize_action(action: Dict[str, Any]) -> Dict[str, Any]:\n    a = dict(action or {})\n    # common variants\n    if a.get(\"type\") == \"open_panel\" and \"panel\" not in a and \"panel_id\" in a:\n        a[\"panel\"] = a.get(\"panel_id\")\n    return a\n\n\ndef _normalize_action_button(btn: Any) -> Dict[str, Any]:\n    if not isinstance(btn, dict):\n        return {\"label\": str(btn), \"action\": {\"type\": \"opt_out\"}}\n    label = str(btn.get(\"label\") or btn.get(\"text\") or \"下一步\")\n    action = btn.get(\"action\")\n    if isinstance(action, dict):\n        a = _normalize_action(action)\n        if not a.get(\"type\"):\n            a[\"type\"] = \"opt_out\"\n        return {\"label\": label, \"action\": a}\n    action_type = btn.get(\"action_type\") or btn.get(\"type\") or \"opt_out\"\n    payload = btn.get(\"payload\") if isinstance(btn.get(\"payload\"), dict) else {}\n    a = {\"type\": str(action_type)}\n    a.update(payload)\n    return {\"label\": label, \"action\": _normalize_action(a)}\n\n\ndef _normalize_a2ui(obj: Dict[str, Any]) -> Optional[Dict[str, Any]]:\n    if not isinstance(obj, dict):\n        return None\n    meta = obj.get(\"meta\")\n    if not isinstance(meta, dict):\n        meta = {}\n\n    comps = obj.get(\"ui_components\")\n    if not isinstance(comps, list):\n        # tolerate alternative root key\n        comps = obj.get(\"components\") if isinstance(obj.get(\"components\"), list) else []\n\n    out_comps: List[Dict[str, Any]] = []\n    for c in comps:\n        if not isinstance(c, dict):\n            continue\n        t = str(c.get(\"type\") or \"\").strip()\n        if not t:\n            continue\n        title = str(c.get(\"title\") or (\"教练回复\" if t == \"markdown_text\" else \"下一步\" if t == \"action_buttons\" else \"组件\"))\n        data = c.get(\"data\")\n        if data is None and \"content\" in c:\n            data = c.get(\"content\")\n        if t == \"action_buttons\":\n            if data is None and \"actions\" in c:\n                data = c.get(\"actions\")\n            if isinstance(data, list):\n                data = [_normalize_action_button(b) for b in data]\n            else:\n                data = []\n        if t == \"markdown_text\" and not isinstance(data, str):\n            data = \"\" if data is None else str(data)\n        out_comps.append({\"type\": t, \"title\": title, \"data\": data})\n\n    if not out_comps:\n        return None\n    # Ensure markdown_text is first component for renderer compatibility.\n    for i, c in enumerate(out_comps):\n        if c.get(\"type\") == \"markdown_text\":\n            if i != 0:\n                out_comps.insert(0, out_comps.pop(i))\n            break\n\n    meta_out = dict(meta)\n    if not isinstance(meta_out.get(\"summary\"), str):\n        meta_out[\"summary\"] = str(meta_out.get(\"summary\") or \"\")\n    return {\"meta\": meta_out, \"ui_components\": out_comps}\n\n\n_PRES_LINE_RE = re.compile(r\"^\\s*\\d+[\\.\\)]\\s*(.+?)\\s*$\")\n_BULLET_LINE_RE = re.compile(r\"^\\s*[-*]\\s*(.+?)\\s*$\")\n_MD_INLINE_RE = re.compile(r\"[*_`]+\")\n\n# =============================================================================\n# Intent Detection for Yunshi\n# =============================================================================\n\nYUNSHI_DAILY_KEYWORDS = [\n    \"今日运势\", \"今天运势\", \"今天的运势\", \"今日的运势\",\n    \"今日运气\", \"今天运气\", \"今天如何\", \"今天怎么样\",\n    \"今日吉凶\", \"今天吉凶\", \"运势如何\", \"运势怎么样\",\n    \"每日运势\", \"日运\",\n]\n\nYUNSHI_ANNUAL_KEYWORDS = [\n    \"流年\", \"今年运势\", \"年运势\", \"今年运气\", \"明年运势\",\n    \"年度运势\", \"今年如何\", \"今年怎么样\", \"年运\",\n]\n\ndef detect_yunshi_intent(text: str) -> Optional[str]:\n    \"\"\"\n    检测用户消息是否为运势查询意图\n\n    Returns:\n        - \"daily\": 今日运势查询\n        - \"annual\": 流年运势查询\n        - None: 非运势查询\n    \"\"\"\n    t = (text or \"\").strip().lower()\n    if not t:\n        return None\n\n    for kw in YUNSHI_DAILY_KEYWORDS:\n        if kw in t:\n            return \"daily\"\n\n    for kw in YUNSHI_ANNUAL_KEYWORDS:\n        if kw in t:\n            return \"annual\"\n\n    return None\n\n\ndef handle_yunshi_intent(\n    user_id: int,\n    session_id: str,\n    intent: str,\n    user_text: str,\n) -> Optional[Dict[str, Any]]:\n    \"\"\"\n    处理运势查询意图，返回 A2UI 格式响应\n\n    Returns:\n        - Dict with a2ui, suggested_tasks, backend if handled\n        - None if should fall through to LLM\n    \"\"\"\n    try:\n        from datetime import date, datetime\n\n        if intent == \"daily\":\n            yunshi = yunshi_service.compute_daily_yunshi(user_id, target_date=date.today())\n            a2ui = build_daily_yunshi_a2ui(yunshi)\n\n            # 提取处方作为任务\n            suggested_tasks = []\n            for p in yunshi.prescriptions[:2]:\n                from stores import fortune_db\n                row = fortune_db.execute_returning_one(\n                    \"\"\"\n                    INSERT INTO fortune_commitment (user_id, session_id, source, commitment_type, title, details, status, yunshi_snapshot_id)\n                    VALUES (%s, %s, 'yunshi', 'start_task', %s, '{}'::jsonb, 'suggested', NULL)\n                    RETURNING task_id\n                    \"\"\",\n                    (int(user_id), session_id, p.content[:200]),\n                )\n                if row and row.get(\"task_id\"):\n                    suggested_tasks.append({\"task_id\": str(row[\"task_id\"]), \"title\": p.content})\n\n            # 确保 action_buttons 包含任务\n            if a2ui.get(\"ui_components\"):\n                for comp in a2ui[\"ui_components\"]:\n                    if comp.get(\"type\") == \"action_buttons\":\n                        buttons = []\n                        for t in suggested_tasks[:2]:\n                            buttons.append({\n                                \"label\": f\"开始：{t['title'][:12]}...\",\n                                \"action\": {\"type\": \"start_task\", \"task_id\": t[\"task_id\"]},\n                            })\n                        buttons.append({\"label\": \"查看详细运势\", \"action\": {\"type\": \"open_panel\", \"panel\": \"yunshi\"}})\n                        buttons.append({\"label\": \"先不需要\", \"action\": {\"type\": \"opt_out\"}})\n                        comp[\"data\"] = buttons\n                        break\n\n            md = yunshi.summary\n            return {\n                \"a2ui\": a2ui,\n                \"content\": md,\n                \"suggested_tasks\": suggested_tasks,\n                \"backend\": \"yunshi\",\n            }\n\n        elif intent == \"annual\":\n            target_year = datetime.now().year\n            yunshi = yunshi_service.compute_annual_yunshi(user_id, target_year=target_year)\n            a2ui = build_annual_yunshi_a2ui(yunshi)\n\n            # 流年不生成即时任务\n            suggested_tasks = []\n\n            md = yunshi.summary\n            return {\n                \"a2ui\": a2ui,\n                \"content\": md,\n                \"suggested_tasks\": suggested_tasks,\n                \"backend\": \"yunshi\",\n            }\n\n    except Exception as e:\n        import logging\n        logging.getLogger(__name__).warning(f\"Yunshi intent handling failed: {e}\")\n        return None\n\n    return None\n\n\ndef _strip_md(text: str) -> str:\n    s = _MD_INLINE_RE.sub(\"\", text or \"\")\n    s = re.sub(r\"\\s+\", \" \", s).strip()\n    return s\n\n\ndef _short_label(text: str, max_len: int = 14) -> str:\n    s = _strip_md(text)\n    s = re.sub(r\"^\\d+[\\.\\)]\\s*\", \"\", s).strip()\n    if len(s) > max_len:\n        s = s[: max_len - 3].rstrip() + \"...\"\n    return s or \"行动\"\n\n\ndef _extract_prescriptions(md: str) -> List[str]:\n    lines = [ln.strip() for ln in (md or \"\").splitlines() if ln.strip()]\n    start: Optional[int] = None\n    for i, ln in enumerate(lines):\n        if \"处方\" in ln and not _PRES_LINE_RE.match(ln):\n            start = i + 1\n            break\n    if start is None:\n        return []\n    out: List[str] = []\n    for ln in lines[start:]:\n        if ln.startswith(\"#\"):\n            break\n        m = _PRES_LINE_RE.match(ln) or _BULLET_LINE_RE.match(ln)\n        if m:\n            item = _strip_md(m.group(1))\n            if item:\n                out.append(item)\n        if len(out) >= 3:\n            break\n    return out\n\n\ndef _insert_suggested_tasks(user_id: int, session_id: str, prescriptions: List[str]) -> List[Dict[str, Any]]:\n    tasks: List[Dict[str, Any]] = []\n    for p in prescriptions[:3]:\n        title = _strip_md(p) or \"行动\"\n        row = fortune_db.execute_returning_one(\n            \"\"\"\n            INSERT INTO fortune_commitment (user_id, session_id, source, commitment_type, title, details, status)\n            VALUES (%s, %s, 'chat', 'start_task', %s, '{}'::jsonb, 'suggested')\n            RETURNING task_id\n            \"\"\",\n            (int(user_id), session_id, title[:200]),\n        )\n        if row and row.get(\"task_id\"):\n            tasks.append({\"task_id\": str(row[\"task_id\"]), \"title\": title})\n    return tasks\n\n\ndef _ensure_action_buttons(a2ui: Dict[str, Any], suggested_tasks: List[Dict[str, Any]]) -> None:\n    buttons = []\n    for t in suggested_tasks[:2]:\n        title = _short_label(str(t.get(\"title\") or \"\"))\n        buttons.append({\"label\": f\"开始：{title}\", \"action\": {\"type\": \"start_task\", \"task_id\": str(t[\"task_id\"])}})\n    if suggested_tasks:\n        buttons.append({\"label\": \"加入今日计划\", \"action\": {\"type\": \"schedule_task\", \"task_id\": str(suggested_tasks[0][\"task_id\"])}})\n    buttons.append({\"label\": \"打开功能区\", \"action\": {\"type\": \"open_panel\", \"panel\": \"bento\"}})\n    buttons.append({\"label\": \"先不需要\", \"action\": {\"type\": \"opt_out\"}})\n\n    comps = a2ui.get(\"ui_components\")\n    if not isinstance(comps, list):\n        a2ui[\"ui_components\"] = comps = []\n\n    for c in comps:\n        if isinstance(c, dict) and c.get(\"type\") == \"action_buttons\":\n            c[\"data\"] = buttons\n            return\n\n    comps.append({\"type\": \"action_buttons\", \"title\": \"下一步\", \"data\": buttons})\n\n\ndef _assistant_markdown(a2ui: Dict[str, Any]) -> str:\n    comps = a2ui.get(\"ui_components\") or []\n    if isinstance(comps, list) and comps:\n        first = comps[0] if isinstance(comps[0], dict) else None\n        if first and isinstance(first.get(\"data\"), str):\n            return first[\"data\"]\n    return json.dumps(a2ui, ensure_ascii=False)\n\n\n@router.post(\"/send\")\ndef chat_send(req: ChatSendRequest, request: Request):\n    \"\"\"\n    Send a chat message and get AI response.\n\n    Supports two backends based on user preference:\n    - fastapi: Direct LLM call (default, current implementation)\n    - agent_service: Vercel AI SDK orchestration (future)\n\n    Also writes audit log to fortune_agent_run for compliance.\n    \"\"\"\n    import time as time_module\n\n    auth = require_auth(request)\n    require_csrf(request, auth)\n    user_id = int(auth[\"user_id\"])\n\n    session_id = (req.session_id or \"\").strip()\n    if session_id and not _UUID_RE.match(session_id):\n        return _err(400, \"invalid_request\", \"invalid_session_id\")\n\n    if not session_id:\n        s = chat_service.create_session(user_id, title=\"\")\n        session_id = s[\"session_id\"]\n    else:\n        if not chat_service.get_session(user_id, session_id):\n            return _err(404, \"not_found\", \"session_not_found\")\n\n    user_text = req.text.strip()\n    if not user_text:\n        return _err(400, \"invalid_request\", \"empty_text\")\n\n    model_name = (os.getenv(\"FORTUNE_AI_GLM_MODEL\") or \"glm-4.7\").strip()\n\n    # Save user message\n    chat_service.append_message(session_id=session_id, user_id=user_id, role=\"user\", content=user_text, model=model_name)\n    chat_service.set_title_if_empty(session_id, user_text[:24])\n\n    profile, prefs, snap = _load_user_context(user_id)\n    if not snap or not snap.get(\"facts\") or not snap.get(\"facts_hash\"):\n        snap = bazi_facts.ensure_snapshot_for_user(user_id)\n\n    # 使用 soul_os 获取完整上下文\n    full_context = soul_os.get_full_context_for_chat(user_id, user_text)\n\n    # 反依赖检查\n    anti_dep = full_context.get(\"anti_dependency\", {})\n    if anti_dep.get(\"should_intervene\"):\n        # 返回反依赖干预消息\n        intervention_msg = anti_dep.get(\"intervention_message\", \"\")\n        a2ui = {\n            \"meta\": {\"summary\": \"让我们先行动起来\"},\n            \"ui_components\": [\n                {\"type\": \"markdown_text\", \"title\": \"教练提醒\", \"data\": intervention_msg},\n                {\"type\": \"action_buttons\", \"title\": \"下一步\", \"data\": [\n                    {\"label\": \"好的，我去做\", \"action\": {\"type\": \"opt_out\"}},\n                    {\"label\": \"打开任务\", \"action\": {\"type\": \"open_panel\", \"panel\": \"tasks\"}},\n                ]},\n            ],\n        }\n        chat_service.append_message(\n            session_id=session_id,\n            user_id=user_id,\n            role=\"assistant\",\n            content=intervention_msg,\n            a2ui=a2ui,\n            model=\"anti_dependency\",\n        )\n        return _ok({\n            \"session_id\": session_id,\n            \"assistant_message\": {\"role\": \"assistant\", \"a2ui\": a2ui},\n            \"suggested_tasks\": [],\n            \"backend\": \"anti_dependency\",\n            \"intervention_type\": anti_dep.get(\"intervention_type\", \"\"),\n        })\n\n    # ==========================================================================\n    # 运势意图检测 - 优先于 LLM 调用\n    # ==========================================================================\n    yunshi_intent = detect_yunshi_intent(user_text)\n    if yunshi_intent:\n        yunshi_response = handle_yunshi_intent(user_id, session_id, yunshi_intent, user_text)\n        if yunshi_response:\n            a2ui = yunshi_response[\"a2ui\"]\n            md = yunshi_response.get(\"content\", \"\")\n            suggested_tasks = yunshi_response.get(\"suggested_tasks\", [])\n\n            chat_service.append_message(\n                session_id=session_id,\n                user_id=user_id,\n                role=\"assistant\",\n                content=md,\n                a2ui=a2ui,\n                model=\"yunshi\",\n            )\n\n            return _ok({\n                \"session_id\": session_id,\n                \"assistant_message\": {\"role\": \"assistant\", \"a2ui\": a2ui},\n                \"suggested_tasks\": suggested_tasks,\n                \"backend\": \"yunshi\",\n            })\n\n    # Check chat backend preference\n    chat_backend = str(prefs.get(\"chat_backend\") or default_chat_backend())\n    start_time = time_module.time()\n    persona_style = full_context.get(\"persona_style\", \"warm\")\n    facts_obj = snap.get(\"facts\") or {}\n    facts_hash = str(snap.get(\"facts_hash\") or \"\")\n\n    if chat_backend == \"agent_service\":\n        # Try Agent Service backend\n        try:\n            # Build messages for agent service\n            hist = chat_service.get_recent_messages_for_llm(user_id, session_id, limit=10)\n            agent_messages = [{\"role\": m.get(\"role\", \"user\"), \"content\": str(m.get(\"content\") or \"\")} for m in hist]\n\n            agent_response = agent_service_client.call_agent_service_sync(\n                user_id=user_id,\n                session_id=session_id,\n                messages=agent_messages,\n                user_context={\"profile\": profile, \"preferences\": prefs},\n                facts=facts_obj,\n                persona_style=persona_style,\n            )\n\n            # Process response\n            a2ui = agent_response.a2ui or _a2ui_from_text(agent_response.text)\n            md = _assistant_markdown(a2ui)\n            prescriptions = _extract_prescriptions(md)\n            suggested_tasks = _insert_suggested_tasks(user_id, session_id, prescriptions)\n            _ensure_action_buttons(a2ui, suggested_tasks)\n\n            chat_service.append_message(\n                session_id=session_id,\n                user_id=user_id,\n                role=\"assistant\",\n                content=md,\n                a2ui=a2ui,\n                model=\"agent_service\",\n            )\n\n            # Write audit log\n            latency_ms = int((time_module.time() - start_time) * 1000)\n            _write_agent_run_log(\n                user_id=user_id,\n                session_id=session_id,\n                agent_name=\"coach\",\n                prompt_version=\"agent_service\",\n                facts_hash=facts_hash,\n                input_data={\"user_text\": user_text, \"backend\": \"agent_service\"},\n                output_data={\"a2ui_summary\": a2ui.get(\"meta\", {}).get(\"summary\", \"\"), \"suggested_tasks\": len(suggested_tasks)},\n                latency_ms=latency_ms,\n            )\n\n            return _ok(\n                {\n                    \"session_id\": session_id,\n                    \"assistant_message\": {\"role\": \"assistant\", \"a2ui\": a2ui},\n                    \"suggested_tasks\": suggested_tasks,\n                    \"backend\": \"agent_service\",\n                }\n            )\n\n        except agent_service_client.AgentServiceUnavailable:\n            # Fall back to FastAPI if agent service unavailable\n            pass\n        except agent_service_client.AgentServiceError as e:\n            # Log error and fall back\n            latency_ms = int((time_module.time() - start_time) * 1000)\n            _write_agent_run_log(\n                user_id=user_id,\n                session_id=session_id,\n                agent_name=\"coach\",\n                prompt_version=\"agent_service\",\n                facts_hash=facts_hash,\n                input_data={\"user_text\": user_text, \"backend\": \"agent_service\"},\n                output_data={},\n                latency_ms=latency_ms,\n                error=str(e),\n            )\n            # Fall back to FastAPI\n            pass\n\n    # === FastAPI Direct LLM Implementation ===\n    # 使用 soul_os 构建的 system prompt 和 evidence\n    user_context = full_context.get(\"user_context\", {})\n    evidence = full_context.get(\"evidence\", {})\n\n    user_context_json = json.dumps(user_context, ensure_ascii=False, default=str)\n    facts_json = json.dumps(facts_obj, ensure_ascii=False)\n    evidence_json = json.dumps(evidence, ensure_ascii=False)\n\n    # 使用 soul_os 生成的 system prompt\n    system = full_context.get(\"system_prompt\", \"\")\n    if not system:\n        system = SYSTEM_PROMPT_TEMPLATE.safe_substitute(\n            persona_style=persona_style,\n            user_context_json=user_context_json,\n            facts_json=facts_json,\n            evidence_json=evidence_json,\n        )\n\n    # 从 evidence 中提取 kb_refs 用于审计\n    kb_refs = evidence.get(\"kb_refs\", [])\n\n    # Build LLM messages from DB (last 10 turns)\n    hist = chat_service.get_recent_messages_for_llm(user_id, session_id, limit=10)\n    llm_messages = [{\"role\": \"system\", \"content\": system}]\n    for m in hist:\n        role = \"assistant\" if m.get(\"role\") == \"assistant\" else \"user\"\n        llm_messages.append({\"role\": role, \"content\": str(m.get(\"content\") or \"\")})\n\n    error_msg = None\n    try:\n        raw_text, raw = glm_client.call_chat_completions(messages=llm_messages)\n    except glm_client.GlmError as e:\n        error_msg = str(e)\n        # Write audit log for failed request\n        latency_ms = int((time_module.time() - start_time) * 1000)\n        _write_agent_run_log(\n            user_id=user_id,\n            session_id=session_id,\n            agent_name=\"coach\",\n            prompt_version=\"v1.0\",\n            facts_hash=facts_hash,\n            input_data={\"user_text\": user_text, \"kb_refs\": kb_refs},\n            output_data={},\n            latency_ms=latency_ms,\n            error=error_msg,\n        )\n        return _err(500, \"glm_error\", error_msg)\n\n    a2ui = _a2ui_from_text(raw_text)\n    md = _assistant_markdown(a2ui)\n    prescriptions = _extract_prescriptions(md)\n    suggested_tasks = _insert_suggested_tasks(user_id, session_id, prescriptions)\n    _ensure_action_buttons(a2ui, suggested_tasks)\n\n    usage = raw.get(\"usage\") if isinstance(raw, dict) else {}\n    prompt_tokens = int(usage.get(\"prompt_tokens\") or usage.get(\"input_tokens\") or 0) if isinstance(usage, dict) else 0\n    completion_tokens = int(usage.get(\"completion_tokens\") or usage.get(\"output_tokens\") or 0) if isinstance(usage, dict) else 0\n\n    chat_service.append_message(\n        session_id=session_id,\n        user_id=user_id,\n        role=\"assistant\",\n        content=md,\n        a2ui=a2ui,\n        model=str(raw.get(\"model\") or model_name),\n        prompt_tokens=prompt_tokens,\n        completion_tokens=completion_tokens,\n    )\n\n    # Write audit log for successful request\n    latency_ms = int((time_module.time() - start_time) * 1000)\n    _write_agent_run_log(\n        user_id=user_id,\n        session_id=session_id,\n        agent_name=\"coach\",\n        prompt_version=\"v1.0\",\n        facts_hash=facts_hash,\n        input_data={\"user_text\": user_text, \"kb_refs\": kb_refs},\n        output_data={\"a2ui_summary\": a2ui.get(\"meta\", {}).get(\"summary\", \"\"), \"suggested_tasks\": len(suggested_tasks)},\n        usage={\"prompt_tokens\": prompt_tokens, \"completion_tokens\": completion_tokens, \"total_tokens\": prompt_tokens + completion_tokens},\n        latency_ms=latency_ms,\n    )\n\n    return _ok(\n        {\n            \"session_id\": session_id,\n            \"assistant_message\": {\"role\": \"assistant\", \"a2ui\": a2ui},\n            \"suggested_tasks\": suggested_tasks,\n            \"backend\": \"fastapi\",\n        }\n    )\n\n\ndef _sse_json(obj: Any) -> str:\n    return f\"data: {json.dumps(obj, ensure_ascii=False)}\\n\\n\"\n\n\n@router.get(\"/stream\")\ndef chat_stream(\n    request: Request,\n    message: str = Query(..., min_length=1, description=\"User message\"),\n    session_id: Optional[str] = Query(None, description=\"Existing session id\"),\n):\n    \"\"\"\n    Stream chat response via Server-Sent Events (SSE).\n\n    Frontend protocol:\n    - data: {\"type\":\"delta\",\"delta\":\"...\"}  (0..n)\n    - data: {\"type\":\"final\",\"data\":{...}}   (1)\n    - data: [DONE]\n    \"\"\"\n    import time as time_module\n\n    auth = require_auth(request)\n    require_csrf(request, auth)\n    user_id = int(auth[\"user_id\"])\n\n    sid = (session_id or \"\").strip()\n    if sid and not _UUID_RE.match(sid):\n        return _err(400, \"invalid_request\", \"invalid_session_id\")\n\n    if not sid:\n        s = chat_service.create_session(user_id, title=\"\")\n        sid = s[\"session_id\"]\n    else:\n        if not chat_service.get_session(user_id, sid):\n            return _err(404, \"not_found\", \"session_not_found\")\n\n    user_text = (message or \"\").strip()\n    if not user_text:\n        return _err(400, \"invalid_request\", \"empty_text\")\n\n    model_name = (os.getenv(\"FORTUNE_AI_GLM_MODEL\") or \"glm-4.7\").strip()\n\n    # Save user message\n    chat_service.append_message(session_id=sid, user_id=user_id, role=\"user\", content=user_text, model=model_name)\n    chat_service.set_title_if_empty(sid, user_text[:24])\n\n    profile, prefs, snap = _load_user_context(user_id)\n    if not snap or not snap.get(\"facts\") or not snap.get(\"facts_hash\"):\n        snap = bazi_facts.ensure_snapshot_for_user(user_id)\n\n    # Use soul_os to get context + anti-dependency check\n    full_context = soul_os.get_full_context_for_chat(user_id, user_text)\n    anti_dep = full_context.get(\"anti_dependency\", {})\n\n    def gen():\n        start_time = time_module.time()\n        facts_obj = snap.get(\"facts\") or {}\n        facts_hash = str(snap.get(\"facts_hash\") or \"\")\n        persona_style = full_context.get(\"persona_style\", \"warm\")\n\n        # Anti-dependency intervention: return immediately\n        if anti_dep.get(\"should_intervene\"):\n            intervention_msg = str(anti_dep.get(\"intervention_message\", \"\") or \"\")\n            a2ui = {\n                \"meta\": {\"summary\": \"让我们先行动起来\"},\n                \"ui_components\": [\n                    {\"type\": \"markdown_text\", \"title\": \"教练提醒\", \"data\": intervention_msg},\n                    {\"type\": \"action_buttons\", \"title\": \"下一步\", \"data\": [\n                        {\"label\": \"好的，我去做\", \"action\": {\"type\": \"opt_out\"}},\n                        {\"label\": \"打开任务\", \"action\": {\"type\": \"open_panel\", \"panel\": \"tasks\"}},\n                    ]},\n                ],\n            }\n            chat_service.append_message(\n                session_id=sid,\n                user_id=user_id,\n                role=\"assistant\",\n                content=intervention_msg,\n                a2ui=a2ui,\n                model=\"anti_dependency\",\n            )\n            yield _sse_json({\"type\": \"delta\", \"delta\": intervention_msg})\n            yield _sse_json(\n                {\n                    \"type\": \"final\",\n                    \"data\": {\n                        \"session_id\": sid,\n                        \"assistant_message\": {\"role\": \"assistant\", \"a2ui\": a2ui},\n                        \"suggested_tasks\": [],\n                        \"backend\": \"anti_dependency\",\n                        \"intervention_type\": str(anti_dep.get(\"intervention_type\") or \"\"),\n                    },\n                }\n            )\n            yield \"data: [DONE]\\n\\n\"\n            return\n\n        # ==========================================================================\n        # 运势意图检测 - 优先于 LLM 调用\n        # ==========================================================================\n        yunshi_intent = detect_yunshi_intent(user_text)\n        if yunshi_intent:\n            yunshi_response = handle_yunshi_intent(user_id, sid, yunshi_intent, user_text)\n            if yunshi_response:\n                a2ui = yunshi_response[\"a2ui\"]\n                md = yunshi_response.get(\"content\", \"\")\n                suggested_tasks = yunshi_response.get(\"suggested_tasks\", [])\n\n                chat_service.append_message(\n                    session_id=sid,\n                    user_id=user_id,\n                    role=\"assistant\",\n                    content=md,\n                    a2ui=a2ui,\n                    model=\"yunshi\",\n                )\n\n                yield _sse_json({\"type\": \"delta\", \"delta\": md})\n                yield _sse_json(\n                    {\n                        \"type\": \"final\",\n                        \"data\": {\n                            \"session_id\": sid,\n                            \"assistant_message\": {\"role\": \"assistant\", \"a2ui\": a2ui},\n                            \"suggested_tasks\": suggested_tasks,\n                            \"backend\": \"yunshi\",\n                        },\n                    }\n                )\n                yield \"data: [DONE]\\n\\n\"\n                return\n\n        # Determine backend preference\n        preferred_backend = str(prefs.get(\"chat_backend\") or default_chat_backend())\n        yield _sse_json({\"type\": \"meta\", \"session_id\": sid, \"backend\": preferred_backend})\n\n        # Build history (last 10 turns)\n        hist = chat_service.get_recent_messages_for_llm(user_id, sid, limit=10)\n        base_messages = [{\"role\": m.get(\"role\", \"user\"), \"content\": str(m.get(\"content\") or \"\")} for m in hist]\n\n        # Context payload for agent service (if used)\n        agent_context: Dict[str, Any] = {\n            \"user\": {\"profile\": profile, \"preferences\": prefs},\n            \"facts\": facts_obj,\n            \"persona_style\": persona_style,\n            \"output_format\": \"markdown\",\n        }\n\n        full_text_parts: List[str] = []\n        backend_used = preferred_backend\n        tool_calls: Optional[List[Dict[str, Any]]] = None\n\n        # Stream from agent_service when selected and available\n        if preferred_backend == \"agent_service\":\n            try:\n                import httpx\n                if not agent_service_client.is_agent_service_configured():\n                    raise agent_service_client.AgentServiceUnavailable(\"Agent service not configured\")\n\n                payload = {\n                    \"user_id\": user_id,\n                    \"session_id\": sid,\n                    \"messages\": [{\"role\": m.get(\"role\", \"user\"), \"content\": str(m.get(\"content\") or \"\")} for m in hist],\n                    \"stream\": True,\n                    \"context\": agent_context,\n                }\n\n                headers = {\n                    \"Content-Type\": \"application/json\",\n                    \"Authorization\": f\"Bearer {agent_service_client.AGENT_SERVICE_TOKEN}\",\n                }\n\n                with httpx.Client(timeout=agent_service_client.AGENT_SERVICE_TIMEOUT) as client:\n                    with client.stream(\"POST\", f\"{agent_service_client.AGENT_SERVICE_URL}/api/chat\", json=payload, headers=headers) as resp:\n                        if resp.status_code == 503:\n                            raise agent_service_client.AgentServiceUnavailable(\"Agent service temporarily unavailable\")\n                        if resp.status_code != 200:\n                            raise agent_service_client.AgentServiceError(f\"Agent service error: {resp.status_code}\")\n\n                        for raw_line in resp.iter_lines():\n                            line = (raw_line or \"\").strip()\n                            if not line or not line.startswith(\"data:\"):\n                                continue\n                            data = line[5:].strip()\n                            if not data:\n                                continue\n                            try:\n                                evt = json.loads(data)\n                            except Exception:\n                                continue\n                            if not isinstance(evt, dict):\n                                continue\n                            if evt.get(\"type\") == \"text\" and isinstance(evt.get(\"content\"), str):\n                                delta = str(evt.get(\"content\") or \"\")\n                                if delta:\n                                    full_text_parts.append(delta)\n                                    yield _sse_json({\"type\": \"delta\", \"delta\": delta})\n                            if evt.get(\"type\") == \"done\":\n                                if isinstance(evt.get(\"text\"), str) and evt.get(\"text\"):\n                                    full_text_parts = [str(evt.get(\"text\") or \"\")]\n                                if isinstance(evt.get(\"tool_calls\"), list):\n                                    tool_calls = evt.get(\"tool_calls\")\n                                break\n            except Exception:\n                backend_used = \"fastapi\"\n\n        # Stream from direct LLM (fastapi)\n        if backend_used != \"agent_service\":\n            user_context = full_context.get(\"user_context\", {})\n            evidence = full_context.get(\"evidence\", {})\n            kb_refs = evidence.get(\"kb_refs\", [])\n\n            user_context_json = json.dumps(user_context, ensure_ascii=False, default=str)\n            facts_json = json.dumps(facts_obj, ensure_ascii=False)\n            evidence_json = json.dumps(evidence, ensure_ascii=False)\n\n            system_stream = SYSTEM_PROMPT_STREAM_TEMPLATE.safe_substitute(\n                persona_style=persona_style,\n                user_context_json=user_context_json,\n                facts_json=facts_json,\n                evidence_json=evidence_json,\n            )\n\n            llm_messages = [{\"role\": \"system\", \"content\": system_stream}]\n            for m in hist:\n                role = \"assistant\" if m.get(\"role\") == \"assistant\" else \"user\"\n                llm_messages.append({\"role\": role, \"content\": str(m.get(\"content\") or \"\")})\n\n            try:\n                got_any = False\n                for delta in glm_client.stream_chat_completions(messages=llm_messages):\n                    if delta:\n                        got_any = True\n                        full_text_parts.append(delta)\n                        yield _sse_json({\"type\": \"delta\", \"delta\": delta})\n                if not got_any:\n                    # Provider may not support streaming; fall back to non-streaming and simulate deltas.\n                    raw_text, _raw = glm_client.call_chat_completions(messages=llm_messages)\n                    raw_text = str(raw_text or \"\")\n                    for i in range(0, len(raw_text), 48):\n                        chunk = raw_text[i : i + 48]\n                        if chunk:\n                            full_text_parts.append(chunk)\n                            yield _sse_json({\"type\": \"delta\", \"delta\": chunk})\n            except glm_client.GlmError as e:\n                # Try a non-streaming fallback before failing.\n                try:\n                    raw_text, _raw = glm_client.call_chat_completions(messages=llm_messages)\n                    raw_text = str(raw_text or \"\")\n                    for i in range(0, len(raw_text), 48):\n                        chunk = raw_text[i : i + 48]\n                        if chunk:\n                            full_text_parts.append(chunk)\n                            yield _sse_json({\"type\": \"delta\", \"delta\": chunk})\n                except glm_client.GlmError:\n                    err = str(e)\n                    latency_ms = int((time_module.time() - start_time) * 1000)\n                    _write_agent_run_log(\n                        user_id=user_id,\n                        session_id=sid,\n                        agent_name=\"coach\",\n                        prompt_version=\"v1.0-stream\",\n                        facts_hash=facts_hash,\n                        input_data={\"user_text\": user_text, \"kb_refs\": kb_refs, \"backend\": \"fastapi\"},\n                        output_data={},\n                        latency_ms=latency_ms,\n                        error=err,\n                    )\n                    yield _sse_json({\"type\": \"error\", \"error\": err})\n                    yield \"data: [DONE]\\n\\n\"\n                    return\n\n        full_text = \"\".join(full_text_parts).strip()\n        a2ui = _a2ui_from_text(full_text)\n        md = _assistant_markdown(a2ui)\n        prescriptions = _extract_prescriptions(md)\n        suggested_tasks = _insert_suggested_tasks(user_id, sid, prescriptions)\n        _ensure_action_buttons(a2ui, suggested_tasks)\n\n        chat_service.append_message(\n            session_id=sid,\n            user_id=user_id,\n            role=\"assistant\",\n            content=md,\n            a2ui=a2ui,\n            model=(\"agent_service\" if backend_used == \"agent_service\" else model_name),\n        )\n\n        latency_ms = int((time_module.time() - start_time) * 1000)\n        _write_agent_run_log(\n            user_id=user_id,\n            session_id=sid,\n            agent_name=\"coach\",\n            prompt_version=(\"agent_service-stream\" if backend_used == \"agent_service\" else \"v1.0-stream\"),\n            facts_hash=facts_hash,\n            input_data={\"user_text\": user_text, \"backend\": backend_used},\n            output_data={\"a2ui_summary\": a2ui.get(\"meta\", {}).get(\"summary\", \"\"), \"suggested_tasks\": len(suggested_tasks)},\n            tool_calls=tool_calls,\n            latency_ms=latency_ms,\n        )\n\n        yield _sse_json(\n            {\n                \"type\": \"final\",\n                \"data\": {\n                    \"session_id\": sid,\n                    \"assistant_message\": {\"role\": \"assistant\", \"a2ui\": a2ui},\n                    \"suggested_tasks\": suggested_tasks,\n                    \"backend\": backend_used,\n                },\n            }\n        )\n        yield \"data: [DONE]\\n\\n\"\n\n    headers = {\n        \"Cache-Control\": \"no-cache\",\n        \"X-Accel-Buffering\": \"no\",\n    }\n    return StreamingResponse(gen(), media_type=\"text/event-stream\", headers=headers)\n\n\n@router.post(\"/ask\")\ndef chat_ask_alias(req: ChatSendRequest, request: Request):\n    # Backward-compatible alias for /api/chat/send\n    return chat_send(req, request)\n","numLines":1106,"startLine":1,"totalLines":1106}}}
{"parentUuid":"3bcd7491-ca85-495f-a428-6b118a59431c","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WGAGRtvWA9kuxTt21JsWf9","type":"tool_result","content":"     1→from fastapi import FastAPI, HTTPException, Request\n     2→from fastapi.responses import HTMLResponse, StreamingResponse, RedirectResponse\n     3→from starlette.middleware.gzip import GZipMiddleware\n     4→from fastapi.middleware.cors import CORSMiddleware\n     5→from fastapi.staticfiles import StaticFiles\n     6→from fastapi.templating import Jinja2Templates\n     7→from pydantic import BaseModel, Field, validator\n     8→from typing import Optional, Dict, Any, Tuple, List\n     9→from uuid import uuid4\n    10→import os\n    11→import urllib.parse\n    12→import json\n    13→import re\n    14→import time\n    15→from datetime import datetime\n    16→\n    17→from common.logging import get_logger\n    18→from services import task_service\n    19→from services.rectification import rectify_birth_time_v2, rectify_birth_time_v2_iter\n    20→from services import rectification_v3\n    21→from user_store import update_fortune_user_rectification_by_name, get_fortune_user_by_name, create_fortune_user\n    22→from services.bazi_engine import calculate_bazi\n    23→from services.bazi_engine import DEFAULT_LOCATION\n    24→from services import prompt_store\n    25→import os as _os\n    26→from integrations import backend_router as be\n    27→from services.conversation_store import append_output, append_prompt, find_user_by_job, save_job_index\n    28→from common.a2ui import validate_a2ui, ValidationError\n    29→import httpx\n    30→from services.task_service import sync_job_gemini_url_to_user\n    31→from services import rectification_store\n    32→from services.tieban import service as tieban_service\n    33→from api.auth_routes import router as auth_router\n    34→from api.deps import get_current_auth\n    35→from api.user_routes import router as user_router\n    36→from api.session_routes import router as session_router\n    37→from api.chat_routes import router as chat_router\n    38→from api.bento_routes import router as bento_router\n    39→from api.dashboard_routes import router as dashboard_router\n    40→from api.bazi_routes import router as bazi_router\n    41→from api.kb_routes import router as kb_router\n    42→from api.plan_routes import router as plan_router\n    43→from api.report_routes import router as report_router\n    44→from api.push_routes import router as push_router\n    45→from api.twin_routes import router as twin_router\n    46→from api.agent_tool import router as agent_tool_router\n    47→from api.social_routes import router as social_router\n    48→from api.jitai_routes import router as jitai_router\n    49→from api.currency_routes import router as currency_router\n    50→from api.goal_routes import router as goal_router\n    51→from api.reflection_routes import router as reflection_router\n    52→from api.yunshi_routes import router as yunshi_router\n    53→from api.poster_routes import router as poster_router\n    54→\n    55→logger = get_logger(__name__)\n    56→\n    57→\n    58→def _patch_anyio_threading_for_tests() -> None:\n    59→    \"\"\"\n    60→    Work around threadpool hangs in the sandboxed test runtime.\n    61→\n    62→    FastAPI runs sync endpoints via `anyio.to_thread.run_sync()`. In this\n    63→    environment it can deadlock; for tests/stub mode we run sync callables inline.\n    64→    \"\"\"\n    65→    if os.getenv(\"STUB_DB\") != \"1\" and not os.getenv(\"PYTEST_CURRENT_TEST\"):\n    66→        return\n    67→\n    68→    try:\n    69→        import anyio.to_thread\n    70→\n    71→        async def _run_sync_inline(func, *args, **kwargs):  # type: ignore[no-untyped-def]\n    72→            kwargs.pop(\"abandon_on_cancel\", None)\n    73→            kwargs.pop(\"cancellable\", None)\n    74→            kwargs.pop(\"limiter\", None)\n    75→            return func(*args, **kwargs)\n    76→\n    77→        anyio.to_thread.run_sync = _run_sync_inline  # type: ignore[assignment]\n    78→    except Exception:\n    79→        return\n    80→\n    81→\n    82→_patch_anyio_threading_for_tests()\n    83→app = FastAPI(title=\"Fortune AI API\")\n    84→app.add_middleware(GZipMiddleware, minimum_size=1024)\n    85→\n    86→# CORS middleware for frontend (port 8231) accessing backend (port 8230)\n    87→app.add_middleware(\n    88→    CORSMiddleware,\n    89→    allow_origins=[\n    90→        \"http://106.37.170.238:8231\",\n    91→        \"http://localhost:8231\",\n    92→        \"http://127.0.0.1:8231\",\n    93→    ],\n    94→    allow_credentials=True,\n    95→    allow_methods=[\"*\"],\n    96→    allow_headers=[\"*\"],\n    97→)\n    98→\n    99→# Strong cache for static files to speed up repeat loads\n   100→@app.middleware(\"http\")\n   101→async def _static_cache_mw(request: Request, call_next):\n   102→    response = await call_next(request)\n   103→    try:\n   104→        path = request.url.path\n   105→        if path.startswith(\"/static/\"):\n   106→            # 1 year immutable cache; files are content-addressed by deploy hash only via manual bumps\n   107→            response.headers.setdefault(\"Cache-Control\", \"public, max-age=31536000, immutable\")\n   108→    except Exception:\n   109→        pass\n   110→    return response\n   111→app.mount(\"/static\", StaticFiles(directory=\"api/static\"), name=\"static\")\n   112→templates = Jinja2Templates(directory=\"api/templates\")\n   113→\n   114→app.include_router(auth_router)\n   115→app.include_router(user_router)\n   116→app.include_router(session_router)\n   117→app.include_router(chat_router)\n   118→app.include_router(bento_router)  # 保持向后兼容\n   119→app.include_router(dashboard_router)  # 新 Dashboard API（Zone B）\n   120→app.include_router(bazi_router)\n   121→app.include_router(kb_router)\n   122→app.include_router(plan_router)\n   123→app.include_router(report_router)\n   124→app.include_router(push_router)\n   125→app.include_router(twin_router)\n   126→app.include_router(agent_tool_router)\n   127→app.include_router(social_router)\n   128→app.include_router(jitai_router)\n   129→app.include_router(currency_router)\n   130→app.include_router(goal_router)\n   131→app.include_router(reflection_router)\n   132→app.include_router(yunshi_router)\n   133→app.include_router(poster_router)\n   134→\n   135→\n   136→class BaziRequest(BaseModel):\n   137→    name: str = Field(..., min_length=1)\n   138→    gender: str = Field(..., min_length=1)\n   139→    year: int\n   140→    month: int\n   141→    day: int\n   142→    hour: int\n   143→    minute: int\n   144→    longitude: Optional[float] = None\n   145→    latitude: Optional[float] = None\n   146→    location_name: Optional[str] = None\n   147→    system_prompt: Optional[str] = None\n   148→\n   149→    @validator(\"longitude\")\n   150→    def longitude_range(cls, v):\n   151→        if v is None:\n   152→            return v\n   153→        if v < -180 or v > 180:\n   154→            raise ValueError(\"longitude out of range\")\n   155→        return v\n   156→\n   157→\n   158→class AskRequest(BaseModel):\n   159→    \"\"\"Ask on Bazi (sync) request payload (REQ-003).\"\"\"\n   160→    name: str = Field(..., min_length=1)\n   161→    gender: str = Field(..., min_length=1)\n   162→    date: str = Field(..., description=\"YYYY-MM-DD\")\n   163→    time: str = Field(..., description=\"HH:MM[:SS]\")\n   164→    tz_offset_hours: Optional[float] = Field(8.0, description=\"Local time offset from UTC in hours, default +8\")\n   165→    longitude: Optional[float] = None\n   166→    latitude: Optional[float] = None\n   167→    location_name: Optional[str] = None\n   168→    question: str = Field(\"\", description=\"User question text\")\n   169→    model: Optional[str] = Field(\"standard\", description=\"Model hint\")\n   170→\n   171→\n   172→class ChatMessage(BaseModel):\n   173→    role: str = Field(..., description=\"user|assistant\")\n   174→    text: str = Field(..., min_length=1)\n   175→\n   176→\n   177→class ChatAskRequest(BaseModel):\n   178→    name: Optional[str] = None\n   179→    session_id: Optional[str] = None\n   180→    system_prompt: Optional[str] = None\n   181→    messages: List[ChatMessage]\n   182→    model: Optional[str] = Field(\"standard\", description=\"Model hint\")\n   183→\n   184→\n   185→def _parse_date_time(date_str: str, time_str: str) -> Tuple[int, int, int, int, int]:\n   186→    \"\"\"Parse 'YYYY-MM-DD' and 'HH:MM[:SS]' into ints.\n   187→\n   188→    Returns: year, month, day, hour, minute\n   189→    \"\"\"\n   190→    try:\n   191→        y, m, d = [int(x) for x in date_str.split(\"-\")]\n   192→        parts = time_str.split(\":\")\n   193→        hh = int(parts[0]); mm = int(parts[1]);\n   194→        return y, m, d, hh, mm\n   195→    except Exception:\n   196→        raise HTTPException(status_code=400, detail=\"invalid_date_time\")\n   197→\n   198→\n   199→def _wuxing_counts(wuxing: Optional[str]) -> Dict[str, int]:\n   200→    counts = {\"金\": 0, \"木\": 0, \"水\": 0, \"火\": 0, \"土\": 0}\n   201→    if not wuxing:\n   202→        return counts\n   203→    for ch in counts:\n   204→        counts[ch] = wuxing.count(ch)\n   205→    return counts\n   206→\n   207→\n   208→def _build_chat_prompt(system_prompt: Optional[str], messages: List[ChatMessage]) -> str:\n   209→    lines: List[str] = []\n   210→    if system_prompt and system_prompt.strip():\n   211→        lines.append(system_prompt.strip())\n   212→    lines.append(\"【对话】\")\n   213→    for m in messages:\n   214→        role = \"用户\" if m.role == \"user\" else \"助手\"\n   215→        lines.append(f\"{role}: {m.text}\")\n   216→    lines.append(\"助手:\")\n   217→    return \"\\n\".join(lines)\n   218→\n   219→\n   220→def _latest_report_summary_for_user(name: str) -> Tuple[Optional[str], Optional[str]]:\n   221→    \"\"\"Find latest assistant text for a user name from local conversation logs.\n   222→\n   223→    Returns (summary_text, doc_url)\n   224→    \"\"\"\n   225→    try:\n   226→        from user_store import get_fortune_user_by_name\n   227→    except Exception:\n   228→        return None, None\n   229→    u = get_fortune_user_by_name(name)\n   230→    if not u or u.get(\"user_id\") is None:\n   231→        return None, None\n   232→    uid = int(u[\"user_id\"])  # type: ignore\n   233→    conv_dir = os.path.join(\"user\", str(uid), \"conversations\")\n   234→    if not os.path.isdir(conv_dir):\n   235→        return None, None\n   236→    latest_path = None\n   237→    latest_mtime = 0.0\n   238→    for fn in os.listdir(conv_dir):\n   239→        if not fn.endswith(\".jsonl\"):\n   240→            continue\n   241→        p = os.path.join(conv_dir, fn)\n   242→        try:\n   243→            mt = os.path.getmtime(p)\n   244→        except Exception:\n   245→            continue\n   246→        if mt > latest_mtime:\n   247→            latest_mtime = mt\n   248→            latest_path = p\n   249→    if not latest_path:\n   250→        return None, None\n   251→    last_text = None\n   252→    doc_url = None\n   253→    try:\n   254→        with open(latest_path, \"r\", encoding=\"utf-8\") as f:\n   255→            for line in f:\n   256→                line = line.strip()\n   257→                if not line:\n   258→                    continue\n   259→                try:\n   260→                    rec = json.loads(line)\n   261→                except Exception:\n   262→                    continue\n   263→                if rec.get(\"role\") == \"assistant\":\n   264→                    last_text = rec.get(\"content\") or last_text\n   265→                    if rec.get(\"doc_url\"):\n   266→                        doc_url = rec.get(\"doc_url\")\n   267→    except Exception:\n   268→        return None, None\n   269→    if not last_text:\n   270→        return None, None\n   271→    # 300–600 字摘要（简单截断作为占位）\n   272→    summary = str(last_text).strip()\n   273→    if len(summary) > 600:\n   274→        summary = summary[:600] + \"…\"\n   275→    return summary, doc_url\n   276→\n   277→\n   278→class AskRequest(BaseModel):\n   279→    \"\"\"Ask on Bazi (sync) request payload (REQ-003).\"\"\"\n   280→    name: str = Field(..., min_length=1)\n   281→    gender: str = Field(..., min_length=1)\n   282→    date: str = Field(..., description=\"YYYY-MM-DD\")\n   283→    time: str = Field(..., description=\"HH:MM[:SS]\")\n   284→    tz_offset_hours: Optional[float] = Field(8.0, description=\"Local time offset from UTC in hours, default +8\")\n   285→    longitude: Optional[float] = None\n   286→    latitude: Optional[float] = None\n   287→    location_name: Optional[str] = None\n   288→    question: str = Field(\"\", description=\"User question text\")\n   289→    model: Optional[str] = Field(\"standard\", description=\"Model hint\")\n   290→\n   291→\n   292→class RectifyEvent(BaseModel):\n   293→    date: str\n   294→    type: str\n   295→    impact: Optional[str] = None\n   296→\n   297→\n   298→class RectifyRequest(BaseModel):\n   299→    name: str = Field(..., min_length=1)\n   300→    birthday: str = Field(..., description=\"YYYY-MM-DD\")\n   301→    latitude: Optional[float] = None\n   302→    longitude: Optional[float] = None\n   303→    window_start: str = Field(..., description=\"HH:MM or HH:MM:SS\")\n   304→    window_end: str = Field(..., description=\"HH:MM or HH:MM:SS\")\n   305→    events: list[RectifyEvent]\n   306→    tz_offset_hours: Optional[float] = Field(8.0, description=\"Local time offset from UTC in hours, default +8\")\n   307→    debug: Optional[bool] = Field(False, description=\"Return debug breakdown when true\")\n   308→\n   309→\n   310→class SystemPromptSaveRequest(BaseModel):\n   311→    openid: str = Field(\"web\", description=\"User identifier for prompt history grouping\")\n   312→    text: str = Field(..., min_length=1, description=\"System prompt text\")\n   313→    model: Optional[str] = Field(\"standard\", description=\"Associated model suggestion\")\n   314→\n   315→class BaziAskRequest(BaseModel):\n   316→    question: str\n   317→    name: Optional[str] = None\n   318→    gender: Optional[str] = None\n   319→    date: Optional[str] = None\n   320→    time: Optional[str] = None\n   321→    tz_offset_hours: Optional[float] = 8.0\n   322→    location_name: Optional[str] = None\n   323→    longitude: Optional[float] = None\n   324→    latitude: Optional[float] = None\n   325→\n   326→\n   327→class TiebanInitRequest(BaseModel):\n   328→    name: str = Field(..., min_length=1)\n   329→    gender: str = Field(..., min_length=1)\n   330→    date: str = Field(..., description=\"YYYY-MM-DD\")\n   331→    time: str = Field(..., description=\"HH:MM or HH:MM:SS\")\n   332→    tz_offset_hours: Optional[float] = Field(8.0, description=\"Local time offset from UTC in hours, default +8\")\n   333→    location_name: Optional[str] = None\n   334→    longitude: Optional[float] = None\n   335→    latitude: Optional[float] = None\n   336→    known_facts: Optional[Dict[str, Any]] = None\n   337→    ruleset_names: Optional[list[str]] = None\n   338→    debug: Optional[bool] = False\n   339→\n   340→\n   341→class TiebanVerifyRequest(BaseModel):\n   342→    run_id: str\n   343→    answers: Dict[str, Any]\n   344→    state_version: Optional[str] = None\n   345→\n   346→\n   347→class TiebanLockRequest(BaseModel):\n   348→    run_id: str\n   349→    state_version: Optional[str] = None\n   350→\n   351→\n   352→class TiebanSelectRequest(BaseModel):\n   353→    run_id: str\n   354→    candidate_id: str\n   355→    state_version: Optional[str] = None\n   356→\n   357→\n   358→def _persist_rectification_result(req: RectifyRequest, result, lat: float, lon: float) -> None:\n   359→    \"\"\"Best-effort persistence of rectification results to fortune_user.\"\"\"\n   360→    user_id: Optional[int] = None\n   361→    used_default_location = (req.latitude is None) or (req.longitude is None)\n   362→    try:\n   363→        user = get_fortune_user_by_name(req.name)\n   364→        if not user:\n   365→            bt_local = result.best_time_local\n   366→            bazi = calculate_bazi(\n   367→                bt_local.year,\n   368→                bt_local.month,\n   369→                bt_local.day,\n   370→                bt_local.hour,\n   371→                bt_local.minute,\n   372→                {\"longitude\": lon, \"latitude\": lat, \"name\": req.name},\n   373→            )\n   374→            base_url = os.getenv(\"GEMINI_BASE_URL\", \"https://gemini.local/user\")\n   375→            create_fortune_user(\n   376→                name=req.name,\n   377→                birthday=f\"{bt_local.year:04d}-{bt_local.month:02d}-{bt_local.day:02d} {bt_local.hour:02d}:{bt_local.minute:02d}:{bt_local.second:02d}\",\n   378→                location={\"longitude\": lon, \"latitude\": lat, \"name\": req.name},\n   379→                bazi_digest=f\"{bazi.year_pillar}-{bazi.month_pillar}-{bazi.day_pillar}-{bazi.hour_pillar}\",\n   380→                gemini_url=f\"{base_url}/{os.getenv('ENV','dev')}-{int(result.best_time_utc.timestamp())}\",\n   381→                notes=\"created by rectify\",\n   382→            )\n   383→            user = get_fortune_user_by_name(req.name)\n   384→        if user and user.get(\"user_id\") is not None:\n   385→            try:\n   386→                user_id = int(user[\"user_id\"])\n   387→            except Exception:\n   388→                user_id = None\n   389→    except Exception:\n   390→        user_id = None\n   391→\n   392→    # DB persistence (may fail if columns not yet migrated).\n   393→    try:\n   394→        update_fortune_user_rectification_by_name(\n   395→            name=req.name,\n   396→            rectified_time=result.best_time_utc.isoformat(),\n   397→            birth_window={\n   398→                \"start\": result.window_start_utc.isoformat(),\n   399→                \"end\": result.window_end_utc.isoformat(),\n   400→                \"start_local\": result.window_start_local.isoformat(),\n   401→                \"end_local\": result.window_end_local.isoformat(),\n   402→                \"tz_offset_hours\": req.tz_offset_hours or 8.0,\n   403→                \"step_seconds\": 30,\n   404→                \"location\": {\"longitude\": lon, \"latitude\": lat, \"used_default\": used_default_location},\n   405→            },\n   406→            life_events=[e.dict() for e in req.events],\n   407→        )\n   408→    except Exception as e:\n   409→        logger.warning(\"rectify persist db failed\", extra={\"operation\": \"rectify_persist_db\", \"error\": str(e)[:200]})\n   410→\n   411→    # Local persistence (always attempt) for audit/debug without exposing via API.\n   412→    if user_id is not None:\n   413→        try:\n   414→            req_payload = {\n   415→                \"birthday\": req.birthday,\n   416→                \"tz_offset_hours\": req.tz_offset_hours or 8.0,\n   417→                \"latitude\": lat,\n   418→                \"longitude\": lon,\n   419→                \"used_default_location\": used_default_location,\n   420→                \"window_start\": req.window_start,\n   421→                \"window_end\": req.window_end,\n   422→                \"events\": [e.dict() for e in req.events],\n   423→            }\n   424→            result_payload = _rectify_response_payload(result, received_events=req_payload[\"events\"])\n   425→            rec = rectification_store.make_rectification_record(name=req.name, req_payload=req_payload, result_payload=result_payload)\n   426→            rectification_store.save_rectification_run(user_id, rec)\n   427→        except Exception:\n   428→            return\n   429→\n   430→\n   431→def _rectify_response_payload(result, received_events: Optional[list] = None) -> Dict[str, Any]:\n   432→    payload: Dict[str, Any] = {\n   433→        \"status\": \"ok\",\n   434→        \"best_time\": result.best_time_utc.isoformat(),\n   435→        \"best_local_time\": result.best_time_local.isoformat(),\n   436→        \"candidates\": [\n   437→            {\n   438→                \"time\": c.time_utc.isoformat(),\n   439→                \"local_time\": c.time_local.isoformat(),\n   440→                \"score\": round(float(c.score), 3),\n   441→                **({\"breakdown\": c.breakdown} if c.breakdown is not None else {}),\n   442→            }\n   443→            for c in result.candidates\n   444→        ],\n   445→        \"window\": {\n   446→            \"start\": result.window_start_utc.isoformat(),\n   447→            \"end\": result.window_end_utc.isoformat(),\n   448→            \"start_local\": result.window_start_local.isoformat(),\n   449→            \"end_local\": result.window_end_local.isoformat(),\n   450→            \"location\": getattr(result, \"window_location\", None) or None,\n   451→        },\n   452→        \"used_swisseph\": result.used_swisseph,\n   453→    }\n   454→    if result.debug is not None:\n   455→        payload[\"debug\"] = result.debug\n   456→    if received_events is not None:\n   457→        payload[\"received_events\"] = received_events\n   458→    return payload\n   459→\n   460→\n   461→@app.on_event(\"startup\")\n   462→def startup():\n   463→    if os.getenv(\"STUB_DB\") == \"1\":\n   464→        return\n   465→    # 初始化保留给 gemini 后端；cli 后端无需池化\n   466→    if os.getenv(\"GEMINI_BACKEND\", \"gemini\").lower() != \"cli\":\n   467→        try:\n   468→            from integrations.gemini_repo import init_connection_pool\n   469→            init_connection_pool()\n   470→        except Exception:\n   471→            pass\n   472→\n   473→\n   474→@app.get(\"/healthz\")\n   475→def healthz():\n   476→    return {\"status\": \"ok\"}\n   477→\n   478→\n   479→@app.get(\"/\", include_in_schema=False)\n   480→def root_redirect():\n   481→    # Redirect root to /new frontend\n   482→    return RedirectResponse(url=\"/new\", status_code=307)\n   483→\n   484→\n   485→@app.get(\"/login\", response_class=HTMLResponse, include_in_schema=False)\n   486→def page_login(request: Request):\n   487→    # Redirect to new frontend login\n   488→    return RedirectResponse(url=\"/new/login\", status_code=307)\n   489→\n   490→\n   491→@app.get(\"/register\", response_class=HTMLResponse, include_in_schema=False)\n   492→def page_register(request: Request):\n   493→    # Redirect to new frontend register\n   494→    return RedirectResponse(url=\"/new/register\", status_code=307)\n   495→\n   496→\n   497→@app.get(\"/bazi\", response_class=HTMLResponse)\n   498→def page_bazi(request: Request):\n   499→    # 使用新版页面（视觉风格与 /tieban 对齐，复用 tieban.css）\n   500→    return templates.TemplateResponse(\"bazi.html\", {\"request\": request})\n   501→\n   502→\n   503→@app.get(\"/tieban\", response_class=HTMLResponse)\n   504→def tieban_page(request: Request):\n   505→    asset_version = os.getenv(\"ASSET_VER\") or str(int(time.time() // 3600))\n   506→    return templates.TemplateResponse(\"tieban.html\", {\"request\": request, \"asset_version\": asset_version})\n   507→\n   508→@app.get(\"/bazi2\", response_class=HTMLResponse)\n   509→def bazi2_page(request: Request):\n   510→    # 兼容旧链接：跳转到 /new\n   511→    return RedirectResponse(url=\"/new\", status_code=307)\n   512→\n   513→@app.get(\"/main\", response_class=HTMLResponse)\n   514→def bazi_main_page(request: Request):\n   515→    \"\"\"Legacy /main page - redirect to /new frontend.\"\"\"\n   516→    # Redirect to new frontend\n   517→    return RedirectResponse(url=\"/new\", status_code=307)\n   518→\n   519→\n   520→@app.get(\"/zone-b\")\n   521→@app.get(\"/dashboard\")\n   522→def page_dashboard():\n   523→    \"\"\"Zone B Dashboard → 重定向到新前端 /new\"\"\"\n   524→    from fastapi.responses import RedirectResponse\n   525→    return RedirectResponse(url=\"/new\", status_code=307)\n   526→\n   527→\n   528→# ------------------------------ Ask on Bazi (sync + SSE) ------------------------------\n   529→\n   530→\n   531→@app.post(\"/api/bazi/ask\")\n   532→def api_bazi_ask(req: AskRequest):\n   533→    \"\"\"Synchronous Ask endpoint (REQ-003).\"\"\"\n   534→    audit_id = str(uuid4())\n   535→    try:\n   536→        y, m, d, hh, mm = _parse_date_time(req.date, req.time)\n   537→        bazi = calculate_bazi(\n   538→            y, m, d, hh, mm,\n   539→            {\"longitude\": req.longitude or DEFAULT_LOCATION[\"longitude\"],\n   540→             \"latitude\": req.latitude or DEFAULT_LOCATION[\"latitude\"],\n   541→             \"name\": req.location_name or DEFAULT_LOCATION.get(\"name\", \"\")},\n   542→        )\n   543→        counts = _wuxing_counts(bazi.wuxing)\n   544→        report_summary, doc_url = _latest_report_summary_for_user(req.name)\n   545→\n   546→        # Build structured markdown per spec\n   547→        lines = []\n   548→        lines.append(\"### 结论要点\")\n   549→        trend = \", \".join([f\"{k}{v}\" for k, v in counts.items() if v > 0]) or \"暂无\"\n   550→        lines.append(f\"- 五行倾向：{trend}\")\n   551→        lines.append(\"- 近期关注：事业/健康/情绪（结合个人上下文自检）\")\n   552→        lines.append(\"\")\n   553→        lines.append(\"### 依据与引用\")\n   554→        lines.append(f\"- 四柱：{bazi.year_pillar}・{bazi.month_pillar}・{bazi.day_pillar}・{bazi.hour_pillar}\")\n   555→        lines.append(f\"- 五行：{bazi.wuxing or '未知'}\")\n   556→        if report_summary:\n   557→            lines.append(\"- 历史报告摘要：\")\n   558→            lines.append(report_summary)\n   559→        else:\n   560→            lines.append(\"- 历史报告：未找到，已仅基于八字作答\")\n   561→        lines.append(\"\")\n   562→        lines.append(\"### 不确定性与下一步\")\n   563→        lines.append(\"- 若存在校准结果，请补充校准时间以提升准确度。\")\n   564→        lines.append(\"- 可提供近三年关键事件以获得更个性化建议。\")\n   565→\n   566→        answer_md = \"\\n\".join(lines)\n   567→\n   568→        # Best-effort: append conversation snapshot to local logs\n   569→        try:\n   570→            u = get_fortune_user_by_name(req.name)\n   571→            user_id = int(u.get(\"user_id\")) if u and u.get(\"user_id\") is not None else None\n   572→        except Exception:\n   573→            user_id = None\n   574→        try:\n   575→            if user_id is not None:\n   576→                session_id = int(time.time())\n   577→                if req.question:\n   578→                    append_prompt(user_id, session_id, req.question, req.model or \"standard\")\n   579→                append_output(user_id, session_id, answer_md, url=doc_url)\n   580→        except Exception:\n   581→            pass\n   582→\n   583→        return {\n   584→            \"status\": \"ok\",\n   585→            \"answer_md\": answer_md,\n   586→            \"used_context\": {\n   587→                \"bazi_used\": {\n   588→                    \"year_pillar\": bazi.year_pillar,\n   589→                    \"month_pillar\": bazi.month_pillar,\n   590→                    \"day_pillar\": bazi.day_pillar,\n   591→                    \"hour_pillar\": bazi.hour_pillar,\n   592→                    \"wuxing\": bazi.wuxing,\n   593→                    \"counts\": counts,\n   594→                },\n   595→                \"report_used\": bool(report_summary),\n   596→                \"doc_url\": doc_url,\n   597→            },\n   598→            \"audit_id\": audit_id,\n   599→        }\n   600→    except HTTPException:\n   601→        raise\n   602→    except Exception as e:\n   603→        logger.error(\"ask sync failed\", extra={\"operation\": \"bazi_ask_sync\", \"error\": str(e), \"audit_id\": audit_id})\n   604→        raise HTTPException(status_code=500, detail=\"ask_failed\")\n   605→\n   606→\n   607→@app.get(\"/api/bazi/ask/stream\")\n   608→def api_bazi_ask_stream(\n   609→    name: str,\n   610→    gender: str,\n   611→    date: str,\n   612→    time: str,\n   613→    tz_offset_hours: float = 8.0,\n   614→    longitude: Optional[float] = None,\n   615→    latitude: Optional[float] = None,\n   616→    location_name: Optional[str] = None,\n   617→    question: str = \"\",\n   618→    model: str = \"standard\",\n   619→):\n   620→    audit_id = str(uuid4())\n   621→\n   622→    def _sse(obj: Dict[str, Any]) -> bytes:\n   623→        return (f\"data: {json.dumps(obj, ensure_ascii=False)}\\n\\n\").encode(\"utf-8\")\n   624→\n   625→    def _gen():\n   626→        try:\n   627→            y, m, d, hh, mm = _parse_date_time(date, time)\n   628→            bazi = calculate_bazi(\n   629→                y, m, d, hh, mm,\n   630→                {\"longitude\": longitude or DEFAULT_LOCATION[\"longitude\"],\n   631→                 \"latitude\": latitude or DEFAULT_LOCATION[\"latitude\"],\n   632→                 \"name\": location_name or DEFAULT_LOCATION.get(\"name\", \"\")},\n   633→            )\n   634→            counts = _wuxing_counts(bazi.wuxing)\n   635→            report_summary, _doc_url = _latest_report_summary_for_user(name)\n   636→\n   637→            chunks = [\n   638→                {\"type\": \"chunk\", \"text\": \"### 结论要点\\n\"},\n   639→                {\"type\": \"chunk\", \"text\": f\"- 五行倾向：{', '.join([f'{k}{v}' for k,v in counts.items() if v>0]) or '暂无'}\\n\"},\n   640→                {\"type\": \"chunk\", \"text\": \"\\n### 依据与引用\\n\"},\n   641→                {\"type\": \"chunk\", \"text\": f\"- 四柱：{bazi.year_pillar}・{bazi.month_pillar}・{bazi.day_pillar}・{bazi.hour_pillar}\\n\"},\n   642→                {\"type\": \"chunk\", \"text\": f\"- 五行：{bazi.wuxing or '未知'}\\n\"},\n   643→            ]\n   644→            if report_summary:\n   645→                chunks.append({\"type\": \"chunk\", \"text\": \"- 历史报告摘要：\\n\" + report_summary + \"\\n\"})\n   646→            else:\n   647→                chunks.append({\"type\": \"chunk\", \"text\": \"- 历史报告：未找到，已仅基于八字作答\\n\"})\n   648→            chunks.extend([\n   649→                {\"type\": \"chunk\", \"text\": \"\\n### 不确定性与下一步\\n\"},\n   650→                {\"type\": \"chunk\", \"text\": \"- 若存在校准结果，请补充校准时间以提升准确度。\\n\"},\n   651→                {\"type\": \"chunk\", \"text\": \"- 可提供近三年关键事件以获得更个性化建议。\\n\"},\n   652→            ])\n   653→\n   654→            for c in chunks:\n   655→                yield _sse({**c, \"audit_id\": audit_id})\n   656→                time.sleep(0.05)\n   657→\n   658→            yield _sse({\n   659→                \"type\": \"done\",\n   660→                \"audit_id\": audit_id,\n   661→            })\n   662→        except Exception as e:\n   663→            logger.error(\"ask stream failed\", extra={\"operation\": \"bazi_ask_stream\", \"error\": str(e), \"audit_id\": audit_id})\n   664→            yield _sse({\"type\": \"error\", \"detail\": \"ask_failed\", \"audit_id\": audit_id})\n   665→\n   666→    return StreamingResponse(\n   667→        _gen(),\n   668→        media_type=\"text/event-stream\",\n   669→        headers={\"Cache-Control\": \"no-cache\", \"X-Accel-Buffering\": \"no\"},\n   670→    )\n   671→\n   672→\n   673→@app.get(\"/h5/a2ui\", response_class=HTMLResponse)\n   674→def h5_a2ui(request: Request):\n   675→    # Legacy page - redirect to new frontend\n   676→    return RedirectResponse(url=\"/new\", status_code=307)\n   677→\n   678→\n   679→@app.get(\"/fortune\", response_class=HTMLResponse)\n   680→def fortune(request: Request):\n   681→    \"\"\"Legacy page - redirect to new frontend.\"\"\"\n   682→    return RedirectResponse(url=\"/new\", status_code=307)\n   683→\n   684→\n   685→@app.get(\"/api/system-prompts\")\n   686→def api_system_prompts(openid: str = \"web\"):\n   687→    # Legacy API - disabled for security\n   688→    raise HTTPException(status_code=410, detail=\"deprecated_use_new_api\")\n   689→\n   690→\n   691→@app.post(\"/api/system-prompts\")\n   692→def api_save_system_prompt(req: SystemPromptSaveRequest):\n   693→    # Legacy API - disabled for security\n   694→    raise HTTPException(status_code=410, detail=\"deprecated_use_new_api\")\n   695→\n   696→\n   697→@app.post(\"/api/tieban/init\")\n   698→def api_tieban_init(req: TiebanInitRequest):\n   699→    try:\n   700→        payload = req.dict()\n   701→        result = tieban_service.init_tieban(payload)\n   702→        return result\n   703→    except Exception as e:\n   704→        logger.error(\"tieban init failed\", extra={\"operation\": \"tieban_init\", \"error\": str(e)[:200]})\n   705→        raise HTTPException(status_code=500, detail=\"tieban_init_error\")\n   706→\n   707→\n   708→@app.post(\"/api/tieban/verify\")\n   709→def api_tieban_verify(req: TiebanVerifyRequest):\n   710→    try:\n   711→        result = tieban_service.verify_tieban(req.run_id, req.answers, req.state_version)\n   712→        return result\n   713→    except Exception as e:\n   714→        if str(e) == \"state_version_conflict\":\n   715→            raise HTTPException(status_code=409, detail=\"state_version_conflict\")\n   716→        logger.error(\"tieban verify failed\", extra={\"operation\": \"tieban_verify\", \"error\": str(e)[:200]})\n   717→        raise HTTPException(status_code=500, detail=\"tieban_verify_error\")\n   718→\n   719→\n   720→@app.post(\"/api/tieban/select\")\n   721→def api_tieban_select(req: TiebanSelectRequest):\n   722→    try:\n   723→        result = tieban_service.select_tieban(req.run_id, req.candidate_id, req.state_version)\n   724→        return result\n   725→    except Exception as e:\n   726→        if str(e) == \"state_version_conflict\":\n   727→            raise HTTPException(status_code=409, detail=\"state_version_conflict\")\n   728→        if str(e) in (\"missing_required_facts\", \"required_fact_not_matched\", \"candidate_not_found\"):\n   729→            raise HTTPException(status_code=400, detail=str(e))\n   730→        logger.error(\"tieban select failed\", extra={\"operation\": \"tieban_select\", \"error\": str(e)[:200]})\n   731→        raise HTTPException(status_code=500, detail=\"tieban_select_error\")\n   732→\n   733→\n   734→@app.post(\"/api/tieban/lock\")\n   735→def api_tieban_lock(req: TiebanLockRequest):\n   736→    try:\n   737→        result = tieban_service.lock_tieban(req.run_id, req.state_version)\n   738→        return result\n   739→    except Exception as e:\n   740→        if str(e) == \"state_version_conflict\":\n   741→            raise HTTPException(status_code=409, detail=\"state_version_conflict\")\n   742→        if str(e) == \"deprecated_use_select\":\n   743→            raise HTTPException(status_code=400, detail=\"deprecated_use_select\")\n   744→        logger.error(\"tieban lock failed\", extra={\"operation\": \"tieban_lock\", \"error\": str(e)[:200]})\n   745→        raise HTTPException(status_code=500, detail=\"tieban_lock_error\")\n   746→\n   747→\n   748→@app.get(\"/api/tieban/report\")\n   749→def api_tieban_report(run_id: str):\n   750→    try:\n   751→        return tieban_service.get_report(run_id)\n   752→    except Exception as e:\n   753→        logger.error(\"tieban report failed\", extra={\"operation\": \"tieban_report\", \"error\": str(e)[:200]})\n   754→        raise HTTPException(status_code=404, detail=\"tieban_report_error\")\n   755→\n   756→\n   757→@app.post(\"/api/calculate\")\n   758→def create_report(req: BaziRequest, backend: str | None = None):\n   759→    # Legacy API - deprecated, use authenticated /api/chat endpoints instead\n   760→    raise HTTPException(status_code=410, detail=\"deprecated_use_new_api\")\n   761→    correlation_id = str(uuid4())\n   762→    try:\n   763→        # 先计算八字命盘并即时返回；后台另起 v2 任务走“standard”模型\n   764→        base = req.dict()\n   765→        from time import time as _now\n   766→        job_id, user_id, used_default, bazi = task_service.submit_bazi_task_v2(\n   767→            {\n   768→                \"openid\": \"web\",\n   769→                \"src\": \"web\",\n   770→                \"model\": \"standard\",\n   771→                **base,\n   772→            },\n   773→            correlation_id=correlation_id,\n   774→            backend_hint=backend,\n   775→            force_nonce=str(int(_now())),\n   776→        )\n   777→        try:\n   778→            if req.system_prompt:\n   779→                prompt_store.append_for_openid(\"web\", req.system_prompt, \"standard\")\n   780→        except Exception:\n   781→            pass\n   782→        return {\n   783→            \"job_id\": job_id,\n   784→            \"user_id\": user_id,\n   785→            \"status\": \"processing\",\n   786→            \"used_default_location\": used_default,\n   787→            \"default_location\": DEFAULT_LOCATION if used_default else None,\n   788→            \"bazi\": {\n   789→                \"year_pillar\": bazi.year_pillar,\n   790→                \"month_pillar\": bazi.month_pillar,\n   791→                \"day_pillar\": bazi.day_pillar,\n   792→                \"hour_pillar\": bazi.hour_pillar,\n   793→                \"wuxing\": bazi.wuxing,\n   794→                \"location\": bazi.location,\n   795→            },\n   796→        }\n   797→    except ValueError as ve:\n   798→        logger.warning(\"validation failed\", extra={\"operation\": \"api_calculate\", \"error\": str(ve), \"correlation_id\": correlation_id})\n   799→        raise HTTPException(status_code=400, detail=str(ve))\n   800→    except Exception as e:\n   801→        msg = str(e)\n   802→        logger.error(\"calculate failed\", extra={\"operation\": \"api_calculate\", \"error\": msg, \"correlation_id\": correlation_id})\n   803→        if msg in (\"empty_prompt\", \"no_tasks\", \"no_tasks_built\"):\n   804→            raise HTTPException(status_code=400, detail=msg)\n   805→        raise HTTPException(status_code=500, detail=\"internal_error\")\n   806→\n   807→\n   808→@app.get(\"/api/report/{job_id}\")\n   809→def get_report(job_id: int, backend: str | None = None):\n   810→    # Legacy API - deprecated, use authenticated /api/chat endpoints instead\n   811→    raise HTTPException(status_code=410, detail=\"deprecated_use_new_api\")\n   812→    tasks = be.get_tasks_by_job_id(job_id, backend=backend)\n   813→    if not tasks:\n   814→        return {\"status\": \"error\", \"message\": \"no_tasks\"}\n   815→\n   816→    main_task = tasks[0]\n   817→    status_val = main_task.get(\"status\", 0)\n   818→    if status_val < 99:\n   819→        return {\"status\": \"processing\", \"progress\": status_val}\n   820→    if not main_task.get(\"output_text\") and not main_task.get(\"output_url\"):\n   821→        # For CLI backend, try expose the first inline file as a download link\n   822→        if (backend or os.getenv(\"GEMINI_BACKEND\", \"gemini\")).strip().lower() == \"cli\":\n   823→            try:\n   824→                from integrations.cli_worker_repo import list_output_files_by_job_id\n   825→                files = list_output_files_by_job_id(job_id)\n   826→                if files:\n   827→                    # choose the first file; if it has content, we can stream it via /api/files\n   828→                    dl = f\"/api/files/{job_id}?backend=cli\"\n   829→                    return {\"status\": \"completed\", \"content\": None, \"doc_url\": dl}\n   830→            except Exception:\n   831→                pass\n   832→        return {\"status\": \"error\", \"message\": \"task_missing_output\"}\n   833→\n   834→    content = main_task.get(\"output_text\")\n   835→    doc_url = main_task.get(\"output_url\")\n   836→    # persist conversation output if user is known\n   837→    try:\n   838→        uid = find_user_by_job(job_id)\n   839→        if uid is not None and (content or doc_url):\n   840→            append_output(uid, job_id, content or \"\", doc_url)\n   841→    except Exception:\n   842→        pass\n   843→\n   844→    # best-effort: sync gemini_url to fortune_user when job is done\n   845→    try:\n   846→        sync_job_gemini_url_to_user(job_id)\n   847→    except Exception:\n   848→        pass\n   849→\n   850→    return {\n   851→        \"status\": \"completed\",\n   852→        \"content\": content,\n   853→        \"doc_url\": doc_url,\n   854→    }\n   855→\n   856→\n   857→@app.post(\"/api/rectify\")\n   858→def api_rectify(req: RectifyRequest):\n   859→    try:\n   860→        # 对于未提供经纬度的情况，使用默认北京经纬度（与八字计算一致）\n   861→        lat = req.latitude if req.latitude is not None else DEFAULT_LOCATION[\"latitude\"]\n   862→        lon = req.longitude if req.longitude is not None else DEFAULT_LOCATION[\"longitude\"]\n   863→        result = rectify_birth_time_v2(\n   864→            name=req.name,\n   865→            birthday=req.birthday,\n   866→            lat=lat,\n   867→            lon=lon,\n   868→            window_start_hms=req.window_start,\n   869→            window_end_hms=req.window_end,\n   870→            events_raw=[e.dict() for e in req.events],\n   871→            tz_offset_hours=req.tz_offset_hours or 8.0,\n   872→            step_seconds=30,\n   873→            debug=bool(req.debug),\n   874→        )\n   875→        _persist_rectification_result(req, result, lat=lat, lon=lon)\n   876→        return _rectify_response_payload(result, received_events=[e.dict() for e in req.events])\n   877→    except Exception as e:\n   878→        logger.error(\"rectify failed\", extra={\"operation\": \"api_rectify\", \"error\": str(e)})\n   879→        raise HTTPException(status_code=400, detail=\"rectify_failed\")\n   880→\n   881→\n   882→@app.post(\"/api/rectify/stream\")\n   883→def api_rectify_stream(req: RectifyRequest):\n   884→    lat = req.latitude if req.latitude is not None else DEFAULT_LOCATION[\"latitude\"]\n   885→    lon = req.longitude if req.longitude is not None else DEFAULT_LOCATION[\"longitude\"]\n   886→    correlation_id = str(uuid4())\n   887→\n   888→    def _sse(obj: Dict[str, Any]) -> bytes:\n   889→        return (f\"data: {json.dumps(obj, ensure_ascii=False)}\\n\\n\").encode(\"utf-8\")\n   890→\n   891→    def _gen():\n   892→        try:\n   893→            received_events = [e.dict() for e in req.events]\n   894→            for msg in rectify_birth_time_v2_iter(\n   895→                name=req.name,\n   896→                birthday=req.birthday,\n   897→                lat=lat,\n   898→                lon=lon,\n   899→                window_start_hms=req.window_start,\n   900→                window_end_hms=req.window_end,\n   901→                events_raw=[e.dict() for e in req.events],\n   902→                tz_offset_hours=req.tz_offset_hours or 8.0,\n   903→                step_seconds=30,\n   904→                debug=bool(req.debug),\n   905→            ):\n   906→                if msg.get(\"type\") == \"result\":\n   907→                    result = msg[\"result\"]\n   908→                    _persist_rectification_result(req, result, lat=lat, lon=lon)\n   909→                    yield _sse({\"type\": \"done\", **_rectify_response_payload(result, received_events=received_events)})\n   910→                else:\n   911→                    out = dict(msg)\n   912→                    out.setdefault(\"correlation_id\", correlation_id)\n   913→                    yield _sse(out)\n   914→        except Exception as e:\n   915→            logger.error(\n   916→                \"rectify stream failed\",\n   917→                extra={\"operation\": \"api_rectify_stream\", \"error\": str(e), \"correlation_id\": correlation_id},\n   918→            )\n   919→            yield _sse({\"type\": \"error\", \"detail\": \"rectify_failed\", \"correlation_id\": correlation_id})\n   920→\n   921→    return StreamingResponse(\n   922→        _gen(),\n   923→        media_type=\"text/event-stream\",\n   924→        headers={\"Cache-Control\": \"no-cache\", \"X-Accel-Buffering\": \"no\"},\n   925→    )\n   926→\n   927→\n   928→# ------------------------------ v3 (interval + fuzzy distribution) ------------------------------\n   929→\n   930→\n   931→@app.post(\"/api/rectify/v3\")\n   932→def api_rectify_v3(req: RectifyRequest):\n   933→    try:\n   934→        lat = req.latitude if req.latitude is not None else DEFAULT_LOCATION[\"latitude\"]\n   935→        lon = req.longitude if req.longitude is not None else DEFAULT_LOCATION[\"longitude\"]\n   936→        result = rectification_v3.rectify_birth_time_v3(\n   937→            name=req.name,\n   938→            birthday=req.birthday,\n   939→            lat=lat,\n   940→            lon=lon,\n   941→            window_start_hms=req.window_start,\n   942→            window_end_hms=req.window_end,\n   943→            events_raw=[e.dict() for e in req.events],\n   944→            tz_offset_hours=req.tz_offset_hours or 8.0,\n   945→            step_seconds=30,\n   946→        )\n   947→        _persist_rectification_result(req, result, lat=lat, lon=lon)\n   948→        result[\"received_events\"] = [e.dict() for e in req.events]\n   949→        return result\n   950→    except Exception as e:\n   951→        logger.error(\"rectify v3 failed\", extra={\"operation\": \"api_rectify_v3\", \"error\": str(e)})\n   952→        raise HTTPException(status_code=400, detail=\"rectify_failed\")\n   953→\n   954→\n   955→@app.post(\"/api/rectify/v3/stream\")\n   956→def api_rectify_v3_stream(req: RectifyRequest):\n   957→    lat = req.latitude if req.latitude is not None else DEFAULT_LOCATION[\"latitude\"]\n   958→    lon = req.longitude if req.longitude is not None else DEFAULT_LOCATION[\"longitude\"]\n   959→    correlation_id = str(uuid4())\n   960→\n   961→    def _sse(obj: Dict[str, Any]) -> bytes:\n   962→        return (f\"data: {json.dumps(obj, ensure_ascii=False)}\\n\\n\").encode(\"utf-8\")\n   963→\n   964→    def _gen():\n   965→        try:\n   966→            received_events = [e.dict() for e in req.events]\n   967→            for msg in rectification_v3.rectify_birth_time_v3_iter(\n   968→                name=req.name,\n   969→                birthday=req.birthday,\n   970→                lat=lat,\n   971→                lon=lon,\n   972→                window_start_hms=req.window_start,\n   973→                window_end_hms=req.window_end,\n   974→                events_raw=received_events,\n   975→                tz_offset_hours=req.tz_offset_hours or 8.0,\n   976→                step_seconds=30,\n   977→            ):\n   978→                if msg.get(\"type\") == \"result\":\n   979→                    res = msg[\"result\"]\n   980→                    res[\"received_events\"] = received_events\n   981→                    _persist_rectification_result(req, res, lat=lat, lon=lon)\n   982→                    yield _sse({\"type\": \"done\", **res})\n   983→                else:\n   984→                    out = dict(msg)\n   985→                    out.setdefault(\"correlation_id\", correlation_id)\n   986→                    yield _sse(out)\n   987→        except Exception as e:\n   988→            logger.error(\n   989→                \"rectify v3 stream failed\",\n   990→                extra={\"operation\": \"api_rectify_v3_stream\", \"error\": str(e), \"correlation_id\": correlation_id},\n   991→            )\n   992→            yield _sse({\"type\": \"error\", \"detail\": \"rectify_failed\", \"correlation_id\": correlation_id})\n   993→\n   994→    return StreamingResponse(\n   995→        _gen(),\n   996→        media_type=\"text/event-stream\",\n   997→        headers={\"Cache-Control\": \"no-cache\", \"X-Accel-Buffering\": \"no\"},\n   998→    )\n   999→\n  1000→\n  1001→# ------------------------------\n  1002→# v2 API per docs/design v2.md\n  1003→# ------------------------------\n  1004→\n  1005→class V2SubmitBirthData(BaseModel):\n  1006→    name: str\n  1007→    gender: str\n  1008→    year: int\n  1009→    month: int\n  1010→    day: int\n  1011→    hour: int\n  1012→    minute: int\n  1013→    longitude: Optional[float] = None\n  1014→    latitude: Optional[float] = None\n  1015→    location_name: Optional[str] = None\n  1016→\n  1017→\n  1018→class V2SubmitRequest(BaseModel):\n  1019→    openid: str = Field(..., min_length=3)\n  1020→    src: str = Field(\"wechat\", description=\"来源渠道\")\n  1021→    model: str = Field(\"standard\", description=\"Gemini 模型：standard | deep_research\")\n  1022→    system_prompt: Optional[str] = Field(None, description=\"可选 system prompt，拼接在八字前作为提示\")\n  1023→    birth_data: V2SubmitBirthData\n  1024→\n  1025→\n  1026→@app.post(\"/api/v2/submit\")\n  1027→def v2_submit(req: V2SubmitRequest, backend: str | None = None):\n  1028→    # Legacy v2 API - deprecated, use authenticated /api/chat endpoints instead\n  1029→    raise HTTPException(status_code=410, detail=\"deprecated_use_new_api\")\n  1030→    correlation_id = str(uuid4())\n  1031→    try:\n  1032→        if os.getenv(\"DEMO_MODE\") == \"1\":\n  1033→            # 极简演示：不依赖 DB，直接返回一个模拟 job_id\n  1034→            return {\n  1035→                \"job_id\": 101,\n  1036→                \"user_id\": 1,\n  1037→                \"status\": \"processing\",\n  1038→                \"eta_seconds\": 2,\n  1039→                \"used_default_location\": False,\n  1040→                \"default_location\": None,\n  1041→            }\n  1042→        # 为降低 CLI 后端的幂等去重概率，这里在 v2 提交强制注入一次性 nonce\n  1043→        from time import time as _now\n  1044→        job_id, user_id, used_default, bazi = task_service.submit_bazi_task_v2(\n  1045→            {\n  1046→                \"openid\": req.openid,\n  1047→                \"src\": req.src,\n  1048→                \"model\": req.model,\n  1049→                \"system_prompt\": req.system_prompt,\n  1050→                **req.birth_data.dict(),\n  1051→            },\n  1052→            correlation_id=correlation_id,\n  1053→            backend_hint=backend,\n  1054→            force_nonce=str(int(_now())),\n  1055→        )\n  1056→        # 记录 prompt 历史（本地 user/prompts/openid_xxx/prompts.json），不写 gemini 表\n  1057→        try:\n  1058→            if req.system_prompt:\n  1059→                prompt_store.append_for_openid(req.openid, req.system_prompt, req.model)\n  1060→        except Exception as _:\n  1061→            pass\n  1062→        return {\n  1063→            \"job_id\": job_id,\n  1064→            \"user_id\": user_id,\n  1065→            \"status\": \"processing\",\n  1066→            \"eta_seconds\": 120,\n  1067→            \"used_default_location\": used_default,\n  1068→            \"default_location\": DEFAULT_LOCATION if used_default else None,\n  1069→            \"bazi\": {\n  1070→                \"year_pillar\": bazi.year_pillar,\n  1071→                \"month_pillar\": bazi.month_pillar,\n  1072→                \"day_pillar\": bazi.day_pillar,\n  1073→                \"hour_pillar\": bazi.hour_pillar,\n  1074→                \"wuxing\": bazi.wuxing,\n  1075→                \"location\": bazi.location,\n  1076→            },\n  1077→        }\n  1078→    except ValueError as ve:\n  1079→        logger.warning(\"v2 submit validation failed\", extra={\"operation\": \"api_v2_submit\", \"error\": str(ve), \"correlation_id\": correlation_id})\n  1080→        raise HTTPException(status_code=400, detail=str(ve))\n  1081→    except Exception as e:\n  1082→        msg = str(e)\n  1083→        logger.error(\"v2 submit failed\", extra={\"operation\": \"api_v2_submit\", \"error\": msg, \"correlation_id\": correlation_id})\n  1084→        if msg in (\"empty_prompt\", \"no_tasks\", \"no_tasks_built\"):\n  1085→            raise HTTPException(status_code=400, detail=msg)\n  1086→        raise HTTPException(status_code=500, detail=\"internal_error\")\n  1087→\n  1088→\n  1089→@app.get(\"/api/v2/report/{job_id}\")\n  1090→def v2_report(job_id: int, backend: str | None = None) -> Dict[str, Any]:\n  1091→    # Legacy v2 API - deprecated, use authenticated /api/chat endpoints instead\n  1092→    raise HTTPException(status_code=410, detail=\"deprecated_use_new_api\")\n  1093→    if os.getenv(\"DEMO_MODE\") == \"1\":\n  1094→        # 极简演示：不再返回写库示例，仅提示处理中\n  1095→        return {\"status\": \"processing\", \"progress\": 0}\n  1096→\n  1097→    tasks = be.get_tasks_by_job_id(job_id, backend=backend)\n  1098→    if not tasks:\n  1099→        return {\"status\": \"error\", \"message\": \"no_tasks\"}\n  1100→\n  1101→    main_task = tasks[0]\n  1102→    status_val = int(main_task.get(\"status\", 0) or 0)\n  1103→    if status_val < 10:\n  1104→        return {\"status\": \"processing\", \"progress\": status_val}\n  1105→\n  1106→    output_text = main_task.get(\"output_text\")\n  1107→    output_url = main_task.get(\"output_url\")\n  1108→    if not output_text:\n  1109→        # 兼容仅有文档链接（output_url）而无内嵌文本的情况\n  1110→        if output_url:\n  1111→            # best-effort: persist conversation output (url only)\n  1112→            try:\n  1113→                uid = find_user_by_job(job_id)\n  1114→                if uid is not None:\n  1115→                    append_output(uid, job_id, \"\", output_url)\n  1116→            except Exception:\n  1117→                pass\n  1118→            # best-effort: sync gemini_url when job is done\n  1119→            try:\n  1120→                sync_job_gemini_url_to_user(job_id)\n  1121→            except Exception:\n  1122→                pass\n  1123→            # 返回可阅读的占位 A2UI（Markdown 组件 + 下载链接）\n  1124→            md = f\"报告已生成，但未返回内嵌文本。请点击下载文档：\\n\\n[下载报告]({output_url})\"\n  1125→            return {\"status\": \"completed\", \"a2ui_data\": {\"meta\": {\"summary\": \"报告已生成（文档链接）\"}, \"ui_components\": [{\"type\": \"markdown_text\", \"title\": \"模型输出\", \"data\": md}]}}\n  1126→        return {\"status\": \"error\", \"message\": \"task_missing_output\"}\n  1127→\n  1128→    try:\n  1129→        import json\n  1130→\n  1131→        a2ui = json.loads(output_text)\n  1132→        validate_a2ui(a2ui)\n  1133→        # persist conversation output for v2 as well\n  1134→        try:\n  1135→            uid = find_user_by_job(job_id)\n  1136→            if uid is not None:\n  1137→                append_output(uid, job_id, output_text)\n  1138→        except Exception:\n  1139→            pass\n  1140→        # best-effort: sync gemini_url to fortune_user when job is done or parsable\n  1141→        try:\n  1142→            sync_job_gemini_url_to_user(job_id)\n  1143→        except Exception:\n  1144→            pass\n  1145→        return {\"status\": \"completed\", \"a2ui_data\": a2ui}\n  1146→    except ValidationError as ve:\n  1147→        # 若为合法 JSON 但不符合 A2UI，按 Markdown 文本回退\n  1148→        return {\"status\": \"completed\", \"a2ui_data\": {\"meta\": {\"summary\": \"模型返回非规范 A2UI，已按 Markdown 展示\"}, \"ui_components\": [{\"type\": \"markdown_text\", \"title\": \"模型输出\", \"data\": output_text}]}}\n  1149→    except Exception:\n  1150→        # 非 JSON：按 Markdown 文本回退\n  1151→        return {\"status\": \"completed\", \"a2ui_data\": {\"meta\": {\"summary\": output_text[:60]}, \"ui_components\": [{\"type\": \"markdown_text\", \"title\": \"模型输出\", \"data\": output_text}]}}\n  1152→\n  1153→\n  1154→# ------------------------------\n  1155→# Files API (CLI backend output streaming)\n  1156→# ------------------------------\n  1157→\n  1158→\n  1159→@app.get(\"/api/files/{job_id}\")\n  1160→def api_files(job_id: int, backend: str | None = None, filename: str | None = None):\n  1161→    # Legacy API - disabled for security, use authenticated endpoints\n  1162→    raise HTTPException(status_code=410, detail=\"deprecated_use_new_api\")\n  1163→    b = (backend or os.getenv(\"GEMINI_BACKEND\", \"gemini\")).strip().lower()\n  1164→    if b != \"cli\":\n  1165→        raise HTTPException(status_code=400, detail=\"files_only_available_for_cli\")\n  1166→    try:\n  1167→        from integrations.cli_worker_repo import fetch_output_file_content, list_output_files_by_job_id\n  1168→        fname, content = fetch_output_file_content(job_id, filename)\n  1169→        if content is None:\n  1170→            # return a lightweight index for UX when nothing inline\n  1171→            files = list_output_files_by_job_id(job_id)\n  1172→            return {\"files\": files}\n  1173→        media = \"text/plain\"\n  1174→        # simple heuristic: .md/.txt → text/plain; otherwise octet-stream\n  1175→        if fname and (str(fname).endswith(\".md\") or str(fname).endswith(\".txt\")):\n  1176→            media = \"text/plain; charset=utf-8\"\n  1177→        headers = {\"Content-Disposition\": f\"inline; filename={fname or 'output.txt'}\"}\n  1178→        return StreamingResponse(iter([content]), media_type=media, headers=headers)\n  1179→    except HTTPException:\n  1180→        raise\n  1181→    except Exception as e:\n  1182→        logger.error(\"files endpoint failed\", extra={\"operation\": \"api_files\", \"error\": str(e)[:200]})\n  1183→        raise HTTPException(status_code=500, detail=\"files_error\")\n  1184→\n  1185→\n  1186→# ------------------------------\n  1187→# WeCom OAuth (Tencent Cloud friendly)\n  1188→# ------------------------------\n  1189→\n  1190→\n  1191→@app.get(\"/qy/oauth/redirect\")\n  1192→def qy_oauth_redirect():\n  1193→    corp_id = os.getenv(\"QY_CORP_ID\")\n  1194→    agent_id = os.getenv(\"QY_AGENT_ID\")\n  1195→    redirect_uri = os.getenv(\"QY_REDIRECT_URI\")\n  1196→    if not (corp_id and agent_id and redirect_uri):\n  1197→        raise HTTPException(status_code=500, detail=\"missing_qy_env\")\n  1198→    auth_url = (\n  1199→        \"https://open.weixin.qq.com/connect/oauth2/authorize?\"\n  1200→        + urllib.parse.urlencode(\n  1201→            {\n  1202→                \"appid\": corp_id,\n  1203→                \"redirect_uri\": redirect_uri,\n  1204→                \"response_type\": \"code\",\n  1205→                \"scope\": \"snsapi_base\",\n  1206→                \"state\": \"a2ui\",\n  1207→                \"agentid\": agent_id,\n  1208→            }\n  1209→        )\n  1210→        + \"#wechat_redirect\"\n  1211→    )\n  1212→    return {\"auth_url\": auth_url}\n  1213→\n  1214→\n  1215→@app.get(\"/qy/oauth/callback\")\n  1216→def qy_oauth_callback(code: str, request: Request):\n  1217→    corp_id = os.getenv(\"QY_CORP_ID\")\n  1218→    corp_secret = os.getenv(\"QY_CORP_SECRET\")\n  1219→    if not (corp_id and corp_secret):\n  1220→        raise HTTPException(status_code=500, detail=\"missing_qy_env\")\n  1221→\n  1222→    # 1) get access token\n  1223→    token_url = \"https://qyapi.weixin.qq.com/cgi-bin/gettoken\"\n  1224→    user_url = \"https://qyapi.weixin.qq.com/cgi-bin/auth/getuserinfo\"\n  1225→    with httpx.Client(timeout=10.0) as client:\n  1226→        r1 = client.get(token_url, params={\"corpid\": corp_id, \"corpsecret\": corp_secret})\n  1227→        r1.raise_for_status()\n  1228→        tok = r1.json()\n  1229→        access_token = tok.get(\"access_token\")\n  1230→        if not access_token:\n  1231→            raise HTTPException(status_code=502, detail=\"qy_token_error\")\n  1232→        r2 = client.get(user_url, params={\"access_token\": access_token, \"code\": code})\n  1233→        r2.raise_for_status()\n  1234→        info = r2.json()\n  1235→\n  1236→    userid = info.get(\"UserId\") or info.get(\"userid\") or info.get(\"external_userid\")\n  1237→    if not userid:\n  1238→        raise HTTPException(status_code=400, detail=\"qy_no_user\")\n  1239→\n  1240→    # Put userid in query and bounce to H5\n  1241→    h5_path = os.getenv(\"QY_H5_PATH\", \"/h5/a2ui\")\n  1242→    target = f\"{h5_path}?userid={urllib.parse.quote(userid)}\"\n  1243→    return templates.TemplateResponse(\n  1244→        \"redirect.html\",\n  1245→        {\"request\": request, \"target\": target},\n  1246→    )\n  1247→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"8d738f5e-4c5c-4b50-90cf-f06f9e60fa49","timestamp":"2026-01-01T15:01:16.942Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aiscend/work/fortune_ai/api/main.py","content":"from fastapi import FastAPI, HTTPException, Request\nfrom fastapi.responses import HTMLResponse, StreamingResponse, RedirectResponse\nfrom starlette.middleware.gzip import GZipMiddleware\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.staticfiles import StaticFiles\nfrom fastapi.templating import Jinja2Templates\nfrom pydantic import BaseModel, Field, validator\nfrom typing import Optional, Dict, Any, Tuple, List\nfrom uuid import uuid4\nimport os\nimport urllib.parse\nimport json\nimport re\nimport time\nfrom datetime import datetime\n\nfrom common.logging import get_logger\nfrom services import task_service\nfrom services.rectification import rectify_birth_time_v2, rectify_birth_time_v2_iter\nfrom services import rectification_v3\nfrom user_store import update_fortune_user_rectification_by_name, get_fortune_user_by_name, create_fortune_user\nfrom services.bazi_engine import calculate_bazi\nfrom services.bazi_engine import DEFAULT_LOCATION\nfrom services import prompt_store\nimport os as _os\nfrom integrations import backend_router as be\nfrom services.conversation_store import append_output, append_prompt, find_user_by_job, save_job_index\nfrom common.a2ui import validate_a2ui, ValidationError\nimport httpx\nfrom services.task_service import sync_job_gemini_url_to_user\nfrom services import rectification_store\nfrom services.tieban import service as tieban_service\nfrom api.auth_routes import router as auth_router\nfrom api.deps import get_current_auth\nfrom api.user_routes import router as user_router\nfrom api.session_routes import router as session_router\nfrom api.chat_routes import router as chat_router\nfrom api.bento_routes import router as bento_router\nfrom api.dashboard_routes import router as dashboard_router\nfrom api.bazi_routes import router as bazi_router\nfrom api.kb_routes import router as kb_router\nfrom api.plan_routes import router as plan_router\nfrom api.report_routes import router as report_router\nfrom api.push_routes import router as push_router\nfrom api.twin_routes import router as twin_router\nfrom api.agent_tool import router as agent_tool_router\nfrom api.social_routes import router as social_router\nfrom api.jitai_routes import router as jitai_router\nfrom api.currency_routes import router as currency_router\nfrom api.goal_routes import router as goal_router\nfrom api.reflection_routes import router as reflection_router\nfrom api.yunshi_routes import router as yunshi_router\nfrom api.poster_routes import router as poster_router\n\nlogger = get_logger(__name__)\n\n\ndef _patch_anyio_threading_for_tests() -> None:\n    \"\"\"\n    Work around threadpool hangs in the sandboxed test runtime.\n\n    FastAPI runs sync endpoints via `anyio.to_thread.run_sync()`. In this\n    environment it can deadlock; for tests/stub mode we run sync callables inline.\n    \"\"\"\n    if os.getenv(\"STUB_DB\") != \"1\" and not os.getenv(\"PYTEST_CURRENT_TEST\"):\n        return\n\n    try:\n        import anyio.to_thread\n\n        async def _run_sync_inline(func, *args, **kwargs):  # type: ignore[no-untyped-def]\n            kwargs.pop(\"abandon_on_cancel\", None)\n            kwargs.pop(\"cancellable\", None)\n            kwargs.pop(\"limiter\", None)\n            return func(*args, **kwargs)\n\n        anyio.to_thread.run_sync = _run_sync_inline  # type: ignore[assignment]\n    except Exception:\n        return\n\n\n_patch_anyio_threading_for_tests()\napp = FastAPI(title=\"Fortune AI API\")\napp.add_middleware(GZipMiddleware, minimum_size=1024)\n\n# CORS middleware for frontend (port 8231) accessing backend (port 8230)\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\n        \"http://106.37.170.238:8231\",\n        \"http://localhost:8231\",\n        \"http://127.0.0.1:8231\",\n    ],\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Strong cache for static files to speed up repeat loads\n@app.middleware(\"http\")\nasync def _static_cache_mw(request: Request, call_next):\n    response = await call_next(request)\n    try:\n        path = request.url.path\n        if path.startswith(\"/static/\"):\n            # 1 year immutable cache; files are content-addressed by deploy hash only via manual bumps\n            response.headers.setdefault(\"Cache-Control\", \"public, max-age=31536000, immutable\")\n    except Exception:\n        pass\n    return response\napp.mount(\"/static\", StaticFiles(directory=\"api/static\"), name=\"static\")\ntemplates = Jinja2Templates(directory=\"api/templates\")\n\napp.include_router(auth_router)\napp.include_router(user_router)\napp.include_router(session_router)\napp.include_router(chat_router)\napp.include_router(bento_router)  # 保持向后兼容\napp.include_router(dashboard_router)  # 新 Dashboard API（Zone B）\napp.include_router(bazi_router)\napp.include_router(kb_router)\napp.include_router(plan_router)\napp.include_router(report_router)\napp.include_router(push_router)\napp.include_router(twin_router)\napp.include_router(agent_tool_router)\napp.include_router(social_router)\napp.include_router(jitai_router)\napp.include_router(currency_router)\napp.include_router(goal_router)\napp.include_router(reflection_router)\napp.include_router(yunshi_router)\napp.include_router(poster_router)\n\n\nclass BaziRequest(BaseModel):\n    name: str = Field(..., min_length=1)\n    gender: str = Field(..., min_length=1)\n    year: int\n    month: int\n    day: int\n    hour: int\n    minute: int\n    longitude: Optional[float] = None\n    latitude: Optional[float] = None\n    location_name: Optional[str] = None\n    system_prompt: Optional[str] = None\n\n    @validator(\"longitude\")\n    def longitude_range(cls, v):\n        if v is None:\n            return v\n        if v < -180 or v > 180:\n            raise ValueError(\"longitude out of range\")\n        return v\n\n\nclass AskRequest(BaseModel):\n    \"\"\"Ask on Bazi (sync) request payload (REQ-003).\"\"\"\n    name: str = Field(..., min_length=1)\n    gender: str = Field(..., min_length=1)\n    date: str = Field(..., description=\"YYYY-MM-DD\")\n    time: str = Field(..., description=\"HH:MM[:SS]\")\n    tz_offset_hours: Optional[float] = Field(8.0, description=\"Local time offset from UTC in hours, default +8\")\n    longitude: Optional[float] = None\n    latitude: Optional[float] = None\n    location_name: Optional[str] = None\n    question: str = Field(\"\", description=\"User question text\")\n    model: Optional[str] = Field(\"standard\", description=\"Model hint\")\n\n\nclass ChatMessage(BaseModel):\n    role: str = Field(..., description=\"user|assistant\")\n    text: str = Field(..., min_length=1)\n\n\nclass ChatAskRequest(BaseModel):\n    name: Optional[str] = None\n    session_id: Optional[str] = None\n    system_prompt: Optional[str] = None\n    messages: List[ChatMessage]\n    model: Optional[str] = Field(\"standard\", description=\"Model hint\")\n\n\ndef _parse_date_time(date_str: str, time_str: str) -> Tuple[int, int, int, int, int]:\n    \"\"\"Parse 'YYYY-MM-DD' and 'HH:MM[:SS]' into ints.\n\n    Returns: year, month, day, hour, minute\n    \"\"\"\n    try:\n        y, m, d = [int(x) for x in date_str.split(\"-\")]\n        parts = time_str.split(\":\")\n        hh = int(parts[0]); mm = int(parts[1]);\n        return y, m, d, hh, mm\n    except Exception:\n        raise HTTPException(status_code=400, detail=\"invalid_date_time\")\n\n\ndef _wuxing_counts(wuxing: Optional[str]) -> Dict[str, int]:\n    counts = {\"金\": 0, \"木\": 0, \"水\": 0, \"火\": 0, \"土\": 0}\n    if not wuxing:\n        return counts\n    for ch in counts:\n        counts[ch] = wuxing.count(ch)\n    return counts\n\n\ndef _build_chat_prompt(system_prompt: Optional[str], messages: List[ChatMessage]) -> str:\n    lines: List[str] = []\n    if system_prompt and system_prompt.strip():\n        lines.append(system_prompt.strip())\n    lines.append(\"【对话】\")\n    for m in messages:\n        role = \"用户\" if m.role == \"user\" else \"助手\"\n        lines.append(f\"{role}: {m.text}\")\n    lines.append(\"助手:\")\n    return \"\\n\".join(lines)\n\n\ndef _latest_report_summary_for_user(name: str) -> Tuple[Optional[str], Optional[str]]:\n    \"\"\"Find latest assistant text for a user name from local conversation logs.\n\n    Returns (summary_text, doc_url)\n    \"\"\"\n    try:\n        from user_store import get_fortune_user_by_name\n    except Exception:\n        return None, None\n    u = get_fortune_user_by_name(name)\n    if not u or u.get(\"user_id\") is None:\n        return None, None\n    uid = int(u[\"user_id\"])  # type: ignore\n    conv_dir = os.path.join(\"user\", str(uid), \"conversations\")\n    if not os.path.isdir(conv_dir):\n        return None, None\n    latest_path = None\n    latest_mtime = 0.0\n    for fn in os.listdir(conv_dir):\n        if not fn.endswith(\".jsonl\"):\n            continue\n        p = os.path.join(conv_dir, fn)\n        try:\n            mt = os.path.getmtime(p)\n        except Exception:\n            continue\n        if mt > latest_mtime:\n            latest_mtime = mt\n            latest_path = p\n    if not latest_path:\n        return None, None\n    last_text = None\n    doc_url = None\n    try:\n        with open(latest_path, \"r\", encoding=\"utf-8\") as f:\n            for line in f:\n                line = line.strip()\n                if not line:\n                    continue\n                try:\n                    rec = json.loads(line)\n                except Exception:\n                    continue\n                if rec.get(\"role\") == \"assistant\":\n                    last_text = rec.get(\"content\") or last_text\n                    if rec.get(\"doc_url\"):\n                        doc_url = rec.get(\"doc_url\")\n    except Exception:\n        return None, None\n    if not last_text:\n        return None, None\n    # 300–600 字摘要（简单截断作为占位）\n    summary = str(last_text).strip()\n    if len(summary) > 600:\n        summary = summary[:600] + \"…\"\n    return summary, doc_url\n\n\nclass AskRequest(BaseModel):\n    \"\"\"Ask on Bazi (sync) request payload (REQ-003).\"\"\"\n    name: str = Field(..., min_length=1)\n    gender: str = Field(..., min_length=1)\n    date: str = Field(..., description=\"YYYY-MM-DD\")\n    time: str = Field(..., description=\"HH:MM[:SS]\")\n    tz_offset_hours: Optional[float] = Field(8.0, description=\"Local time offset from UTC in hours, default +8\")\n    longitude: Optional[float] = None\n    latitude: Optional[float] = None\n    location_name: Optional[str] = None\n    question: str = Field(\"\", description=\"User question text\")\n    model: Optional[str] = Field(\"standard\", description=\"Model hint\")\n\n\nclass RectifyEvent(BaseModel):\n    date: str\n    type: str\n    impact: Optional[str] = None\n\n\nclass RectifyRequest(BaseModel):\n    name: str = Field(..., min_length=1)\n    birthday: str = Field(..., description=\"YYYY-MM-DD\")\n    latitude: Optional[float] = None\n    longitude: Optional[float] = None\n    window_start: str = Field(..., description=\"HH:MM or HH:MM:SS\")\n    window_end: str = Field(..., description=\"HH:MM or HH:MM:SS\")\n    events: list[RectifyEvent]\n    tz_offset_hours: Optional[float] = Field(8.0, description=\"Local time offset from UTC in hours, default +8\")\n    debug: Optional[bool] = Field(False, description=\"Return debug breakdown when true\")\n\n\nclass SystemPromptSaveRequest(BaseModel):\n    openid: str = Field(\"web\", description=\"User identifier for prompt history grouping\")\n    text: str = Field(..., min_length=1, description=\"System prompt text\")\n    model: Optional[str] = Field(\"standard\", description=\"Associated model suggestion\")\n\nclass BaziAskRequest(BaseModel):\n    question: str\n    name: Optional[str] = None\n    gender: Optional[str] = None\n    date: Optional[str] = None\n    time: Optional[str] = None\n    tz_offset_hours: Optional[float] = 8.0\n    location_name: Optional[str] = None\n    longitude: Optional[float] = None\n    latitude: Optional[float] = None\n\n\nclass TiebanInitRequest(BaseModel):\n    name: str = Field(..., min_length=1)\n    gender: str = Field(..., min_length=1)\n    date: str = Field(..., description=\"YYYY-MM-DD\")\n    time: str = Field(..., description=\"HH:MM or HH:MM:SS\")\n    tz_offset_hours: Optional[float] = Field(8.0, description=\"Local time offset from UTC in hours, default +8\")\n    location_name: Optional[str] = None\n    longitude: Optional[float] = None\n    latitude: Optional[float] = None\n    known_facts: Optional[Dict[str, Any]] = None\n    ruleset_names: Optional[list[str]] = None\n    debug: Optional[bool] = False\n\n\nclass TiebanVerifyRequest(BaseModel):\n    run_id: str\n    answers: Dict[str, Any]\n    state_version: Optional[str] = None\n\n\nclass TiebanLockRequest(BaseModel):\n    run_id: str\n    state_version: Optional[str] = None\n\n\nclass TiebanSelectRequest(BaseModel):\n    run_id: str\n    candidate_id: str\n    state_version: Optional[str] = None\n\n\ndef _persist_rectification_result(req: RectifyRequest, result, lat: float, lon: float) -> None:\n    \"\"\"Best-effort persistence of rectification results to fortune_user.\"\"\"\n    user_id: Optional[int] = None\n    used_default_location = (req.latitude is None) or (req.longitude is None)\n    try:\n        user = get_fortune_user_by_name(req.name)\n        if not user:\n            bt_local = result.best_time_local\n            bazi = calculate_bazi(\n                bt_local.year,\n                bt_local.month,\n                bt_local.day,\n                bt_local.hour,\n                bt_local.minute,\n                {\"longitude\": lon, \"latitude\": lat, \"name\": req.name},\n            )\n            base_url = os.getenv(\"GEMINI_BASE_URL\", \"https://gemini.local/user\")\n            create_fortune_user(\n                name=req.name,\n                birthday=f\"{bt_local.year:04d}-{bt_local.month:02d}-{bt_local.day:02d} {bt_local.hour:02d}:{bt_local.minute:02d}:{bt_local.second:02d}\",\n                location={\"longitude\": lon, \"latitude\": lat, \"name\": req.name},\n                bazi_digest=f\"{bazi.year_pillar}-{bazi.month_pillar}-{bazi.day_pillar}-{bazi.hour_pillar}\",\n                gemini_url=f\"{base_url}/{os.getenv('ENV','dev')}-{int(result.best_time_utc.timestamp())}\",\n                notes=\"created by rectify\",\n            )\n            user = get_fortune_user_by_name(req.name)\n        if user and user.get(\"user_id\") is not None:\n            try:\n                user_id = int(user[\"user_id\"])\n            except Exception:\n                user_id = None\n    except Exception:\n        user_id = None\n\n    # DB persistence (may fail if columns not yet migrated).\n    try:\n        update_fortune_user_rectification_by_name(\n            name=req.name,\n            rectified_time=result.best_time_utc.isoformat(),\n            birth_window={\n                \"start\": result.window_start_utc.isoformat(),\n                \"end\": result.window_end_utc.isoformat(),\n                \"start_local\": result.window_start_local.isoformat(),\n                \"end_local\": result.window_end_local.isoformat(),\n                \"tz_offset_hours\": req.tz_offset_hours or 8.0,\n                \"step_seconds\": 30,\n                \"location\": {\"longitude\": lon, \"latitude\": lat, \"used_default\": used_default_location},\n            },\n            life_events=[e.dict() for e in req.events],\n        )\n    except Exception as e:\n        logger.warning(\"rectify persist db failed\", extra={\"operation\": \"rectify_persist_db\", \"error\": str(e)[:200]})\n\n    # Local persistence (always attempt) for audit/debug without exposing via API.\n    if user_id is not None:\n        try:\n            req_payload = {\n                \"birthday\": req.birthday,\n                \"tz_offset_hours\": req.tz_offset_hours or 8.0,\n                \"latitude\": lat,\n                \"longitude\": lon,\n                \"used_default_location\": used_default_location,\n                \"window_start\": req.window_start,\n                \"window_end\": req.window_end,\n                \"events\": [e.dict() for e in req.events],\n            }\n            result_payload = _rectify_response_payload(result, received_events=req_payload[\"events\"])\n            rec = rectification_store.make_rectification_record(name=req.name, req_payload=req_payload, result_payload=result_payload)\n            rectification_store.save_rectification_run(user_id, rec)\n        except Exception:\n            return\n\n\ndef _rectify_response_payload(result, received_events: Optional[list] = None) -> Dict[str, Any]:\n    payload: Dict[str, Any] = {\n        \"status\": \"ok\",\n        \"best_time\": result.best_time_utc.isoformat(),\n        \"best_local_time\": result.best_time_local.isoformat(),\n        \"candidates\": [\n            {\n                \"time\": c.time_utc.isoformat(),\n                \"local_time\": c.time_local.isoformat(),\n                \"score\": round(float(c.score), 3),\n                **({\"breakdown\": c.breakdown} if c.breakdown is not None else {}),\n            }\n            for c in result.candidates\n        ],\n        \"window\": {\n            \"start\": result.window_start_utc.isoformat(),\n            \"end\": result.window_end_utc.isoformat(),\n            \"start_local\": result.window_start_local.isoformat(),\n            \"end_local\": result.window_end_local.isoformat(),\n            \"location\": getattr(result, \"window_location\", None) or None,\n        },\n        \"used_swisseph\": result.used_swisseph,\n    }\n    if result.debug is not None:\n        payload[\"debug\"] = result.debug\n    if received_events is not None:\n        payload[\"received_events\"] = received_events\n    return payload\n\n\n@app.on_event(\"startup\")\ndef startup():\n    if os.getenv(\"STUB_DB\") == \"1\":\n        return\n    # 初始化保留给 gemini 后端；cli 后端无需池化\n    if os.getenv(\"GEMINI_BACKEND\", \"gemini\").lower() != \"cli\":\n        try:\n            from integrations.gemini_repo import init_connection_pool\n            init_connection_pool()\n        except Exception:\n            pass\n\n\n@app.get(\"/healthz\")\ndef healthz():\n    return {\"status\": \"ok\"}\n\n\n@app.get(\"/\", include_in_schema=False)\ndef root_redirect():\n    # Redirect root to /new frontend\n    return RedirectResponse(url=\"/new\", status_code=307)\n\n\n@app.get(\"/login\", response_class=HTMLResponse, include_in_schema=False)\ndef page_login(request: Request):\n    # Redirect to new frontend login\n    return RedirectResponse(url=\"/new/login\", status_code=307)\n\n\n@app.get(\"/register\", response_class=HTMLResponse, include_in_schema=False)\ndef page_register(request: Request):\n    # Redirect to new frontend register\n    return RedirectResponse(url=\"/new/register\", status_code=307)\n\n\n@app.get(\"/bazi\", response_class=HTMLResponse)\ndef page_bazi(request: Request):\n    # 使用新版页面（视觉风格与 /tieban 对齐，复用 tieban.css）\n    return templates.TemplateResponse(\"bazi.html\", {\"request\": request})\n\n\n@app.get(\"/tieban\", response_class=HTMLResponse)\ndef tieban_page(request: Request):\n    asset_version = os.getenv(\"ASSET_VER\") or str(int(time.time() // 3600))\n    return templates.TemplateResponse(\"tieban.html\", {\"request\": request, \"asset_version\": asset_version})\n\n@app.get(\"/bazi2\", response_class=HTMLResponse)\ndef bazi2_page(request: Request):\n    # 兼容旧链接：跳转到 /new\n    return RedirectResponse(url=\"/new\", status_code=307)\n\n@app.get(\"/main\", response_class=HTMLResponse)\ndef bazi_main_page(request: Request):\n    \"\"\"Legacy /main page - redirect to /new frontend.\"\"\"\n    # Redirect to new frontend\n    return RedirectResponse(url=\"/new\", status_code=307)\n\n\n@app.get(\"/zone-b\")\n@app.get(\"/dashboard\")\ndef page_dashboard():\n    \"\"\"Zone B Dashboard → 重定向到新前端 /new\"\"\"\n    from fastapi.responses import RedirectResponse\n    return RedirectResponse(url=\"/new\", status_code=307)\n\n\n# ------------------------------ Ask on Bazi (sync + SSE) ------------------------------\n\n\n@app.post(\"/api/bazi/ask\")\ndef api_bazi_ask(req: AskRequest):\n    \"\"\"Synchronous Ask endpoint (REQ-003).\"\"\"\n    audit_id = str(uuid4())\n    try:\n        y, m, d, hh, mm = _parse_date_time(req.date, req.time)\n        bazi = calculate_bazi(\n            y, m, d, hh, mm,\n            {\"longitude\": req.longitude or DEFAULT_LOCATION[\"longitude\"],\n             \"latitude\": req.latitude or DEFAULT_LOCATION[\"latitude\"],\n             \"name\": req.location_name or DEFAULT_LOCATION.get(\"name\", \"\")},\n        )\n        counts = _wuxing_counts(bazi.wuxing)\n        report_summary, doc_url = _latest_report_summary_for_user(req.name)\n\n        # Build structured markdown per spec\n        lines = []\n        lines.append(\"### 结论要点\")\n        trend = \", \".join([f\"{k}{v}\" for k, v in counts.items() if v > 0]) or \"暂无\"\n        lines.append(f\"- 五行倾向：{trend}\")\n        lines.append(\"- 近期关注：事业/健康/情绪（结合个人上下文自检）\")\n        lines.append(\"\")\n        lines.append(\"### 依据与引用\")\n        lines.append(f\"- 四柱：{bazi.year_pillar}・{bazi.month_pillar}・{bazi.day_pillar}・{bazi.hour_pillar}\")\n        lines.append(f\"- 五行：{bazi.wuxing or '未知'}\")\n        if report_summary:\n            lines.append(\"- 历史报告摘要：\")\n            lines.append(report_summary)\n        else:\n            lines.append(\"- 历史报告：未找到，已仅基于八字作答\")\n        lines.append(\"\")\n        lines.append(\"### 不确定性与下一步\")\n        lines.append(\"- 若存在校准结果，请补充校准时间以提升准确度。\")\n        lines.append(\"- 可提供近三年关键事件以获得更个性化建议。\")\n\n        answer_md = \"\\n\".join(lines)\n\n        # Best-effort: append conversation snapshot to local logs\n        try:\n            u = get_fortune_user_by_name(req.name)\n            user_id = int(u.get(\"user_id\")) if u and u.get(\"user_id\") is not None else None\n        except Exception:\n            user_id = None\n        try:\n            if user_id is not None:\n                session_id = int(time.time())\n                if req.question:\n                    append_prompt(user_id, session_id, req.question, req.model or \"standard\")\n                append_output(user_id, session_id, answer_md, url=doc_url)\n        except Exception:\n            pass\n\n        return {\n            \"status\": \"ok\",\n            \"answer_md\": answer_md,\n            \"used_context\": {\n                \"bazi_used\": {\n                    \"year_pillar\": bazi.year_pillar,\n                    \"month_pillar\": bazi.month_pillar,\n                    \"day_pillar\": bazi.day_pillar,\n                    \"hour_pillar\": bazi.hour_pillar,\n                    \"wuxing\": bazi.wuxing,\n                    \"counts\": counts,\n                },\n                \"report_used\": bool(report_summary),\n                \"doc_url\": doc_url,\n            },\n            \"audit_id\": audit_id,\n        }\n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(\"ask sync failed\", extra={\"operation\": \"bazi_ask_sync\", \"error\": str(e), \"audit_id\": audit_id})\n        raise HTTPException(status_code=500, detail=\"ask_failed\")\n\n\n@app.get(\"/api/bazi/ask/stream\")\ndef api_bazi_ask_stream(\n    name: str,\n    gender: str,\n    date: str,\n    time: str,\n    tz_offset_hours: float = 8.0,\n    longitude: Optional[float] = None,\n    latitude: Optional[float] = None,\n    location_name: Optional[str] = None,\n    question: str = \"\",\n    model: str = \"standard\",\n):\n    audit_id = str(uuid4())\n\n    def _sse(obj: Dict[str, Any]) -> bytes:\n        return (f\"data: {json.dumps(obj, ensure_ascii=False)}\\n\\n\").encode(\"utf-8\")\n\n    def _gen():\n        try:\n            y, m, d, hh, mm = _parse_date_time(date, time)\n            bazi = calculate_bazi(\n                y, m, d, hh, mm,\n                {\"longitude\": longitude or DEFAULT_LOCATION[\"longitude\"],\n                 \"latitude\": latitude or DEFAULT_LOCATION[\"latitude\"],\n                 \"name\": location_name or DEFAULT_LOCATION.get(\"name\", \"\")},\n            )\n            counts = _wuxing_counts(bazi.wuxing)\n            report_summary, _doc_url = _latest_report_summary_for_user(name)\n\n            chunks = [\n                {\"type\": \"chunk\", \"text\": \"### 结论要点\\n\"},\n                {\"type\": \"chunk\", \"text\": f\"- 五行倾向：{', '.join([f'{k}{v}' for k,v in counts.items() if v>0]) or '暂无'}\\n\"},\n                {\"type\": \"chunk\", \"text\": \"\\n### 依据与引用\\n\"},\n                {\"type\": \"chunk\", \"text\": f\"- 四柱：{bazi.year_pillar}・{bazi.month_pillar}・{bazi.day_pillar}・{bazi.hour_pillar}\\n\"},\n                {\"type\": \"chunk\", \"text\": f\"- 五行：{bazi.wuxing or '未知'}\\n\"},\n            ]\n            if report_summary:\n                chunks.append({\"type\": \"chunk\", \"text\": \"- 历史报告摘要：\\n\" + report_summary + \"\\n\"})\n            else:\n                chunks.append({\"type\": \"chunk\", \"text\": \"- 历史报告：未找到，已仅基于八字作答\\n\"})\n            chunks.extend([\n                {\"type\": \"chunk\", \"text\": \"\\n### 不确定性与下一步\\n\"},\n                {\"type\": \"chunk\", \"text\": \"- 若存在校准结果，请补充校准时间以提升准确度。\\n\"},\n                {\"type\": \"chunk\", \"text\": \"- 可提供近三年关键事件以获得更个性化建议。\\n\"},\n            ])\n\n            for c in chunks:\n                yield _sse({**c, \"audit_id\": audit_id})\n                time.sleep(0.05)\n\n            yield _sse({\n                \"type\": \"done\",\n                \"audit_id\": audit_id,\n            })\n        except Exception as e:\n            logger.error(\"ask stream failed\", extra={\"operation\": \"bazi_ask_stream\", \"error\": str(e), \"audit_id\": audit_id})\n            yield _sse({\"type\": \"error\", \"detail\": \"ask_failed\", \"audit_id\": audit_id})\n\n    return StreamingResponse(\n        _gen(),\n        media_type=\"text/event-stream\",\n        headers={\"Cache-Control\": \"no-cache\", \"X-Accel-Buffering\": \"no\"},\n    )\n\n\n@app.get(\"/h5/a2ui\", response_class=HTMLResponse)\ndef h5_a2ui(request: Request):\n    # Legacy page - redirect to new frontend\n    return RedirectResponse(url=\"/new\", status_code=307)\n\n\n@app.get(\"/fortune\", response_class=HTMLResponse)\ndef fortune(request: Request):\n    \"\"\"Legacy page - redirect to new frontend.\"\"\"\n    return RedirectResponse(url=\"/new\", status_code=307)\n\n\n@app.get(\"/api/system-prompts\")\ndef api_system_prompts(openid: str = \"web\"):\n    # Legacy API - disabled for security\n    raise HTTPException(status_code=410, detail=\"deprecated_use_new_api\")\n\n\n@app.post(\"/api/system-prompts\")\ndef api_save_system_prompt(req: SystemPromptSaveRequest):\n    # Legacy API - disabled for security\n    raise HTTPException(status_code=410, detail=\"deprecated_use_new_api\")\n\n\n@app.post(\"/api/tieban/init\")\ndef api_tieban_init(req: TiebanInitRequest):\n    try:\n        payload = req.dict()\n        result = tieban_service.init_tieban(payload)\n        return result\n    except Exception as e:\n        logger.error(\"tieban init failed\", extra={\"operation\": \"tieban_init\", \"error\": str(e)[:200]})\n        raise HTTPException(status_code=500, detail=\"tieban_init_error\")\n\n\n@app.post(\"/api/tieban/verify\")\ndef api_tieban_verify(req: TiebanVerifyRequest):\n    try:\n        result = tieban_service.verify_tieban(req.run_id, req.answers, req.state_version)\n        return result\n    except Exception as e:\n        if str(e) == \"state_version_conflict\":\n            raise HTTPException(status_code=409, detail=\"state_version_conflict\")\n        logger.error(\"tieban verify failed\", extra={\"operation\": \"tieban_verify\", \"error\": str(e)[:200]})\n        raise HTTPException(status_code=500, detail=\"tieban_verify_error\")\n\n\n@app.post(\"/api/tieban/select\")\ndef api_tieban_select(req: TiebanSelectRequest):\n    try:\n        result = tieban_service.select_tieban(req.run_id, req.candidate_id, req.state_version)\n        return result\n    except Exception as e:\n        if str(e) == \"state_version_conflict\":\n            raise HTTPException(status_code=409, detail=\"state_version_conflict\")\n        if str(e) in (\"missing_required_facts\", \"required_fact_not_matched\", \"candidate_not_found\"):\n            raise HTTPException(status_code=400, detail=str(e))\n        logger.error(\"tieban select failed\", extra={\"operation\": \"tieban_select\", \"error\": str(e)[:200]})\n        raise HTTPException(status_code=500, detail=\"tieban_select_error\")\n\n\n@app.post(\"/api/tieban/lock\")\ndef api_tieban_lock(req: TiebanLockRequest):\n    try:\n        result = tieban_service.lock_tieban(req.run_id, req.state_version)\n        return result\n    except Exception as e:\n        if str(e) == \"state_version_conflict\":\n            raise HTTPException(status_code=409, detail=\"state_version_conflict\")\n        if str(e) == \"deprecated_use_select\":\n            raise HTTPException(status_code=400, detail=\"deprecated_use_select\")\n        logger.error(\"tieban lock failed\", extra={\"operation\": \"tieban_lock\", \"error\": str(e)[:200]})\n        raise HTTPException(status_code=500, detail=\"tieban_lock_error\")\n\n\n@app.get(\"/api/tieban/report\")\ndef api_tieban_report(run_id: str):\n    try:\n        return tieban_service.get_report(run_id)\n    except Exception as e:\n        logger.error(\"tieban report failed\", extra={\"operation\": \"tieban_report\", \"error\": str(e)[:200]})\n        raise HTTPException(status_code=404, detail=\"tieban_report_error\")\n\n\n@app.post(\"/api/calculate\")\ndef create_report(req: BaziRequest, backend: str | None = None):\n    # Legacy API - deprecated, use authenticated /api/chat endpoints instead\n    raise HTTPException(status_code=410, detail=\"deprecated_use_new_api\")\n    correlation_id = str(uuid4())\n    try:\n        # 先计算八字命盘并即时返回；后台另起 v2 任务走“standard”模型\n        base = req.dict()\n        from time import time as _now\n        job_id, user_id, used_default, bazi = task_service.submit_bazi_task_v2(\n            {\n                \"openid\": \"web\",\n                \"src\": \"web\",\n                \"model\": \"standard\",\n                **base,\n            },\n            correlation_id=correlation_id,\n            backend_hint=backend,\n            force_nonce=str(int(_now())),\n        )\n        try:\n            if req.system_prompt:\n                prompt_store.append_for_openid(\"web\", req.system_prompt, \"standard\")\n        except Exception:\n            pass\n        return {\n            \"job_id\": job_id,\n            \"user_id\": user_id,\n            \"status\": \"processing\",\n            \"used_default_location\": used_default,\n            \"default_location\": DEFAULT_LOCATION if used_default else None,\n            \"bazi\": {\n                \"year_pillar\": bazi.year_pillar,\n                \"month_pillar\": bazi.month_pillar,\n                \"day_pillar\": bazi.day_pillar,\n                \"hour_pillar\": bazi.hour_pillar,\n                \"wuxing\": bazi.wuxing,\n                \"location\": bazi.location,\n            },\n        }\n    except ValueError as ve:\n        logger.warning(\"validation failed\", extra={\"operation\": \"api_calculate\", \"error\": str(ve), \"correlation_id\": correlation_id})\n        raise HTTPException(status_code=400, detail=str(ve))\n    except Exception as e:\n        msg = str(e)\n        logger.error(\"calculate failed\", extra={\"operation\": \"api_calculate\", \"error\": msg, \"correlation_id\": correlation_id})\n        if msg in (\"empty_prompt\", \"no_tasks\", \"no_tasks_built\"):\n            raise HTTPException(status_code=400, detail=msg)\n        raise HTTPException(status_code=500, detail=\"internal_error\")\n\n\n@app.get(\"/api/report/{job_id}\")\ndef get_report(job_id: int, backend: str | None = None):\n    # Legacy API - deprecated, use authenticated /api/chat endpoints instead\n    raise HTTPException(status_code=410, detail=\"deprecated_use_new_api\")\n    tasks = be.get_tasks_by_job_id(job_id, backend=backend)\n    if not tasks:\n        return {\"status\": \"error\", \"message\": \"no_tasks\"}\n\n    main_task = tasks[0]\n    status_val = main_task.get(\"status\", 0)\n    if status_val < 99:\n        return {\"status\": \"processing\", \"progress\": status_val}\n    if not main_task.get(\"output_text\") and not main_task.get(\"output_url\"):\n        # For CLI backend, try expose the first inline file as a download link\n        if (backend or os.getenv(\"GEMINI_BACKEND\", \"gemini\")).strip().lower() == \"cli\":\n            try:\n                from integrations.cli_worker_repo import list_output_files_by_job_id\n                files = list_output_files_by_job_id(job_id)\n                if files:\n                    # choose the first file; if it has content, we can stream it via /api/files\n                    dl = f\"/api/files/{job_id}?backend=cli\"\n                    return {\"status\": \"completed\", \"content\": None, \"doc_url\": dl}\n            except Exception:\n                pass\n        return {\"status\": \"error\", \"message\": \"task_missing_output\"}\n\n    content = main_task.get(\"output_text\")\n    doc_url = main_task.get(\"output_url\")\n    # persist conversation output if user is known\n    try:\n        uid = find_user_by_job(job_id)\n        if uid is not None and (content or doc_url):\n            append_output(uid, job_id, content or \"\", doc_url)\n    except Exception:\n        pass\n\n    # best-effort: sync gemini_url to fortune_user when job is done\n    try:\n        sync_job_gemini_url_to_user(job_id)\n    except Exception:\n        pass\n\n    return {\n        \"status\": \"completed\",\n        \"content\": content,\n        \"doc_url\": doc_url,\n    }\n\n\n@app.post(\"/api/rectify\")\ndef api_rectify(req: RectifyRequest):\n    try:\n        # 对于未提供经纬度的情况，使用默认北京经纬度（与八字计算一致）\n        lat = req.latitude if req.latitude is not None else DEFAULT_LOCATION[\"latitude\"]\n        lon = req.longitude if req.longitude is not None else DEFAULT_LOCATION[\"longitude\"]\n        result = rectify_birth_time_v2(\n            name=req.name,\n            birthday=req.birthday,\n            lat=lat,\n            lon=lon,\n            window_start_hms=req.window_start,\n            window_end_hms=req.window_end,\n            events_raw=[e.dict() for e in req.events],\n            tz_offset_hours=req.tz_offset_hours or 8.0,\n            step_seconds=30,\n            debug=bool(req.debug),\n        )\n        _persist_rectification_result(req, result, lat=lat, lon=lon)\n        return _rectify_response_payload(result, received_events=[e.dict() for e in req.events])\n    except Exception as e:\n        logger.error(\"rectify failed\", extra={\"operation\": \"api_rectify\", \"error\": str(e)})\n        raise HTTPException(status_code=400, detail=\"rectify_failed\")\n\n\n@app.post(\"/api/rectify/stream\")\ndef api_rectify_stream(req: RectifyRequest):\n    lat = req.latitude if req.latitude is not None else DEFAULT_LOCATION[\"latitude\"]\n    lon = req.longitude if req.longitude is not None else DEFAULT_LOCATION[\"longitude\"]\n    correlation_id = str(uuid4())\n\n    def _sse(obj: Dict[str, Any]) -> bytes:\n        return (f\"data: {json.dumps(obj, ensure_ascii=False)}\\n\\n\").encode(\"utf-8\")\n\n    def _gen():\n        try:\n            received_events = [e.dict() for e in req.events]\n            for msg in rectify_birth_time_v2_iter(\n                name=req.name,\n                birthday=req.birthday,\n                lat=lat,\n                lon=lon,\n                window_start_hms=req.window_start,\n                window_end_hms=req.window_end,\n                events_raw=[e.dict() for e in req.events],\n                tz_offset_hours=req.tz_offset_hours or 8.0,\n                step_seconds=30,\n                debug=bool(req.debug),\n            ):\n                if msg.get(\"type\") == \"result\":\n                    result = msg[\"result\"]\n                    _persist_rectification_result(req, result, lat=lat, lon=lon)\n                    yield _sse({\"type\": \"done\", **_rectify_response_payload(result, received_events=received_events)})\n                else:\n                    out = dict(msg)\n                    out.setdefault(\"correlation_id\", correlation_id)\n                    yield _sse(out)\n        except Exception as e:\n            logger.error(\n                \"rectify stream failed\",\n                extra={\"operation\": \"api_rectify_stream\", \"error\": str(e), \"correlation_id\": correlation_id},\n            )\n            yield _sse({\"type\": \"error\", \"detail\": \"rectify_failed\", \"correlation_id\": correlation_id})\n\n    return StreamingResponse(\n        _gen(),\n        media_type=\"text/event-stream\",\n        headers={\"Cache-Control\": \"no-cache\", \"X-Accel-Buffering\": \"no\"},\n    )\n\n\n# ------------------------------ v3 (interval + fuzzy distribution) ------------------------------\n\n\n@app.post(\"/api/rectify/v3\")\ndef api_rectify_v3(req: RectifyRequest):\n    try:\n        lat = req.latitude if req.latitude is not None else DEFAULT_LOCATION[\"latitude\"]\n        lon = req.longitude if req.longitude is not None else DEFAULT_LOCATION[\"longitude\"]\n        result = rectification_v3.rectify_birth_time_v3(\n            name=req.name,\n            birthday=req.birthday,\n            lat=lat,\n            lon=lon,\n            window_start_hms=req.window_start,\n            window_end_hms=req.window_end,\n            events_raw=[e.dict() for e in req.events],\n            tz_offset_hours=req.tz_offset_hours or 8.0,\n            step_seconds=30,\n        )\n        _persist_rectification_result(req, result, lat=lat, lon=lon)\n        result[\"received_events\"] = [e.dict() for e in req.events]\n        return result\n    except Exception as e:\n        logger.error(\"rectify v3 failed\", extra={\"operation\": \"api_rectify_v3\", \"error\": str(e)})\n        raise HTTPException(status_code=400, detail=\"rectify_failed\")\n\n\n@app.post(\"/api/rectify/v3/stream\")\ndef api_rectify_v3_stream(req: RectifyRequest):\n    lat = req.latitude if req.latitude is not None else DEFAULT_LOCATION[\"latitude\"]\n    lon = req.longitude if req.longitude is not None else DEFAULT_LOCATION[\"longitude\"]\n    correlation_id = str(uuid4())\n\n    def _sse(obj: Dict[str, Any]) -> bytes:\n        return (f\"data: {json.dumps(obj, ensure_ascii=False)}\\n\\n\").encode(\"utf-8\")\n\n    def _gen():\n        try:\n            received_events = [e.dict() for e in req.events]\n            for msg in rectification_v3.rectify_birth_time_v3_iter(\n                name=req.name,\n                birthday=req.birthday,\n                lat=lat,\n                lon=lon,\n                window_start_hms=req.window_start,\n                window_end_hms=req.window_end,\n                events_raw=received_events,\n                tz_offset_hours=req.tz_offset_hours or 8.0,\n                step_seconds=30,\n            ):\n                if msg.get(\"type\") == \"result\":\n                    res = msg[\"result\"]\n                    res[\"received_events\"] = received_events\n                    _persist_rectification_result(req, res, lat=lat, lon=lon)\n                    yield _sse({\"type\": \"done\", **res})\n                else:\n                    out = dict(msg)\n                    out.setdefault(\"correlation_id\", correlation_id)\n                    yield _sse(out)\n        except Exception as e:\n            logger.error(\n                \"rectify v3 stream failed\",\n                extra={\"operation\": \"api_rectify_v3_stream\", \"error\": str(e), \"correlation_id\": correlation_id},\n            )\n            yield _sse({\"type\": \"error\", \"detail\": \"rectify_failed\", \"correlation_id\": correlation_id})\n\n    return StreamingResponse(\n        _gen(),\n        media_type=\"text/event-stream\",\n        headers={\"Cache-Control\": \"no-cache\", \"X-Accel-Buffering\": \"no\"},\n    )\n\n\n# ------------------------------\n# v2 API per docs/design v2.md\n# ------------------------------\n\nclass V2SubmitBirthData(BaseModel):\n    name: str\n    gender: str\n    year: int\n    month: int\n    day: int\n    hour: int\n    minute: int\n    longitude: Optional[float] = None\n    latitude: Optional[float] = None\n    location_name: Optional[str] = None\n\n\nclass V2SubmitRequest(BaseModel):\n    openid: str = Field(..., min_length=3)\n    src: str = Field(\"wechat\", description=\"来源渠道\")\n    model: str = Field(\"standard\", description=\"Gemini 模型：standard | deep_research\")\n    system_prompt: Optional[str] = Field(None, description=\"可选 system prompt，拼接在八字前作为提示\")\n    birth_data: V2SubmitBirthData\n\n\n@app.post(\"/api/v2/submit\")\ndef v2_submit(req: V2SubmitRequest, backend: str | None = None):\n    # Legacy v2 API - deprecated, use authenticated /api/chat endpoints instead\n    raise HTTPException(status_code=410, detail=\"deprecated_use_new_api\")\n    correlation_id = str(uuid4())\n    try:\n        if os.getenv(\"DEMO_MODE\") == \"1\":\n            # 极简演示：不依赖 DB，直接返回一个模拟 job_id\n            return {\n                \"job_id\": 101,\n                \"user_id\": 1,\n                \"status\": \"processing\",\n                \"eta_seconds\": 2,\n                \"used_default_location\": False,\n                \"default_location\": None,\n            }\n        # 为降低 CLI 后端的幂等去重概率，这里在 v2 提交强制注入一次性 nonce\n        from time import time as _now\n        job_id, user_id, used_default, bazi = task_service.submit_bazi_task_v2(\n            {\n                \"openid\": req.openid,\n                \"src\": req.src,\n                \"model\": req.model,\n                \"system_prompt\": req.system_prompt,\n                **req.birth_data.dict(),\n            },\n            correlation_id=correlation_id,\n            backend_hint=backend,\n            force_nonce=str(int(_now())),\n        )\n        # 记录 prompt 历史（本地 user/prompts/openid_xxx/prompts.json），不写 gemini 表\n        try:\n            if req.system_prompt:\n                prompt_store.append_for_openid(req.openid, req.system_prompt, req.model)\n        except Exception as _:\n            pass\n        return {\n            \"job_id\": job_id,\n            \"user_id\": user_id,\n            \"status\": \"processing\",\n            \"eta_seconds\": 120,\n            \"used_default_location\": used_default,\n            \"default_location\": DEFAULT_LOCATION if used_default else None,\n            \"bazi\": {\n                \"year_pillar\": bazi.year_pillar,\n                \"month_pillar\": bazi.month_pillar,\n                \"day_pillar\": bazi.day_pillar,\n                \"hour_pillar\": bazi.hour_pillar,\n                \"wuxing\": bazi.wuxing,\n                \"location\": bazi.location,\n            },\n        }\n    except ValueError as ve:\n        logger.warning(\"v2 submit validation failed\", extra={\"operation\": \"api_v2_submit\", \"error\": str(ve), \"correlation_id\": correlation_id})\n        raise HTTPException(status_code=400, detail=str(ve))\n    except Exception as e:\n        msg = str(e)\n        logger.error(\"v2 submit failed\", extra={\"operation\": \"api_v2_submit\", \"error\": msg, \"correlation_id\": correlation_id})\n        if msg in (\"empty_prompt\", \"no_tasks\", \"no_tasks_built\"):\n            raise HTTPException(status_code=400, detail=msg)\n        raise HTTPException(status_code=500, detail=\"internal_error\")\n\n\n@app.get(\"/api/v2/report/{job_id}\")\ndef v2_report(job_id: int, backend: str | None = None) -> Dict[str, Any]:\n    # Legacy v2 API - deprecated, use authenticated /api/chat endpoints instead\n    raise HTTPException(status_code=410, detail=\"deprecated_use_new_api\")\n    if os.getenv(\"DEMO_MODE\") == \"1\":\n        # 极简演示：不再返回写库示例，仅提示处理中\n        return {\"status\": \"processing\", \"progress\": 0}\n\n    tasks = be.get_tasks_by_job_id(job_id, backend=backend)\n    if not tasks:\n        return {\"status\": \"error\", \"message\": \"no_tasks\"}\n\n    main_task = tasks[0]\n    status_val = int(main_task.get(\"status\", 0) or 0)\n    if status_val < 10:\n        return {\"status\": \"processing\", \"progress\": status_val}\n\n    output_text = main_task.get(\"output_text\")\n    output_url = main_task.get(\"output_url\")\n    if not output_text:\n        # 兼容仅有文档链接（output_url）而无内嵌文本的情况\n        if output_url:\n            # best-effort: persist conversation output (url only)\n            try:\n                uid = find_user_by_job(job_id)\n                if uid is not None:\n                    append_output(uid, job_id, \"\", output_url)\n            except Exception:\n                pass\n            # best-effort: sync gemini_url when job is done\n            try:\n                sync_job_gemini_url_to_user(job_id)\n            except Exception:\n                pass\n            # 返回可阅读的占位 A2UI（Markdown 组件 + 下载链接）\n            md = f\"报告已生成，但未返回内嵌文本。请点击下载文档：\\n\\n[下载报告]({output_url})\"\n            return {\"status\": \"completed\", \"a2ui_data\": {\"meta\": {\"summary\": \"报告已生成（文档链接）\"}, \"ui_components\": [{\"type\": \"markdown_text\", \"title\": \"模型输出\", \"data\": md}]}}\n        return {\"status\": \"error\", \"message\": \"task_missing_output\"}\n\n    try:\n        import json\n\n        a2ui = json.loads(output_text)\n        validate_a2ui(a2ui)\n        # persist conversation output for v2 as well\n        try:\n            uid = find_user_by_job(job_id)\n            if uid is not None:\n                append_output(uid, job_id, output_text)\n        except Exception:\n            pass\n        # best-effort: sync gemini_url to fortune_user when job is done or parsable\n        try:\n            sync_job_gemini_url_to_user(job_id)\n        except Exception:\n            pass\n        return {\"status\": \"completed\", \"a2ui_data\": a2ui}\n    except ValidationError as ve:\n        # 若为合法 JSON 但不符合 A2UI，按 Markdown 文本回退\n        return {\"status\": \"completed\", \"a2ui_data\": {\"meta\": {\"summary\": \"模型返回非规范 A2UI，已按 Markdown 展示\"}, \"ui_components\": [{\"type\": \"markdown_text\", \"title\": \"模型输出\", \"data\": output_text}]}}\n    except Exception:\n        # 非 JSON：按 Markdown 文本回退\n        return {\"status\": \"completed\", \"a2ui_data\": {\"meta\": {\"summary\": output_text[:60]}, \"ui_components\": [{\"type\": \"markdown_text\", \"title\": \"模型输出\", \"data\": output_text}]}}\n\n\n# ------------------------------\n# Files API (CLI backend output streaming)\n# ------------------------------\n\n\n@app.get(\"/api/files/{job_id}\")\ndef api_files(job_id: int, backend: str | None = None, filename: str | None = None):\n    # Legacy API - disabled for security, use authenticated endpoints\n    raise HTTPException(status_code=410, detail=\"deprecated_use_new_api\")\n    b = (backend or os.getenv(\"GEMINI_BACKEND\", \"gemini\")).strip().lower()\n    if b != \"cli\":\n        raise HTTPException(status_code=400, detail=\"files_only_available_for_cli\")\n    try:\n        from integrations.cli_worker_repo import fetch_output_file_content, list_output_files_by_job_id\n        fname, content = fetch_output_file_content(job_id, filename)\n        if content is None:\n            # return a lightweight index for UX when nothing inline\n            files = list_output_files_by_job_id(job_id)\n            return {\"files\": files}\n        media = \"text/plain\"\n        # simple heuristic: .md/.txt → text/plain; otherwise octet-stream\n        if fname and (str(fname).endswith(\".md\") or str(fname).endswith(\".txt\")):\n            media = \"text/plain; charset=utf-8\"\n        headers = {\"Content-Disposition\": f\"inline; filename={fname or 'output.txt'}\"}\n        return StreamingResponse(iter([content]), media_type=media, headers=headers)\n    except HTTPException:\n        raise\n    except Exception as e:\n        logger.error(\"files endpoint failed\", extra={\"operation\": \"api_files\", \"error\": str(e)[:200]})\n        raise HTTPException(status_code=500, detail=\"files_error\")\n\n\n# ------------------------------\n# WeCom OAuth (Tencent Cloud friendly)\n# ------------------------------\n\n\n@app.get(\"/qy/oauth/redirect\")\ndef qy_oauth_redirect():\n    corp_id = os.getenv(\"QY_CORP_ID\")\n    agent_id = os.getenv(\"QY_AGENT_ID\")\n    redirect_uri = os.getenv(\"QY_REDIRECT_URI\")\n    if not (corp_id and agent_id and redirect_uri):\n        raise HTTPException(status_code=500, detail=\"missing_qy_env\")\n    auth_url = (\n        \"https://open.weixin.qq.com/connect/oauth2/authorize?\"\n        + urllib.parse.urlencode(\n            {\n                \"appid\": corp_id,\n                \"redirect_uri\": redirect_uri,\n                \"response_type\": \"code\",\n                \"scope\": \"snsapi_base\",\n                \"state\": \"a2ui\",\n                \"agentid\": agent_id,\n            }\n        )\n        + \"#wechat_redirect\"\n    )\n    return {\"auth_url\": auth_url}\n\n\n@app.get(\"/qy/oauth/callback\")\ndef qy_oauth_callback(code: str, request: Request):\n    corp_id = os.getenv(\"QY_CORP_ID\")\n    corp_secret = os.getenv(\"QY_CORP_SECRET\")\n    if not (corp_id and corp_secret):\n        raise HTTPException(status_code=500, detail=\"missing_qy_env\")\n\n    # 1) get access token\n    token_url = \"https://qyapi.weixin.qq.com/cgi-bin/gettoken\"\n    user_url = \"https://qyapi.weixin.qq.com/cgi-bin/auth/getuserinfo\"\n    with httpx.Client(timeout=10.0) as client:\n        r1 = client.get(token_url, params={\"corpid\": corp_id, \"corpsecret\": corp_secret})\n        r1.raise_for_status()\n        tok = r1.json()\n        access_token = tok.get(\"access_token\")\n        if not access_token:\n            raise HTTPException(status_code=502, detail=\"qy_token_error\")\n        r2 = client.get(user_url, params={\"access_token\": access_token, \"code\": code})\n        r2.raise_for_status()\n        info = r2.json()\n\n    userid = info.get(\"UserId\") or info.get(\"userid\") or info.get(\"external_userid\")\n    if not userid:\n        raise HTTPException(status_code=400, detail=\"qy_no_user\")\n\n    # Put userid in query and bounce to H5\n    h5_path = os.getenv(\"QY_H5_PATH\", \"/h5/a2ui\")\n    target = f\"{h5_path}?userid={urllib.parse.quote(userid)}\"\n    return templates.TemplateResponse(\n        \"redirect.html\",\n        {\"request\": request, \"target\": target},\n    )\n","numLines":1247,"startLine":1,"totalLines":1247}}}
{"parentUuid":"8d738f5e-4c5c-4b50-90cf-f06f9e60fa49","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_019SgpJXrqvhyTqbJQD2NzDf","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me examine the other key route files to get a complete picture:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":17283,"cache_creation_input_tokens":19672,"cache_read_input_tokens":22337,"cache_creation":{"ephemeral_5m_input_tokens":19672,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrnZiWCTChrivmJdbFi","type":"assistant","uuid":"26d695d8-d5c6-4ab5-b7d7-b4116a871376","timestamp":"2026-01-01T15:01:22.344Z"}
{"parentUuid":"26d695d8-d5c6-4ab5-b7d7-b4116a871376","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_019SgpJXrqvhyTqbJQD2NzDf","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01WSEbyehAsjMtijdybn492D","name":"Read","input":{"file_path":"/home/aiscend/work/fortune_ai/api/auth_routes.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":17283,"cache_creation_input_tokens":19672,"cache_read_input_tokens":22337,"cache_creation":{"ephemeral_5m_input_tokens":19672,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrnZiWCTChrivmJdbFi","type":"assistant","uuid":"e89af9b9-789f-4bd3-8e31-363881de8d43","timestamp":"2026-01-01T15:01:22.976Z"}
{"parentUuid":"e89af9b9-789f-4bd3-8e31-363881de8d43","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_019SgpJXrqvhyTqbJQD2NzDf","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01G8n3sCd8KZj9HL2CGvhkjr","name":"Read","input":{"file_path":"/home/aiscend/work/fortune_ai/api/session_routes.py"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":17283,"cache_creation_input_tokens":19672,"cache_read_input_tokens":22337,"cache_creation":{"ephemeral_5m_input_tokens":19672,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrnZiWCTChrivmJdbFi","type":"assistant","uuid":"1703c9da-b3c1-46cc-8863-a0ceb67fa466","timestamp":"2026-01-01T15:01:22.984Z"}
{"parentUuid":"1703c9da-b3c1-46cc-8863-a0ceb67fa466","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_019SgpJXrqvhyTqbJQD2NzDf","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_019ZsdbbAPPuBkbhVTHo2bx7","name":"Bash","input":{"command":"head -50 /home/aiscend/work/fortune_ai/api/bazi_routes.py /home/aiscend/work/fortune_ai/api/user_routes.py /home/aiscend/work/fortune_ai/api/dashboard_routes.py 2>/dev/null | head -100","description":"Preview other route files"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":17283,"cache_creation_input_tokens":19672,"cache_read_input_tokens":22337,"cache_creation":{"ephemeral_5m_input_tokens":19672,"ephemeral_1h_input_tokens":0},"output_tokens":272,"service_tier":"standard"}},"requestId":"req_011CWgrnZiWCTChrivmJdbFi","type":"assistant","uuid":"1dfcc764-4701-429d-9796-4af062ad6ccf","timestamp":"2026-01-01T15:01:23.557Z"}
{"parentUuid":"1dfcc764-4701-429d-9796-4af062ad6ccf","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01WSEbyehAsjMtijdybn492D","type":"tool_result","content":"     1→from __future__ import annotations\n     2→\n     3→import math\n     4→import os\n     5→from datetime import datetime\n     6→from typing import Any, Dict, Optional\n     7→\n     8→from fastapi import APIRouter, HTTPException, Request\n     9→from fastapi.responses import JSONResponse\n    10→from pydantic import BaseModel, Field\n    11→\n    12→from api.deps import get_client_ip, get_user_agent, require_auth, require_csrf\n    13→from services import auth_service, bazi_facts\n    14→from services.bazi_engine import DEFAULT_LOCATION\n    15→\n    16→\n    17→router = APIRouter(prefix=\"/api/auth\", tags=[\"auth\"])\n    18→\n    19→\n    20→def _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    21→    return JSONResponse({\"ok\": True, \"data\": data or {}})\n    22→\n    23→\n    24→def _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    25→    return JSONResponse(\n    26→        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n    27→        status_code=status,\n    28→    )\n    29→\n    30→\n    31→def _cookie_secure() -> bool:\n    32→    return os.getenv(\"FORTUNE_COOKIE_SECURE\", \"0\") == \"1\"\n    33→\n    34→\n    35→def _set_session_cookies(resp: JSONResponse, tokens: auth_service.SessionTokens) -> None:\n    36→    max_age = 30 * 24 * 3600\n    37→    resp.set_cookie(\n    38→        \"fortune_session\",\n    39→        tokens.session_token,\n    40→        httponly=True,\n    41→        samesite=\"lax\",\n    42→        secure=_cookie_secure(),\n    43→        max_age=max_age,\n    44→        path=\"/\",\n    45→    )\n    46→    resp.set_cookie(\n    47→        \"fortune_csrf\",\n    48→        tokens.csrf_token,\n    49→        httponly=False,\n    50→        samesite=\"lax\",\n    51→        secure=_cookie_secure(),\n    52→        max_age=max_age,\n    53→        path=\"/\",\n    54→    )\n    55→\n    56→\n    57→def _clear_session_cookies(resp: JSONResponse) -> None:\n    58→    resp.delete_cookie(\"fortune_session\", path=\"/\")\n    59→    resp.delete_cookie(\"fortune_csrf\", path=\"/\")\n    60→\n    61→\n    62→class RegisterRequest(BaseModel):\n    63→    email: str = Field(..., min_length=3)\n    64→    password: str = Field(..., min_length=8)\n    65→    name: str = Field(..., min_length=1)\n    66→    gender: str = Field(..., min_length=1)\n    67→    birthday_local: str = Field(..., min_length=19, description=\"YYYY-MM-DD HH:MM:SS\")\n    68→    tz_offset_hours: float = Field(8.0)\n    69→    location: Dict[str, Any]\n    70→\n    71→\n    72→class LoginRequest(BaseModel):\n    73→    email: str = Field(..., min_length=3)\n    74→    password: str = Field(..., min_length=1)\n    75→\n    76→\n    77→class PasswordChangeRequest(BaseModel):\n    78→    old_password: str = Field(..., min_length=1)\n    79→    new_password: str = Field(..., min_length=8)\n    80→\n    81→\n    82→class DeleteAccountRequest(BaseModel):\n    83→    password: str = Field(..., min_length=1)\n    84→\n    85→\n    86→class PreviewRequest(BaseModel):\n    87→    gender: str = Field(..., min_length=1)\n    88→    birthday_local: str = Field(..., min_length=10, description=\"YYYY-MM-DD HH:MM[:SS]\")\n    89→    tz_offset_hours: float = Field(8.0)\n    90→    location: Dict[str, Any] = Field(default_factory=dict)\n    91→    name: Optional[str] = None\n    92→\n    93→\n    94→class ValidationPointsRequest(BaseModel):\n    95→    mode: str = Field(\"bazi\", description=\"bazi|ziwei|astro\")\n    96→    gender: str = Field(..., min_length=1)\n    97→    birthday_local: str = Field(..., min_length=10, description=\"YYYY-MM-DD HH:MM[:SS]\")\n    98→    tz_offset_hours: float = Field(8.0)\n    99→    location: Dict[str, Any] = Field(default_factory=dict)\n   100→\n   101→\n   102→def _finite_float(x: Any) -> Optional[float]:\n   103→    try:\n   104→        v = float(x)\n   105→    except Exception:\n   106→        return None\n   107→    return v if math.isfinite(v) else None\n   108→\n   109→\n   110→def _coerce_location(location: Dict[str, Any]) -> tuple[Dict[str, Any], bool]:\n   111→    default = {\n   112→        \"name\": str(DEFAULT_LOCATION.get(\"name\") or \"北京\"),\n   113→        \"longitude\": float(DEFAULT_LOCATION.get(\"longitude\") or 116.4074),\n   114→        \"latitude\": float(DEFAULT_LOCATION.get(\"latitude\") or 39.9042),\n   115→    }\n   116→    if not isinstance(location, dict):\n   117→        return default, True\n   118→\n   119→    name = str(location.get(\"name\") or \"\").strip() or default[\"name\"]\n   120→    lon = _finite_float(location.get(\"longitude\"))\n   121→    lat = _finite_float(location.get(\"latitude\"))\n   122→    if lon is None or lat is None:\n   123→        return {**default, \"name\": name}, True\n   124→    if lon < -180 or lon > 180 or lat < -90 or lat > 90:\n   125→        return {**default, \"name\": name}, True\n   126→    return {\"name\": name, \"longitude\": lon, \"latitude\": lat}, False\n   127→\n   128→\n   129→def _parse_birthday_local(text: str) -> datetime:\n   130→    s = str(text or \"\").strip()\n   131→    if len(s) == 16 and s[10] == \" \" and s[13] == \":\":\n   132→        s = s + \":00\"\n   133→    try:\n   134→        return datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\")\n   135→    except Exception:\n   136→        raise auth_service.AuthError(\"invalid_birthday_local\")\n   137→\n   138→\n   139→@router.post(\"/register\")\n   140→def register(req: RegisterRequest, request: Request):\n   141→    try:\n   142→        user_id = auth_service.register_user(\n   143→            email=req.email,\n   144→            password=req.password,\n   145→            name=req.name,\n   146→            gender=req.gender,\n   147→            birthday_local=req.birthday_local,\n   148→            tz_offset_hours=req.tz_offset_hours,\n   149→            location=req.location,\n   150→        )\n   151→        tokens = auth_service.create_session(user_id, ip=get_client_ip(request), user_agent=get_user_agent(request))\n   152→        auth_service.update_last_login(user_id)\n   153→        resp = _ok({\"user_id\": user_id, \"email\": req.email.strip().lower(), \"profile_summary\": {\"name\": req.name, \"gender\": req.gender, \"location_name\": str(req.location.get(\"name\") or \"\")}})\n   154→        _set_session_cookies(resp, tokens)\n   155→        return resp\n   156→    except auth_service.AuthError as e:\n   157→        msg = str(e)\n   158→        if msg == \"email_exists\":\n   159→            return _err(409, \"conflict\", \"email_exists\", {\"field\": \"email\"})\n   160→        if msg == \"invalid_email\":\n   161→            return _err(400, \"invalid_request\", \"invalid_email\", {\"field\": \"email\"})\n   162→        if msg == \"invalid_credentials\":\n   163→            return _err(401, \"unauthorized\", \"invalid_credentials\")\n   164→        if msg == \"password_too_short\":\n   165→            return _err(400, \"invalid_request\", \"password_too_short\", {\"field\": \"password\"})\n   166→        if msg == \"invalid_birthday_local\":\n   167→            return _err(400, \"invalid_request\", \"invalid_birthday_local\", {\"field\": \"birthday_local\"})\n   168→        if msg == \"invalid_location\":\n   169→            return _err(400, \"invalid_request\", \"invalid_location\", {\"field\": \"location\"})\n   170→        if msg == \"invalid_gender\":\n   171→            return _err(400, \"invalid_request\", \"invalid_gender\", {\"field\": \"gender\"})\n   172→        return _err(400, \"invalid_request\", msg)\n   173→    except Exception:\n   174→        return _err(500, \"internal_error\", \"register_failed\")\n   175→\n   176→\n   177→@router.post(\"/login\")\n   178→def login(req: LoginRequest, request: Request):\n   179→    try:\n   180→        user_id = auth_service.authenticate(req.email, req.password)\n   181→        tokens = auth_service.create_session(user_id, ip=get_client_ip(request), user_agent=get_user_agent(request))\n   182→        auth_service.update_last_login(user_id)\n   183→        resp = _ok({\"user_id\": user_id, \"email\": req.email.strip().lower()})\n   184→        _set_session_cookies(resp, tokens)\n   185→        return resp\n   186→    except auth_service.AuthError:\n   187→        return _err(401, \"unauthorized\", \"invalid_credentials\")\n   188→    except Exception:\n   189→        return _err(500, \"internal_error\", \"login_failed\")\n   190→\n   191→\n   192→@router.get(\"/me\")\n   193→def me(request: Request):\n   194→    auth = require_auth(request)\n   195→    return _ok(\n   196→        {\n   197→            \"user_id\": int(auth[\"user_id\"]),\n   198→            \"email\": str(auth.get(\"email\") or \"\"),\n   199→            \"name\": str(auth.get(\"name\") or \"\"),\n   200→            \"persona_style\": str(auth.get(\"persona_style\") or \"warm\"),\n   201→        }\n   202→    )\n   203→\n   204→\n   205→@router.post(\"/logout\")\n   206→def logout(request: Request):\n   207→    auth = require_auth(request)\n   208→    require_csrf(request, auth)\n   209→    auth_service.revoke_session(str(auth[\"session_id\"]))\n   210→    resp = _ok({})\n   211→    _clear_session_cookies(resp)\n   212→    return resp\n   213→\n   214→\n   215→@router.get(\"/sessions\")\n   216→def sessions(request: Request):\n   217→    auth = require_auth(request)\n   218→    rows = auth_service.list_sessions(int(auth[\"user_id\"]))\n   219→    items = [\n   220→        {\n   221→            \"session_id\": str(r[\"session_id\"]),\n   222→            \"created_at\": str(r[\"created_at\"]),\n   223→            \"expires_at\": str(r[\"expires_at\"]),\n   224→            \"ip\": str(r.get(\"ip\") or \"\"),\n   225→            \"user_agent\": str(r.get(\"user_agent\") or \"\"),\n   226→            \"revoked_at\": (str(r[\"revoked_at\"]) if r.get(\"revoked_at\") else None),\n   227→        }\n   228→        for r in rows\n   229→    ]\n   230→    return _ok({\"sessions\": items})\n   231→\n   232→\n   233→@router.post(\"/logout-all\")\n   234→def logout_all(request: Request):\n   235→    auth = require_auth(request)\n   236→    require_csrf(request, auth)\n   237→    auth_service.revoke_all_sessions(int(auth[\"user_id\"]))\n   238→    resp = _ok({})\n   239→    _clear_session_cookies(resp)\n   240→    return resp\n   241→\n   242→\n   243→@router.put(\"/password\")\n   244→def change_password(req: PasswordChangeRequest, request: Request):\n   245→    auth = require_auth(request)\n   246→    require_csrf(request, auth)\n   247→    try:\n   248→        auth_service.change_password(int(auth[\"user_id\"]), req.old_password, req.new_password)\n   249→    except auth_service.AuthError:\n   250→        return _err(401, \"unauthorized\", \"invalid_credentials\")\n   251→    auth_service.revoke_all_sessions(int(auth[\"user_id\"]))\n   252→    resp = _ok({})\n   253→    _clear_session_cookies(resp)\n   254→    return resp\n   255→\n   256→\n   257→@router.delete(\"/account\")\n   258→def delete_account(req: DeleteAccountRequest, request: Request):\n   259→    auth = require_auth(request)\n   260→    require_csrf(request, auth)\n   261→    try:\n   262→        auth_service.delete_account(int(auth[\"user_id\"]), req.password)\n   263→    except auth_service.AuthError:\n   264→        return _err(401, \"unauthorized\", \"invalid_credentials\")\n   265→    auth_service.revoke_all_sessions(int(auth[\"user_id\"]))\n   266→    resp = _ok({})\n   267→    _clear_session_cookies(resp)\n   268→    return resp\n   269→\n   270→\n   271→@router.post(\"/preview\")\n   272→def preview(req: PreviewRequest):\n   273→    \"\"\"\n   274→    Public, non-persistent preview for \"try before you sign up\".\n   275→\n   276→    - Does NOT write any DB rows.\n   277→    - Returns a small derived payload for rendering the preview card.\n   278→    \"\"\"\n   279→    try:\n   280→        gender = str(req.gender or \"\").strip()\n   281→        if gender not in (\"男\", \"女\"):\n   282→            raise auth_service.AuthError(\"invalid_gender\")\n   283→\n   284→        tz = _finite_float(req.tz_offset_hours)\n   285→        if tz is None or tz < -12 or tz > 14:\n   286→            raise auth_service.AuthError(\"invalid_tz_offset_hours\")\n   287→\n   288→        birthday_local = _parse_birthday_local(req.birthday_local)\n   289→        loc, used_default = _coerce_location(req.location)\n   290→\n   291→        facts = bazi_facts.compute_facts(\n   292→            name=str(req.name or \"你\"),\n   293→            gender=gender,\n   294→            birthday_local=birthday_local,\n   295→            tz_offset_hours=float(tz),\n   296→            location=loc,\n   297→        )\n   298→        bazi = facts.get(\"bazi\") or {}\n   299→        luck = bazi.get(\"luck\") or {}\n   300→        strength = bazi.get(\"strength\")\n   301→        strength_status = \"\"\n   302→        favorable_elements: list[str] = []\n   303→        if isinstance(strength, dict):\n   304→            strength_status = str(strength.get(\"status\") or \"\")\n   305→            fe = strength.get(\"favorable_elements\")\n   306→            if isinstance(fe, list):\n   307→                favorable_elements = [str(x) for x in fe if x is not None]\n   308→        elif strength is not None:\n   309→            strength_status = str(strength)\n   310→\n   311→        return _ok(\n   312→            {\n   313→                \"pillars\": bazi.get(\"pillars\") or {},\n   314→                \"day_master\": bazi.get(\"day_master\") or {},\n   315→                \"wuxing_count\": bazi.get(\"wuxing_count\") or {},\n   316→                \"strength\": strength_status,\n   317→                \"favorable_elements\": favorable_elements,\n   318→                \"luck\": {\n   319→                    \"forward\": (luck.get(\"forward\") if \"forward\" in luck else None),\n   320→                    \"start_age_year\": (luck.get(\"start_age_year\") if \"start_age_year\" in luck else None),\n   321→                },\n   322→                \"digest\": bazi_facts.make_bazi_digest(facts),\n   323→                \"used_default_location\": bool(used_default),\n   324→            }\n   325→        )\n   326→    except auth_service.AuthError as e:\n   327→        msg = str(e)\n   328→        if msg == \"invalid_gender\":\n   329→            return _err(400, \"invalid_request\", \"invalid_gender\", {\"field\": \"gender\"})\n   330→        if msg == \"invalid_birthday_local\":\n   331→            return _err(400, \"invalid_request\", \"invalid_birthday_local\", {\"field\": \"birthday_local\"})\n   332→        if msg == \"invalid_tz_offset_hours\":\n   333→            return _err(400, \"invalid_request\", \"invalid_tz_offset_hours\", {\"field\": \"tz_offset_hours\"})\n   334→        return _err(400, \"invalid_request\", msg)\n   335→    except Exception:\n   336→        return _err(500, \"internal_error\", \"preview_failed\")\n   337→\n   338→\n   339→# Validation point templates based on personality traits\n   340→_VALIDATION_TEMPLATES = {\n   341→    \"bazi\": {\n   342→        # Day master element based templates\n   343→        \"甲\": [\n   344→            \"你是不是经常有很多新想法，但不一定都会付诸行动？\",\n   345→            \"你在面对挑战时，第一反应是迎难而上而不是绕道？\",\n   346→            \"你是否觉得自己有时候太固执，不够灵活？\",\n   347→        ],\n   348→        \"乙\": [\n   349→            \"你是不是很会察言观色，在人际关系中游刃有余？\",\n   350→            \"你面对压力时，更喜欢用柔和的方式化解而非正面对抗？\",\n   351→            \"你是否经常在照顾别人的同时，忽略了自己的需求？\",\n   352→        ],\n   353→        \"丙\": [\n   354→            \"你是不是天生热情洋溢，很容易感染周围的人？\",\n   355→            \"你在人群中是否经常是焦点或者话题中心？\",\n   356→            \"你会不会有时候过于直接，说话不留余地？\",\n   357→        ],\n   358→        \"丁\": [\n   359→            \"你是不是内心敏感细腻，能感知到别人忽略的细节？\",\n   360→            \"你在表达情感时，更喜欢含蓄委婉而非直白表露？\",\n   361→            \"你是否经常思虑过多，容易陷入内心的纠结？\",\n   362→        ],\n   363→        \"戊\": [\n   364→            \"你是不是给人一种稳重可靠的感觉，很多人喜欢向你倾诉？\",\n   365→            \"你做事是否讲究步骤和规划，不喜欢冒进？\",\n   366→            \"你会不会有时候太过保守，错失一些机会？\",\n   367→        ],\n   368→        \"己\": [\n   369→            \"你是不是很有包容心，能接纳各种不同的人和事？\",\n   370→            \"你在帮助别人时，会不会不自觉地牺牲自己的利益？\",\n   371→            \"你是否经常扮演调解者的角色，化解周围人的矛盾？\",\n   372→        ],\n   373→        \"庚\": [\n   374→            \"你是不是很有原则，认定的事情不轻易妥协？\",\n   375→            \"你在做决定时，是否倾向于果断、不拖泥带水？\",\n   376→            \"你会不会有时候过于强势，让身边的人感到压力？\",\n   377→        ],\n   378→        \"辛\": [\n   379→            \"你是不是对美有很高的追求，对品质很挑剔？\",\n   380→            \"你是否很注重自己的形象和给人的印象？\",\n   381→            \"你在面对粗糙或不完美的事物时，会不会很难忍受？\",\n   382→        ],\n   383→        \"壬\": [\n   384→            \"你是不是思维活跃，想法很多很跳跃？\",\n   385→            \"你是否喜欢探索未知，对新鲜事物充满好奇？\",\n   386→            \"你会不会有时候静不下心来，注意力容易分散？\",\n   387→        ],\n   388→        \"癸\": [\n   389→            \"你是不是直觉很准，有时候说不清为什么但就是知道？\",\n   390→            \"你是否更喜欢独处思考，而非热闹的社交场合？\",\n   391→            \"你会不会容易多愁善感，情绪起伏较大？\",\n   392→        ],\n   393→    },\n   394→    \"ziwei\": [\n   395→        \"你是不是经常感觉自己有某种使命感或责任感？\",\n   396→        \"你在关键时刻是否总能做出正确的选择？\",\n   397→        \"你是否对自己有很高的期望，不容易满足于现状？\",\n   398→    ],\n   399→    \"astro\": [\n   400→        \"你是不是经常在满月前后情绪波动比较大？\",\n   401→        \"你是否注意到某些日期或时段对你特别重要？\",\n   402→        \"你会不会觉得星象变化确实影响到你的状态？\",\n   403→    ],\n   404→}\n   405→\n   406→_STRENGTH_TEMPLATES = {\n   407→    \"身强\": [\n   408→        \"你是不是精力充沛，能同时处理多件事情？\",\n   409→        \"你在团队中是否经常担任领导或主导的角色？\",\n   410→    ],\n   411→    \"身弱\": [\n   412→        \"你是不是比较注重内在修养，不喜欢张扬？\",\n   413→        \"你在合作中是否更擅长辅助和配合？\",\n   414→    ],\n   415→}\n   416→\n   417→\n   418→def _get_validation_points(mode: str, facts: Dict[str, Any]) -> list[str]:\n   419→    \"\"\"Generate 3 validation points based on mode and computed facts.\"\"\"\n   420→    points: list[str] = []\n   421→    bazi = facts.get(\"bazi\") or {}\n   422→\n   423→    if mode == \"bazi\":\n   424→        day_master = bazi.get(\"day_master\") or {}\n   425→        gan = str(day_master.get(\"gan\") or \"\")\n   426→\n   427→        # Get templates for this day master\n   428→        templates = _VALIDATION_TEMPLATES.get(\"bazi\", {}).get(gan, [])\n   429→        if templates:\n   430→            points.extend(templates[:2])\n   431→\n   432→        # Add strength-based point\n   433→        strength = bazi.get(\"strength\")\n   434→        if isinstance(strength, dict):\n   435→            status = str(strength.get(\"status\") or \"\")\n   436→            strength_templates = _STRENGTH_TEMPLATES.get(status, [])\n   437→            if strength_templates:\n   438→                points.append(strength_templates[0])\n   439→\n   440→        # Ensure we have at least 3 points\n   441→        if len(points) < 3 and templates:\n   442→            for t in templates[2:]:\n   443→                if len(points) >= 3:\n   444→                    break\n   445→                points.append(t)\n   446→\n   447→    elif mode == \"ziwei\":\n   448→        points = _VALIDATION_TEMPLATES.get(\"ziwei\", [])[:3]\n   449→\n   450→    elif mode == \"astro\":\n   451→        points = _VALIDATION_TEMPLATES.get(\"astro\", [])[:3]\n   452→\n   453→    # Fallback generic points\n   454→    if len(points) < 3:\n   455→        generic = [\n   456→            \"你是不是有时候觉得自己与众不同？\",\n   457→            \"你是否在某些方面有独特的直觉或天赋？\",\n   458→            \"你会不会经常思考人生的意义和方向？\",\n   459→        ]\n   460→        for g in generic:\n   461→            if len(points) >= 3:\n   462→                break\n   463→            if g not in points:\n   464→                points.append(g)\n   465→\n   466→    return points[:3]\n   467→\n   468→\n   469→@router.post(\"/validation-points\")\n   470→def validation_points(req: ValidationPointsRequest):\n   471→    \"\"\"\n   472→    Generate 3 \"that's me!\" validation points for cold-start trust building.\n   473→\n   474→    Based on birth chart facts, returns personality/behavior statements\n   475→    that users can identify with.\n   476→    \"\"\"\n   477→    try:\n   478→        gender = str(req.gender or \"\").strip()\n   479→        if gender not in (\"男\", \"女\"):\n   480→            raise auth_service.AuthError(\"invalid_gender\")\n   481→\n   482→        tz = _finite_float(req.tz_offset_hours)\n   483→        if tz is None or tz < -12 or tz > 14:\n   484→            raise auth_service.AuthError(\"invalid_tz_offset_hours\")\n   485→\n   486→        birthday_local = _parse_birthday_local(req.birthday_local)\n   487→        loc, _ = _coerce_location(req.location)\n   488→\n   489→        mode = str(req.mode or \"bazi\").strip().lower()\n   490→        if mode not in (\"bazi\", \"ziwei\", \"astro\"):\n   491→            mode = \"bazi\"\n   492→\n   493→        facts = bazi_facts.compute_facts(\n   494→            name=\"你\",\n   495→            gender=gender,\n   496→            birthday_local=birthday_local,\n   497→            tz_offset_hours=float(tz),\n   498→            location=loc,\n   499→        )\n   500→\n   501→        points = _get_validation_points(mode, facts)\n   502→\n   503→        return _ok({\"points\": points, \"mode\": mode})\n   504→    except auth_service.AuthError as e:\n   505→        msg = str(e)\n   506→        return _err(400, \"invalid_request\", msg)\n   507→    except Exception:\n   508→        return _err(500, \"internal_error\", \"validation_points_failed\")\n   509→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"91dfc78a-dfff-4c36-95a8-6b82b650d310","timestamp":"2026-01-01T15:01:23.793Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aiscend/work/fortune_ai/api/auth_routes.py","content":"from __future__ import annotations\n\nimport math\nimport os\nfrom datetime import datetime\nfrom typing import Any, Dict, Optional\n\nfrom fastapi import APIRouter, HTTPException, Request\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field\n\nfrom api.deps import get_client_ip, get_user_agent, require_auth, require_csrf\nfrom services import auth_service, bazi_facts\nfrom services.bazi_engine import DEFAULT_LOCATION\n\n\nrouter = APIRouter(prefix=\"/api/auth\", tags=[\"auth\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n\ndef _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    return JSONResponse(\n        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n        status_code=status,\n    )\n\n\ndef _cookie_secure() -> bool:\n    return os.getenv(\"FORTUNE_COOKIE_SECURE\", \"0\") == \"1\"\n\n\ndef _set_session_cookies(resp: JSONResponse, tokens: auth_service.SessionTokens) -> None:\n    max_age = 30 * 24 * 3600\n    resp.set_cookie(\n        \"fortune_session\",\n        tokens.session_token,\n        httponly=True,\n        samesite=\"lax\",\n        secure=_cookie_secure(),\n        max_age=max_age,\n        path=\"/\",\n    )\n    resp.set_cookie(\n        \"fortune_csrf\",\n        tokens.csrf_token,\n        httponly=False,\n        samesite=\"lax\",\n        secure=_cookie_secure(),\n        max_age=max_age,\n        path=\"/\",\n    )\n\n\ndef _clear_session_cookies(resp: JSONResponse) -> None:\n    resp.delete_cookie(\"fortune_session\", path=\"/\")\n    resp.delete_cookie(\"fortune_csrf\", path=\"/\")\n\n\nclass RegisterRequest(BaseModel):\n    email: str = Field(..., min_length=3)\n    password: str = Field(..., min_length=8)\n    name: str = Field(..., min_length=1)\n    gender: str = Field(..., min_length=1)\n    birthday_local: str = Field(..., min_length=19, description=\"YYYY-MM-DD HH:MM:SS\")\n    tz_offset_hours: float = Field(8.0)\n    location: Dict[str, Any]\n\n\nclass LoginRequest(BaseModel):\n    email: str = Field(..., min_length=3)\n    password: str = Field(..., min_length=1)\n\n\nclass PasswordChangeRequest(BaseModel):\n    old_password: str = Field(..., min_length=1)\n    new_password: str = Field(..., min_length=8)\n\n\nclass DeleteAccountRequest(BaseModel):\n    password: str = Field(..., min_length=1)\n\n\nclass PreviewRequest(BaseModel):\n    gender: str = Field(..., min_length=1)\n    birthday_local: str = Field(..., min_length=10, description=\"YYYY-MM-DD HH:MM[:SS]\")\n    tz_offset_hours: float = Field(8.0)\n    location: Dict[str, Any] = Field(default_factory=dict)\n    name: Optional[str] = None\n\n\nclass ValidationPointsRequest(BaseModel):\n    mode: str = Field(\"bazi\", description=\"bazi|ziwei|astro\")\n    gender: str = Field(..., min_length=1)\n    birthday_local: str = Field(..., min_length=10, description=\"YYYY-MM-DD HH:MM[:SS]\")\n    tz_offset_hours: float = Field(8.0)\n    location: Dict[str, Any] = Field(default_factory=dict)\n\n\ndef _finite_float(x: Any) -> Optional[float]:\n    try:\n        v = float(x)\n    except Exception:\n        return None\n    return v if math.isfinite(v) else None\n\n\ndef _coerce_location(location: Dict[str, Any]) -> tuple[Dict[str, Any], bool]:\n    default = {\n        \"name\": str(DEFAULT_LOCATION.get(\"name\") or \"北京\"),\n        \"longitude\": float(DEFAULT_LOCATION.get(\"longitude\") or 116.4074),\n        \"latitude\": float(DEFAULT_LOCATION.get(\"latitude\") or 39.9042),\n    }\n    if not isinstance(location, dict):\n        return default, True\n\n    name = str(location.get(\"name\") or \"\").strip() or default[\"name\"]\n    lon = _finite_float(location.get(\"longitude\"))\n    lat = _finite_float(location.get(\"latitude\"))\n    if lon is None or lat is None:\n        return {**default, \"name\": name}, True\n    if lon < -180 or lon > 180 or lat < -90 or lat > 90:\n        return {**default, \"name\": name}, True\n    return {\"name\": name, \"longitude\": lon, \"latitude\": lat}, False\n\n\ndef _parse_birthday_local(text: str) -> datetime:\n    s = str(text or \"\").strip()\n    if len(s) == 16 and s[10] == \" \" and s[13] == \":\":\n        s = s + \":00\"\n    try:\n        return datetime.strptime(s, \"%Y-%m-%d %H:%M:%S\")\n    except Exception:\n        raise auth_service.AuthError(\"invalid_birthday_local\")\n\n\n@router.post(\"/register\")\ndef register(req: RegisterRequest, request: Request):\n    try:\n        user_id = auth_service.register_user(\n            email=req.email,\n            password=req.password,\n            name=req.name,\n            gender=req.gender,\n            birthday_local=req.birthday_local,\n            tz_offset_hours=req.tz_offset_hours,\n            location=req.location,\n        )\n        tokens = auth_service.create_session(user_id, ip=get_client_ip(request), user_agent=get_user_agent(request))\n        auth_service.update_last_login(user_id)\n        resp = _ok({\"user_id\": user_id, \"email\": req.email.strip().lower(), \"profile_summary\": {\"name\": req.name, \"gender\": req.gender, \"location_name\": str(req.location.get(\"name\") or \"\")}})\n        _set_session_cookies(resp, tokens)\n        return resp\n    except auth_service.AuthError as e:\n        msg = str(e)\n        if msg == \"email_exists\":\n            return _err(409, \"conflict\", \"email_exists\", {\"field\": \"email\"})\n        if msg == \"invalid_email\":\n            return _err(400, \"invalid_request\", \"invalid_email\", {\"field\": \"email\"})\n        if msg == \"invalid_credentials\":\n            return _err(401, \"unauthorized\", \"invalid_credentials\")\n        if msg == \"password_too_short\":\n            return _err(400, \"invalid_request\", \"password_too_short\", {\"field\": \"password\"})\n        if msg == \"invalid_birthday_local\":\n            return _err(400, \"invalid_request\", \"invalid_birthday_local\", {\"field\": \"birthday_local\"})\n        if msg == \"invalid_location\":\n            return _err(400, \"invalid_request\", \"invalid_location\", {\"field\": \"location\"})\n        if msg == \"invalid_gender\":\n            return _err(400, \"invalid_request\", \"invalid_gender\", {\"field\": \"gender\"})\n        return _err(400, \"invalid_request\", msg)\n    except Exception:\n        return _err(500, \"internal_error\", \"register_failed\")\n\n\n@router.post(\"/login\")\ndef login(req: LoginRequest, request: Request):\n    try:\n        user_id = auth_service.authenticate(req.email, req.password)\n        tokens = auth_service.create_session(user_id, ip=get_client_ip(request), user_agent=get_user_agent(request))\n        auth_service.update_last_login(user_id)\n        resp = _ok({\"user_id\": user_id, \"email\": req.email.strip().lower()})\n        _set_session_cookies(resp, tokens)\n        return resp\n    except auth_service.AuthError:\n        return _err(401, \"unauthorized\", \"invalid_credentials\")\n    except Exception:\n        return _err(500, \"internal_error\", \"login_failed\")\n\n\n@router.get(\"/me\")\ndef me(request: Request):\n    auth = require_auth(request)\n    return _ok(\n        {\n            \"user_id\": int(auth[\"user_id\"]),\n            \"email\": str(auth.get(\"email\") or \"\"),\n            \"name\": str(auth.get(\"name\") or \"\"),\n            \"persona_style\": str(auth.get(\"persona_style\") or \"warm\"),\n        }\n    )\n\n\n@router.post(\"/logout\")\ndef logout(request: Request):\n    auth = require_auth(request)\n    require_csrf(request, auth)\n    auth_service.revoke_session(str(auth[\"session_id\"]))\n    resp = _ok({})\n    _clear_session_cookies(resp)\n    return resp\n\n\n@router.get(\"/sessions\")\ndef sessions(request: Request):\n    auth = require_auth(request)\n    rows = auth_service.list_sessions(int(auth[\"user_id\"]))\n    items = [\n        {\n            \"session_id\": str(r[\"session_id\"]),\n            \"created_at\": str(r[\"created_at\"]),\n            \"expires_at\": str(r[\"expires_at\"]),\n            \"ip\": str(r.get(\"ip\") or \"\"),\n            \"user_agent\": str(r.get(\"user_agent\") or \"\"),\n            \"revoked_at\": (str(r[\"revoked_at\"]) if r.get(\"revoked_at\") else None),\n        }\n        for r in rows\n    ]\n    return _ok({\"sessions\": items})\n\n\n@router.post(\"/logout-all\")\ndef logout_all(request: Request):\n    auth = require_auth(request)\n    require_csrf(request, auth)\n    auth_service.revoke_all_sessions(int(auth[\"user_id\"]))\n    resp = _ok({})\n    _clear_session_cookies(resp)\n    return resp\n\n\n@router.put(\"/password\")\ndef change_password(req: PasswordChangeRequest, request: Request):\n    auth = require_auth(request)\n    require_csrf(request, auth)\n    try:\n        auth_service.change_password(int(auth[\"user_id\"]), req.old_password, req.new_password)\n    except auth_service.AuthError:\n        return _err(401, \"unauthorized\", \"invalid_credentials\")\n    auth_service.revoke_all_sessions(int(auth[\"user_id\"]))\n    resp = _ok({})\n    _clear_session_cookies(resp)\n    return resp\n\n\n@router.delete(\"/account\")\ndef delete_account(req: DeleteAccountRequest, request: Request):\n    auth = require_auth(request)\n    require_csrf(request, auth)\n    try:\n        auth_service.delete_account(int(auth[\"user_id\"]), req.password)\n    except auth_service.AuthError:\n        return _err(401, \"unauthorized\", \"invalid_credentials\")\n    auth_service.revoke_all_sessions(int(auth[\"user_id\"]))\n    resp = _ok({})\n    _clear_session_cookies(resp)\n    return resp\n\n\n@router.post(\"/preview\")\ndef preview(req: PreviewRequest):\n    \"\"\"\n    Public, non-persistent preview for \"try before you sign up\".\n\n    - Does NOT write any DB rows.\n    - Returns a small derived payload for rendering the preview card.\n    \"\"\"\n    try:\n        gender = str(req.gender or \"\").strip()\n        if gender not in (\"男\", \"女\"):\n            raise auth_service.AuthError(\"invalid_gender\")\n\n        tz = _finite_float(req.tz_offset_hours)\n        if tz is None or tz < -12 or tz > 14:\n            raise auth_service.AuthError(\"invalid_tz_offset_hours\")\n\n        birthday_local = _parse_birthday_local(req.birthday_local)\n        loc, used_default = _coerce_location(req.location)\n\n        facts = bazi_facts.compute_facts(\n            name=str(req.name or \"你\"),\n            gender=gender,\n            birthday_local=birthday_local,\n            tz_offset_hours=float(tz),\n            location=loc,\n        )\n        bazi = facts.get(\"bazi\") or {}\n        luck = bazi.get(\"luck\") or {}\n        strength = bazi.get(\"strength\")\n        strength_status = \"\"\n        favorable_elements: list[str] = []\n        if isinstance(strength, dict):\n            strength_status = str(strength.get(\"status\") or \"\")\n            fe = strength.get(\"favorable_elements\")\n            if isinstance(fe, list):\n                favorable_elements = [str(x) for x in fe if x is not None]\n        elif strength is not None:\n            strength_status = str(strength)\n\n        return _ok(\n            {\n                \"pillars\": bazi.get(\"pillars\") or {},\n                \"day_master\": bazi.get(\"day_master\") or {},\n                \"wuxing_count\": bazi.get(\"wuxing_count\") or {},\n                \"strength\": strength_status,\n                \"favorable_elements\": favorable_elements,\n                \"luck\": {\n                    \"forward\": (luck.get(\"forward\") if \"forward\" in luck else None),\n                    \"start_age_year\": (luck.get(\"start_age_year\") if \"start_age_year\" in luck else None),\n                },\n                \"digest\": bazi_facts.make_bazi_digest(facts),\n                \"used_default_location\": bool(used_default),\n            }\n        )\n    except auth_service.AuthError as e:\n        msg = str(e)\n        if msg == \"invalid_gender\":\n            return _err(400, \"invalid_request\", \"invalid_gender\", {\"field\": \"gender\"})\n        if msg == \"invalid_birthday_local\":\n            return _err(400, \"invalid_request\", \"invalid_birthday_local\", {\"field\": \"birthday_local\"})\n        if msg == \"invalid_tz_offset_hours\":\n            return _err(400, \"invalid_request\", \"invalid_tz_offset_hours\", {\"field\": \"tz_offset_hours\"})\n        return _err(400, \"invalid_request\", msg)\n    except Exception:\n        return _err(500, \"internal_error\", \"preview_failed\")\n\n\n# Validation point templates based on personality traits\n_VALIDATION_TEMPLATES = {\n    \"bazi\": {\n        # Day master element based templates\n        \"甲\": [\n            \"你是不是经常有很多新想法，但不一定都会付诸行动？\",\n            \"你在面对挑战时，第一反应是迎难而上而不是绕道？\",\n            \"你是否觉得自己有时候太固执，不够灵活？\",\n        ],\n        \"乙\": [\n            \"你是不是很会察言观色，在人际关系中游刃有余？\",\n            \"你面对压力时，更喜欢用柔和的方式化解而非正面对抗？\",\n            \"你是否经常在照顾别人的同时，忽略了自己的需求？\",\n        ],\n        \"丙\": [\n            \"你是不是天生热情洋溢，很容易感染周围的人？\",\n            \"你在人群中是否经常是焦点或者话题中心？\",\n            \"你会不会有时候过于直接，说话不留余地？\",\n        ],\n        \"丁\": [\n            \"你是不是内心敏感细腻，能感知到别人忽略的细节？\",\n            \"你在表达情感时，更喜欢含蓄委婉而非直白表露？\",\n            \"你是否经常思虑过多，容易陷入内心的纠结？\",\n        ],\n        \"戊\": [\n            \"你是不是给人一种稳重可靠的感觉，很多人喜欢向你倾诉？\",\n            \"你做事是否讲究步骤和规划，不喜欢冒进？\",\n            \"你会不会有时候太过保守，错失一些机会？\",\n        ],\n        \"己\": [\n            \"你是不是很有包容心，能接纳各种不同的人和事？\",\n            \"你在帮助别人时，会不会不自觉地牺牲自己的利益？\",\n            \"你是否经常扮演调解者的角色，化解周围人的矛盾？\",\n        ],\n        \"庚\": [\n            \"你是不是很有原则，认定的事情不轻易妥协？\",\n            \"你在做决定时，是否倾向于果断、不拖泥带水？\",\n            \"你会不会有时候过于强势，让身边的人感到压力？\",\n        ],\n        \"辛\": [\n            \"你是不是对美有很高的追求，对品质很挑剔？\",\n            \"你是否很注重自己的形象和给人的印象？\",\n            \"你在面对粗糙或不完美的事物时，会不会很难忍受？\",\n        ],\n        \"壬\": [\n            \"你是不是思维活跃，想法很多很跳跃？\",\n            \"你是否喜欢探索未知，对新鲜事物充满好奇？\",\n            \"你会不会有时候静不下心来，注意力容易分散？\",\n        ],\n        \"癸\": [\n            \"你是不是直觉很准，有时候说不清为什么但就是知道？\",\n            \"你是否更喜欢独处思考，而非热闹的社交场合？\",\n            \"你会不会容易多愁善感，情绪起伏较大？\",\n        ],\n    },\n    \"ziwei\": [\n        \"你是不是经常感觉自己有某种使命感或责任感？\",\n        \"你在关键时刻是否总能做出正确的选择？\",\n        \"你是否对自己有很高的期望，不容易满足于现状？\",\n    ],\n    \"astro\": [\n        \"你是不是经常在满月前后情绪波动比较大？\",\n        \"你是否注意到某些日期或时段对你特别重要？\",\n        \"你会不会觉得星象变化确实影响到你的状态？\",\n    ],\n}\n\n_STRENGTH_TEMPLATES = {\n    \"身强\": [\n        \"你是不是精力充沛，能同时处理多件事情？\",\n        \"你在团队中是否经常担任领导或主导的角色？\",\n    ],\n    \"身弱\": [\n        \"你是不是比较注重内在修养，不喜欢张扬？\",\n        \"你在合作中是否更擅长辅助和配合？\",\n    ],\n}\n\n\ndef _get_validation_points(mode: str, facts: Dict[str, Any]) -> list[str]:\n    \"\"\"Generate 3 validation points based on mode and computed facts.\"\"\"\n    points: list[str] = []\n    bazi = facts.get(\"bazi\") or {}\n\n    if mode == \"bazi\":\n        day_master = bazi.get(\"day_master\") or {}\n        gan = str(day_master.get(\"gan\") or \"\")\n\n        # Get templates for this day master\n        templates = _VALIDATION_TEMPLATES.get(\"bazi\", {}).get(gan, [])\n        if templates:\n            points.extend(templates[:2])\n\n        # Add strength-based point\n        strength = bazi.get(\"strength\")\n        if isinstance(strength, dict):\n            status = str(strength.get(\"status\") or \"\")\n            strength_templates = _STRENGTH_TEMPLATES.get(status, [])\n            if strength_templates:\n                points.append(strength_templates[0])\n\n        # Ensure we have at least 3 points\n        if len(points) < 3 and templates:\n            for t in templates[2:]:\n                if len(points) >= 3:\n                    break\n                points.append(t)\n\n    elif mode == \"ziwei\":\n        points = _VALIDATION_TEMPLATES.get(\"ziwei\", [])[:3]\n\n    elif mode == \"astro\":\n        points = _VALIDATION_TEMPLATES.get(\"astro\", [])[:3]\n\n    # Fallback generic points\n    if len(points) < 3:\n        generic = [\n            \"你是不是有时候觉得自己与众不同？\",\n            \"你是否在某些方面有独特的直觉或天赋？\",\n            \"你会不会经常思考人生的意义和方向？\",\n        ]\n        for g in generic:\n            if len(points) >= 3:\n                break\n            if g not in points:\n                points.append(g)\n\n    return points[:3]\n\n\n@router.post(\"/validation-points\")\ndef validation_points(req: ValidationPointsRequest):\n    \"\"\"\n    Generate 3 \"that's me!\" validation points for cold-start trust building.\n\n    Based on birth chart facts, returns personality/behavior statements\n    that users can identify with.\n    \"\"\"\n    try:\n        gender = str(req.gender or \"\").strip()\n        if gender not in (\"男\", \"女\"):\n            raise auth_service.AuthError(\"invalid_gender\")\n\n        tz = _finite_float(req.tz_offset_hours)\n        if tz is None or tz < -12 or tz > 14:\n            raise auth_service.AuthError(\"invalid_tz_offset_hours\")\n\n        birthday_local = _parse_birthday_local(req.birthday_local)\n        loc, _ = _coerce_location(req.location)\n\n        mode = str(req.mode or \"bazi\").strip().lower()\n        if mode not in (\"bazi\", \"ziwei\", \"astro\"):\n            mode = \"bazi\"\n\n        facts = bazi_facts.compute_facts(\n            name=\"你\",\n            gender=gender,\n            birthday_local=birthday_local,\n            tz_offset_hours=float(tz),\n            location=loc,\n        )\n\n        points = _get_validation_points(mode, facts)\n\n        return _ok({\"points\": points, \"mode\": mode})\n    except auth_service.AuthError as e:\n        msg = str(e)\n        return _err(400, \"invalid_request\", msg)\n    except Exception:\n        return _err(500, \"internal_error\", \"validation_points_failed\")\n","numLines":509,"startLine":1,"totalLines":509}}}
{"parentUuid":"91dfc78a-dfff-4c36-95a8-6b82b650d310","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01G8n3sCd8KZj9HL2CGvhkjr","type":"tool_result","content":"     1→from __future__ import annotations\n     2→\n     3→import re\n     4→from typing import Any, Dict, Optional\n     5→\n     6→from fastapi import APIRouter, Request\n     7→from fastapi.responses import JSONResponse\n     8→from pydantic import BaseModel, Field\n     9→\n    10→from api.deps import require_auth, require_csrf\n    11→from services import chat_service\n    12→\n    13→\n    14→router = APIRouter(prefix=\"/api/session\", tags=[\"session\"])\n    15→\n    16→\n    17→def _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    18→    return JSONResponse({\"ok\": True, \"data\": data or {}})\n    19→\n    20→\n    21→def _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    22→    return JSONResponse(\n    23→        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n    24→        status_code=status,\n    25→    )\n    26→\n    27→\n    28→_UUID_RE = re.compile(r\"^[0-9a-fA-F-]{36}$\")\n    29→\n    30→\n    31→class SessionNewRequest(BaseModel):\n    32→    title: str = Field(\"\", max_length=80)\n    33→\n    34→\n    35→@router.post(\"/new\")\n    36→def new_session(req: SessionNewRequest, request: Request):\n    37→    auth = require_auth(request)\n    38→    require_csrf(request, auth)\n    39→    s = chat_service.create_session(int(auth[\"user_id\"]), title=req.title)\n    40→    return _ok(s)\n    41→\n    42→\n    43→@router.get(\"/list\")\n    44→def list_sessions(request: Request, limit: int = 20):\n    45→    auth = require_auth(request)\n    46→    rows = chat_service.list_sessions(int(auth[\"user_id\"]), limit=limit)\n    47→    items = [\n    48→        {\n    49→            \"session_id\": str(r[\"session_id\"]),\n    50→            \"title\": str(r.get(\"title\") or \"\"),\n    51→            \"updated_at\": str(r.get(\"updated_at\") or \"\"),\n    52→            \"preview\": str(r.get(\"preview\") or \"\")[:160],\n    53→        }\n    54→        for r in rows\n    55→    ]\n    56→    return _ok({\"sessions\": items})\n    57→\n    58→\n    59→@router.get(\"/{session_id}\")\n    60→def get_session_messages(session_id: str, request: Request, limit: int = 200):\n    61→    auth = require_auth(request)\n    62→    if not _UUID_RE.match(session_id or \"\"):\n    63→        return _err(400, \"invalid_request\", \"invalid_session_id\")\n    64→    if not chat_service.get_session(int(auth[\"user_id\"]), session_id):\n    65→        return _err(404, \"not_found\", \"session_not_found\")\n    66→    rows = chat_service.get_messages(int(auth[\"user_id\"]), session_id, limit=limit)\n    67→    messages = [\n    68→        {\n    69→            \"role\": str(r.get(\"role\") or \"\"),\n    70→            \"content\": str(r.get(\"content\") or \"\"),\n    71→            \"a2ui\": r.get(\"a2ui\"),\n    72→        }\n    73→        for r in rows\n    74→    ]\n    75→    return _ok({\"messages\": messages})\n    76→\n    77→\n\n<system-reminder>\nWhenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.\n</system-reminder>\n"}]},"uuid":"2b088384-e263-4b18-8ced-5f8b62525c6e","timestamp":"2026-01-01T15:01:23.793Z","toolUseResult":{"type":"text","file":{"filePath":"/home/aiscend/work/fortune_ai/api/session_routes.py","content":"from __future__ import annotations\n\nimport re\nfrom typing import Any, Dict, Optional\n\nfrom fastapi import APIRouter, Request\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field\n\nfrom api.deps import require_auth, require_csrf\nfrom services import chat_service\n\n\nrouter = APIRouter(prefix=\"/api/session\", tags=[\"session\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n\ndef _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    return JSONResponse(\n        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n        status_code=status,\n    )\n\n\n_UUID_RE = re.compile(r\"^[0-9a-fA-F-]{36}$\")\n\n\nclass SessionNewRequest(BaseModel):\n    title: str = Field(\"\", max_length=80)\n\n\n@router.post(\"/new\")\ndef new_session(req: SessionNewRequest, request: Request):\n    auth = require_auth(request)\n    require_csrf(request, auth)\n    s = chat_service.create_session(int(auth[\"user_id\"]), title=req.title)\n    return _ok(s)\n\n\n@router.get(\"/list\")\ndef list_sessions(request: Request, limit: int = 20):\n    auth = require_auth(request)\n    rows = chat_service.list_sessions(int(auth[\"user_id\"]), limit=limit)\n    items = [\n        {\n            \"session_id\": str(r[\"session_id\"]),\n            \"title\": str(r.get(\"title\") or \"\"),\n            \"updated_at\": str(r.get(\"updated_at\") or \"\"),\n            \"preview\": str(r.get(\"preview\") or \"\")[:160],\n        }\n        for r in rows\n    ]\n    return _ok({\"sessions\": items})\n\n\n@router.get(\"/{session_id}\")\ndef get_session_messages(session_id: str, request: Request, limit: int = 200):\n    auth = require_auth(request)\n    if not _UUID_RE.match(session_id or \"\"):\n        return _err(400, \"invalid_request\", \"invalid_session_id\")\n    if not chat_service.get_session(int(auth[\"user_id\"]), session_id):\n        return _err(404, \"not_found\", \"session_not_found\")\n    rows = chat_service.get_messages(int(auth[\"user_id\"]), session_id, limit=limit)\n    messages = [\n        {\n            \"role\": str(r.get(\"role\") or \"\"),\n            \"content\": str(r.get(\"content\") or \"\"),\n            \"a2ui\": r.get(\"a2ui\"),\n        }\n        for r in rows\n    ]\n    return _ok({\"messages\": messages})\n\n","numLines":77,"startLine":1,"totalLines":77}}}
{"parentUuid":"2b088384-e263-4b18-8ced-5f8b62525c6e","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_019ZsdbbAPPuBkbhVTHo2bx7","type":"tool_result","content":"==> /home/aiscend/work/fortune_ai/api/bazi_routes.py <==\nfrom __future__ import annotations\n\nfrom typing import Any, Dict, Optional\n\nfrom fastapi import APIRouter, Request\nfrom fastapi.responses import JSONResponse\n\nfrom api.deps import require_auth\nfrom services import bazi_facts\n\n\nrouter = APIRouter(prefix=\"/api/bazi\", tags=[\"bazi\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n\ndef _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    return JSONResponse(\n        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n        status_code=status,\n    )\n\n\n@router.get(\"/facts\")\ndef get_facts(request: Request):\n    auth = require_auth(request)\n    user_id = int(auth[\"user_id\"])\n    try:\n        snap = bazi_facts.ensure_snapshot_for_user(user_id)\n    except ValueError as e:\n        msg = str(e)\n        if msg == \"user_not_found\":\n            return _err(404, \"not_found\", \"user_not_found\")\n        return _err(400, \"invalid_request\", msg)\n    return _ok({\"compute_version\": snap.get(\"compute_version\") or \"\", \"facts_hash\": snap.get(\"facts_hash\") or \"\", \"facts\": snap.get(\"facts\") or {}})\n\n\n==> /home/aiscend/work/fortune_ai/api/user_routes.py <==\nfrom __future__ import annotations\n\nimport json\nimport re\nfrom datetime import datetime, timedelta, timezone\nfrom typing import Any, Dict, Optional\n\nfrom fastapi import APIRouter, Request\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field\n\nfrom api.deps import require_auth, require_csrf\nfrom stores import fortune_db\nfrom services import bazi_facts\nfrom services.chat_backend_config import default_chat_backend, normalize_chat_backend\n\n\nrouter = APIRouter(prefix=\"/api/user\", tags=[\"user\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n\ndef _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    return JSONResponse(\n        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n        status_code=status,\n    )\n\n\ndef _parse_birthday_local(text: str) -> datetime:\n    try:\n        return datetime.strptime((text or \"\").strip(), \"%Y-%m-%d %H:%M:%S\")\n    except Exception:\n        raise ValueError(\"invalid_birthday_local\")\n\n\ndef _to_utc(local_dt: datetime, tz_offset_hours: float) -> datetime:\n    off = float(tz_offset_hours)\n    if off < -12 or off > 14:\n        raise ValueError(\"invalid_tz_offset_hours\")\n    return (local_dt - timedelta(hours=off)).replace(tzinfo=timezone.utc)\n\n\ndef _validate_location(location: Dict[str, Any]) -> Dict[str, Any]:\n    if not isinstance(location, dict):\n        raise ValueError(\"invalid_location\")\n    name = str(location.get(\"name\") or \"\").strip()\n    try:\n\n==> /home/aiscend/work/fortune_ai/api/dashboard_routes.py <==\n\"\"\"\nDashboard API 路由\n\nZone B Dashboard = 6 Tabs:\n1. 概览 (Overview): State Score + PERMA + 今日任务\n2. 状态 (Status): L0 事实 + L1 图式\n3. 趋势 (Trends): 历史数据 + 事件标记","is_error":false}]},"uuid":"0b01458d-cb9b-489b-a5b6-e115f9109626","timestamp":"2026-01-01T15:01:23.931Z","toolUseResult":{"stdout":"==> /home/aiscend/work/fortune_ai/api/bazi_routes.py <==\nfrom __future__ import annotations\n\nfrom typing import Any, Dict, Optional\n\nfrom fastapi import APIRouter, Request\nfrom fastapi.responses import JSONResponse\n\nfrom api.deps import require_auth\nfrom services import bazi_facts\n\n\nrouter = APIRouter(prefix=\"/api/bazi\", tags=[\"bazi\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n\ndef _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    return JSONResponse(\n        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n        status_code=status,\n    )\n\n\n@router.get(\"/facts\")\ndef get_facts(request: Request):\n    auth = require_auth(request)\n    user_id = int(auth[\"user_id\"])\n    try:\n        snap = bazi_facts.ensure_snapshot_for_user(user_id)\n    except ValueError as e:\n        msg = str(e)\n        if msg == \"user_not_found\":\n            return _err(404, \"not_found\", \"user_not_found\")\n        return _err(400, \"invalid_request\", msg)\n    return _ok({\"compute_version\": snap.get(\"compute_version\") or \"\", \"facts_hash\": snap.get(\"facts_hash\") or \"\", \"facts\": snap.get(\"facts\") or {}})\n\n\n==> /home/aiscend/work/fortune_ai/api/user_routes.py <==\nfrom __future__ import annotations\n\nimport json\nimport re\nfrom datetime import datetime, timedelta, timezone\nfrom typing import Any, Dict, Optional\n\nfrom fastapi import APIRouter, Request\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field\n\nfrom api.deps import require_auth, require_csrf\nfrom stores import fortune_db\nfrom services import bazi_facts\nfrom services.chat_backend_config import default_chat_backend, normalize_chat_backend\n\n\nrouter = APIRouter(prefix=\"/api/user\", tags=[\"user\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n\ndef _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    return JSONResponse(\n        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n        status_code=status,\n    )\n\n\ndef _parse_birthday_local(text: str) -> datetime:\n    try:\n        return datetime.strptime((text or \"\").strip(), \"%Y-%m-%d %H:%M:%S\")\n    except Exception:\n        raise ValueError(\"invalid_birthday_local\")\n\n\ndef _to_utc(local_dt: datetime, tz_offset_hours: float) -> datetime:\n    off = float(tz_offset_hours)\n    if off < -12 or off > 14:\n        raise ValueError(\"invalid_tz_offset_hours\")\n    return (local_dt - timedelta(hours=off)).replace(tzinfo=timezone.utc)\n\n\ndef _validate_location(location: Dict[str, Any]) -> Dict[str, Any]:\n    if not isinstance(location, dict):\n        raise ValueError(\"invalid_location\")\n    name = str(location.get(\"name\") or \"\").strip()\n    try:\n\n==> /home/aiscend/work/fortune_ai/api/dashboard_routes.py <==\n\"\"\"\nDashboard API 路由\n\nZone B Dashboard = 6 Tabs:\n1. 概览 (Overview): State Score + PERMA + 今日任务\n2. 状态 (Status): L0 事实 + L1 图式\n3. 趋势 (Trends): 历史数据 + 事件标记","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"0b01458d-cb9b-489b-a5b6-e115f9109626","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01UtyDaxkCnG3fF3hLAQJuFY","type":"message","role":"assistant","content":[{"type":"text","text":"Now let me examine more of the route files to get a complete picture:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":27576,"cache_read_input_tokens":42009,"cache_creation":{"ephemeral_5m_input_tokens":27576,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgro3fmM3hEdzRTbs794","type":"assistant","uuid":"0bafbe91-2aa5-46bd-a855-952737f229a7","timestamp":"2026-01-01T15:01:28.580Z"}
{"parentUuid":"0bafbe91-2aa5-46bd-a855-952737f229a7","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01UtyDaxkCnG3fF3hLAQJuFY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01L1trjGSDhippAErBtVwwEv","name":"Bash","input":{"command":"grep -l \"router = APIRouter\" /home/aiscend/work/fortune_ai/api/*.py | xargs -I {} basename {}","description":"List all route files"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":27576,"cache_read_input_tokens":42009,"cache_creation":{"ephemeral_5m_input_tokens":27576,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgro3fmM3hEdzRTbs794","type":"assistant","uuid":"e611463e-c7e0-409e-a3b6-09ffc3a53b6f","timestamp":"2026-01-01T15:01:29.140Z"}
{"parentUuid":"e611463e-c7e0-409e-a3b6-09ffc3a53b6f","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01UtyDaxkCnG3fF3hLAQJuFY","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_011aXoSLmn3rhZ8XvdM7ZTpB","name":"Bash","input":{"command":"for f in /home/aiscend/work/fortune_ai/api/{bento,kb,goal,reflection,yunshi,poster}_routes.py; do echo \"=== $(basename $f) ===\"; head -30 \"$f\"; echo; done","description":"Preview additional route files"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":27576,"cache_read_input_tokens":42009,"cache_creation":{"ephemeral_5m_input_tokens":27576,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgro3fmM3hEdzRTbs794","type":"assistant","uuid":"616a028f-3562-49ac-a710-b53931ab9506","timestamp":"2026-01-01T15:01:29.746Z"}
{"parentUuid":"616a028f-3562-49ac-a710-b53931ab9506","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01L1trjGSDhippAErBtVwwEv","type":"tool_result","content":"agent_tool.py\nauth_routes.py\nbazi_routes.py\nbento_routes.py\nchat_routes.py\ncurrency_routes.py\ndashboard_routes.py\ngoal_routes.py\njitai_routes.py\nkb_routes.py\nplan_routes.py\nposter_routes.py\npush_routes.py\nreflection_routes.py\nreport_routes.py\nsession_routes.py\nsocial_routes.py\ntwin_routes.py\nuser_routes.py\nyunshi_routes.py","is_error":false}]},"uuid":"b2c5b48e-0b35-41e6-8654-b2ad658de70d","timestamp":"2026-01-01T15:01:33.465Z","toolUseResult":{"stdout":"agent_tool.py\nauth_routes.py\nbazi_routes.py\nbento_routes.py\nchat_routes.py\ncurrency_routes.py\ndashboard_routes.py\ngoal_routes.py\njitai_routes.py\nkb_routes.py\nplan_routes.py\nposter_routes.py\npush_routes.py\nreflection_routes.py\nreport_routes.py\nsession_routes.py\nsocial_routes.py\ntwin_routes.py\nuser_routes.py\nyunshi_routes.py","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"b2c5b48e-0b35-41e6-8654-b2ad658de70d","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_011aXoSLmn3rhZ8XvdM7ZTpB","type":"tool_result","content":"=== bento_routes.py ===\nfrom __future__ import annotations\n\nimport re\nfrom datetime import datetime, time, timezone\nfrom typing import Any, Dict, Optional\nfrom zoneinfo import ZoneInfo\n\nfrom fastapi import APIRouter, Request\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field\n\nfrom api.deps import require_auth, require_csrf\nfrom services import bento_service\nfrom stores import fortune_db\n\n\nrouter = APIRouter(prefix=\"/api/bento\", tags=[\"bento\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n\ndef _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    return JSONResponse(\n        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n        status_code=status,\n    )\n\n\n\n=== kb_routes.py ===\nfrom __future__ import annotations\n\nfrom typing import Any, Dict, Optional\n\nfrom fastapi import APIRouter, Query, Request\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field\n\nfrom api.deps import require_auth\nfrom services import kb_service\n\n\nrouter = APIRouter(prefix=\"/api/kb\", tags=[\"kb\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n\ndef _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    return JSONResponse(\n        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n        status_code=status,\n    )\n\n\nclass SearchRequest(BaseModel):\n    query: str = Field(..., min_length=1)\n    top_k: int = Field(5, ge=1, le=20)\n\n\n=== goal_routes.py ===\n\"\"\"\nGoal API Routes - 目标设定模块 API\n\n基于 os_design_claude_mvp v1.md §3.5 设计：\n- POST /api/goal/create          创建目标\n- GET  /api/goal/list            获取用户目标列表\n- GET  /api/goal/{goal_id}       获取单个目标详情\n- PUT  /api/goal/{goal_id}       更新目标\n- POST /api/goal/{goal_id}/link  关联任务到目标\n- POST /api/goal/{goal_id}/checkpoint  记录检查点进展\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import Any, Dict, List, Optional\n\nfrom fastapi import APIRouter, Request\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field\n\nfrom api.deps import require_auth, require_csrf\nfrom services import goal_service\n\n\nrouter = APIRouter(prefix=\"/api/goal\", tags=[\"goal\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n\n=== reflection_routes.py ===\n\"\"\"\nReflection API Routes - 复盘模块 API\n\n基于 os_design_claude_mvp v1.md §4.5 设计：\n- POST /api/reflection/create    创建复盘\n- GET  /api/reflection/list      获取复盘列表\n- GET  /api/reflection/latest    获取最新复盘（按类型）\n- GET  /api/reflection/prompt    获取复盘引导问题（根据类型）\n- GET  /api/reflection/context   获取复盘上下文\n- GET  /api/reflection/should-prompt  检查是否应该提示复盘\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom datetime import date\nfrom typing import Any, Dict, List, Optional\n\nfrom fastapi import APIRouter, Request\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field\n\nfrom api.deps import require_auth, require_csrf\nfrom services import reflection_service\n\n\nrouter = APIRouter(prefix=\"/api/reflection\", tags=[\"reflection\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n=== yunshi_routes.py ===\n\"\"\"\n运势 API 路由\n\n提供今日运势、周运势、月运势、流年运势查询接口\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom datetime import date, datetime\nfrom typing import Any, Dict, Optional\n\nfrom fastapi import APIRouter, Request\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field\n\nfrom api.deps import require_auth\nfrom services.yunshi_service import yunshi_service, build_daily_yunshi_a2ui, build_annual_yunshi_a2ui\n\n\nrouter = APIRouter(prefix=\"/api/yunshi\", tags=[\"yunshi\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n\ndef _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    return JSONResponse(\n        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n        status_code=status,\n\n=== poster_routes.py ===\n\"\"\"\n海报生成API路由\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import Any, Dict, Optional\n\nfrom fastapi import APIRouter, Request\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field\n\nfrom api.deps import require_auth, require_csrf\nfrom services.poster_service import PosterRequest, PosterType, poster_service\n\n\nrouter = APIRouter(prefix=\"/api/poster\", tags=[\"poster\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n\ndef _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    return JSONResponse(\n        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n        status_code=status,\n    )","is_error":false}]},"uuid":"aa6d9bac-816d-4b82-b537-6ea7c4993fb7","timestamp":"2026-01-01T15:01:33.704Z","toolUseResult":{"stdout":"=== bento_routes.py ===\nfrom __future__ import annotations\n\nimport re\nfrom datetime import datetime, time, timezone\nfrom typing import Any, Dict, Optional\nfrom zoneinfo import ZoneInfo\n\nfrom fastapi import APIRouter, Request\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field\n\nfrom api.deps import require_auth, require_csrf\nfrom services import bento_service\nfrom stores import fortune_db\n\n\nrouter = APIRouter(prefix=\"/api/bento\", tags=[\"bento\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n\ndef _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    return JSONResponse(\n        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n        status_code=status,\n    )\n\n\n\n=== kb_routes.py ===\nfrom __future__ import annotations\n\nfrom typing import Any, Dict, Optional\n\nfrom fastapi import APIRouter, Query, Request\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field\n\nfrom api.deps import require_auth\nfrom services import kb_service\n\n\nrouter = APIRouter(prefix=\"/api/kb\", tags=[\"kb\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n\ndef _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    return JSONResponse(\n        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n        status_code=status,\n    )\n\n\nclass SearchRequest(BaseModel):\n    query: str = Field(..., min_length=1)\n    top_k: int = Field(5, ge=1, le=20)\n\n\n=== goal_routes.py ===\n\"\"\"\nGoal API Routes - 目标设定模块 API\n\n基于 os_design_claude_mvp v1.md §3.5 设计：\n- POST /api/goal/create          创建目标\n- GET  /api/goal/list            获取用户目标列表\n- GET  /api/goal/{goal_id}       获取单个目标详情\n- PUT  /api/goal/{goal_id}       更新目标\n- POST /api/goal/{goal_id}/link  关联任务到目标\n- POST /api/goal/{goal_id}/checkpoint  记录检查点进展\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import Any, Dict, List, Optional\n\nfrom fastapi import APIRouter, Request\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field\n\nfrom api.deps import require_auth, require_csrf\nfrom services import goal_service\n\n\nrouter = APIRouter(prefix=\"/api/goal\", tags=[\"goal\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n\n=== reflection_routes.py ===\n\"\"\"\nReflection API Routes - 复盘模块 API\n\n基于 os_design_claude_mvp v1.md §4.5 设计：\n- POST /api/reflection/create    创建复盘\n- GET  /api/reflection/list      获取复盘列表\n- GET  /api/reflection/latest    获取最新复盘（按类型）\n- GET  /api/reflection/prompt    获取复盘引导问题（根据类型）\n- GET  /api/reflection/context   获取复盘上下文\n- GET  /api/reflection/should-prompt  检查是否应该提示复盘\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom datetime import date\nfrom typing import Any, Dict, List, Optional\n\nfrom fastapi import APIRouter, Request\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field\n\nfrom api.deps import require_auth, require_csrf\nfrom services import reflection_service\n\n\nrouter = APIRouter(prefix=\"/api/reflection\", tags=[\"reflection\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n=== yunshi_routes.py ===\n\"\"\"\n运势 API 路由\n\n提供今日运势、周运势、月运势、流年运势查询接口\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom datetime import date, datetime\nfrom typing import Any, Dict, Optional\n\nfrom fastapi import APIRouter, Request\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field\n\nfrom api.deps import require_auth\nfrom services.yunshi_service import yunshi_service, build_daily_yunshi_a2ui, build_annual_yunshi_a2ui\n\n\nrouter = APIRouter(prefix=\"/api/yunshi\", tags=[\"yunshi\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n\ndef _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    return JSONResponse(\n        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n        status_code=status,\n\n=== poster_routes.py ===\n\"\"\"\n海报生成API路由\n\"\"\"\n\nfrom __future__ import annotations\n\nfrom typing import Any, Dict, Optional\n\nfrom fastapi import APIRouter, Request\nfrom fastapi.responses import JSONResponse\nfrom pydantic import BaseModel, Field\n\nfrom api.deps import require_auth, require_csrf\nfrom services.poster_service import PosterRequest, PosterType, poster_service\n\n\nrouter = APIRouter(prefix=\"/api/poster\", tags=[\"poster\"])\n\n\ndef _ok(data: Dict[str, Any] | None = None) -> JSONResponse:\n    return JSONResponse({\"ok\": True, \"data\": data or {}})\n\n\ndef _err(status: int, code: str, message: str, detail: Optional[Dict[str, Any]] = None) -> JSONResponse:\n    return JSONResponse(\n        {\"ok\": False, \"error\": {\"code\": code, \"message\": message, \"detail\": detail or {}}},\n        status_code=status,\n    )","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"aa6d9bac-816d-4b82-b537-6ea7c4993fb7","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01DCMCNVfQieS9mNiNUf49nH","type":"message","role":"assistant","content":[{"type":"text","text":"Perfect! Now let me create a comprehensive summary document. Let me check if there are any CSRF-related patterns and look at the services layer briefly:"}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":2154,"cache_read_input_tokens":69585,"cache_creation":{"ephemeral_5m_input_tokens":2154,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrohDyQvua7PqNk3yXW","type":"assistant","uuid":"8bb43a74-d5d5-44c7-b758-7ddb6cc60ac2","timestamp":"2026-01-01T15:01:37.018Z"}
{"parentUuid":"8bb43a74-d5d5-44c7-b758-7ddb6cc60ac2","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01DCMCNVfQieS9mNiNUf49nH","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01HnT7NbvBc6ejaCyjV9HrWX","name":"Bash","input":{"command":"grep -r \"require_csrf\" /home/aiscend/work/fortune_ai/api/ --include=\"*.py\" | wc -l","description":"Count CSRF protection usage"}}],"stop_reason":null,"stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":2154,"cache_read_input_tokens":69585,"cache_creation":{"ephemeral_5m_input_tokens":2154,"ephemeral_1h_input_tokens":0},"output_tokens":1,"service_tier":"standard"}},"requestId":"req_011CWgrohDyQvua7PqNk3yXW","type":"assistant","uuid":"aa809fa2-1c33-4268-98d2-89f0e33a840c","timestamp":"2026-01-01T15:01:37.682Z"}
{"parentUuid":"aa809fa2-1c33-4268-98d2-89f0e33a840c","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01DCMCNVfQieS9mNiNUf49nH","type":"message","role":"assistant","content":[{"type":"tool_use","id":"toolu_01GntvZT9M63gRjz6AFH2fQq","name":"Bash","input":{"command":"ls -la /home/aiscend/work/fortune_ai/api/static/ /home/aiscend/work/fortune_ai/api/templates/ 2>/dev/null | head -30","description":"Check static and template directories"}}],"stop_reason":"tool_use","stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":2154,"cache_read_input_tokens":69585,"cache_creation":{"ephemeral_5m_input_tokens":2154,"ephemeral_1h_input_tokens":0},"output_tokens":240,"service_tier":"standard"}},"requestId":"req_011CWgrohDyQvua7PqNk3yXW","type":"assistant","uuid":"9d7fa321-fda0-4c5b-ad0d-8f2f10548682","timestamp":"2026-01-01T15:01:38.192Z"}
{"parentUuid":"9d7fa321-fda0-4c5b-ad0d-8f2f10548682","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01HnT7NbvBc6ejaCyjV9HrWX","type":"tool_result","content":"53","is_error":false}]},"uuid":"466ba24d-abd1-42a3-8bc4-bcb38d33a2eb","timestamp":"2026-01-01T15:01:38.504Z","toolUseResult":{"stdout":"53","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"466ba24d-abd1-42a3-8bc4-bcb38d33a2eb","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","type":"user","message":{"role":"user","content":[{"tool_use_id":"toolu_01GntvZT9M63gRjz6AFH2fQq","type":"tool_result","content":"/home/aiscend/work/fortune_ai/api/static/:\n总计 196\ndrwxrwxr-x 2 aiscend aiscend  4096  1月  1 21:17 .\ndrwxrwxr-x 5 aiscend aiscend  4096  1月  1 17:03 ..\n-rw-rw-r-- 1 aiscend aiscend 30646  1月  1 21:17 auth.js\n-rw-rw-r-- 1 aiscend aiscend 21510 12月 29 16:39 main.js\n-rw-rw-r-- 1 aiscend aiscend  1714 12月 18 13:55 style.css\n-rw-rw-r-- 1 aiscend aiscend  4489 12月 29 16:39 tieban.css\n-rw-rw-r-- 1 aiscend aiscend 12148 12月 29 16:39 tieban.js\n-rw-rw-r-- 1 aiscend aiscend 32644 12月 30 21:59 ui.css\n-rw-rw-r-- 1 aiscend aiscend 76571 12月 30 22:54 ui.js\n\n/home/aiscend/work/fortune_ai/api/templates/:\n总计 148\ndrwxrwxr-x 2 aiscend aiscend  4096  1月  1 21:16 .\ndrwxrwxr-x 5 aiscend aiscend  4096  1月  1 17:03 ..\n-rw-rw-r-- 1 aiscend aiscend 18156 12月 18 13:55 a2ui.html\n-rw-rw-r-- 1 aiscend aiscend 43050  1月  1 21:16 auth.html\n-rw-rw-r-- 1 aiscend aiscend 20034  1月  1 15:03 bazi2.html\n-rw-rw-r-- 1 aiscend aiscend  6687 12月 25 18:56 bazi.html\n-rw-rw-r-- 1 aiscend aiscend  5632 12月 18 18:09 index.html\n-rw-rw-r-- 1 aiscend aiscend  2047 12月 29 17:00 login.html\n-rw-rw-r-- 1 aiscend aiscend    77 12月 22 20:48 main.html\n-rw-rw-r-- 1 aiscend aiscend   517 12月 17 12:16 redirect.html\n-rw-rw-r-- 1 aiscend aiscend 23361 12月 30 23:44 register.html\n-rw-rw-r-- 1 aiscend aiscend  3736 12月 29 16:39 tieban.html","is_error":false}]},"uuid":"e0616cac-576d-40ea-ad6f-b078e1029dcb","timestamp":"2026-01-01T15:01:38.527Z","toolUseResult":{"stdout":"/home/aiscend/work/fortune_ai/api/static/:\n总计 196\ndrwxrwxr-x 2 aiscend aiscend  4096  1月  1 21:17 .\ndrwxrwxr-x 5 aiscend aiscend  4096  1月  1 17:03 ..\n-rw-rw-r-- 1 aiscend aiscend 30646  1月  1 21:17 auth.js\n-rw-rw-r-- 1 aiscend aiscend 21510 12月 29 16:39 main.js\n-rw-rw-r-- 1 aiscend aiscend  1714 12月 18 13:55 style.css\n-rw-rw-r-- 1 aiscend aiscend  4489 12月 29 16:39 tieban.css\n-rw-rw-r-- 1 aiscend aiscend 12148 12月 29 16:39 tieban.js\n-rw-rw-r-- 1 aiscend aiscend 32644 12月 30 21:59 ui.css\n-rw-rw-r-- 1 aiscend aiscend 76571 12月 30 22:54 ui.js\n\n/home/aiscend/work/fortune_ai/api/templates/:\n总计 148\ndrwxrwxr-x 2 aiscend aiscend  4096  1月  1 21:16 .\ndrwxrwxr-x 5 aiscend aiscend  4096  1月  1 17:03 ..\n-rw-rw-r-- 1 aiscend aiscend 18156 12月 18 13:55 a2ui.html\n-rw-rw-r-- 1 aiscend aiscend 43050  1月  1 21:16 auth.html\n-rw-rw-r-- 1 aiscend aiscend 20034  1月  1 15:03 bazi2.html\n-rw-rw-r-- 1 aiscend aiscend  6687 12月 25 18:56 bazi.html\n-rw-rw-r-- 1 aiscend aiscend  5632 12月 18 18:09 index.html\n-rw-rw-r-- 1 aiscend aiscend  2047 12月 29 17:00 login.html\n-rw-rw-r-- 1 aiscend aiscend    77 12月 22 20:48 main.html\n-rw-rw-r-- 1 aiscend aiscend   517 12月 17 12:16 redirect.html\n-rw-rw-r-- 1 aiscend aiscend 23361 12月 30 23:44 register.html\n-rw-rw-r-- 1 aiscend aiscend  3736 12月 29 16:39 tieban.html","stderr":"","interrupted":false,"isImage":false}}
{"parentUuid":"e0616cac-576d-40ea-ad6f-b078e1029dcb","isSidechain":true,"userType":"external","cwd":"/home/aiscend/work/fortune_ai","sessionId":"57d1b191-4eb4-429c-96ac-40f334a1945a","version":"2.0.76","gitBranch":"main","agentId":"a559d1f","slug":"serene-brewing-frog","message":{"model":"claude-haiku-4-5-20251001","id":"msg_01JBqetKMWEhUEkq91tJJVnH","type":"message","role":"assistant","content":[{"type":"text","text":"Perfect! Now I have enough information to provide a comprehensive analysis. Let me create the structured summary:\n\n## FASTAPI BACKEND STRUCTURE ANALYSIS\n\n### 1. MAIN ENTRY POINT & ROUTER REGISTRATION\n\n**File:** `/home/aiscend/work/fortune_ai/api/main.py`\n\n**Architecture:**\n- Single FastAPI app instance with 20 router registrations\n- CORS middleware configured for port 8231 frontend access\n- GZip compression enabled (min 1KB)\n- Static file caching (1 year immutable)\n- Jinja2 templates for legacy pages\n\n**Middleware Stack:**\n```\nGZipMiddleware (minimum_size=1024)\n  ↓\nCORSMiddleware (allow_origins: 106.37.170.238:8231, localhost:8231, 127.0.0.1:8231)\n  ↓\nCustom _static_cache_mw (Cache-Control headers for /static/*)\n```\n\n**Router Registration Order (lines 114-133):**\n1. `auth_router` (/api/auth)\n2. `user_router` (/api/user)\n3. `session_router` (/api/session)\n4. `chat_router` (/api/chat) - **PRIMARY REFACTORING TARGET**\n5. `bento_router` (/api/bento)\n6. `dashboard_router` (/api/dashboard)\n7. `bazi_router` (/api/bazi)\n8. `kb_router` (/api/kb)\n9. `plan_router` (/api/plan)\n10. `report_router` (/api/report)\n11. `push_router` (/api/push)\n12. `twin_router` (/api/twin)\n13. `agent_tool_router` (/api/agent-tool)\n14. `social_router` (/api/social)\n15. `jitai_router` (/api/jitai)\n16. `currency_router` (/api/currency)\n17. `goal_router` (/api/goal)\n18. `reflection_router` (/api/reflection)\n19. `yunshi_router` (/api/yunshi)\n20. `poster_router` (/api/poster)\n\n---\n\n### 2. ALL ROUTE FILES & ENDPOINTS\n\n| File | Prefix | Key Endpoints | Auth Required | CSRF Required | Purpose |\n|------|--------|---------------|---------------|---------------|---------|\n| `auth_routes.py` | /api/auth | POST /register, /login, /logout, /logout-all, /preview, /validation-points, GET /me, PUT /password, DELETE /account, GET /sessions | Mixed | register/login=No, others=Yes | User authentication & session mgmt |\n| `user_routes.py` | /api/user | GET /profile, PUT /profile, GET /preferences, PUT /preferences, POST /preferences/chat-backend, POST /preferences/persona-style | Yes | Yes | User profile/preferences |\n| `session_routes.py` | /api/session | POST /new, GET /list, GET /{session_id} | Yes | Yes | Chat session management |\n| `chat_routes.py` | /api/chat | POST /send, GET /stream, POST /ask | Yes | Yes | **Core chat logic - Agent coaching responses** |\n| `bazi_routes.py` | /api/bazi | GET /facts | Yes | No | Bazi snapshot retrieval |\n| `bento_routes.py` | /api/bento | Multiple GET/POST endpoints | Yes | Mixed | Bento box (task/module) management |\n| `dashboard_routes.py` | /api/dashboard | GET /overview, /status, /trends, /state-score | Yes | No | Zone B dashboard (new UI) |\n| `kb_routes.py` | /api/kb | GET /search, POST /index | Yes | Mixed | Knowledge base search |\n| `goal_routes.py` | /api/goal | POST /create, GET /list, GET /{goal_id}, PUT /{goal_id}, POST /{goal_id}/link, POST /{goal_id}/checkpoint | Yes | Yes | Goal setting & tracking |\n| `reflection_routes.py` | /api/reflection | POST /create, GET /list, /latest, /prompt, /context, /should-prompt | Yes | Yes | Reflection/review prompts |\n| `yunshi_routes.py` | /api/yunshi | GET /daily, /annual | Yes | No | Daily/annual fortune predictions |\n| `poster_routes.py` | /api/poster | POST /generate | Yes | Yes | Poster generation |\n| `push_routes.py` | /api/push | Notification management | Yes | Yes | Push notification config |\n| `report_routes.py` | /api/report | Report generation & retrieval | Yes | Mixed | Report APIs |\n| `social_routes.py` | /api/social | Social features | Yes | Yes | Social interaction |\n| `twin_routes.py` | /api/twin | Twin data APIs | Yes | Mixed | Twin/pair analysis |\n| `plan_routes.py` | /api/plan | Plan management | Yes | Yes | Planning APIs |\n| `jitai_routes.py` | /api/jitai | 吉日 (lucky day) prediction | Yes | No | Auspicious date finder |\n| `currency_routes.py` | /api/currency | Currency conversion | Yes | No | Currency utilities |\n| `agent_tool.py` | /api/agent-tool | Agent-specific tools | Yes | Mixed | Agent service utilities |\n\n---\n\n### 3. DEPENDENCY INJECTION PATTERNS (deps.py)\n\n**File:** `/home/aiscend/work/fortune_ai/api/deps.py`\n\n**Core Functions:**\n```python\nget_client_ip(request: Request) -> str\n  Extracts client IP from request.client.host\n\nget_user_agent(request: Request) -> str\n  Extracts user agent (first 500 chars)\n\nget_current_auth(request: Request) -> Optional[Dict[str, Any]]\n  Retrieves auth from \"fortune_session\" cookie via auth_service.get_user_by_session_token()\n\nrequire_auth(request: Request) -> Dict[str, Any]\n  Enforces authentication, raises HTTPException(401) if missing\n\nrequire_csrf(request: Request, auth: Dict) -> None\n  Validates X-CSRF-Token header against auth.csrf_token_hash\n  Uses sha256_hex for token validation\n  Raises HTTPException(403) if missing or invalid\n```\n\n**Session Token Format:**\n- Cookie name: `fortune_session` (HttpOnly, SameSite=Lax)\n- CSRF token cookie: `fortune_csrf` (not HttpOnly, readable by JS)\n- Both set with max_age=30 days, path=/\n- Secure flag depends on `FORTUNE_COOKIE_SECURE` env var\n\n---\n\n### 4. AUTHENTICATION & SESSION HANDLING\n\n**Auth Service Integration:**\n```python\nauth_service.register_user()\n  → Creates user with hashed password, location, bazi facts snapshot\n\nauth_service.authenticate(email, password)\n  → Validates credentials, returns user_id\n\nauth_service.create_session(user_id, ip, user_agent)\n  → Returns SessionTokens { session_token, csrf_token, csrf_token_hash }\n\nauth_service.get_user_by_session_token(session_token)\n  → Returns auth dict { user_id, email, name, persona_style, session_id, csrf_token_hash }\n\nauth_service.revoke_session(session_id)\n  → Single session revocation\n\nauth_service.revoke_all_sessions(user_id)\n  → All sessions revocation (for password change)\n```\n\n**Current Flow:**\n1. User registers/logs in at POST /api/auth/register or /api/auth/login\n2. Response includes two cookies: `fortune_session` + `fortune_csrf`\n3. Frontend stores CSRF token from cookie in memory\n4. For protected endpoints: `X-CSRF-Token` header + cookies required\n5. Backend validates both session token (from DB) and CSRF hash\n\n**Password Management:**\n- Hash algorithm: SHA256 (via services/security.py)\n- Password change revokes ALL sessions\n- Account deletion also revokes all sessions\n\n---\n\n### 5. CHAT_ROUTES.PY - CORE REFACTORING TARGET\n\n**File:** `/home/aiscend/work/fortune_ai/api/chat_routes.py` (1,106 lines)\n\n**Two Endpoints:**\n\n#### A. POST /api/chat/send (Synchronous)\n```python\nRequest:\n  - session_id: Optional[str] (UUID format)\n  - text: str (min_length=1)\n\nResponse Structure:\n  {\n    \"ok\": bool,\n    \"data\": {\n      \"session_id\": str,\n      \"assistant_message\": {\n        \"role\": \"assistant\",\n        \"a2ui\": { ... }  # A2UI JSON format\n      },\n      \"suggested_tasks\": [ { \"task_id\", \"title\" } ],\n      \"backend\": str  # \"fastapi\" | \"agent_service\" | \"yunshi\" | \"anti_dependency\"\n    }\n  }\n```\n\n#### B. GET /api/chat/stream (Server-Sent Events)\n```python\nQuery Params:\n  - message: str (user message)\n  - session_id: Optional[str] (UUID)\n\nResponse Format (SSE):\n  data: {\"type\": \"meta\", \"session_id\": str, \"backend\": str}\n  data: {\"type\": \"delta\", \"delta\": str}  (0..n times)\n  data: {\"type\": \"final\", \"data\": { ... full response ... }}\n  data: [DONE]\n```\n\n**Internal Flow:**\n\n1. **Auth Check** (require_auth + require_csrf)\n2. **Session Management:**\n   - Create new if not provided\n   - Validate existing session UUID\n3. **User Input Validation:**\n   - Store message in DB via chat_service.append_message()\n   - Set session title if empty\n4. **Context Loading:**\n   - User profile, preferences, bazi facts snapshot\n   - soul_os.get_full_context_for_chat() → complete context\n\n5. **Intent Detection (Priority Order):**\n   - Anti-dependency intervention check (reflection on past failures)\n   - Yunshi (运势) intent detection (daily/annual fortune query)\n   \n6. **Backend Selection:**\n   - Check user preference: `chat_backend` from fortune_user_preferences\n   - Fallback to `default_chat_backend()` if not set\n   - Supports: \"fastapi\" (direct LLM) | \"agent_service\" (remote)\n\n7. **LLM Call (FastAPI):**\n   - System prompt from soul_os or template\n   - Includes: persona_style, user_context_json, facts_json, evidence_json\n   - Message history: last 10 turns from DB\n   - Model: GLM-4.7 (or FORTUNE_AI_GLM_MODEL env)\n\n8. **Response Post-Processing:**\n   - Extract A2UI from LLM output (with fallback wrapper)\n   - Extract prescriptions from markdown\n   - Insert suggested tasks (3 max) into DB\n   - Ensure action_buttons component exists\n\n9. **Audit Logging:**\n   - Write to fortune_agent_run table\n   - Records: input_data, output_data, tool_calls, usage, latency_ms, error\n\n**Key Functions:**\n- `_load_user_context()` → profile, prefs, snapshot\n- `_a2ui_from_text()` → Parse A2UI JSON or fallback\n- `_normalize_a2ui()` → Standardize A2UI structure\n- `_extract_prescriptions()` → Parse numbered/bulleted items\n- `_insert_suggested_tasks()` → Create tasks from prescriptions\n- `_ensure_action_buttons()` → Guarantee action component exists\n- `_write_agent_run_log()` → Audit trail\n- `detect_yunshi_intent()` → Pattern match on keywords\n- `handle_yunshi_intent()` → Return pre-computed yunshi response\n\n**System Prompts:**\n- `SYSTEM_PROMPT_TEMPLATE` → For sync (JSON A2UI output)\n- `SYSTEM_PROMPT_STREAM_TEMPLATE` → For streaming (Markdown only)\n\nBoth enforce:\n1. Coaching persona (積極心理学 focus)\n2. Must cite facts (禁止自行计算八字)\n3. Action-oriented (処方 = if_then conditions)\n4. Anti-manipulation (禁止恐吓/羞辱/宿命论)\n\n---\n\n### 6. AUTHENTICATION MIDDLEWARE SUMMARY\n\n**Session Cookie Validation:**\n```\nRequest → get_current_auth(request)\n  1. Read \"fortune_session\" cookie\n  2. Call auth_service.get_user_by_session_token(token)\n  3. Returns auth dict or None\n  4. raise HTTPException(401) if None\n```\n\n**CSRF Validation:**\n```\nrequire_csrf(request, auth) called on protected POST/PUT/DELETE\n  1. Extract X-CSRF-Token header\n  2. SHA256 hash the token\n  3. Compare to auth.csrf_token_hash from DB\n  4. raise HTTPException(403) if mismatch\n```\n\n**Endpoints WITHOUT require_csrf:**\n- POST /api/auth/register (open endpoint)\n- POST /api/auth/login (open endpoint)\n- GET /api/auth/me (read-only)\n- GET /api/auth/sessions (read-only)\n- GET /api/auth/preview (public)\n- GET /api/auth/validation-points (public)\n- GET /api/bazi/facts (read-only)\n- GET /api/dashboard/* (read-only)\n- GET /api/yunshi/* (read-only)\n- GET /api/jitai/* (read-only)\n- GET /api/currency/* (read-only)\n- GET /api/chat/stream (streaming endpoint - uses old token validation)\n\n**Endpoints WITH require_csrf:**\n- All POST/PUT/DELETE endpoints (53 uses across all routes)\n- Particularly: auth, user preferences, chat send, goal/reflection creation, poster gen\n\n---\n\n### 7. REFACTORING RECOMMENDATIONS: FASTAPI vs NEXT.JS\n\n**CANDIDATES TO STAY IN FASTAPI (Backend-only, no UI):**\n1. **Auth Core** (/api/auth/register, /login) - Must stay (session creation)\n2. **Chat API** (/api/chat/send, /stream) - **CANDIDATE FOR NEXT.JS INTEGRATION**\n3. **Bazi/Facts** (/api/bazi/facts) - Can stay (heavy computation)\n4. **Yunshi** (/api/yunshi/*) - Can stay (computation)\n5. **KB Search** (/api/kb/search) - Can stay (backend compute)\n6. **Goal/Reflection** (/api/goal/*, /reflection/*) - Can stay (DB-heavy)\n7. **Push/Notifications** (/api/push/*) - Can stay (service layer)\n\n**CANDIDATES TO MIGRATE TO NEXT.JS (Frontend state + API proxy):**\n1. **Session Management** (/api/session/*) - Wrapper over chat service\n2. **User Preferences** (/api/user/preferences) - Read-mostly, UI-driven\n3. **Dashboard** (/api/dashboard/*) - Pure data aggregation\n4. **Bento/Modules** (/api/bento/*) - UI state container\n5. **Poster Generation UI** (/api/poster/generate) - Can move form handling\n6. **Plan/Twin** (/api/plan/*, /api/twin/*) - Low auth criticality\n\n**CORE COMPLEXITY IN CHAT_ROUTES:**\n- **Dependencies:** soul_os, glm_client, agent_service_client, yunshi_service, bazi_facts, kb_service\n- **Multi-backend support:** fastapi vs agent_service with fallback\n- **State management:** session history, facts snapshot, user context\n- **Streaming:** SSE protocol with delta events\n- **Intent detection:** Yunshi keywords, anti-dependency checks\n\n**Migration Strategy:**\n- Keep `/api/auth/*` in FastAPI (session token generation)\n- Keep `/api/chat/send` + `/api/chat/stream` in FastAPI (complexity)\n- Create Next.js middleware layer for /api/session, /api/user/preferences\n- Use FastAPI as pure backend; Next.js as API orchestration + rendering\n\n---\n\n### 8. KEY FINDINGS SUMMARY\n\n| Aspect | Current State | Notes |\n|--------|---------------|-------|\n| **Entry Point** | `/api/main.py` | Single app, 20 routers |\n| **CORS Config** | 3 origins (CN IP + localhost) | Hardcoded, no env var |\n| **Auth Pattern** | Cookie (fortune_session) + CSRF token | Stateful sessions in DB |\n| **CSRF Protection** | SHA256 token hashing | Applied to 53 mutation endpoints |\n| **Session Duration** | 30 days | No refresh token, hard expiry |\n| **Chat Backends** | FastAPI (LLM) + Agent Service (fallback) | Streaming & sync modes |\n| **Audit Logging** | fortune_agent_run table | Every chat request logged |\n| **Intent Detection** | Regex pattern matching (Yunshi + anti-dep) | In-memory, no ML |\n| **Static Files** | 1-year immutable cache | Content-addressed by manual bumps |\n| **Template Rendering** | Jinja2 for legacy pages | Legacy redirects to /new |\n| **Error Handling** | Custom _ok/_err JSON wrappers | Consistent across routes |\n\n---\n\n### 9. FILE LOCATIONS - ABSOLUTE PATHS\n\n**Core Configuration:**\n- `/home/aiscend/work/fortune_ai/api/main.py` (1,247 lines)\n- `/home/aiscend/work/fortune_ai/api/deps.py` (43 lines)\n\n**Route Files:**\n- `/home/aiscend/work/fortune_ai/api/auth_routes.py` (509 lines)\n- `/home/aiscend/work/fortune_ai/api/user_routes.py` (~200 lines)\n- `/home/aiscend/work/fortune_ai/api/session_routes.py` (77 lines)\n- `/home/aiscend/work/fortune_ai/api/chat_routes.py` (1,106 lines) **PRIMARY TARGET**\n- `/home/aiscend/work/fortune_ai/api/bazi_routes.py` (~40 lines)\n- `/home/aiscend/work/fortune_ai/api/bento_routes.py` (~300 lines)\n- `/home/aiscend/work/fortune_ai/api/dashboard_routes.py` (~400 lines)\n- `/home/aiscend/work/fortune_ai/api/kb_routes.py` (~100 lines)\n- `/home/aiscend/work/fortune_ai/api/goal_routes.py` (~350 lines)\n- `/home/aiscend/work/fortune_ai/api/reflection_routes.py` (~300 lines)\n- `/home/aiscend/work/fortune_ai/api/yunshi_routes.py` (~200 lines)\n- `/home/aiscend/work/fortune_ai/api/poster_routes.py` (~150 lines)\n- Plus: `push_routes.py`, `report_routes.py`, `social_routes.py`, `twin_routes.py`, `plan_routes.py`, `jitai_routes.py`, `currency_routes.py`, `agent_tool.py`\n\n**Static Assets:**\n- `/home/aiscend/work/fortune_ai/api/static/ui.js` (76 KB)\n- `/home/aiscend/work/fortune_ai/api/static/ui.css` (32 KB)\n- `/home/aiscend/work/fortune_ai/api/static/auth.js` (30 KB)\n- `/home/aiscend/work/fortune_ai/api/static/tieban.js`, `tieban.css`, `main.js`, `style.css`\n\n**Templates:**\n- `/home/aiscend/work/fortune_ai/api/templates/auth.html` (43 KB)\n- `/home/aiscend/work/fortune_ai/api/templates/register.html` (23 KB)\n- `/home/aiscend/work/fortune_ai/api/templates/bazi2.html` (20 KB)\n- Plus: `a2ui.html`, `tieban.html`, `bazi.html`, `index.html`, `login.html`, `main.html`, `redirect.html`\n\n---\n\nThis completes the structural analysis. The FastAPI backend is well-organized with clear separation of concerns. The chat_routes.py is the most complex component with multi-backend orchestration, streaming, and sophisticated intent detection. Authentication is solid with CSRF protection and audit logging throughout."}],"stop_reason":"end_turn","stop_sequence":null,"usage":{"input_tokens":7,"cache_creation_input_tokens":1467,"cache_read_input_tokens":71739,"cache_creation":{"ephemeral_5m_input_tokens":1467,"ephemeral_1h_input_tokens":0},"output_tokens":5153,"service_tier":"standard"}},"requestId":"req_011CWgrp3sCYa5G4TUXJwq3P","type":"assistant","uuid":"2a0a9bc6-b86d-4223-9812-f76220fd8e44","timestamp":"2026-01-01T15:02:24.675Z"}
