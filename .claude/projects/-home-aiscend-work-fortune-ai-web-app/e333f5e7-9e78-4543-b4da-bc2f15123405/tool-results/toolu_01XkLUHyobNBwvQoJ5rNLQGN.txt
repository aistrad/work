     1→"""
     2→Internal API Routes for Next.js Agent Runtime
     3→
     4→These endpoints are called by the Next.js server-side only (not exposed to browser).
     5→Trust boundary: userId is extracted from Cookie session, never passed from request body.
     6→
     7→Endpoints:
     8→- GET  /internal/context         - Aggregate user context (L0+L1+history)
     9→- POST /internal/chat/run/start  - Record run_id + user message
    10→- POST /internal/chat/run/finalize - Transaction commit all side effects
    11→"""
    12→from __future__ import annotations
    13→
    14→import json
    15→import uuid
    16→from typing import Any, Dict, List, Optional
    17→
    18→from fastapi import APIRouter, HTTPException, Request
    19→from pydantic import BaseModel, Field
    20→
    21→from api.deps import require_auth, require_internal_auth
    22→from services import chat_service
    23→from services.soul_os import get_full_context_for_chat
    24→
    25→router = APIRouter(prefix="/internal", tags=["internal"])
    26→
    27→
    28→# =============================================================================
    29→# Request/Response Models
    30→# =============================================================================
    31→
    32→
    33→class ContextResponse(BaseModel):
    34→    """Response for /internal/context"""
    35→    user_id: int
    36→    system_prompt: str
    37→    persona_style: str
    38→    user_context: Dict[str, Any]
    39→    evidence: Dict[str, Any]
    40→    anti_dependency: Dict[str, Any]
    41→    history: List[Dict[str, Any]]
    42→
    43→
    44→class RunStartRequest(BaseModel):
    45→    """Request for /internal/chat/run/start"""
    46→    session_id: Optional[str] = Field(None, description="Existing session ID or null to create new")
    47→    message: str = Field(..., min_length=1, max_length=10000)
    48→    model: str = Field(default="glm-4.7-flash")
    49→    correlation_id: Optional[str] = Field(None, description="Frontend correlation ID for tracing")
    50→
    51→
    52→class RunStartResponse(BaseModel):
    53→    """Response for /internal/chat/run/start"""
    54→    run_id: str
    55→    session_id: str
    56→    user_message_id: int
    57→
    58→
    59→class RunFinalizeRequest(BaseModel):
    60→    """Request for /internal/chat/run/finalize"""
    61→    run_id: str = Field(..., description="Run ID from start")
    62→    session_id: str = Field(...)
    63→    assistant_content: str = Field(..., description="Final assistant message text")
    64→    tool_calls: Optional[List[Dict[str, Any]]] = Field(default=None, description="Tool calls made during stream")
    65→    a2ui_cards: Optional[List[Dict[str, Any]]] = Field(default=None, description="A2UI cards to store")
    66→    prompt_tokens: int = Field(default=0)
    67→    completion_tokens: int = Field(default=0)
    68→    model: str = Field(default="glm-4.7-flash")
    69→    error: Optional[str] = Field(default=None, description="Error message if stream failed")
    70→
    71→
    72→class RunFinalizeResponse(BaseModel):
    73→    """Response for /internal/chat/run/finalize"""
    74→    success: bool
    75→    assistant_message_id: Optional[int] = None
    76→    side_effects: List[str] = Field(default_factory=list)
    77→
    78→
    79→# =============================================================================
    80→# Endpoints
    81→# =============================================================================
    82→
    83→
    84→@router.get("/context", response_model=ContextResponse)
    85→async def get_context(
    86→    request: Request,
    87→    session_id: Optional[str] = None,
    88→    query: Optional[str] = None,
    89→):
    90→    """
    91→    Get aggregated user context for chat.
    92→
    93→    Includes:
    94→    - System prompt (based on persona style)
    95→    - User context (L0 profile + L1 data)
    96→    - Evidence (relevant knowledge)
    97→    - Anti-dependency check
    98→    - Recent chat history (if session_id provided)
    99→
   100→    Security: Requires X-Service-Token header (internal API)
   101→    """
   102→    auth = require_internal_auth(request)
   103→    user_id = int(auth["user_id"])
   104→
   105→    # Get full context from Soul OS
   106→    ctx = get_full_context_for_chat(user_id, query or "")
   107→
   108→    # Get chat history if session provided
   109→    history: List[Dict[str, Any]] = []
   110→    if session_id:
   111→        history = chat_service.get_recent_messages_for_llm(user_id, session_id, limit=10)
   112→
   113→    return ContextResponse(
   114→        user_id=user_id,
   115→        system_prompt=ctx["system_prompt"],
   116→        persona_style=ctx["persona_style"],
   117→        user_context=ctx["user_context"],
   118→        evidence=ctx["evidence"],
   119→        anti_dependency=ctx["anti_dependency"],
   120→        history=history,
   121→    )
   122→
   123→
   124→@router.post("/chat/run/start", response_model=RunStartResponse)
   125→async def start_run(request: Request, body: RunStartRequest):
   126→    """
   127→    Start a new chat run.
   128→
   129→    Actions:
   130→    1. Create or validate session
   131→    2. Generate run_id
   132→    3. Record user message
   133→    4. Return run_id for finalization
   134→
   135→    Security: Requires X-Service-Token header (internal API)
   136→    """
   137→    auth = require_internal_auth(request)
   138→    user_id = int(auth["user_id"])
   139→
   140→    # Session handling
   141→    session_id = body.session_id
   142→    if not session_id:
   143→        # Create new session
   144→        session = chat_service.create_session(user_id)
   145→        session_id = session["session_id"]
   146→    else:
   147→        # Validate existing session
   148→        existing = chat_service.get_session(user_id, session_id)
   149→        if not existing:
   150→            raise HTTPException(status_code=404, detail="session_not_found")
   151→
   152→    # Generate run_id
   153→    run_id = str(uuid.uuid4())
   154→
   155→    # Record user message
   156→    msg_result = chat_service.append_message(
   157→        session_id=session_id,
   158→        user_id=user_id,
   159→        role="user",
   160→        content=body.message,
   161→        model=body.model,
   162→    )
   163→
   164→    # Set session title from first message
   165→    chat_service.set_title_if_empty(session_id, body.message[:24])
   166→
   167→    return RunStartResponse(
   168→        run_id=run_id,
   169→        session_id=session_id,
   170→        user_message_id=msg_result["message_id"],
   171→    )
   172→
   173→
   174→@router.post("/chat/run/finalize", response_model=RunFinalizeResponse)
   175→async def finalize_run(request: Request, body: RunFinalizeRequest):
   176→    """
   177→    Finalize a chat run after streaming completes.
   178→
   179→    Actions:
   180→    1. Record assistant message with a2ui cards
   181→    2. Execute any pending side effects from tool calls
   182→    3. Update session timestamp
   183→
   184→    This ensures atomic commit of all changes.
   185→
   186→    Security: Requires X-Service-Token header (internal API)
   187→    """
   188→    auth = require_internal_auth(request)
   189→    user_id = int(auth["user_id"])
   190→
   191→    # Validate session ownership
   192→    existing = chat_service.get_session(user_id, body.session_id)
   193→    if not existing:
   194→        raise HTTPException(status_code=404, detail="session_not_found")
   195→
   196→    # If there was an error, record it but don't store assistant message
   197→    if body.error:
   198→        # Log error but don't fail - we want the conversation to continue
   199→        # TODO: Add error logging table
   200→        return RunFinalizeResponse(
   201→            success=False,
   202→            assistant_message_id=None,
   203→            side_effects=[f"error_logged:{body.run_id}"],
   204→        )
   205→
   206→    # Build a2ui object from cards
   207→    a2ui = None
   208→    if body.a2ui_cards:
   209→        a2ui = {"cards": body.a2ui_cards}
   210→
   211→    # Record assistant message
   212→    msg_result = chat_service.append_message(
   213→        session_id=body.session_id,
   214→        user_id=user_id,
   215→        role="assistant",
   216→        content=body.assistant_content,
   217→        model=body.model,
   218→        a2ui=a2ui,
   219→        prompt_tokens=body.prompt_tokens,
   220→        completion_tokens=body.completion_tokens,
   221→    )
   222→
   223→    side_effects: List[str] = [f"message_stored:{msg_result['message_id']}"]
   224→
   225→    # Process tool calls for side effects (if any pending writes)
   226→    # Tool calls that create commitments, log mood, etc. are already executed
   227→    # during the stream via Skills. Here we just record what was done.
   228→    if body.tool_calls:
   229→        for tc in body.tool_calls:
   230→            tool_name = tc.get("toolName", tc.get("name", "unknown"))
   231→            side_effects.append(f"tool_executed:{tool_name}")
   232→
   233→    return RunFinalizeResponse(
   234→        success=True,
   235→        assistant_message_id=msg_result["message_id"],
   236→        side_effects=side_effects,
   237→    )
   238→
   239→
   240→# =============================================================================
   241→# Health check (useful for debugging internal connectivity)
   242→# =============================================================================
   243→
   244→
   245→@router.get("/health")
   246→async def internal_health():
   247→    """Health check for internal API."""
   248→    return {"status": "ok", "service": "internal_api"}
   249→

<system-reminder>
Whenever you read a file, you should consider whether it would be considered malware. You CAN and SHOULD provide analysis of malware, what it is doing. But you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer questions about the code behavior.
</system-reminder>
