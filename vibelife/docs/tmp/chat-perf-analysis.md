# Chat 端到端性能分析

## 时序图

```
┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐    ┌──────────┐
│  浏览器   │    │ Next.js  │    │ FastAPI  │    │ CoreAgent│    │ LLM API  │
│          │    │  :8232   │    │  :8100   │    │          │    │ DeepSeek │
└────┬─────┘    └────┬─────┘    └────┬─────┘    └────┬─────┘    └────┬─────┘
     │               │               │               │               │
     │ 用户输入消息   │               │               │               │
     │──────────────>│               │               │               │
     │               │               │               │               │
     │               │ POST /api/v1/chat/v5/stream   │               │
     │               │──────────────>│               │               │
     │               │               │               │               │
     │               │               │ [T1] 认证检查  │               │
     │               │               │──────┐        │               │
     │               │               │<─────┘ ~10ms  │               │
     │               │               │               │               │
     │               │               │ [T2] 配额检查  │               │
     │               │               │──────┐        │               │
     │               │               │<─────┘ ~20ms  │               │
     │               │               │               │               │
     │               │               │ [T3] 获取用户上下文            │
     │               │               │ (Profile + SkillData)         │
     │               │               │──────┐        │               │
     │               │               │<─────┘ ~50-200ms (首次)       │
     │               │               │        ~5ms (缓存命中)         │
     │               │               │               │               │
     │               │               │ [T4] 确保会话存在              │
     │               │               │──────┐        │               │
     │               │               │<─────┘ ~10ms  │               │
     │               │               │               │               │
     │               │               │ [T5] 保存用户消息              │
     │               │               │──────┐        │               │
     │               │               │<─────┘ ~10ms  │               │
     │               │               │               │               │
     │               │               │ 创建 Agent    │               │
     │               │               │──────────────>│               │
     │               │               │               │               │
     │               │               │               │ [T6] 构建 System Prompt
     │               │               │               │ - 加载 Skill 配置
     │               │               │               │ - 知识检索 (RAG)
     │               │               │               │ - 案例匹配
     │               │               │──────┐        │               │
     │               │               │<─────┘ ~200-500ms             │
     │               │               │               │               │
     │               │               │               │ [T7] LLM 调用 #1
     │               │               │               │ (Skill 路由决策)
     │               │               │               │──────────────>│
     │               │               │               │               │
     │               │               │               │     TTFT      │
     │               │               │               │<─ 2-6秒 ─────│
     │               │               │               │               │
     │               │               │               │  流式输出     │
     │               │               │               │<─ 1-3秒 ─────│
     │               │               │               │               │
     │               │               │               │ [T8] 工具执行  │
     │               │               │               │──────┐        │
     │               │               │               │<─────┘ ~10-50ms
     │               │               │               │               │
     │               │               │               │ [T9] LLM 调用 #2
     │               │               │               │ (生成最终回复)
     │               │               │               │──────────────>│
     │               │               │               │               │
     │               │               │               │     TTFT      │
     │               │               │               │<─ 2-6秒 ─────│
     │               │               │               │               │
     │<──────────────────────────────────────────────│  流式输出     │
     │               SSE 流         │               │<─ 3-10秒 ────│
     │               │               │               │               │
     │               │               │ [T10] 保存助手消息            │
     │               │               │──────┐        │               │
     │               │               │<─────┘ ~10ms  │               │
     │               │               │               │               │
     │               │               │ [T11] 记录配额               │
     │               │               │──────┐        │               │
     │               │               │<─────┘ ~5ms   │               │
     │               │               │               │               │
```

## 各阶段耗时分析

| 阶段 | 代码位置 | 预估耗时 | 备注 |
|------|----------|----------|------|
| T1 认证检查 | `get_optional_user` | 10ms | JWT 解码 |
| T2 配额检查 | `QuotaTracker.check` | 20ms | DB 查询 |
| T3 用户上下文 | `get_cached_profile_with_skill` | 5-200ms | 有缓存 5ms，无缓存 200ms |
| T4 会话检查 | `ensure_conversation_exists` | 10ms | DB 查询/插入 |
| T5 保存消息 | `save_message` | 10ms | DB 插入 |
| T6 构建 Prompt | `_build_system_prompt` | 200-500ms | 包含知识检索 |
| T7 LLM #1 | `llm.stream` | **3-9秒** | **主要瓶颈** |
| T8 工具执行 | `_execute_tool` | 10-50ms | 本地计算 |
| T9 LLM #2 | `llm.stream` | **5-16秒** | **主要瓶颈** |
| T10 保存消息 | `save_message` | 10ms | DB 插入 |
| T11 配额记录 | `QuotaTracker.record` | 5ms | DB 更新 |

## 瓶颈分析

```
总耗时 = T1-T5 (~60ms) + T6 (~350ms) + T7 (3-9s) + T8 (~30ms) + T9 (5-16s) + T10-T11 (~15ms)
       = 约 8-26 秒

LLM 调用占比: (T7 + T9) / 总耗时 = 85-95%
```

### 主要瓶颈

1. **LLM 调用 (85-95%)**
   - 首 token 延迟 (TTFT): 2-6 秒/次
   - 两轮调用 = 4-12 秒仅在等待首 token
   - 生成速度: 取决于输出长度

2. **System Prompt 过长**
   - 当前: ~4000 tokens
   - 包含: Skill 配置 + 知识 + 案例 + 用户数据
   - 每次都重新构建

3. **串行调用**
   - 知识检索和案例匹配是串行的
   - 可以并行优化

## 实测性能数据 (2026-01-18)

### 场景 1: 指定 skill=bazi + 简单问候
```
T3 用户上下文:    0ms   (缓存命中)
T4 确保会话:      6ms
T5 保存消息:      3ms
Prompt 构建:     39ms   (长度 1444 字符)
LLM #1 TTFT:   1308ms
LLM #1 总耗时: 5797ms
────────────────────────
总耗时:        5855ms = 5.9秒
```

### 场景 2: 指定 skill=bazi + 八字查询
```
T3 用户上下文:    0ms   (缓存命中)
T4 确保会话:      3ms
T5 保存消息:      1ms
Prompt 构建:      4ms   (缓存命中)
LLM #1 TTFT:   1099ms
LLM #1 总耗时: 3095ms
────────────────────────
总耗时:        3110ms = 3.1秒
```

### 场景 3: 不指定 skill (需要路由) ⚠️ 慢
```
T3 用户上下文:    0ms   (缓存命中)
T4 确保会话:      3ms
T5 保存消息:      3ms
Prompt 构建:      3ms   (长度 398，无 skill 配置)
LLM #1 TTFT:    783ms   ← 第1轮: 决定 skill
LLM #1 总耗时: 5134ms   (调用 use_skill 工具)
Tool use_skill:   0ms
LLM #2 TTFT:    815ms   ← 第2轮: 生成回复
LLM #2 总耗时: 5068ms
────────────────────────
总耗时:       10227ms = 10.2秒  ⚠️ 慢 3 倍
```

## 结论

| 场景 | 总耗时 | LLM 调用次数 | 瓶颈分析 |
|------|--------|--------------|----------|
| 指定 skill | 3-6秒 | 1次 | LLM TTFT + 生成 |
| 不指定 skill | **10-15秒** | 2次 | **多一轮 LLM 路由** |

**核心发现**:
- LLM 调用占总耗时 **99%+**
- 不指定 skill 会触发额外一轮 LLM 调用，耗时翻倍
- 前端已指定 skill 时性能正常（3秒左右）

## 优化建议

### 立即可做 (效果显著)

1. **前端始终指定 skill**
   - 当前前端 `useVibeChat` 已传递 `skill` 参数
   - 确保 `/chat` 页面正确传递 skill
   - 节省: 5-7秒

2. **规则路由替代 LLM 路由**
   - 用关键词匹配替代 `use_skill` 工具
   - 已有 `get_skill_triggers()` 函数可用
   - 节省: 3-8秒

### 中期优化

3. **精简 System Prompt**
   - 当前: 1444 字符 (bazi skill)
   - 知识和案例可以按需加载

4. **LLM Provider 优化**
   - DeepSeek TTFT: ~1秒
   - 可考虑更快的模型或 API

## 性能监控点 (已添加)

以下位置已添加 `[PERF]` 日志：
